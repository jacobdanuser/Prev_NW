diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..2aa7f164eb896acc1264e4d8491b1f4e6b7fc450
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,201 @@
+#!/usr/bin/env python3
+"""ATOM: Automated Technical Optimization and Maintenance.
+
+This utility helps reduce common technical issues in a project by:
+- fixing whitespace and newline hygiene
+- normalizing mixed line endings
+- validating Python syntax
+- producing a clear summary report
+
+It is intentionally conservative: it only edits text files and only applies
+safe formatting changes.
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Iterable
+
+SKIP_DIRS = {
+    ".git",
+    ".hg",
+    ".svn",
+    "__pycache__",
+    ".mypy_cache",
+    ".pytest_cache",
+    ".venv",
+    "venv",
+    "node_modules",
+    "dist",
+    "build",
+}
+
+TEXT_EXTENSIONS = {
+    ".py",
+    ".md",
+    ".txt",
+    ".json",
+    ".yaml",
+    ".yml",
+    ".toml",
+    ".ini",
+    ".cfg",
+    ".sh",
+    ".js",
+    ".ts",
+    ".css",
+    ".html",
+}
+
+
+@dataclass
+class FileResult:
+    path: Path
+    changed: bool = False
+    syntax_ok: bool = True
+    notes: list[str] | None = None
+
+    def __post_init__(self) -> None:
+        if self.notes is None:
+            self.notes = []
+
+
+@dataclass
+class Summary:
+    scanned: int = 0
+    changed: int = 0
+    syntax_errors: int = 0
+
+
+def is_probably_text(path: Path) -> bool:
+    if path.suffix.lower() in TEXT_EXTENSIONS:
+        return True
+    try:
+        sample = path.read_bytes()[:1024]
+    except OSError:
+        return False
+    return b"\x00" not in sample
+
+
+def iter_files(root: Path) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if path.is_dir():
+            continue
+        if any(part in SKIP_DIRS for part in path.parts):
+            continue
+        if is_probably_text(path):
+            yield path
+
+
+def normalize_text(content: str) -> tuple[str, list[str]]:
+    notes: list[str] = []
+    updated = content.replace("\r\n", "\n").replace("\r", "\n")
+    if updated != content:
+        notes.append("normalized line endings")
+
+    lines = [line.rstrip() for line in updated.split("\n")]
+    stripped = "\n".join(lines)
+    if stripped != updated:
+        notes.append("trimmed trailing whitespace")
+
+    if stripped and not stripped.endswith("\n"):
+        stripped += "\n"
+        notes.append("added final newline")
+
+    return stripped, notes
+
+
+def check_python_syntax(path: Path, content: str) -> tuple[bool, str | None]:
+    if path.suffix.lower() != ".py":
+        return True, None
+    try:
+        ast.parse(content, filename=str(path))
+        return True, None
+    except SyntaxError as exc:
+        return False, f"syntax error at line {exc.lineno}: {exc.msg}"
+
+
+def process_file(path: Path, write: bool) -> FileResult:
+    result = FileResult(path=path)
+    try:
+        original = path.read_text(encoding="utf-8")
+    except UnicodeDecodeError:
+        result.notes.append("skipped non-utf8 text")
+        return result
+    except OSError as exc:
+        result.notes.append(f"read error: {exc}")
+        return result
+
+    updated, notes = normalize_text(original)
+    result.notes.extend(notes)
+
+    syntax_ok, syntax_note = check_python_syntax(path, updated)
+    result.syntax_ok = syntax_ok
+    if syntax_note:
+        result.notes.append(syntax_note)
+
+    if write and updated != original:
+        path.write_text(updated, encoding="utf-8")
+        result.changed = True
+
+    return result
+
+
+def run(root: Path, write: bool, verbose: bool) -> int:
+    summary = Summary()
+
+    for path in iter_files(root):
+        summary.scanned += 1
+        result = process_file(path, write=write)
+
+        if result.changed:
+            summary.changed += 1
+
+        if not result.syntax_ok:
+            summary.syntax_errors += 1
+
+        if verbose and result.notes:
+            print(f"[{path}]")
+            for note in result.notes:
+                print(f"  - {note}")
+
+    print("\nATOM report")
+    print(f"  scanned files : {summary.scanned}")
+    print(f"  changed files : {summary.changed} {'(dry-run)' if not write else ''}")
+    print(f"  syntax errors : {summary.syntax_errors}")
+
+    return 1 if summary.syntax_errors else 0
+
+
+def parse_args() -> argparse.Namespace:
+    parser = argparse.ArgumentParser(
+        description="Fix common technical formatting issues and validate Python syntax."
+    )
+    parser.add_argument("path", nargs="?", default=".", help="root path to scan")
+    parser.add_argument(
+        "--apply",
+        action="store_true",
+        help="write safe fixes to disk (default is dry-run)",
+    )
+    parser.add_argument(
+        "--verbose",
+        action="store_true",
+        help="show per-file actions and findings",
+    )
+    return parser.parse_args()
+
+
+def main() -> int:
+    args = parse_args()
+    root = Path(args.path).resolve()
+    if not root.exists():
+        print(f"error: path does not exist: {root}")
+        return 2
+    return run(root, write=args.apply, verbose=args.verbose)
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/README.md b/README.md
index 4d7ccaa8ce6e61c69d6948882582873badef63da..56c43d46e1353196c0b3934cff0426eee31334be 100644
--- a/README.md
+++ b/README.md
@@ -344724,26 +344724,43 @@ class MetaphysicalPractitioner:
 
         # Check if capability is enabled
         if not capability.is_usable:
             return False, "Capability is disabled."
 
         # Check energy
         energy_cost = capability.base_power_level * 0.5
         if self.energy_pool < energy_cost:
             return False, f"Insufficient energy. Need {energy_cost:.1f}, have {self.energy_pool:.1f}"
 
         # Check consciousness
         if self.consciousness_level < 0.5:
             return False, "Consciousness level too low to maintain metaphysical connection."
 
         # Check all philosophical frameworks
         for framework in self.philosophical_frameworks:
             if not framework.evaluate_restriction(capability):
                 return False, f"Violates {type(framework).__name__}: {framework.get_restriction_reason()}"
 
         return True, "Capability can be used."
 
     def use_capability(self, capability: MetaphysicalCapability) -> Dict:
         """Attempt to use a capability. Returns result details."""
         can_use, reason = self.can_use_capability(capability)
         
-        result = {
\ No newline at end of file
+        result = {
+## ATOM utility
+
+`atom.py` is a small maintenance utility (**A**utomated **T**echnical **O**ptimization and **M**aintenance) that helps reduce common technical issues in a codebase.
+
+### What it does
+- Normalizes line endings to Unix style (`\n`)
+- Trims trailing whitespace
+- Ensures a final newline for text files
+- Checks Python files for syntax errors
+
+### Usage
+- Dry run (no file changes):
+  - `python atom.py --verbose`
+- Apply safe fixes:
+  - `python atom.py --apply --verbose`
+
+Exit code is non-zero if Python syntax errors are found.
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..2aa7f164eb896acc1264e4d8491b1f4e6b7fc450
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,201 @@
+#!/usr/bin/env python3
+"""ATOM: Automated Technical Optimization and Maintenance.
+
+This utility helps reduce common technical issues in a project by:
+- fixing whitespace and newline hygiene
+- normalizing mixed line endings
+- validating Python syntax
+- producing a clear summary report
+
+It is intentionally conservative: it only edits text files and only applies
+safe formatting changes.
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Iterable
+
+SKIP_DIRS = {
+    ".git",
+    ".hg",
+    ".svn",
+    "__pycache__",
+    ".mypy_cache",
+    ".pytest_cache",
+    ".venv",
+    "venv",
+    "node_modules",
+    "dist",
+    "build",
+}
+
+TEXT_EXTENSIONS = {
+    ".py",
+    ".md",
+    ".txt",
+    ".json",
+    ".yaml",
+    ".yml",
+    ".toml",
+    ".ini",
+    ".cfg",
+    ".sh",
+    ".js",
+    ".ts",
+    ".css",
+    ".html",
+}
+
+
+@dataclass
+class FileResult:
+    path: Path
+    changed: bool = False
+    syntax_ok: bool = True
+    notes: list[str] | None = None
+
+    def __post_init__(self) -> None:
+        if self.notes is None:
+            self.notes = []
+
+
+@dataclass
+class Summary:
+    scanned: int = 0
+    changed: int = 0
+    syntax_errors: int = 0
+
+
+def is_probably_text(path: Path) -> bool:
+    if path.suffix.lower() in TEXT_EXTENSIONS:
+        return True
+    try:
+        sample = path.read_bytes()[:1024]
+    except OSError:
+        return False
+    return b"\x00" not in sample
+
+
+def iter_files(root: Path) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if path.is_dir():
+            continue
+        if any(part in SKIP_DIRS for part in path.parts):
+            continue
+        if is_probably_text(path):
+            yield path
+
+
+def normalize_text(content: str) -> tuple[str, list[str]]:
+    notes: list[str] = []
+    updated = content.replace("\r\n", "\n").replace("\r", "\n")
+    if updated != content:
+        notes.append("normalized line endings")
+
+    lines = [line.rstrip() for line in updated.split("\n")]
+    stripped = "\n".join(lines)
+    if stripped != updated:
+        notes.append("trimmed trailing whitespace")
+
+    if stripped and not stripped.endswith("\n"):
+        stripped += "\n"
+        notes.append("added final newline")
+
+    return stripped, notes
+
+
+def check_python_syntax(path: Path, content: str) -> tuple[bool, str | None]:
+    if path.suffix.lower() != ".py":
+        return True, None
+    try:
+        ast.parse(content, filename=str(path))
+        return True, None
+    except SyntaxError as exc:
+        return False, f"syntax error at line {exc.lineno}: {exc.msg}"
+
+
+def process_file(path: Path, write: bool) -> FileResult:
+    result = FileResult(path=path)
+    try:
+        original = path.read_text(encoding="utf-8")
+    except UnicodeDecodeError:
+        result.notes.append("skipped non-utf8 text")
+        return result
+    except OSError as exc:
+        result.notes.append(f"read error: {exc}")
+        return result
+
+    updated, notes = normalize_text(original)
+    result.notes.extend(notes)
+
+    syntax_ok, syntax_note = check_python_syntax(path, updated)
+    result.syntax_ok = syntax_ok
+    if syntax_note:
+        result.notes.append(syntax_note)
+
+    if write and updated != original:
+        path.write_text(updated, encoding="utf-8")
+        result.changed = True
+
+    return result
+
+
+def run(root: Path, write: bool, verbose: bool) -> int:
+    summary = Summary()
+
+    for path in iter_files(root):
+        summary.scanned += 1
+        result = process_file(path, write=write)
+
+        if result.changed:
+            summary.changed += 1
+
+        if not result.syntax_ok:
+            summary.syntax_errors += 1
+
+        if verbose and result.notes:
+            print(f"[{path}]")
+            for note in result.notes:
+                print(f"  - {note}")
+
+    print("\nATOM report")
+    print(f"  scanned files : {summary.scanned}")
+    print(f"  changed files : {summary.changed} {'(dry-run)' if not write else ''}")
+    print(f"  syntax errors : {summary.syntax_errors}")
+
+    return 1 if summary.syntax_errors else 0
+
+
+def parse_args() -> argparse.Namespace:
+    parser = argparse.ArgumentParser(
+        description="Fix common technical formatting issues and validate Python syntax."
+    )
+    parser.add_argument("path", nargs="?", default=".", help="root path to scan")
+    parser.add_argument(
+        "--apply",
+        action="store_true",
+        help="write safe fixes to disk (default is dry-run)",
+    )
+    parser.add_argument(
+        "--verbose",
+        action="store_true",
+        help="show per-file actions and findings",
+    )
+    return parser.parse_args()
+
+
+def main() -> int:
+    args = parse_args()
+    root = Path(args.path).resolve()
+    if not root.exists():
+        print(f"error: path does not exist: {root}")
+        return 2
+    return run(root, write=args.apply, verbose=args.verbose)
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..38688953397ff57677449fcaa1fad06f0e5d2624
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,145 @@
+"""ATOM: A lightweight code cleaner for common technical issues.
+
+This module provides practical, safe fixes for common source-code mistakes:
+- Normalizes line endings and trailing whitespace.
+- Collapses accidental duplicate commas.
+- Normalizes repeated punctuation in comments and docs.
+- Optionally validates Python syntax and reports actionable diagnostics.
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+from dataclasses import dataclass
+from pathlib import Path
+from typing import List, Optional
+
+
+@dataclass
+class AtomReport:
+    """Result of cleaning and validating a source file."""
+
+    path: Path
+    changed: bool
+    syntax_ok: bool
+    syntax_error: Optional[str]
+    fixes_applied: List[str]
+
+
+class AtomCleaner:
+    """Apply safe text-level fixes and perform syntax validation."""
+
+    def __init__(self) -> None:
+        self._fixes: List[str] = []
+
+    def clean_text(self, text: str) -> str:
+        self._fixes.clear()
+
+        original = text
+
+        if "\r\n" in text or "\r" in text:
+            text = text.replace("\r\n", "\n").replace("\r", "\n")
+            self._fixes.append("normalized_line_endings")
+
+        cleaned_lines = []
+        had_trailing_spaces = False
+        for line in text.split("\n"):
+            stripped = line.rstrip()
+            if stripped != line:
+                had_trailing_spaces = True
+            cleaned_lines.append(stripped)
+        if had_trailing_spaces:
+            self._fixes.append("removed_trailing_whitespace")
+        text = "\n".join(cleaned_lines)
+
+        collapsed = text.replace(",,", ",")
+        while ",," in collapsed:
+            collapsed = collapsed.replace(",,", ",")
+        if collapsed != text:
+            self._fixes.append("collapsed_duplicate_commas")
+        text = collapsed
+
+        # Normalize accidental repeated punctuation in comments and doc-like lines.
+        normalized = []
+        punctuation_fixed = False
+        for line in text.split("\n"):
+            candidate = line
+            if line.lstrip().startswith("#") or '"""' in line or "'''" in line:
+                while ",," in candidate:
+                    candidate = candidate.replace(",,", ",")
+                while ".." in candidate:
+                    candidate = candidate.replace("..", ".")
+            if candidate != line:
+                punctuation_fixed = True
+            normalized.append(candidate)
+        if punctuation_fixed:
+            self._fixes.append("normalized_comment_punctuation")
+        text = "\n".join(normalized)
+
+        # Ensure exactly one trailing newline for consistency.
+        if text and not text.endswith("\n"):
+            text = text + "\n"
+            self._fixes.append("added_trailing_newline")
+
+        if text == original:
+            self._fixes.append("no_changes_needed")
+
+        return text
+
+    def validate_python(self, text: str) -> tuple[bool, Optional[str]]:
+        try:
+            ast.parse(text)
+            return True, None
+        except SyntaxError as exc:
+            message = f"SyntaxError at line {exc.lineno}, column {exc.offset}: {exc.msg}"
+            return False, message
+
+    def process_file(self, path: Path, write: bool = True) -> AtomReport:
+        source = path.read_text(encoding="utf-8")
+        cleaned = self.clean_text(source)
+        syntax_ok, syntax_error = self.validate_python(cleaned)
+
+        changed = cleaned != source
+        if write and changed:
+            path.write_text(cleaned, encoding="utf-8")
+
+        return AtomReport(
+            path=path,
+            changed=changed,
+            syntax_ok=syntax_ok,
+            syntax_error=syntax_error,
+            fixes_applied=list(self._fixes),
+        )
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="ATOM code cleaner")
+    parser.add_argument("file", type=Path, help="Python source file to clean")
+    parser.add_argument(
+        "--check",
+        action="store_true",
+        help="Do not modify file; only report issues",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    cleaner = AtomCleaner()
+    report = cleaner.process_file(args.file, write=not args.check)
+
+    print(f"File: {report.path}")
+    print(f"Changed: {report.changed}")
+    print(f"Fixes: {', '.join(report.fixes_applied)}")
+    print(f"Syntax OK: {report.syntax_ok}")
+    if report.syntax_error:
+        print(report.syntax_error)
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/test_atom.py b/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..b6dc87780379c28471be22b083572165cdc28911
--- /dev/null
+++ b/test_atom.py
@@ -0,0 +1,25 @@
+from pathlib import Path
+
+from atom import AtomCleaner
+
+
+def test_clean_text_normalizes_common_issues(tmp_path: Path) -> None:
+    dirty = "x = 1,,2  \r\n# comment,, with dots..\r\n"
+    cleaner = AtomCleaner()
+
+    cleaned = cleaner.clean_text(dirty)
+
+    assert ",," not in cleaned
+    assert "\r" not in cleaned
+    assert "comment, with dots." in cleaned
+
+
+def test_process_file_reports_syntax_error(tmp_path: Path) -> None:
+    target = tmp_path / "broken.py"
+    target.write_text("def bad(:\n    pass\n", encoding="utf-8")
+
+    cleaner = AtomCleaner()
+    report = cleaner.process_file(target, write=False)
+
+    assert not report.syntax_ok
+    assert report.syntax_error is not None
diff --git a/atom_cleaner.py b/atom_cleaner.py
new file mode 100644
index 0000000000000000000000000000000000000000..d67d2ca3c28d6dfdda7e444f0a14521a48c98fa6
--- /dev/null
+++ b/atom_cleaner.py
@@ -0,0 +1,114 @@
+"""Atom Cleaner: normalize messy technical/error-heavy text into clear plain language.
+
+This utility is designed for "Atom" style note cleanup workflows where incoming text
+contains mixed syntax fragments, stack traces, and overly technical jargon.
+"""
+
+from __future__ import annotations
+
+import re
+from dataclasses import dataclass
+from typing import Iterable
+
+
+DEFAULT_TECHNICAL_TERMS = {
+    "syntax error",
+    "stack trace",
+    "traceback",
+    "exception",
+    "segmentation fault",
+    "null pointer",
+    "runtime error",
+    "compile error",
+    "undefined reference",
+    "debug",
+    "hotfix",
+    "patch",
+    "dependency",
+    "deprecation",
+}
+
+COMMON_REPLACEMENTS = {
+    "descripting": "descriptive",
+    "teh": "the",
+    "wierd": "weird",
+    " occured ": " occurred ",
+}
+
+
+@dataclass(frozen=True)
+class CleanupConfig:
+    """Configuration for how aggressively text should be cleaned."""
+
+    remove_technical_terms: bool = True
+    remove_error_lines: bool = True
+    collapse_repeated_punctuation: bool = True
+    normalize_spacing: bool = True
+
+
+class AtomCleaner:
+    """Cleaner that removes bug/error-heavy noise and over-technical language."""
+
+    def __init__(self, config: CleanupConfig | None = None, technical_terms: Iterable[str] | None = None) -> None:
+        self.config = config or CleanupConfig()
+        self.technical_terms = {t.lower().strip() for t in (technical_terms or DEFAULT_TECHNICAL_TERMS)}
+
+    def clean(self, text: str) -> str:
+        """Return cleaned text in plain language."""
+        cleaned = text or ""
+
+        for old, new in COMMON_REPLACEMENTS.items():
+            cleaned = cleaned.replace(old, new)
+
+        if self.config.remove_error_lines:
+            cleaned = self._remove_error_lines(cleaned)
+
+        if self.config.remove_technical_terms:
+            cleaned = self._remove_technical_terms(cleaned)
+
+        if self.config.collapse_repeated_punctuation:
+            cleaned = re.sub(r"([!?.,])\1{1,}", r"\1", cleaned)
+            cleaned = re.sub(r"([!?.,])\s*([!?.,])+", r"\1", cleaned)
+
+        if self.config.normalize_spacing:
+            cleaned = re.sub(r"[ \t]+", " ", cleaned)
+            cleaned = re.sub(r"\s+([!?.,])", r"\1", cleaned)
+            cleaned = re.sub(r"\n{3,}", "\n\n", cleaned)
+            cleaned = "\n".join(line.strip() for line in cleaned.splitlines())
+            cleaned = cleaned.strip()
+
+        return cleaned
+
+    def _remove_error_lines(self, text: str) -> str:
+        patterns = [
+            r"^\s*traceback \(most recent call last\):",
+            r"^\s*file\s+\".+?\",\s*line\s+\d+",
+            r"^\s*[a-z_]*error:\s",
+            r"^\s*at\s+.+?:\d+",
+        ]
+        regex = re.compile("|".join(patterns), flags=re.IGNORECASE)
+        kept_lines = [line for line in text.splitlines() if not regex.search(line)]
+        return "\n".join(kept_lines)
+
+    def _remove_technical_terms(self, text: str) -> str:
+        cleaned = text
+        for term in sorted(self.technical_terms, key=len, reverse=True):
+            cleaned = re.sub(rf"\b{re.escape(term)}\b", " ", cleaned, flags=re.IGNORECASE)
+        return cleaned
+
+
+def clean_for_atom(text: str) -> str:
+    """Convenience helper for single-call usage."""
+    return AtomCleaner().clean(text)
+
+
+if __name__ == "__main__":
+    import argparse
+    import sys
+
+    parser = argparse.ArgumentParser(description="Clean technical/error-heavy text for plain language output.")
+    parser.add_argument("input", nargs="?", help="Input text. If omitted, stdin is used.")
+    args = parser.parse_args()
+
+    source = args.input if args.input is not None else sys.stdin.read()
+    print(clean_for_atom(source))
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..63691e8424dcdd209b65f9c596173227dcdfe9b3
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,152 @@
+"""ATOM: Automated Technical Optimization Module.
+
+This module provides practical, dependency-free utilities to reduce common
+technical quality problems in text and Python code:
+- cleanup of wording/description noise
+- formatting normalization
+- syntax validation for Python snippets/files
+
+It cannot *guarantee* removal of every possible bug, but it provides a safe
+baseline that catches and fixes many frequent issues.
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import re
+from dataclasses import dataclass
+from pathlib import Path
+from typing import List, Sequence
+
+
+@dataclass(frozen=True)
+class Issue:
+    """Represents a detected issue."""
+
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+class AtomRepairEngine:
+    """A light-weight fixer and validator for text and Python code."""
+
+    _COMMON_TEXT_FIXES = {
+        "descripting": "descriptive",
+        "teh": "the",
+        "recieve": "receive",
+        "adn": "and",
+        "  ": " ",
+    }
+
+    def clean_description(self, text: str) -> str:
+        """Repair common spelling/punctuation noise in descriptive text."""
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+
+        for wrong, right in self._COMMON_TEXT_FIXES.items():
+            cleaned = cleaned.replace(wrong, right)
+
+        cleaned = re.sub(r",{2,}", ",", cleaned)
+        cleaned = re.sub(r"\.{2,}", ".", cleaned)
+        cleaned = re.sub(r"\s+", " ", cleaned).strip()
+        return cleaned
+
+    def clean_python_formatting(self, code: str) -> str:
+        """Apply safe formatting cleanup that does not alter behavior."""
+        code = code.replace("\r\n", "\n").replace("\r", "\n")
+        lines = [line.rstrip().replace("\t", "    ") for line in code.split("\n")]
+        normalized = "\n".join(lines).rstrip() + "\n"
+        return normalized
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        """Return syntax issues found in Python code."""
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [
+                Issue(
+                    kind="syntax",
+                    message=exc.msg,
+                    line=exc.lineno,
+                    column=exc.offset,
+                )
+            ]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue]]:
+        """Clean and validate Python code.
+
+        Returns repaired code and list of remaining issues.
+        """
+        repaired = self.clean_python_formatting(code)
+        issues = self.validate_python_syntax(repaired)
+        return repaired, issues
+
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM quality fixer")
+    parser.add_argument("path", type=Path, help="Path to a text or .py file")
+    parser.add_argument(
+        "--mode",
+        choices=["auto", "text", "python"],
+        default="auto",
+        help="Fix mode (auto detects by extension)",
+    )
+    parser.add_argument(
+        "--check-only",
+        action="store_true",
+        help="Do not write changes, only report issues",
+    )
+
+    args = parser.parse_args(argv)
+    engine = AtomRepairEngine()
+
+    source = _read_file(args.path)
+    mode = args.mode
+    if mode == "auto":
+        mode = "python" if args.path.suffix == ".py" else "text"
+
+    if mode == "text":
+        fixed = engine.clean_description(source)
+        issues: List[Issue] = []
+    else:
+        fixed, issues = engine.repair_python_code(source)
+
+    if args.check_only:
+        if issues:
+            for issue in issues:
+                print(f"[{issue.kind}] line={issue.line} col={issue.column}: {issue.message}")
+            return 1
+        print("No issues detected.")
+        return 0
+
+    if fixed != source:
+        _write_file(args.path, fixed)
+        print(f"Updated: {args.path}")
+    else:
+        print("No changes needed.")
+
+    if issues:
+        for issue in issues:
+            print(f"[{issue.kind}] line={issue.line} col={issue.column}: {issue.message}")
+        return 1
+
+    print("ATOM completed with no remaining syntax issues.")
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..bab58939174b258645afe53002ab69344e66d577
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,28 @@
+import unittest
+
+from atom import AtomRepairEngine
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def setUp(self):
+        self.engine = AtomRepairEngine()
+
+    def test_clean_description_repairs_common_noise(self):
+        raw = "This is teh descripting text,, with   extra   spaces..."
+        cleaned = self.engine.clean_description(raw)
+        self.assertEqual(cleaned, "This is the descriptive text, with extra spaces.")
+
+    def test_repair_python_code_normalizes_tabs_and_detects_syntax(self):
+        raw = "def x():\n\treturn 1\n"
+        repaired, issues = self.engine.repair_python_code(raw)
+        self.assertIn("    return 1", repaired)
+        self.assertEqual(issues, [])
+
+    def test_validate_python_syntax_reports_error(self):
+        issues = self.engine.validate_python_syntax("def bad(:\n    pass\n")
+        self.assertEqual(len(issues), 1)
+        self.assertEqual(issues[0].kind, "syntax")
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..f9945ed871ecf429113d2fa4faf431cc6253f90e
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,258 @@
+"""ATOM: Automated Technical Optimization Module.
+
+A standalone quality and migration utility focused on two goals:
+1) Improve text/Python technical hygiene (formatting + syntax checks).
+2) Remove Atom editor integration references (e.g. Atom-Hydrogen/Atom-Carbon)
+   from files in a language-agnostic way.
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import re
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+DEFAULT_FORBIDDEN_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),
+    re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class Issue:
+    """Represents a detected issue."""
+
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    """Outcome of processing a single file."""
+
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+
+
+class AtomRepairEngine:
+    """Standalone fixer and validator for text and Python code."""
+
+    _COMMON_TEXT_FIXES = {
+        "descripting": "descriptive",
+        "teh": "the",
+        "recieve": "receive",
+        "adn": "and",
+    }
+
+    def __init__(self, forbidden_patterns: Iterable[re.Pattern[str]] | None = None):
+        self.forbidden_patterns = tuple(forbidden_patterns or DEFAULT_FORBIDDEN_PATTERNS)
+
+    def clean_description(self, text: str) -> str:
+        """Repair common spelling/punctuation noise in descriptive text."""
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+
+        for wrong, right in self._COMMON_TEXT_FIXES.items():
+            cleaned = cleaned.replace(wrong, right)
+
+        lines = [self._normalize_line(line) for line in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        line = re.sub(r"\s+", " ", line).strip()
+        return line
+
+    def strip_forbidden_atom_references(self, text: str) -> tuple[str, int]:
+        """Remove references to Atom-Hydrogen/Atom-Carbon related terms."""
+        updated = text
+        total_removed = 0
+
+        for pattern in self.forbidden_patterns:
+            updated, count = pattern.subn("", updated)
+            total_removed += count
+
+        normalized_lines: list[str] = []
+        for line in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n"):
+            # Preserve indentation while normalizing extra interior spaces.
+            indent_match = re.match(r"^[ \t]*", line)
+            indent = indent_match.group(0) if indent_match else ""
+            content = line[len(indent):]
+            content = re.sub(r"[ \t]{2,}", " ", content).strip()
+            normalized_lines.append(indent + content if content else "")
+
+        updated = "\n".join(normalized_lines)
+        updated = re.sub(r"\n{3,}", "\n\n", updated)
+        return updated.rstrip() + "\n", total_removed
+
+    def clean_python_formatting(self, code: str) -> str:
+        """Apply safe formatting cleanup that does not alter behavior."""
+        code = code.replace("\r\n", "\n").replace("\r", "\n")
+        lines = [line.rstrip().replace("\t", "    ") for line in code.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        """Return syntax issues found in Python code."""
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [
+                Issue(
+                    kind="syntax",
+                    message=exc.msg,
+                    line=exc.lineno,
+                    column=exc.offset,
+                )
+            ]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        """Clean, strip forbidden references, and validate Python code."""
+        repaired = self.clean_python_formatting(code)
+        repaired, removed = self.strip_forbidden_atom_references(repaired)
+        issues = self.validate_python_syntax(repaired)
+        return repaired, issues, removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        """Clean descriptive text and strip forbidden references."""
+        cleaned = self.clean_description(text)
+        return self.strip_forbidden_atom_references(cleaned)
+
+
+TEXT_SUFFIXES = {
+    ".txt",
+    ".md",
+    ".rst",
+    ".json",
+    ".yaml",
+    ".yml",
+    ".toml",
+    ".ini",
+    ".cfg",
+    ".js",
+    ".ts",
+    ".jsx",
+    ".tsx",
+    ".java",
+    ".c",
+    ".cpp",
+    ".h",
+    ".hpp",
+    ".cs",
+    ".rb",
+    ".go",
+    ".rs",
+    ".swift",
+    ".php",
+    ".html",
+    ".css",
+    ".scss",
+    ".xml",
+}
+
+
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    if requested_mode != "auto":
+        return requested_mode
+    if path.suffix == ".py":
+        return "python"
+    return "text"
+
+
+def _iter_target_files(root: Path, include: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts):
+            continue
+        if not path.is_file():
+            continue
+        if include and not fnmatch.fnmatch(str(path.relative_to(root)), include):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(engine: AtomRepairEngine, path: Path, mode: str, check_only: bool) -> FileResult:
+    source = _read_file(path)
+    detected_mode = _detect_mode(path, mode)
+
+    if detected_mode == "python":
+        fixed, issues, removed = engine.repair_python_code(source)
+    else:
+        fixed, removed = engine.repair_text(source)
+        issues = []
+
+    changed = fixed != source
+    if changed and not check_only:
+        _write_file(path, fixed)
+
+    return FileResult(path=path, changed=changed, removed_references=removed, issues=tuple(issues))
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path, help="File or directory to process")
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--check-only", action="store_true", help="Do not write changes")
+    parser.add_argument(
+        "--include",
+        default="*",
+        help="Glob for relative file paths when path is a directory (default: '*')",
+    )
+
+    args = parser.parse_args(argv)
+    engine = AtomRepairEngine()
+
+    results: list[FileResult] = []
+    if args.path.is_file():
+        results.append(process_file(engine, args.path, args.mode, args.check_only))
+    else:
+        for file_path in _iter_target_files(args.path, args.include):
+            results.append(process_file(engine, file_path, args.mode, args.check_only))
+
+    changed_count = sum(1 for result in results if result.changed)
+    removed_count = sum(result.removed_references for result in results)
+    issue_count = sum(len(result.issues) for result in results)
+
+    for result in results:
+        if result.changed:
+            status = "would update" if args.check_only else "updated"
+            print(f"{status}: {result.path}")
+        if result.removed_references:
+            print(f"removed {result.removed_references} Atom-reference(s): {result.path}")
+        for issue in result.issues:
+            print(f"[{issue.kind}] {result.path}:{issue.line}:{issue.column} {issue.message}")
+
+    print(
+        "Summary: "
+        f"files={len(results)} changed={changed_count} "
+        f"atom_refs_removed={removed_count} issues={issue_count}"
+    )
+
+    if issue_count:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..b06564914023a92bdecbad9c7ac5c567c257a5e4
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,50 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, process_file
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def setUp(self):
+        self.engine = AtomRepairEngine()
+
+    def test_clean_description_repairs_common_noise(self):
+        raw = "This is teh descripting text,, with   extra   spaces..."
+        cleaned = self.engine.clean_description(raw)
+        self.assertEqual(cleaned, "This is the descriptive text, with extra spaces.\n")
+
+    def test_repair_python_code_normalizes_tabs_and_detects_syntax(self):
+        raw = "def x():\n\treturn 1\n"
+        repaired, issues, removed = self.engine.repair_python_code(raw)
+        self.assertIn("    return 1", repaired)
+        self.assertEqual(issues, [])
+        self.assertEqual(removed, 0)
+
+    def test_validate_python_syntax_reports_error(self):
+        issues = self.engine.validate_python_syntax("def bad(:\n    pass\n")
+        self.assertEqual(len(issues), 1)
+        self.assertEqual(issues[0].kind, "syntax")
+
+    def test_strip_atom_hydrogen_and_carbon_references(self):
+        raw = "Use Atom-Hydrogen and atom carbon plugins."
+        cleaned, removed = self.engine.strip_forbidden_atom_references(raw)
+        self.assertEqual(removed, 2)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("atom carbon", cleaned.lower())
+
+    def test_process_file_directory_safe_for_python(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            path = Path(tmp) / "sample.py"
+            path.write_text("# Atom-Carbon\ndef ok():\n\treturn 1\n", encoding="utf-8")
+
+            result = process_file(self.engine, path, mode="auto", check_only=False)
+            rewritten = path.read_text(encoding="utf-8")
+
+            self.assertTrue(result.changed)
+            self.assertGreaterEqual(result.removed_references, 1)
+            self.assertIn("    return 1", rewritten)
+
+
+if __name__ == "__main__":
+    unittest.main()
node .\atom_care.js --report
node .\atom_care.js --clean
node .\atom_care.js --audit
node .\atom_care.js --disable-risky
node .\atom_care.js --safe-mode
#!/usr/bin/env node
/**
 * atom_care.js
 * A gentle, reversible ‚Äúcare package‚Äù for Atom:
 * - backups
 * - cache cleanup
 * - package audit + risky disable list
 * - safe mode launch
 *
 * Designed for Windows but should mostly work elsewhere.
 */

const fs = require("fs");
const path = require("path");
const os = require("os");
const child = require("child_process");

const argv = new Set(process.argv.slice(2));

const HOME = os.homedir();
const ATOM_HOME =
  process.env.ATOM_HOME ||
  (process.platform === "win32"
    ? path.join(HOME, ".atom")
    : path.join(HOME, ".atom"));

const ATOM_APPDATA =
  process.platform === "win32"
    ? path.join(process.env.LOCALAPPDATA || path.join(HOME, "AppData", "Local"), "atom")
    : null;

const nowStamp = new Date().toISOString().replace(/[:.]/g, "-");
const BACKUP_DIR = path.join(ATOM_HOME, `atom-care-backup-${nowStamp}`);

function log(msg) {
  process.stdout.write(msg + "\n");
}

function exists(p) {
  try { fs.accessSync(p, fs.constants.F_OK); return true; } catch { return false; }
}

function mkdirp(p) {
  fs.mkdirSync(p, { recursive: true });
}

function safeCopyDir(src, dst) {
  mkdirp(dst);
  for (const entry of fs.readdirSync(src, { withFileTypes: true })) {
    const s = path.join(src, entry.name);
    const d = path.join(dst, entry.name);
    if (entry.isDirectory()) safeCopyDir(s, d);
    else if (entry.isFile()) fs.copyFileSync(s, d);
  }
}

function safeRemoveDir(dir) {
  // Remove directory if exists, but never touch outside Atom directories
  if (!exists(dir)) return;
  fs.rmSync(dir, { recursive: true, force: true });
}

function run(cmd, args, opts = {}) {
  try {
    const out = child.spawnSync(cmd, args, { encoding: "utf8", shell: false, ...opts });
    return { ok: out.status === 0, stdout: out.stdout || "", stderr: out.stderr || "", status: out.status };
  } catch (e) {
    return { ok: false, stdout: "", stderr: String(e), status: -1 };
  }
}

function findApm() {
  // apm is usually on PATH if Atom installed; also often in Atom resources
  const candidates = [];

  if (process.platform === "win32") {
    candidates.push("apm.cmd", "apm");
    // Common install paths
    const programFiles = process.env.ProgramFiles || "C:\\Program Files";
    const programFilesX86 = process.env["ProgramFiles(x86)"] || "C:\\Program Files (x86)";
    candidates.push(
      path.join(programFiles, "Atom", "resources", "app", "apm", "bin", "apm.cmd"),
      path.join(programFilesX86, "Atom", "resources", "app", "apm", "bin", "apm.cmd")
    );
  } else {
    candidates.push("apm");
  }

  for (const c of candidates) {
    if (c.includes(path.sep)) {
      if (exists(c)) return c;
    } else {
      const r = run(c, ["--version"]);
      if (r.ok) return c;
    }
  }
  return null;
}

function readPackagesList() {
  const apm = findApm();
  if (!apm) return { apm: null, packages: [], note: "apm not found; package audit limited." };

  const r = run(apm, ["list", "--installed", "--bare"]);
  if (!r.ok) return { apm, packages: [], note: "apm list failed; package audit limited." };

  // lines like: package@1.2.3
  const packages = r.stdout
    .split(/\r?\n/)
    .map((l) => l.trim())
    .filter(Boolean)
    .map((l) => {
      const [name, version] = l.split("@");
      return { name, version: version || "" };
    });

  return { apm, packages, note: "" };
}

function atomConfigPath() {
  // Atom config: config.cson (classic)
  const p = path.join(ATOM_HOME, "config.cson");
  return exists(p) ? p : null;
}

function parseDisabledPackagesFromConfig(configText) {
  // Very small heuristic: looks for disabledPackages: [ ... ] in CSON-ish text.
  const disabled = new Set();
  const m = configText.match(/disabledPackages\s*:\s*\[([\s\S]*?)\]/m);
  if (!m) return disabled;
  const body = m[1];
  // match "name" entries
  const re = /["']([^"']+)["']/g;
  let mm;
  while ((mm = re.exec(body))) disabled.add(mm[1]);
  return disabled;
}

function upsertDisabledPackagesInConfig(configText, toDisable) {
  // If disabledPackages exists, append entries; else create under "*": root or top-level.
  // Keep it simple and safe: if we can‚Äôt confidently edit, we‚Äôll write a separate override file.

  const m = configText.match(/disabledPackages\s*:\s*\[([\s\S]*?)\]/m);
  const list = Array.from(toDisable).sort();

  if (m) {
    const existing = parseDisabledPackagesFromConfig(configText);
    for (const p of list) existing.add(p);

    const replacement =
      `disabledPackages: [\n` +
      Array.from(existing).sort().map((p) => `  "${p}"`).join("\n") +
      `\n]`;

    return configText.replace(/disabledPackages\s*:\s*\[[\s\S]*?\]/m, replacement);
  }

  // No disabledPackages found ‚Äî append a safe block at end
  const block =
    `\n\n# Added by atom_care.js (${new Date().toISOString()})\n` +
    `disabledPackages: [\n` +
    list.map((p) => `  "${p}"`).join("\n") +
    `\n]\n`;

  return configText + block;
}

function backupAtomHome() {
  if (!exists(ATOM_HOME)) throw new Error(`Atom home not found: ${ATOM_HOME}`);
  mkdirp(BACKUP_DIR);
  safeCopyDir(ATOM_HOME, BACKUP_DIR);
  log(`‚úÖ Backup created: ${BACKUP_DIR}`);
}

function cleanCaches() {
  // These are common ‚Äújunk / corruption / performance drag‚Äù locations.
  const targets = [];

  // Atom home caches
  targets.push(path.join(ATOM_HOME, "compile-cache"));
  targets.push(path.join(ATOM_HOME, "storage"));
  targets.push(path.join(ATOM_HOME, "blob-store"));
  targets.push(path.join(ATOM_HOME, ".apm", ".cache")); // sometimes exists

  // Windows local app data cache
  if (ATOM_APPDATA) {
    targets.push(path.join(ATOM_APPDATA, "Cache"));
    targets.push(path.join(ATOM_APPDATA, "Code Cache"));
    targets.push(path.join(ATOM_APPDATA, "GPUCache"));
    targets.push(path.join(ATOM_APPDATA, "DawnCache"));
    targets.push(path.join(ATOM_APPDATA, "Local Storage"));
    targets.push(path.join(ATOM_APPDATA, "Session Storage"));
  }

  let removed = 0;
  for (const t of targets) {
    if (exists(t)) {
      safeRemoveDir(t);
      removed++;
      log(`üßº Removed cache dir: ${t}`);
    }
  }
  if (removed === 0) log("‚ÑπÔ∏è No known cache directories found to remove.");
}

function riskyPackageHeuristics(pkgName) {
  // Not ‚Äúauthoritative‚Äù‚Äîjust practical heuristics for stability/perf/security.
  // You can adjust this list.
  const riskyByPattern = [
    /minimap/i,
    /linter/i,
    /autocomplete/i,
    /ide-/i,
    /languageclient/i,
    /teletype/i,
    /platformio/i,
    /atom-beautify/i,
    /file-icons/i,
    /git-plus/i,
    /terminal/i
  ];

  const riskyExact = new Set([
    "teletype",
    "atom-ide-ui",
    "ide-typescript",
    "atom-typescript",
    "minimap",
    "minimap-highlight-selected",
    "minimap-find-and-replace",
    "platformio-ide-terminal",
    "languageclient",
    "linter",
    "linter-ui-default",
    "busy-signal"
  ]);

  if (riskyExact.has(pkgName)) return true;
  return riskyByPattern.some((re) => re.test(pkgName));
}

function auditPackages() {
  const { apm, packages, note } = readPackagesList();
  if (note) log(`‚ÑπÔ∏è ${note}`);
  if (!packages.length) {
    log("No packages detected (or apm unavailable).");
    return { packages: [], risky: [] };
  }

  const risky = packages.filter((p) => riskyPackageHeuristics(p.name));
  log(`üì¶ Installed packages: ${packages.length}`);
  log(`‚ö†Ô∏è Potentially heavy/risky packages (heuristic): ${risky.length}`);
  for (const p of risky) log(`  - ${p.name}@${p.version}`);

  if (apm) log(`(apm: ${apm})`);
  return { packages, risky };
}

function disableRiskyPackages() {
  const cfgPath = atomConfigPath();
  if (!cfgPath) {
    log("‚ùå Could not find config.cson in Atom home. Aborting disable step.");
    return;
  }

  const cfg = fs.readFileSync(cfgPath, "utf8");
  const currentDisabled = parseDisabledPackagesFromConfig(cfg);

  const { risky } = auditPackages();
  const toDisable = new Set(risky.map((p) => p.name));

  // Don‚Äôt disable anything already disabled; but keep it harmless.
  for (const p of currentDisabled) toDisable.add(p);

  const updated = upsertDisabledPackagesInConfig(cfg, toDisable);
  fs.writeFileSync(cfgPath, updated, "utf8");
  log(`‚úÖ Updated disabledPackages in: ${cfgPath}`);
  log(`‚ÑπÔ∏è Disabled count now: ${toDisable.size}`);
}

function findAtomExecutable() {
  if (process.platform !== "win32") return "atom";
  const candidates = [];
  const programFiles = process.env.ProgramFiles || "C:\\Program Files";
  const programFilesX86 = process.env["ProgramFiles(x86)"] || "C:\\Program Files (x86)";
  candidates.push(
    path.join(programFiles, "Atom", "atom.exe"),
    path.join(programFilesX86, "Atom", "atom.exe")
  );
  for (const c of candidates) if (exists(c)) return c;
  return "atom.exe"; // rely on PATH
}

function safeModeLaunch() {
  const atom = findAtomExecutable();
  log("üöë Launching Atom in SAFE MODE (no packages)...");
  // Atom flags: --safe, also --clear-window-state can help; keep it safe and reversible.
  const childProc = child.spawn(atom, ["--safe"], { stdio: "inherit", detached: true });
  childProc.unref();
  log("‚úÖ Atom launched (safe mode). Close it when done testing.");
}

function report() {
  log("=== Atom Care Report ===");
  log(`Atom home: ${ATOM_HOME}`);
  log(`Atom local app data: ${ATOM_APPDATA || "(n/a)"}`);
  log(`Config path: ${atomConfigPath() || "(missing)"}`);
  const apm = findApm();
  log(`apm: ${apm || "(not found)"}`);

  // Disk usage snapshot (rough)
  try {
    const sizes = [];
    if (exists(ATOM_HOME)) sizes.push({ name: "ATOM_HOME", bytes: dirSize(ATOM_HOME) });
    if (ATOM_APPDATA && exists(ATOM_APPDATA)) sizes.push({ name: "ATOM_APPDATA", bytes: dirSize(ATOM_APPDATA) });
    for (const s of sizes) log(`Size ${s.name}: ${(s.bytes / (1024 * 1024)).toFixed(1)} MB`);
  } catch {
    log("‚ÑπÔ∏è Size snapshot skipped (permissions/locked files).");
  }

  auditPackages();
  log("=== End Report ===");
}

function dirSize(dir) {
  let total = 0;
  for (const entry of fs.readdirSync(dir, { withFileTypes: true })) {
    const p = path.join(dir, entry.name);
    if (entry.isDirectory()) total += dirSize(p);
    else if (entry.isFile()) total += fs.statSync(p).size;
  }
  return total;
}

// ---------------------- Main ----------------------

(function main() {
  try {
    if (!exists(ATOM_HOME)) {
      log(`‚ùå Atom home not found at: ${ATOM_HOME}`);
      log("If Atom uses a custom ATOM_HOME, set it and re-run.");
      process.exit(1);
    }

    const doAnything =
      argv.has("--report") ||
      argv.has("--clean") ||
      argv.has("--audit") ||
      argv.has("--disable-risky") ||
      argv.has("--safe-mode") ||
      argv.has("--all");

    if (!doAnything) {
      log("Atom Care Toolkit");
      log("Usage:");
      log("  node atom_care.js --report");
      log("  node atom_care.js --clean");
      log("  node atom_care.js --audit");
      log("  node atom_care.js --disable-risky");
      log("  node atom_care.js --safe-mode");
      log("  node atom_care.js --all");
      process.exit(0);
    }

    if (argv.has("--all")) {
      backupAtomHome();
      report();
      cleanCaches();
      disableRiskyPackages();
      log("‚úÖ Done. Next: launch Atom and validate. Use --safe-mode if issues persist.");
      process.exit(0);
    }

    if (argv.has("--report")) report();
    if (argv.has("--audit")) auditPackages();

    if (argv.has("--clean")) {
      backupAtomHome();
      cleanCaches();
      log("‚úÖ Clean complete. Launch Atom to rebuild caches.");
    }

    if (argv.has("--disable-risky")) {
      backupAtomHome();
      disableRiskyPackages();
      log("‚úÖ Package disable complete. Launch Atom to test stability/performance.");
    }

    if (argv.has("--safe-mode")) safeModeLaunch();
  } catch (e) {
    log(`\nFATAL: ${e && e.message ? e.message : String(e)}`);
    log("If something went wrong, restore from the backup folder created in ~/.atom.");
    process.exit(1);
  }
})();
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..e523b9d377eda6c1af80683bd8534891b8ede29a
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,254 @@
+"""ATOM: Automated Technical Optimization Module.
+
+A standalone quality and migration utility focused on two goals:
+1) Improve text/Python technical hygiene (formatting + syntax checks).
+2) Remove Atom editor integration references (e.g. Atom-Hydrogen/Atom-Carbon)
+   from files in a language-agnostic way.
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import re
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+DEFAULT_FORBIDDEN_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),
+    re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class Issue:
+    """Represents a detected issue."""
+
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    """Outcome of processing a single file."""
+
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+
+
+class AtomRepairEngine:
+    """Standalone fixer and validator for text and Python code."""
+
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        forbidden_patterns: Iterable[re.Pattern[str]] | None = None,
+        *,
+        strip_atom_references: bool = True,
+    ):
+        self.forbidden_patterns = tuple(forbidden_patterns or DEFAULT_FORBIDDEN_PATTERNS)
+        self.strip_atom_references = strip_atom_references
+
+    def clean_description(self, text: str) -> str:
+        """Repair common spelling/punctuation noise in descriptive text."""
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+
+        for wrong_pattern, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong_pattern.sub(right, cleaned)
+
+        lines = [self._normalize_line(line) for line in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        line = re.sub(r"\s+", " ", line).strip()
+        return line
+
+    def strip_forbidden_atom_references(self, text: str) -> tuple[str, int]:
+        """Remove references to Atom-Hydrogen/Atom-Carbon related terms."""
+        if not self.strip_atom_references:
+            return text, 0
+
+        updated = text
+        total_removed = 0
+
+        for pattern in self.forbidden_patterns:
+            updated, count = pattern.subn("", updated)
+            total_removed += count
+
+        normalized_lines: list[str] = []
+        for line in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n"):
+            indent_match = re.match(r"^[ \t]*", line)
+            indent = indent_match.group(0) if indent_match else ""
+            content = line[len(indent):]
+            content = re.sub(r"[ \t]{2,}", " ", content).strip()
+            normalized_lines.append(indent + content if content else "")
+
+        updated = "\n".join(normalized_lines)
+        updated = re.sub(r"\n{3,}", "\n\n", updated)
+        return updated.rstrip() + "\n", total_removed
+
+    def clean_python_formatting(self, code: str) -> str:
+        """Apply safe formatting cleanup that does not alter behavior."""
+        code = code.replace("\r\n", "\n").replace("\r", "\n")
+        lines = [line.rstrip().replace("\t", "    ") for line in code.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        """Return syntax issues found in Python code."""
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [
+                Issue(
+                    kind="syntax",
+                    message=exc.msg,
+                    line=exc.lineno,
+                    column=exc.offset,
+                )
+            ]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        """Clean, optionally strip forbidden references, and validate Python code."""
+        repaired = self.clean_python_formatting(code)
+        repaired, removed = self.strip_forbidden_atom_references(repaired)
+        issues = self.validate_python_syntax(repaired)
+        return repaired, issues, removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        """Clean descriptive text and optionally strip forbidden references."""
+        cleaned = self.clean_description(text)
+        return self.strip_forbidden_atom_references(cleaned)
+
+
+TEXT_SUFFIXES = {
+    ".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg",
+    ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs",
+    ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml",
+}
+
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    if requested_mode != "auto":
+        return requested_mode
+    return "python" if path.suffix == ".py" else "text"
+
+
+def _iter_target_files(root: Path, include: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts):
+            continue
+        if not path.is_file():
+            continue
+        if include and not fnmatch.fnmatch(str(path.relative_to(root)), include):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(engine: AtomRepairEngine, path: Path, mode: str, check_only: bool) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        issues.append(Issue(kind="encoding", message="non-utf8 file skipped"))
+        return FileResult(path=path, changed=False, removed_references=0, issues=tuple(issues))
+    except OSError as exc:
+        issues.append(Issue(kind="io", message=f"read failed: {exc}"))
+        return FileResult(path=path, changed=False, removed_references=0, issues=tuple(issues))
+
+    detected_mode = _detect_mode(path, mode)
+    if detected_mode == "python":
+        fixed, syntax_issues, removed = engine.repair_python_code(source)
+        issues.extend(syntax_issues)
+    else:
+        fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    if changed and not check_only:
+        try:
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue(kind="io", message=f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path=path, changed=changed, removed_references=removed, issues=tuple(issues))
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path, help="File or directory to process")
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--check-only", action="store_true", help="Do not write changes")
+    parser.add_argument("--no-strip-atom-refs", action="store_true", help="Disable Atom ref removal")
+    parser.add_argument("--fail-on-change", action="store_true", help="Exit non-zero if changes are needed")
+    parser.add_argument(
+        "--include",
+        default="*",
+        help="Glob for relative file paths when path is a directory (default: '*')",
+    )
+
+    args = parser.parse_args(argv)
+    engine = AtomRepairEngine(strip_atom_references=not args.no_strip_atom_refs)
+
+    results: list[FileResult] = []
+    if args.path.is_file():
+        results.append(process_file(engine, args.path, args.mode, args.check_only))
+    else:
+        for file_path in _iter_target_files(args.path, args.include):
+            results.append(process_file(engine, file_path, args.mode, args.check_only))
+
+    changed_count = sum(1 for result in results if result.changed)
+    removed_count = sum(result.removed_references for result in results)
+    issue_count = sum(len(result.issues) for result in results)
+
+    for result in results:
+        if result.changed:
+            status = "would update" if args.check_only else "updated"
+            print(f"{status}: {result.path}")
+        if result.removed_references:
+            print(f"removed {result.removed_references} Atom-reference(s): {result.path}")
+        for issue in result.issues:
+            print(f"[{issue.kind}] {result.path}:{issue.line}:{issue.column} {issue.message}")
+
+    print(
+        "Summary: "
+        f"files={len(results)} changed={changed_count} "
+        f"atom_refs_removed={removed_count} issues={issue_count}"
+    )
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed_count:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..8058304556185c33c0cb00508a335a2eb846290c
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,71 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def setUp(self):
+        self.engine = AtomRepairEngine()
+
+    def test_clean_description_repairs_common_noise(self):
+        raw = "This is teh descripting text,, with   extra   spaces..."
+        cleaned = self.engine.clean_description(raw)
+        self.assertEqual(cleaned, "This is the descriptive text, with extra spaces.\n")
+
+    def test_clean_description_respects_word_boundaries(self):
+        raw = "The word technical must stay; cathedral should not become cathe dral."
+        cleaned = self.engine.clean_description(raw)
+        self.assertIn("technical", cleaned)
+
+    def test_repair_python_code_normalizes_tabs_and_detects_syntax(self):
+        raw = "def x():\n\treturn 1\n"
+        repaired, issues, removed = self.engine.repair_python_code(raw)
+        self.assertIn("    return 1", repaired)
+        self.assertEqual(issues, [])
+        self.assertEqual(removed, 0)
+
+    def test_validate_python_syntax_reports_error(self):
+        issues = self.engine.validate_python_syntax("def bad(:\n    pass\n")
+        self.assertEqual(len(issues), 1)
+        self.assertEqual(issues[0].kind, "syntax")
+
+    def test_strip_atom_hydrogen_and_carbon_references(self):
+        raw = "Use Atom-Hydrogen and atom carbon plugins."
+        cleaned, removed = self.engine.strip_forbidden_atom_references(raw)
+        self.assertEqual(removed, 2)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("atom carbon", cleaned.lower())
+
+    def test_process_file_directory_safe_for_python(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            path = Path(tmp) / "sample.py"
+            path.write_text("# Atom-Carbon\ndef ok():\n\treturn 1\n", encoding="utf-8")
+
+            result = process_file(self.engine, path, mode="auto", check_only=False)
+            rewritten = path.read_text(encoding="utf-8")
+
+            self.assertTrue(result.changed)
+            self.assertGreaterEqual(result.removed_references, 1)
+            self.assertIn("    return 1", rewritten)
+
+    def test_process_file_handles_non_utf8(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            path = Path(tmp) / "bad.txt"
+            path.write_bytes(b"\xff\xfe\x00")
+            result = process_file(self.engine, path, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+    def test_cli_no_strip_atom_refs(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            path = Path(tmp) / "doc.txt"
+            path.write_text("Atom-Hydrogen adapter", encoding="utf-8")
+            rc = run_cli([str(path), "--mode", "text", "--no-strip-atom-refs"])
+            self.assertEqual(rc, 0)
+            self.assertIn("Atom-Hydrogen", path.read_text(encoding="utf-8"))
+
+
+if __name__ == "__main__":
+    unittest.main()
node .\atom_care_suite.js help
node .\atom_care_suite.js report
node .\atom_care_suite.js heal
node .\atom_care_suite.js optimize
node .\atom_care_suite.js lockdown
node .\atom_care_suite.js restore --from "C:\Users\YOU\.atom\atom-care-backup-...."
#!/usr/bin/env node
/**
 * atom_care_suite.js
 * Extended ‚Äúcare suite‚Äù for Atom on Windows (mostly cross-platform).
 *
 * What it does (reversible):
 *  - backup ~/.atom
 *  - generate a health report (versions, packages, sizes, common corruption signals)
 *  - clean known-bad caches/state
 *  - optimize config to reduce stalls (Tree-sitter enable, reduce restore/state churn)
 *  - disable high-risk/heavy packages (heuristic + your allow/deny lists)
 *  - optional: Windows Firewall outbound block for atom.exe (‚Äúoffline‚Äù mode)
 *  - restore from backup
 *
 * NOTE: It cannot rewrite Atom core/Electron internals. It stabilizes from the outside.
 */

const fs = require("fs");
const path = require("path");
const os = require("os");
const child = require("child_process");

const args = process.argv.slice(2);
const cmd = (args[0] || "help").toLowerCase();
const flags = new Set(args.slice(1));

const HOME = os.homedir();
const ATOM_HOME =
  process.env.ATOM_HOME ||
  (process.platform === "win32" ? path.join(HOME, ".atom") : path.join(HOME, ".atom"));

const LOCAL_APPDATA = process.env.LOCALAPPDATA || path.join(HOME, "AppData", "Local");
const ATOM_APPDATA = process.platform === "win32" ? path.join(LOCAL_APPDATA, "atom") : null;

const stamp = new Date().toISOString().replace(/[:.]/g, "-");
const DEFAULT_BACKUP_DIR = path.join(ATOM_HOME, `atom-care-backup-${stamp}`);
const LOG_PATH = path.join(process.cwd(), `atom-care-${stamp}.log`);

function log(line) {
  fs.appendFileSync(LOG_PATH, line + "\n", "utf8");
  process.stdout.write(line + "\n");
}

function die(msg) {
  log("FATAL: " + msg);
  process.exit(1);
}

function exists(p) {
  try { fs.accessSync(p); return true; } catch { return false; }
}

function mkdirp(p) {
  fs.mkdirSync(p, { recursive: true });
}

function run(cmd, args, opts = {}) {
  const r = child.spawnSync(cmd, args, { encoding: "utf8", shell: false, ...opts });
  return { ok: r.status === 0, status: r.status, stdout: r.stdout || "", stderr: r.stderr || "" };
}

function runPS(script) {
  const full = `powershell.exe -NoProfile -ExecutionPolicy Bypass -Command "${script.replace(/"/g, '\\"')}"`;
  const r = child.spawnSync(full, { encoding: "utf8", shell: true });
  return { ok: r.status === 0, status: r.status, stdout: r.stdout || "", stderr: r.stderr || "" };
}

function safeCopyDir(src, dst) {
  mkdirp(dst);
  for (const entry of fs.readdirSync(src, { withFileTypes: true })) {
    const s = path.join(src, entry.name);
    const d = path.join(dst, entry.name);
    if (entry.isDirectory()) safeCopyDir(s, d);
    else if (entry.isFile()) fs.copyFileSync(s, d);
  }
}

function safeRemoveDir(dir) {
  if (!exists(dir)) return;
  fs.rmSync(dir, { recursive: true, force: true });
}

function dirSizeBytes(dir) {
  let total = 0;
  for (const entry of fs.readdirSync(dir, { withFileTypes: true })) {
    const p = path.join(dir, entry.name);
    try {
      if (entry.isDirectory()) total += dirSizeBytes(p);
      else if (entry.isFile()) total += fs.statSync(p).size;
    } catch { /* ignore locked files */ }
  }
  return total;
}

function findAtomExe() {
  if (process.platform !== "win32") return "atom";
  const pf = process.env.ProgramFiles || "C:\\Program Files";
  const pf86 = process.env["ProgramFiles(x86)"] || "C:\\Program Files (x86)";
  const candidates = [
    path.join(pf, "Atom", "atom.exe"),
    path.join(pf86, "Atom", "atom.exe"),
    "atom.exe"
  ];
  for (const c of candidates) if (!c.includes("\\") || exists(c)) return c;
  return "atom.exe";
}

function findApm() {
  const candidates = [];
  if (process.platform === "win32") {
    const pf = process.env.ProgramFiles || "C:\\Program Files";
    const pf86 = process.env["ProgramFiles(x86)"] || "C:\\Program Files (x86)";
    candidates.push("apm.cmd", "apm");
    candidates.push(
      path.join(pf, "Atom", "resources", "app", "apm", "bin", "apm.cmd"),
      path.join(pf86, "Atom", "resources", "app", "apm", "bin", "apm.cmd")
    );
  } else {
    candidates.push("apm");
  }
  for (const c of candidates) {
    if (c.includes(path.sep)) {
      if (exists(c)) return c;
    } else {
      const r = run(c, ["--version"]);
      if (r.ok) return c;
    }
  }
  return null;
}

function atomConfigPath() {
  const p = path.join(ATOM_HOME, "config.cson");
  return exists(p) ? p : null;
}

function readConfig() {
  const p = atomConfigPath();
  if (!p) return { path: null, text: "" };
  return { path: p, text: fs.readFileSync(p, "utf8") };
}

function writeConfig(p, text) {
  fs.writeFileSync(p, text, "utf8");
}

function parseDisabledPackages(configText) {
  const disabled = new Set();
  const m = configText.match(/disabledPackages\s*:\s*\[([\s\S]*?)\]/m);
  if (!m) return disabled;
  const body = m[1];
  const re = /["']([^"']+)["']/g;
  let mm;
  while ((mm = re.exec(body))) disabled.add(mm[1]);
  return disabled;
}

function upsertDisabledPackages(configText, pkgs) {
  const list = Array.from(pkgs).sort();
  const m = configText.match(/disabledPackages\s*:\s*\[([\s\S]*?)\]/m);

  const replacement =
    `disabledPackages: [\n` +
    list.map((p) => `  "${p}"`).join("\n") +
    `\n]`;

  if (m) {
    return configText.replace(/disabledPackages\s*:\s*\[[\s\S]*?\]/m, replacement);
  }

  // append at end (simple + safe)
  return configText +
    `\n\n# Added by atom_care_suite.js (${new Date().toISOString()})\n` +
    replacement + "\n";
}

function ensureSetting(configText, dottedKey, valueLiteral) {
  // Simple, safe ‚Äúappend setting note‚Äù approach rather than fragile CSON AST editing.
  // We add a dedicated block at end that Atom will read as top-level keys.
  // For many Atom configs this is sufficient; if your config is deeply nested, we still avoid breaking it.
  const marker = `# atom_care_suite setting: ${dottedKey}`;
  if (configText.includes(marker)) return configText;

  return configText +
    `\n${marker}\n` +
    `${dottedKey}: ${valueLiteral}\n`;
}

function listInstalledPackages() {
  const apm = findApm();
  if (!apm) return { apm: null, packages: [], note: "apm not found; package list limited." };
  const r = run(apm, ["list", "--installed", "--bare"]);
  if (!r.ok) return { apm, packages: [], note: "apm list failed." };

  const packages = r.stdout
    .split(/\r?\n/)
    .map((l) => l.trim())
    .filter(Boolean)
    .map((l) => {
      const [name, version] = l.split("@");
      return { name, version: version || "" };
    });
  return { apm, packages, note: "" };
}

/**
 * Risk model: these are ‚Äúcommonly heavy / commonly implicated in freezes/crashes‚Äù
 * This is *not* a moral judgment; it‚Äôs a stability heuristic.
 */
function isHeuristicRisky(name) {
  const exact = new Set([
    "teletype",
    "atom-ide-ui",
    "platformio-ide-terminal",
    "languageclient",
    "linter",
    "linter-ui-default",
    "busy-signal",
    "minimap",
    "file-icons",
    "atom-beautify",
    "git-plus",
  ]);
  const patterns = [
    /languageclient/i,
    /^ide-/i,
    /linter/i,
    /minimap/i,
    /terminal/i,
    /autocomplete/i,
  ];
  if (exact.has(name)) return true;
  return patterns.some((re) => re.test(name));
}

function backupAtomHome(destDir = DEFAULT_BACKUP_DIR) {
  if (!exists(ATOM_HOME)) die(`Atom home not found: ${ATOM_HOME}`);
  mkdirp(destDir);
  safeCopyDir(ATOM_HOME, destDir);
  log(`‚úÖ Backup created: ${destDir}`);
  return destDir;
}

function cleanKnownBadState() {
  const targets = [
    path.join(ATOM_HOME, "compile-cache"),
    path.join(ATOM_HOME, "storage"),
    path.join(ATOM_HOME, "blob-store"),
    path.join(ATOM_HOME, ".apm", ".cache"),
  ];

  if (ATOM_APPDATA) {
    targets.push(
      path.join(ATOM_APPDATA, "Cache"),
      path.join(ATOM_APPDATA, "Code Cache"),
      path.join(ATOM_APPDATA, "GPUCache"),
      path.join(ATOM_APPDATA, "DawnCache"),
      path.join(ATOM_APPDATA, "Local Storage"),
      path.join(ATOM_APPDATA, "Session Storage")
    );
  }

  let removed = 0;
  for (const t of targets) {
    if (exists(t)) {
      safeRemoveDir(t);
      log(`üßº Removed: ${t}`);
      removed++;
    }
  }
  if (!removed) log("‚ÑπÔ∏è No known cache/state directories found to remove.");
}

function optimizeConfig() {
  const { path: cfgPath, text } = readConfig();
  if (!cfgPath) die("config.cson not found in ATOM_HOME.");

  // ‚ÄúBackend-ish‚Äù knobs you can influence without breaking Atom:
  // - Enable Tree-sitter where possible (reduces expensive legacy grammar tokenization)
  // - Reduce state restore churn (can reduce startup weirdness)
  // - Avoid excessive project scanning behavior by limiting restore prompts (soft)
  let updated = text;

  // Tree-sitter setting varies by Atom version; still safe to set (ignored if unsupported).
  updated = ensureSetting(updated, '"core".useTreeSitterParsers', "true");

  // Reduce noisy restore behavior (soft). Safe if unknown.
  updated = ensureSetting(updated, '"core".restorePreviousWindowsOnStart', '"no"');

  // Make package load less ‚Äúsurprising‚Äù: if you keep it lean, this helps.
  updated = ensureSetting(updated, '"core".automaticallyUpdate', "false");
  updated = ensureSetting(updated, '"core".telemetryConsent', '"no"'); // some builds ignore

  if (updated !== text) {
    writeConfig(cfgPath, updated);
    log(`‚úÖ Config optimized: ${cfgPath}`);
  } else {
    log("‚ÑπÔ∏è Config already contains care-suite markers; no changes made.");
  }
}

function disableRiskyPackages({ allow = new Set(), deny = new Set() } = {}) {
  const { path: cfgPath, text } = readConfig();
  if (!cfgPath) die("config.cson not found.");

  const { packages, note } = listInstalledPackages();
  if (note) log(`‚ÑπÔ∏è ${note}`);

  const currentlyDisabled = parseDisabledPackages(text);
  const toDisable = new Set([...currentlyDisabled]);

  // Add explicit denies
  for (const d of deny) toDisable.add(d);

  // Heuristic disables
  for (const p of packages) {
    if (allow.has(p.name)) continue;
    if (isHeuristicRisky(p.name)) toDisable.add(p.name);
  }

  // Never disable core-ish packages you rely on unless explicitly denied
  const protectedCore = ["language-gfm", "whitespace", "tabs", "status-bar", "tree-view", "settings-view"];
  for (const core of protectedCore) {
    if (!deny.has(core)) toDisable.delete(core);
  }

  const updated = upsertDisabledPackages(text, toDisable);
  writeConfig(cfgPath, updated);

  log(`‚úÖ Updated disabledPackages. Total disabled: ${toDisable.size}`);
  const newly = [...toDisable].filter((p) => !currentlyDisabled.has(p));
  if (newly.length) {
    log("Newly disabled (sample):");
    newly.slice(0, 30).forEach((p) => log(`  - ${p}`));
    if (newly.length > 30) log(`  ...and ${newly.length - 30} more`);
  }
}

function launchSafeMode() {
  const atom = findAtomExe();
  log("üöë Launching Atom in SAFE MODE‚Ä¶");
  const p = child.spawn(atom, ["--safe"], { stdio: "inherit", detached: true });
  p.unref();
  log("‚úÖ Atom launched. Close it after testing.");
}

function launchClearState() {
  const atom = findAtomExe();
  log("üßΩ Launching Atom with window state cleared‚Ä¶");
  const p = child.spawn(atom, ["--clear-window-state"], { stdio: "inherit", detached: true });
  p.unref();
  log("‚úÖ Atom launched. If it loads cleanly, close it, then run optimize/disable-risky.");
}

function windowsOfflineLockdown(enable) {
  if (process.platform !== "win32") {
    log("‚ÑπÔ∏è Offline lockdown is Windows-only in this script.");
    return;
  }

  // Block/Unblock Atom outbound at Windows Firewall level (safely scoped to atom.exe)
  // This is NOT ‚Äújamming‚Äù; it‚Äôs a local host firewall rule.
  const atomExe = findAtomExe();
  if (!atomExe.toLowerCase().endsWith("atom.exe")) {
    log("‚ÑπÔ∏è atom.exe not found in common locations; rule may still work if Atom is on PATH.");
  }

  if (enable) {
    log("üîí Enabling Atom outbound BLOCK rule‚Ä¶");
    const ps = `
      $atom = "${atomExe.replace(/\\/g, "\\\\")}";
      if (-not (Get-NetFirewallRule -DisplayName "Block Atom Outbound" -ErrorAction SilentlyContinue)) {
        New-NetFirewallRule -DisplayName "Block Atom Outbound" -Direction Outbound -Action Block -Program $atom | Out-Null
      }
    `;
    const r = runPS(ps);
    if (!r.ok) log("WARN: Failed to set firewall rule. Run as Administrator.\n" + r.stderr);
    else log("‚úÖ Atom outbound blocked (Windows Firewall).");
  } else {
    log("üîì Removing Atom outbound BLOCK rule‚Ä¶");
    const ps = `
      $r = Get-NetFirewallRule -DisplayName "Block Atom Outbound" -ErrorAction SilentlyContinue;
      if ($r) { Remove-NetFirewallRule -DisplayName "Block Atom Outbound" }
    `;
    const r = runPS(ps);
    if (!r.ok) log("WARN: Failed to remove rule.\n" + r.stderr);
    else log("‚úÖ Atom outbound block rule removed.");
  }
}

function report() {
  log("=== Atom Care Suite Report ===");
  log(`Log: ${LOG_PATH}`);
  log(`ATOM_HOME: ${ATOM_HOME} ${exists(ATOM_HOME) ? "" : "(missing)"}`);
  log(`ATOM_APPDATA: ${ATOM_APPDATA || "(n/a)"} ${ATOM_APPDATA && exists(ATOM_APPDATA) ? "" : "(missing)"}`);
  log(`config.cson: ${atomConfigPath() || "(missing)"}`);

  // sizes (helps detect runaway caches)
  if (exists(ATOM_HOME)) {
    const s = dirSizeBytes(ATOM_HOME) / (1024 * 1024);
    log(`Size ATOM_HOME: ${s.toFixed(1)} MB`);
  }
  if (ATOM_APPDATA && exists(ATOM_APPDATA)) {
    const s = dirSizeBytes(ATOM_APPDATA) / (1024 * 1024);
    log(`Size ATOM_APPDATA: ${s.toFixed(1)} MB`);
  }

  const atomExe = findAtomExe();
  log(`Atom executable guess: ${atomExe}`);

  const apm = findApm();
  log(`apm: ${apm || "(not found)"}`);

  if (apm) {
    const v = run(apm, ["--version"]);
    if (v.ok) log("apm --version:\n" + v.stdout.trim());
  }

  // package stats
  const { packages, note } = listInstalledPackages();
  if (note) log(`‚ÑπÔ∏è ${note}`);
  log(`Installed packages detected: ${packages.length}`);
  const risky = packages.filter((p) => isHeuristicRisky(p.name));
  log(`Heuristic ‚Äúheavy/risky‚Äù packages: ${risky.length}`);
  risky.slice(0, 25).forEach((p) => log(`  - ${p.name}@${p.version}`));
  if (risky.length > 25) log(`  ...and ${risky.length - 25} more`);

  // corruption hints
  const suspicious = [];
  const candidates = [
    path.join(ATOM_HOME, "storage"),
    path.join(ATOM_HOME, "compile-cache"),
    ATOM_APPDATA ? path.join(ATOM_APPDATA, "GPUCache") : null
  ].filter(Boolean);

  for (const c of candidates) {
    if (exists(c)) {
      // very large caches often correlate with stalls/crash loops
      const mb = dirSizeBytes(c) / (1024 * 1024);
      if (mb > 500) suspicious.push(`${c} is large (${mb.toFixed(0)} MB)`);
    }
  }
  if (suspicious.length) {
    log("‚ö†Ô∏è Potential trouble signals:");
    suspicious.forEach((s) => log("  - " + s));
  } else {
    log("‚úÖ No obvious cache-size red flags.");
  }

  log("=== End Report ===");
}

function restore(fromDir) {
  if (!fromDir) die("restore requires --from <backupDir>");
  if (!exists(fromDir)) die(`Backup dir not found: ${fromDir}`);
  if (!exists(ATOM_HOME)) die(`ATOM_HOME not found: ${ATOM_HOME}`);

  // Safety: refuse to restore if ATOM_HOME doesn't look like .atom
  if (path.basename(ATOM_HOME).toLowerCase() !== ".atom") {
    die(`Refusing restore: ATOM_HOME does not end with .atom (${ATOM_HOME})`);
  }

  const restoreBackup = path.join(ATOM_HOME, `atom-care-pre-restore-${stamp}`);
  log(`Creating pre-restore backup: ${restoreBackup}`);
  backupAtomHome(restoreBackup);

  log("Restoring backup into ATOM_HOME‚Ä¶");
  // wipe Atom home (not the parent) then copy backup in
  for (const entry of fs.readdirSync(ATOM_HOME)) {
    const p = path.join(ATOM_HOME, entry);
    safeRemoveDir(p);
  }
  safeCopyDir(fromDir, ATOM_HOME);
  log("‚úÖ Restore complete.");
}

function help() {
  console.log(`
Atom Care Suite (Extended)
Commands:
  help
  report                -> health report + package/risk summary
  heal                  -> backup + clean caches/state + safe-mode launch
  optimize              -> backup + config optimizations (Tree-sitter, reduce restore churn)
  disable-risky         -> backup + disable heavy/risky packages (heuristic)
  clear-state           -> launch Atom with --clear-window-state
  safe-mode             -> launch Atom with --safe
  lockdown              -> (Windows) block Atom outbound via Firewall rule
  unlock                -> (Windows) remove the outbound block rule
  restore --from <dir>  -> restore ~/.atom from a backup folder

Examples:
  node atom_care_suite.js report
  node atom_care_suite.js heal
  node atom_care_suite.js optimize
  node atom_care_suite.js disable-risky
  node atom_care_suite.js lockdown
`);
}

function heal() {
  backupAtomHome();
  report();
  cleanKnownBadState();
  launchSafeMode();
  log("‚úÖ HEAL done. If safe mode is stable, run optimize + disable-risky.");
}

function optimize() {
  backupAtomHome();
  optimizeConfig();
  log("‚úÖ OPTIMIZE done. Next: disable-risky, then launch Atom normally.");
}

function disableRisky() {
  backupAtomHome();
  disableRiskyPackages();
  log("‚úÖ DISABLE-RISKY done. Launch Atom normally to test.");
}

(function main() {
  try {
    if (!exists(ATOM_HOME) && cmd !== "help") {
      die(`ATOM_HOME not found: ${ATOM_HOME} (set ATOM_HOME if you use a custom path)`);
    }

    switch (cmd) {
      case "help": help(); break;
      case "report": report(); break;
      case "heal": heal(); break;
      case "optimize": optimize(); break;
      case "disable-risky": disableRisky(); break;
      case "safe-mode": launchSafeMode(); break;
      case "clear-state": launchClearState(); break;
      case "lockdown": windowsOfflineLockdown(true); break;
      case "unlock": windowsOfflineLockdown(false); break;
      case "restore": {
        const idx = args.indexOf("--from");
        const from = idx >= 0 ? args[idx + 1] : null;
        restore(from);
        break;
      }
      default:
        help();
        process.exitCode = 1;
    }
  } catch (e) {
    die(e && e.message ? e.message : String(e));
  }
})();
apm list --installed --bare
apm rebuild
apm clean
apm install
Keybinding Resolver (Ctrl + .)
~/.atom/keymap.cson
apm disable spell-check
core:
  autoSave: "off"
core:
  restorePreviousWindowsOnStart: "no"
core:
  fileEncoding: "utf8"
~/.atom/storage
atom --disable-gpu
atom --profile-startup
tasklist | findstr node
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..e16076a8b66ee200d46fd0178b7864a7a9d292f1
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,297 @@
+"""ATOM: Automated Technical Optimization Module.
+
+A standalone quality and migration utility focused on:
+1) Improving text/Python technical hygiene (formatting + syntax checks).
+2) Removing unwanted domain references (Atom plugin names and physical-domain terms)
+   while preserving executable code behavior.
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import re
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+DEFAULT_FORBIDDEN_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),
+    re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),
+)
+
+DEFAULT_PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bphysical\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borgan(?:s|ic)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class Issue:
+    """Represents a detected issue."""
+
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    """Outcome of processing a single file."""
+
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+
+
+class AtomRepairEngine:
+    """Standalone fixer and validator for text and Python code."""
+
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        forbidden_patterns: Iterable[re.Pattern[str]] | None = None,
+        *,
+        physical_patterns: Iterable[re.Pattern[str]] | None = None,
+        strip_atom_references: bool = True,
+        strip_physical_references: bool = True,
+    ):
+        self.forbidden_patterns = tuple(forbidden_patterns or DEFAULT_FORBIDDEN_PATTERNS)
+        self.physical_patterns = tuple(physical_patterns or DEFAULT_PHYSICAL_PATTERNS)
+        self.strip_atom_references = strip_atom_references
+        self.strip_physical_references_enabled = strip_physical_references
+
+    def clean_description(self, text: str) -> str:
+        """Repair common spelling/punctuation noise in descriptive text."""
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+
+        for wrong_pattern, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong_pattern.sub(right, cleaned)
+
+        lines = [self._normalize_line(line) for line in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        line = re.sub(r"\s+", " ", line).strip()
+        return line
+
+    def _strip_patterns(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        total_removed = 0
+        for pattern in patterns:
+            updated, count = pattern.subn("", updated)
+            total_removed += count
+
+        normalized_lines: list[str] = []
+        for line in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n"):
+            indent_match = re.match(r"^[ \t]*", line)
+            indent = indent_match.group(0) if indent_match else ""
+            content = line[len(indent):]
+            content = re.sub(r"[ \t]{2,}", " ", content).strip()
+            normalized_lines.append(indent + content if content else "")
+
+        updated = "\n".join(normalized_lines)
+        updated = re.sub(r"\n{3,}", "\n\n", updated)
+        return updated.rstrip() + "\n", total_removed
+
+    def strip_forbidden_atom_references(self, text: str) -> tuple[str, int]:
+        """Remove references to Atom-Hydrogen/Atom-Carbon related terms."""
+        if not self.strip_atom_references:
+            return text, 0
+        return self._strip_patterns(text, self.forbidden_patterns)
+
+    def strip_physical_references(self, text: str) -> tuple[str, int]:
+        """Remove physical-domain references (physiology/chemistry/anatomy/etc.)."""
+        if not self.strip_physical_references_enabled:
+            return text, 0
+        return self._strip_patterns(text, self.physical_patterns)
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        """Sanitize only Python comment lines to avoid altering executable code."""
+        removed_total = 0
+        output_lines: list[str] = []
+        for line in code.split("\n"):
+            stripped = line.lstrip()
+            if stripped.startswith("#"):
+                cleaned, removed = self.strip_physical_references(line)
+                cleaned, removed_atom = self.strip_forbidden_atom_references(cleaned)
+                output_lines.append(cleaned.rstrip("\n"))
+                removed_total += removed + removed_atom
+            else:
+                output_lines.append(line)
+        return "\n".join(output_lines).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        """Apply safe formatting cleanup that does not alter behavior."""
+        code = code.replace("\r\n", "\n").replace("\r", "\n")
+        lines = [line.rstrip().replace("\t", "    ") for line in code.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        """Return syntax issues found in Python code."""
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [
+                Issue(
+                    kind="syntax",
+                    message=exc.msg,
+                    line=exc.lineno,
+                    column=exc.offset,
+                )
+            ]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        """Clean and validate Python code, sanitizing comments only."""
+        repaired = self.clean_python_formatting(code)
+        repaired, removed = self.sanitize_python_comments(repaired)
+        issues = self.validate_python_syntax(repaired)
+        return repaired, issues, removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        """Clean descriptive text and strip configured references."""
+        cleaned = self.clean_description(text)
+        cleaned, removed_atom = self.strip_forbidden_atom_references(cleaned)
+        cleaned, removed_physical = self.strip_physical_references(cleaned)
+        return cleaned, removed_atom + removed_physical
+
+
+TEXT_SUFFIXES = {
+    ".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg",
+    ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs",
+    ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml",
+}
+
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    if requested_mode != "auto":
+        return requested_mode
+    return "python" if path.suffix == ".py" else "text"
+
+
+def _iter_target_files(root: Path, include: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts):
+            continue
+        if not path.is_file():
+            continue
+        if include and not fnmatch.fnmatch(str(path.relative_to(root)), include):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(engine: AtomRepairEngine, path: Path, mode: str, check_only: bool) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        issues.append(Issue(kind="encoding", message="non-utf8 file skipped"))
+        return FileResult(path=path, changed=False, removed_references=0, issues=tuple(issues))
+    except OSError as exc:
+        issues.append(Issue(kind="io", message=f"read failed: {exc}"))
+        return FileResult(path=path, changed=False, removed_references=0, issues=tuple(issues))
+
+    detected_mode = _detect_mode(path, mode)
+    if detected_mode == "python":
+        fixed, syntax_issues, removed = engine.repair_python_code(source)
+        issues.extend(syntax_issues)
+    else:
+        fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    if changed and not check_only:
+        try:
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue(kind="io", message=f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path=path, changed=changed, removed_references=removed, issues=tuple(issues))
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path, help="File or directory to process")
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--check-only", action="store_true", help="Do not write changes")
+    parser.add_argument("--no-strip-atom-refs", action="store_true", help="Disable Atom ref removal")
+    parser.add_argument("--no-strip-physical-refs", action="store_true", help="Disable physical-domain ref removal")
+    parser.add_argument("--fail-on-change", action="store_true", help="Exit non-zero if changes are needed")
+    parser.add_argument(
+        "--include",
+        default="*",
+        help="Glob for relative file paths when path is a directory (default: '*')",
+    )
+
+    args = parser.parse_args(argv)
+    engine = AtomRepairEngine(
+        strip_atom_references=not args.no_strip_atom_refs,
+        strip_physical_references=not args.no_strip_physical_refs,
+    )
+
+    results: list[FileResult] = []
+    if args.path.is_file():
+        results.append(process_file(engine, args.path, args.mode, args.check_only))
+    else:
+        for file_path in _iter_target_files(args.path, args.include):
+            results.append(process_file(engine, file_path, args.mode, args.check_only))
+
+    changed_count = sum(1 for result in results if result.changed)
+    removed_count = sum(result.removed_references for result in results)
+    issue_count = sum(len(result.issues) for result in results)
+
+    for result in results:
+        if result.changed:
+            status = "would update" if args.check_only else "updated"
+            print(f"{status}: {result.path}")
+        if result.removed_references:
+            print(f"removed {result.removed_references} reference(s): {result.path}")
+        for issue in result.issues:
+            print(f"[{issue.kind}] {result.path}:{issue.line}:{issue.column} {issue.message}")
+
+    print(
+        "Summary: "
+        f"files={len(results)} changed={changed_count} "
+        f"refs_removed={removed_count} issues={issue_count}"
+    )
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed_count:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..4f309d326bc20e7aff33c9657e0335dd5e1a2ea7
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,61 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def setUp(self):
+        self.engine = AtomRepairEngine()
+
+    def test_clean_description_repairs_common_noise(self):
+        raw = "This is teh descripting text,, with   extra   spaces..."
+        cleaned = self.engine.clean_description(raw)
+        self.assertEqual(cleaned, "This is the descriptive text, with extra spaces.\n")
+
+    def test_clean_description_respects_word_boundaries(self):
+        raw = "The word technical must stay; cathedral should not change."
+        cleaned = self.engine.clean_description(raw)
+        self.assertIn("technical", cleaned)
+
+    def test_repair_python_code_preserves_code_and_sanitizes_comments(self):
+        raw = "x = 'physical'\n# physiology and Atom-Hydrogen\ndef ok():\n\treturn 1\n"
+        repaired, issues, removed = self.engine.repair_python_code(raw)
+        self.assertIn("x = 'physical'", repaired)
+        self.assertIn("    return 1", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 2)
+
+    def test_validate_python_syntax_reports_error(self):
+        issues = self.engine.validate_python_syntax("def bad(:\n    pass\n")
+        self.assertEqual(len(issues), 1)
+        self.assertEqual(issues[0].kind, "syntax")
+
+    def test_strip_physical_references_in_text(self):
+        raw = "This includes physiology, chemistry, compounds, and anatomy."
+        cleaned, removed = self.engine.strip_physical_references(raw)
+        self.assertGreaterEqual(removed, 4)
+        lowered = cleaned.lower()
+        self.assertNotIn("physiology", lowered)
+        self.assertNotIn("chemistry", lowered)
+
+    def test_process_file_handles_non_utf8(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            path = Path(tmp) / "bad.txt"
+            path.write_bytes(b"\xff\xfe\x00")
+            result = process_file(self.engine, path, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+    def test_cli_no_strip_physical_refs(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            path = Path(tmp) / "doc.txt"
+            path.write_text("physical chemistry", encoding="utf-8")
+            rc = run_cli([str(path), "--mode", "text", "--no-strip-physical-refs"])
+            self.assertEqual(rc, 0)
+            self.assertIn("physical", path.read_text(encoding="utf-8"))
+
+
+if __name__ == "__main__":
+    unittest.main()
powershell -ExecutionPolicy Bypass -File .\Restore-AtomBaseline.ps1

# Restore-AtomBaseline.ps1
# Nearly-perfect Atom baseline restore (reversible via backups).
# Run in PowerShell (preferably Admin).

$ErrorActionPreference = "Stop"

function Write-Note($m) { Write-Host $m }
function Ensure-Dir($p) { if (!(Test-Path $p)) { New-Item -ItemType Directory -Path $p | Out-Null } }

$Home = $env:USERPROFILE
$AtomHome = if ($env:ATOM_HOME) { $env:ATOM_HOME } else { Join-Path $Home ".atom" }
$AtomAppData = Join-Path $env:LOCALAPPDATA "atom"

$Stamp = (Get-Date).ToString("yyyy-MM-dd_HH-mm-ss")
$BackupRoot = Join-Path $Home "AtomBaselineBackups"
Ensure-Dir $BackupRoot
$BackupDir = Join-Path $BackupRoot "backup_$Stamp"
Ensure-Dir $BackupDir

Write-Note "=== Atom Baseline Restore ==="
Write-Note "AtomHome: $AtomHome"
Write-Note "AtomAppData: $AtomAppData"
Write-Note "BackupDir: $BackupDir"

# 0) Stop Atom-related processes (soft kill then hard if needed)
Write-Note "`n[0] Stopping Atom / apm / node helper processes..."
$procNames = @("atom","atom-beta","apm","apm-beta","node")
foreach ($n in $procNames) {
  Get-Process -Name $n -ErrorAction SilentlyContinue | ForEach-Object {
    try { $_.CloseMainWindow() | Out-Null } catch {}
  }
}
Start-Sleep -Seconds 2
foreach ($n in $procNames) {
  Get-Process -Name $n -ErrorAction SilentlyContinue | Stop-Process -Force -ErrorAction SilentlyContinue
}

# 1) Backup current state (reversible)
Write-Note "`n[1] Backing up current Atom state..."
if (Test-Path $AtomHome) {
  Copy-Item $AtomHome -Destination (Join-Path $BackupDir ".atom") -Recurse -Force
  Write-Note "  ‚úÖ Backed up $AtomHome"
} else {
  Write-Note "  ‚ÑπÔ∏è $AtomHome not found (Atom may not be configured yet)."
}

if (Test-Path $AtomAppData) {
  Copy-Item $AtomAppData -Destination (Join-Path $BackupDir "atom_appdata") -Recurse -Force
  Write-Note "  ‚úÖ Backed up $AtomAppData"
} else {
  Write-Note "  ‚ÑπÔ∏è $AtomAppData not found."
}

# 2) Purge known corruption/state caches (the usual ‚Äúhidden culprits‚Äù)
Write-Note "`n[2] Purging known cache/state locations (safe)..."
$targets = @(
  (Join-Path $AtomHome "compile-cache"),
  (Join-Path $AtomHome "storage"),
  (Join-Path $AtomHome "blob-store"),
  (Join-Path $AtomHome ".apm\.cache"),
  (Join-Path $AtomAppData "Cache"),
  (Join-Path $AtomAppData "Code Cache"),
  (Join-Path $AtomAppData "GPUCache"),
  (Join-Path $AtomAppData "DawnCache"),
  (Join-Path $AtomAppData "Local Storage"),
  (Join-Path $AtomAppData "Session Storage")
) | Where-Object { $_ -and (Test-Path $_) }

foreach ($t in $targets) {
  try {
    Remove-Item $t -Recurse -Force
    Write-Note "  üßº Removed: $t"
  } catch {
    Write-Note "  ‚ö†Ô∏è Could not remove (in use/locked): $t"
  }
}
if ($targets.Count -eq 0) { Write-Note "  ‚ÑπÔ∏è No known cache dirs found to purge." }

# 3) Baseline reset: move existing config aside, keep it restorable
Write-Note "`n[3] Resetting Atom user profile to baseline (reversible)..."
Ensure-Dir $AtomHome

$BaselineDir = Join-Path $BackupDir "baseline_reset_previous_dot_atom"
Ensure-Dir $BaselineDir

# Move only the most problematic/user-tuned files, not everything
$moveItems = @("config.cson","keymap.cson","init.coffee","snippets.cson","styles.less","packages","projects.cson")
foreach ($item in $moveItems) {
  $p = Join-Path $AtomHome $item
  if (Test-Path $p) {
    Move-Item $p -Destination (Join-Path $BaselineDir $item) -Force
    Write-Note "  ‚Ü™ moved: $item"
  }
}

# 4) Create a minimal, stable config.cson (low drama settings)
Write-Note "`n[4] Writing minimal stable config.cson..."
$configPath = Join-Path $AtomHome "config.cson"

$minimalConfig = @'
"*":
  core:
    # Stability-first baseline
    restorePreviousWindowsOnStart: "no"
    automaticallyUpdate: false
    fileEncoding: "utf8"
    telemetryConsent: "no"
    useTreeSitterParsers: true
  editor:
    # Reduce expensive UI churn on large repos
    scrollPastEnd: false
    showIndentGuide: true
    softWrap: false
'@

Set-Content -Path $configPath -Value $minimalConfig -Encoding UTF8
Write-Note "  ‚úÖ Wrote: $configPath"

# 5) Optional: apm rebuild/clean (fixes native module ABI drift)
Write-Note "`n[5] Attempting apm maintenance (if available)..."
function Find-Apm {
  $candidates = @("apm.cmd","apm")
  $pf = ${env:ProgramFiles}
  $pf86 = ${env:ProgramFiles(x86)}
  if ($pf) { $candidates += (Join-Path $pf "Atom\resources\app\apm\bin\apm.cmd") }
  if ($pf86) { $candidates += (Join-Path $pf86 "Atom\resources\app\apm\bin\apm.cmd") }
  foreach ($c in $candidates) {
    try {
      $r = & $c --version 2>$null
      if ($LASTEXITCODE -eq 0) { return $c }
    } catch {}
  }
  return $null
}

$apm = Find-Apm
if ($apm) {
  Write-Note "  ‚úÖ apm found: $apm"
  try {
    Write-Note "  Running: apm rebuild"
    & $apm rebuild
  } catch {
    Write-Note "  ‚ö†Ô∏è apm rebuild failed (non-fatal)."
  }
} else {
  Write-Note "  ‚ÑπÔ∏è apm not found; skipping rebuild."
}

# 6) Provide recommended launch modes (safe, clear-state, disable-gpu)
Write-Note "`n=== DONE ==="
Write-Note "Backups created at: $BackupDir"
Write-Note ""
Write-Note "Next recommended launches (pick one):"
Write-Note "  1) Safe Mode:        atom --safe"
Write-Note "  2) Clear State:      atom --clear-window-state"
Write-Note "  3) Disable GPU test: atom --disable-gpu"
Write-Note ""
Write-Note "If you want your old setup back, restore from:"
Write-Note "  $BackupDir"
# Windows-Baseline-Repair.ps1
Write-Host "Running DISM health restore..."
DISM /Online /Cleanup-Image /RestoreHealth

Write-Host "Running System File Checker..."
sfc /scannow

Write-Host "Done. Reboot recommended."
# --- Block Atom outbound traffic (offline mode) ---

# Try common install locations first; fall back to PATH name
$paths = @(
  "$env:ProgramFiles\Atom\atom.exe",
  "${env:ProgramFiles(x86)}\Atom\atom.exe"
)
$atomExe = ($paths | Where-Object { Test-Path $_ } | Select-Object -First 1)
if (-not $atomExe) { $atomExe = "atom.exe" }

# Create rule (idempotent)
$ruleName = "Block Atom Outbound"
if (-not (Get-NetFirewallRule -DisplayName $ruleName -ErrorAction SilentlyContinue)) {
  New-NetFirewallRule -DisplayName $ruleName -Direction Outbound -Action Block -Program $atomExe | Out-Null
  Write-Host "‚úÖ Created firewall rule: $ruleName ($atomExe)"
} else {
  Write-Host "‚ÑπÔ∏è Rule already exists: $ruleName"
}
$ruleName = "Block Atom Outbound"
Get-NetFirewallRule -DisplayName $ruleName -ErrorAction SilentlyContinue | Remove-NetFirewallRule
Write-Host "‚úÖ Removed firewall rule: $ruleName"
Get-NetFirewallRule -DisplayName "Block Atom Outbound" | Format-List DisplayName,Enabled,Direction,Action
# atom_offline.rb
require "open3"

def run(cmd)
  out, err, st = Open3.capture3(cmd)
  puts out unless out.empty?
  warn err unless err.empty?
  raise "Command failed: #{cmd}" unless st.success?
end

rule = "Block Atom Outbound"

# Find atom.exe in common install paths (fallback to atom.exe on PATH)
candidates = [
  File.join(ENV["ProgramFiles"].to_s, "Atom", "atom.exe"),
  File.join(ENV["ProgramFiles(x86)"].to_s, "Atom", "atom.exe"),
]
atom = candidates.find { |p| File.exist?(p) } || "atom.exe"

ps = %Q{
  $ruleName = "#{rule}";
  if (-not (Get-NetFirewallRule -DisplayName $ruleName -ErrorAction SilentlyContinue)) {
    New-NetFirewallRule -DisplayName $ruleName -Direction Outbound -Action Block -Program "#{atom}" | Out-Null
    Write-Output "Created: #{$ruleName}"
  } else {
    Write-Output "Already exists: #{$ruleName}"
  }
}

run(%Q{powershell.exe -NoProfile -ExecutionPolicy Bypass -Command "#{ps.gsub('"','\\"')}"})
puts "‚úÖ Atom offline mode enabled."
Get-NetFirewallRule -DisplayName "Block Atom Outbound" -ErrorAction SilentlyContinue | Remove-NetFirewallRule
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..2846bccad1d3a2516faec3acf4e2d64e01087aae
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,328 @@
+"""ATOM: Automated Technical Optimization Module.
+
+A standalone quality and migration utility focused on:
+1) Improving text/Python technical hygiene (formatting + syntax checks).
+2) Removing unwanted domain references (Atom plugin names and physical-domain terms)
+   while preserving executable code behavior.
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import io
+import re
+import tokenize
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+DEFAULT_FORBIDDEN_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),
+    re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),
+)
+
+DEFAULT_PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bphysical\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borgan(?:s|ic)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class Issue:
+    """Represents a detected issue."""
+
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    """Outcome of processing a single file."""
+
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+
+
+class AtomRepairEngine:
+    """Standalone fixer and validator for text and Python code."""
+
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        forbidden_patterns: Iterable[re.Pattern[str]] | None = None,
+        *,
+        physical_patterns: Iterable[re.Pattern[str]] | None = None,
+        strip_atom_references: bool = True,
+        strip_physical_references: bool = True,
+    ):
+        self.forbidden_patterns = tuple(forbidden_patterns or DEFAULT_FORBIDDEN_PATTERNS)
+        self.physical_patterns = tuple(physical_patterns or DEFAULT_PHYSICAL_PATTERNS)
+        self.strip_atom_references = strip_atom_references
+        self.strip_physical_references_enabled = strip_physical_references
+
+    def clean_description(self, text: str) -> str:
+        """Repair common spelling/punctuation noise in descriptive text."""
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+
+        for wrong_pattern, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong_pattern.sub(right, cleaned)
+
+        lines = [self._normalize_line(line) for line in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        line = re.sub(r"\s+", " ", line).strip()
+        return line
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        total_removed = 0
+        for pattern in patterns:
+            updated, count = pattern.subn("", updated)
+            total_removed += count
+        updated = re.sub(r"[ \t]{2,}", " ", updated).strip()
+        return updated, total_removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        total_removed = 0
+        for pattern in patterns:
+            updated, count = pattern.subn("", updated)
+            total_removed += count
+
+        normalized_lines: list[str] = []
+        for line in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n"):
+            indent_match = re.match(r"^[ \t]*", line)
+            indent = indent_match.group(0) if indent_match else ""
+            content = line[len(indent):]
+            content = re.sub(r"[ \t]{2,}", " ", content).strip()
+            normalized_lines.append(indent + content if content else "")
+
+        updated = "\n".join(normalized_lines)
+        updated = re.sub(r"\n{3,}", "\n\n", updated)
+        return updated.rstrip() + "\n", total_removed
+
+    def strip_forbidden_atom_references(self, text: str) -> tuple[str, int]:
+        """Remove references to Atom-Hydrogen/Atom-Carbon related terms."""
+        if not self.strip_atom_references:
+            return text, 0
+        return self._strip_patterns_block(text, self.forbidden_patterns)
+
+    def strip_physical_references(self, text: str) -> tuple[str, int]:
+        """Remove physical-domain references (physiology/chemistry/anatomy/etc.)."""
+        if not self.strip_physical_references_enabled:
+            return text, 0
+        return self._strip_patterns_block(text, self.physical_patterns)
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        """Sanitize Python COMMENT tokens, preserving executable code tokens."""
+        removed_total = 0
+        out_tokens: list[tokenize.TokenInfo] = []
+
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment_text = tok.string
+                cleaned = comment_text
+                removed = 0
+
+                if self.strip_physical_references_enabled:
+                    cleaned, physical_removed = self._strip_patterns_inline(cleaned, self.physical_patterns)
+                    removed += physical_removed
+                if self.strip_atom_references:
+                    cleaned, atom_removed = self._strip_patterns_inline(cleaned, self.forbidden_patterns)
+                    removed += atom_removed
+
+                if not cleaned.startswith("#"):
+                    cleaned = f"# {cleaned}" if cleaned else "#"
+
+                tok = tokenize.TokenInfo(tok.type, cleaned, tok.start, tok.end, tok.line)
+                removed_total += removed
+
+            out_tokens.append(tok)
+
+        rebuilt = tokenize.untokenize(out_tokens)
+        return rebuilt.rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        """Apply safe formatting cleanup that does not alter behavior."""
+        code = code.replace("\r\n", "\n").replace("\r", "\n")
+        lines = [line.rstrip().replace("\t", "    ") for line in code.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        """Return syntax issues found in Python code."""
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [
+                Issue(
+                    kind="syntax",
+                    message=exc.msg,
+                    line=exc.lineno,
+                    column=exc.offset,
+                )
+            ]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        """Clean and validate Python code, sanitizing comment tokens only."""
+        repaired = self.clean_python_formatting(code)
+        repaired, removed = self.sanitize_python_comments(repaired)
+        issues = self.validate_python_syntax(repaired)
+        return repaired, issues, removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        """Clean descriptive text and strip configured references."""
+        cleaned = self.clean_description(text)
+        cleaned, removed_atom = self.strip_forbidden_atom_references(cleaned)
+        cleaned, removed_physical = self.strip_physical_references(cleaned)
+        return cleaned, removed_atom + removed_physical
+
+
+TEXT_SUFFIXES = {
+    ".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg",
+    ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs",
+    ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml",
+}
+
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    if requested_mode != "auto":
+        return requested_mode
+    return "python" if path.suffix == ".py" else "text"
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts):
+            continue
+        if not path.is_file():
+            continue
+
+        relative = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(relative, include):
+            continue
+        if exclude and fnmatch.fnmatch(relative, exclude):
+            continue
+
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(engine: AtomRepairEngine, path: Path, mode: str, check_only: bool) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        issues.append(Issue(kind="encoding", message="non-utf8 file skipped"))
+        return FileResult(path=path, changed=False, removed_references=0, issues=tuple(issues))
+    except OSError as exc:
+        issues.append(Issue(kind="io", message=f"read failed: {exc}"))
+        return FileResult(path=path, changed=False, removed_references=0, issues=tuple(issues))
+
+    detected_mode = _detect_mode(path, mode)
+    if detected_mode == "python":
+        fixed, syntax_issues, removed = engine.repair_python_code(source)
+        issues.extend(syntax_issues)
+    else:
+        fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    if changed and not check_only:
+        try:
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue(kind="io", message=f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path=path, changed=changed, removed_references=removed, issues=tuple(issues))
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path, help="File or directory to process")
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--check-only", action="store_true", help="Do not write changes")
+    parser.add_argument("--no-strip-atom-refs", action="store_true", help="Disable Atom ref removal")
+    parser.add_argument("--no-strip-physical-refs", action="store_true", help="Disable physical-domain ref removal")
+    parser.add_argument("--fail-on-change", action="store_true", help="Exit non-zero if changes are needed")
+    parser.add_argument("--exclude", default="", help="Exclude glob when path is a directory")
+    parser.add_argument(
+        "--include",
+        default="*",
+        help="Glob for relative file paths when path is a directory (default: '*')",
+    )
+
+    args = parser.parse_args(argv)
+    engine = AtomRepairEngine(
+        strip_atom_references=not args.no_strip_atom_refs,
+        strip_physical_references=not args.no_strip_physical_refs,
+    )
+
+    results: list[FileResult] = []
+    if args.path.is_file():
+        results.append(process_file(engine, args.path, args.mode, args.check_only))
+    else:
+        for file_path in _iter_target_files(args.path, args.include, args.exclude):
+            results.append(process_file(engine, file_path, args.mode, args.check_only))
+
+    changed_count = sum(1 for result in results if result.changed)
+    removed_count = sum(result.removed_references for result in results)
+    issue_count = sum(len(result.issues) for result in results)
+
+    for result in results:
+        if result.changed:
+            status = "would update" if args.check_only else "updated"
+            print(f"{status}: {result.path}")
+        if result.removed_references:
+            print(f"removed {result.removed_references} reference(s): {result.path}")
+        for issue in result.issues:
+            print(f"[{issue.kind}] {result.path}:{issue.line}:{issue.column} {issue.message}")
+
+    print(
+        "Summary: "
+        f"files={len(results)} changed={changed_count} "
+        f"refs_removed={removed_count} issues={issue_count}"
+    )
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed_count:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..39f116f6aaccee4aa6fd4d8210ea070091000ef4
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,81 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def setUp(self):
+        self.engine = AtomRepairEngine()
+
+    def test_clean_description_repairs_common_noise(self):
+        raw = "This is teh descripting text,, with   extra   spaces..."
+        cleaned = self.engine.clean_description(raw)
+        self.assertEqual(cleaned, "This is the descriptive text, with extra spaces.\n")
+
+    def test_clean_description_respects_word_boundaries(self):
+        raw = "The word technical must stay; cathedral should not change."
+        cleaned = self.engine.clean_description(raw)
+        self.assertIn("technical", cleaned)
+
+    def test_repair_python_code_preserves_strings_and_sanitizes_comments(self):
+        raw = (
+            "x = 'physical'\n"
+            "# physiology and Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn 1  # chemistry and compounds\n"
+        )
+        repaired, issues, removed = self.engine.repair_python_code(raw)
+        self.assertIn("x = 'physical'", repaired)
+        self.assertIn("#", repaired)
+        self.assertIn("    return 1", repaired)
+        self.assertNotIn("chemistry", repaired.lower())
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_validate_python_syntax_reports_error(self):
+        issues = self.engine.validate_python_syntax("def bad(:\n    pass\n")
+        self.assertEqual(len(issues), 1)
+        self.assertEqual(issues[0].kind, "syntax")
+
+    def test_strip_physical_references_in_text(self):
+        raw = "This includes physiology, chemistry, compounds, and anatomy."
+        cleaned, removed = self.engine.strip_physical_references(raw)
+        self.assertGreaterEqual(removed, 4)
+        lowered = cleaned.lower()
+        self.assertNotIn("physiology", lowered)
+        self.assertNotIn("chemistry", lowered)
+
+    def test_process_file_handles_non_utf8(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            path = Path(tmp) / "bad.txt"
+            path.write_bytes(b"\xff\xfe\x00")
+            result = process_file(self.engine, path, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+    def test_cli_no_strip_physical_refs(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            path = Path(tmp) / "doc.txt"
+            path.write_text("physical chemistry", encoding="utf-8")
+            rc = run_cli([str(path), "--mode", "text", "--no-strip-physical-refs"])
+            self.assertEqual(rc, 0)
+            self.assertIn("physical", path.read_text(encoding="utf-8"))
+
+    def test_cli_directory_exclude_glob(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "keep.txt"
+            b = root / "skip.md"
+            a.write_text("chemistry", encoding="utf-8")
+            b.write_text("chemistry", encoding="utf-8")
+
+            rc = run_cli([str(root), "--mode", "text", "--exclude", "*.md"])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("chemistry", a.read_text(encoding="utf-8").lower())
+            self.assertIn("chemistry", b.read_text(encoding="utf-8").lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
# Atom_Offline.ps1
# Blocks outbound network traffic for Atom (atom.exe). Run as Administrator.

$ErrorActionPreference = "Stop"
$ruleName = "Block Atom Outbound"

$paths = @(
  "$env:ProgramFiles\Atom\atom.exe",
  "${env:ProgramFiles(x86)}\Atom\atom.exe"
)
$atomExe = ($paths | Where-Object { Test-Path $_ } | Select-Object -First 1)
if (-not $atomExe) { $atomExe = "atom.exe" }  # fallback to PATH

if (-not (Get-NetFirewallRule -DisplayName $ruleName -ErrorAction SilentlyContinue)) {
  New-NetFirewallRule -DisplayName $ruleName -Direction Outbound -Action Block -Program $atomExe | Out-Null
  Write-Host "‚úÖ Created rule: $ruleName ($atomExe)"
} else {
  Write-Host "‚ÑπÔ∏è Rule already exists: $ruleName"
}

Write-Host "Verify:"
Get-NetFirewallRule -DisplayName $ruleName | Format-List DisplayName,Enabled,Direction,Action
# Atom_py_Offline.ps1
# Blocks outbound traffic for the Python interpreter used to run Atom.py.
# Run as Administrator.

$ErrorActionPreference = "Stop"

# EDIT these to the exact python.exe used for Atom.py
$pythonCandidates = @(
  "C:\Path\To\Atom.py\venv\Scripts\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python312\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python311\python.exe"
)

$pythonExe = ($pythonCandidates | Where-Object { Test-Path $_ } | Select-Object -First 1)
if (-not $pythonExe) { $pythonExe = "python.exe" } # fallback, less precise

$ruleName = "Block Atom.py (Python) Outbound"

if (-not (Get-NetFirewallRule -DisplayName $ruleName -ErrorAction SilentlyContinue)) {
  New-NetFirewallRule -DisplayName $ruleName -Direction Outbound -Action Block -Program $pythonExe | Out-Null
  Write-Host "‚úÖ Created rule: $ruleName ($pythonExe)"
} else {
  Write-Host "‚ÑπÔ∏è Rule already exists: $ruleName"
}

Write-Host "Verify:"
Get-NetFirewallRule -DisplayName $ruleName | Format-List DisplayName,Enabled,Direction,Action
# Atom_Hydrogen_Offline.ps1
# Blocks outbound for Atom + Hydrogen-related kernel executables (Python/Jupyter/Node).
# Run as Administrator.

$ErrorActionPreference = "Stop"

function Ensure-BlockRule($name, $programPath) {
  if (-not $programPath) { return }
  if (-not (Get-NetFirewallRule -DisplayName $name -ErrorAction SilentlyContinue)) {
    New-NetFirewallRule -DisplayName $name -Direction Outbound -Action Block -Program $programPath | Out-Null
    Write-Host "‚úÖ Created rule: $name ($programPath)"
  } else {
    Write-Host "‚ÑπÔ∏è Rule exists: $name"
  }
}

# --- Atom executable ---
$atomPaths = @(
  "$env:ProgramFiles\Atom\atom.exe",
  "${env:ProgramFiles(x86)}\Atom\atom.exe"
)
$atomExe = ($atomPaths | Where-Object { Test-Path $_ } | Select-Object -First 1)
if (-not $atomExe) { $atomExe = "atom.exe" }

# --- Kernel executables (EDIT for your environment / venvs) ---
$pythonCandidates = @(
  "C:\Path\To\Your\KernelVenv\Scripts\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python312\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python311\python.exe"
)
$jupyterCandidates = @(
  "C:\Path\To\Your\KernelVenv\Scripts\jupyter.exe",
  "C:\Path\To\Your\KernelVenv\Scripts\jupyter-notebook.exe",
  "C:\Path\To\Your\KernelVenv\Scripts\jupyter-lab.exe"
)
$nodeCandidates = @(
  "$env:ProgramFiles\nodejs\node.exe",
  "${env:ProgramFiles(x86)}\nodejs\node.exe"
)

$pythonExe  = ($pythonCandidates  | Where-Object { Test-Path $_ } | Select-Object -First 1)
$jupyterExe = ($jupyterCandidates | Where-Object { Test-Path $_ } | Select-Object -First 1)
$nodeExe    = ($nodeCandidates    | Where-Object { Test-Path $_ } | Select-Object -First 1)

Ensure-BlockRule "Block Atom Outbound (Hydrogen Profile)" $atomExe
Ensure-BlockRule "Block Hydrogen Kernel Python Outbound"  ($pythonExe  ? $pythonExe  : "python.exe")
if ($jupyterExe) { Ensure-BlockRule "Block Hydrogen Jupyter Outbound" $jupyterExe }
if ($nodeExe)    { Ensure-BlockRule "Block Hydrogen Node Outbound"   $nodeExe }

Write-Host "`nVerify created rules:"
Get-NetFirewallRule -DisplayName "Block Atom Outbound (Hydrogen Profile)","Block Hydrogen Kernel Python Outbound","Block Hydrogen Jupyter Outbound","Block Hydrogen Node Outbound" `
  -ErrorAction SilentlyContinue | Format-Table DisplayName,Enabled,Direction,Action -AutoSize
  Get-NetFirewallRule -DisplayName "Block Atom Outbound","Block Atom.py (Python) Outbound","Block Atom Outbound (Hydrogen Profile)","Block Hydrogen Kernel Python Outbound","Block Hydrogen Jupyter Outbound","Block Hydrogen Node Outbound" `
  -ErrorAction SilentlyContinue | Remove-NetFirewallRule
  # Redact_Terms_CopyOnly.ps1
# Creates redacted copies under .\redacted_output\ (no in-place edits).

$ErrorActionPreference = "Stop"
$sourceRoot = "C:\Path\To\Atom.py"   # EDIT (or point to your .atom/packages/hydrogen folder)
$outRoot = Join-Path (Get-Location) "redacted_output"
New-Item -ItemType Directory -Path $outRoot -Force | Out-Null

# Terms to redact (EDIT freely)
$terms = @(
  "magic","spell","spells","hex","hexes","curse","curses",
  "master","masters","god","gods","deity","deities",
  "physics","chemistry","quantum","nuclear","atomic"
)

$exts = @(".txt",".md",".cson",".json",".yml",".yaml",".ini",".cfg",".log",".py",".js",".ts",".rb")

Get-ChildItem -Path $sourceRoot -Recurse -File | Where-Object { $exts -contains $_.Extension.ToLower() } | ForEach-Object {
  $rel = $_.FullName.Substring($sourceRoot.Length).TrimStart("\","/")
  $dest = Join-Path $outRoot $rel
  New-Item -ItemType Directory -Path (Split-Path $dest -Parent) -Force | Out-Null

  $content = Get-Content $_.FullName -Raw -ErrorAction SilentlyContinue
  if ($null -eq $content) { return }

  foreach ($t in $terms) {
    $pattern = "(?i)\b" + [Regex]::Escape($t) + "\b"
    $content = [Regex]::Replace($content, $pattern, "[REDACTED]")
  }

  Set-Content -Path $dest -Value $content -Encoding UTF8
}

Write-Host "‚úÖ Redacted copies written to: $outRoot"
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..2e35abf26b3e24038052698bb8155fa2030e0072
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,346 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+This module provides long-lived, configurable sanitization for technical projects.
+It supports separate profiles for:
+- Atom
+- Atom-Hydrogen
+- Atom-Carbon
+
+Each profile can remove problematic language in text and Python comments while
+preserving executable Python tokens.
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import io
+import re
+import tokenize
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+# Global technical-hygiene targets.
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+PROGRAM_PATTERNS: dict[str, tuple[re.Pattern[str], ...]] = {
+    "atom": (
+        re.compile(r"\batom(?:\.py)?\b", re.IGNORECASE),
+    ),
+    "atom-hydrogen": (
+        re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),
+    ),
+    "atom-carbon": (
+        re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),
+    ),
+}
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\bblood\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+
+
+class AtomRepairEngine:
+    """Adaptive sanitizer for text files and Python comments."""
+
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        program: str = "atom",
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+    ):
+        if program not in PROGRAM_PATTERNS:
+            raise ValueError(f"unknown program profile: {program}")
+
+        self.program = program
+        self.program_patterns = PROGRAM_PATTERNS[program]
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        return PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            hits = sum(1 for p in patterns if p.search(text))
+            if hits >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong_pattern, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong_pattern.sub(right, cleaned)
+
+        lines = [self._normalize_line(line) for line in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        line = re.sub(r"\s+", " ", line).strip()
+        return line
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, count = pattern.subn("", updated)
+            removed += count
+        updated = re.sub(r"[ \t]{2,}", " ", updated).strip()
+        return updated, removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = []
+        for line in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n"):
+            lines.append(self._normalize_line(line))
+        collapsed = re.sub(r"\n{3,}", "\n\n", "\n".join(lines))
+        return collapsed.rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.program_patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        patterns = self._patterns_for_content(text)
+        return self._strip_patterns_block(text, patterns)
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out_tokens: list[tokenize.TokenInfo] = []
+
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+
+                if self.strip_problematic_refs:
+                    comment, count = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += count
+                if self.strip_program_refs:
+                    comment, count = self._strip_patterns_inline(comment, self.program_patterns)
+                    removed += count
+
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+
+            out_tokens.append(tok)
+
+        rebuilt = tokenize.untokenize(out_tokens)
+        return rebuilt.rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        code = code.replace("\r\n", "\n").replace("\r", "\n")
+        lines = [line.rstrip().replace("\t", "    ") for line in code.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue(kind="syntax", message=exc.msg, line=exc.lineno, column=exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        repaired = self.clean_python_formatting(code)
+        repaired, removed = self.sanitize_python_comments(repaired)
+        issues = self.validate_python_syntax(repaired)
+        return repaired, issues, removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, removed_program = self.strip_program_references(cleaned)
+        cleaned, removed_problematic = self.strip_problematic_references(cleaned)
+        return cleaned, removed_program + removed_problematic
+
+
+TEXT_SUFFIXES = {
+    ".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg",
+    ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs",
+    ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml",
+}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    if requested_mode != "auto":
+        return requested_mode
+    return "python" if path.suffix == ".py" else "text"
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts):
+            continue
+        if not path.is_file():
+            continue
+
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(engine: AtomRepairEngine, path: Path, mode: str, check_only: bool) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        issues.append(Issue(kind="encoding", message="non-utf8 file skipped"))
+        return FileResult(path=path, changed=False, removed_references=0, issues=tuple(issues))
+    except OSError as exc:
+        issues.append(Issue(kind="io", message=f"read failed: {exc}"))
+        return FileResult(path=path, changed=False, removed_references=0, issues=tuple(issues))
+
+    detected_mode = _detect_mode(path, mode)
+    if detected_mode == "python":
+        fixed, syntax_issues, removed = engine.repair_python_code(source)
+        issues.extend(syntax_issues)
+    else:
+        fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    if changed and not check_only:
+        try:
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue(kind="io", message=f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path=path, changed=changed, removed_references=removed, issues=tuple(issues))
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path, help="File or directory to process")
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-hydrogen", "atom-carbon"], default="atom")
+    parser.add_argument("--check-only", action="store_true", help="Do not write changes")
+    parser.add_argument("--no-strip-program-refs", action="store_true", help="Disable target program ref removal")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true", help="Disable physical/mystical/hierarchy ref removal")
+    parser.add_argument("--no-adaptive", action="store_true", help="Disable adaptive pattern expansion")
+    parser.add_argument("--fail-on-change", action="store_true", help="Exit non-zero if changes are needed")
+    parser.add_argument("--exclude", default="", help="Exclude glob when path is a directory")
+    parser.add_argument("--include", default="*", help="Include glob when path is a directory")
+
+    args = parser.parse_args(argv)
+    engine = AtomRepairEngine(
+        program=args.program,
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+    )
+
+    results: list[FileResult] = []
+    if args.path.is_file():
+        results.append(process_file(engine, args.path, args.mode, args.check_only))
+    else:
+        for fp in _iter_target_files(args.path, args.include, args.exclude):
+            results.append(process_file(engine, fp, args.mode, args.check_only))
+
+    changed_count = sum(1 for r in results if r.changed)
+    removed_count = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+
+    for result in results:
+        if result.changed:
+            status = "would update" if args.check_only else "updated"
+            print(f"{status}: {result.path}")
+        if result.removed_references:
+            print(f"removed {result.removed_references} reference(s): {result.path}")
+        for issue in result.issues:
+            print(f"[{issue.kind}] {result.path}:{issue.line}:{issue.column} {issue.message}")
+
+    print(
+        f"Summary: files={len(results)} changed={changed_count} refs_removed={removed_count} "
+        f"issues={issue_count} program={args.program} adaptive={not args.no_adaptive}"
+    )
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed_count:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..94d67c621aefa1c988365e749ae422b1d352f082
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,85 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(program="atom")
+        hydrogen_engine = AtomRepairEngine(program="atom-hydrogen")
+        carbon_engine = AtomRepairEngine(program="atom-carbon")
+
+        text = "Atom.py Atom-Hydrogen Atom-Carbon"
+        cleaned_atom, _ = atom_engine.strip_program_references(text)
+        cleaned_h, _ = hydrogen_engine.strip_program_references(text)
+        cleaned_c, _ = carbon_engine.strip_program_references(text)
+
+        self.assertNotIn("Atom.py", cleaned_atom)
+        self.assertNotIn("Atom-Hydrogen", cleaned_h)
+        self.assertNotIn("Atom-Carbon", cleaned_c)
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(program="atom")
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+        self.assertNotIn("spell", cleaned.lower())
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(program="atom-hydrogen")
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_adaptive_mode(self):
+        engine = AtomRepairEngine(program="atom", adaptive=True)
+        cleaned, removed = engine.repair_text("chemistry physiology transmutation")
+        self.assertGreaterEqual(removed, 3)
+        self.assertNotIn("transmutation", cleaned.lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(program="atom")
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program",
+                "atom-hydrogen",
+                "--exclude",
+                "*.md",
+                "--mode",
+                "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+
+if __name__ == "__main__":
+    unittest.main()
powershell -ExecutionPolicy Bypass -File .\AtomGuardian.ps1 -Once
# Or continuous loop:
powershell -ExecutionPolicy Bypass -File .\AtomGuardian.ps1 -Loop -IntervalSeconds 300
param(
  [switch]$Once,
  [switch]$Loop,
  [int]$IntervalSeconds = 300
)

$ErrorActionPreference = "Stop"

# -------------------------
# Paths / targets (edit these if your names differ)
# -------------------------
$Home = $env:USERPROFILE
$AtomHome = if ($env:ATOM_HOME) { $env:ATOM_HOME } else { Join-Path $Home ".atom" }
$AtomAppData = Join-Path $env:LOCALAPPDATA "atom"

# Atom variants you mentioned (edit to actual exe paths if you have them)
$AtomExeCandidates = @(
  "$env:ProgramFiles\Atom\atom.exe",
  "${env:ProgramFiles(x86)}\Atom\atom.exe",
  "atom.exe"
)

# If "Atom-Carbon" is a separate build, add its exe path here:
$AtomCarbonExeCandidates = @(
  "$env:ProgramFiles\Atom-Carbon\atom-carbon.exe",
  "${env:ProgramFiles(x86)}\Atom-Carbon\atom-carbon.exe",
  "atom-carbon.exe"
)

# Atom.py: point to the python interpreter used for Atom.py if applicable
$AtomPyPythonCandidates = @(
  "C:\Path\To\Atom.py\venv\Scripts\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python312\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python311\python.exe",
  "python.exe"
)

# Hydrogen kernel tools (optional but helpful)
$JupyterCandidates = @(
  "C:\Path\To\KernelVenv\Scripts\jupyter.exe",
  "jupyter.exe"
)

# Logging
$Stamp = (Get-Date).ToString("yyyy-MM-dd_HH-mm-ss")
$LogDir = Join-Path $Home "AtomGuardianLogs"
New-Item -ItemType Directory -Path $LogDir -Force | Out-Null
$LogPath = Join-Path $LogDir "atom-guardian_$Stamp.log"

function Log($m) {
  $line = "[{0}] {1}" -f (Get-Date).ToString("s"), $m
  $line | Tee-Object -FilePath $LogPath -Append
}

function FirstExisting($candidates) {
  foreach ($c in $candidates) {
    if ($c -match "^[A-Za-z]:\\") {
      if (Test-Path $c) { return $c }
    } else {
      # name on PATH; return as-is
      return $c
    }
  }
  return $null
}

function DirSizeMB($p) {
  if (!(Test-Path $p)) { return 0 }
  try {
    $bytes = (Get-ChildItem -Path $p -Recurse -File -ErrorAction SilentlyContinue | Measure-Object -Property Length -Sum).Sum
    if ($null -eq $bytes) { return 0 }
    return [Math]::Round($bytes / 1MB, 1)
  } catch { return 0 }
}

function Find-Apm {
  $candidates = @("apm.cmd","apm")
  $pf = $env:ProgramFiles
  $pf86 = ${env:ProgramFiles(x86)}
  if ($pf)  { $candidates += (Join-Path $pf  "Atom\resources\app\apm\bin\apm.cmd") }
  if ($pf86){ $candidates += (Join-Path $pf86 "Atom\resources\app\apm\bin\apm.cmd") }
  foreach ($c in $candidates) {
    try { & $c --version *> $null; if ($LASTEXITCODE -eq 0) { return $c } } catch {}
  }
  return $null
}

function Backup-AtomHome {
  if (!(Test-Path $AtomHome)) { return $null }
  $backupRoot = Join-Path $Home "AtomGuardianBackups"
  New-Item -ItemType Directory -Path $backupRoot -Force | Out-Null
  $bdir = Join-Path $backupRoot ("backup_" + (Get-Date).ToString("yyyy-MM-dd_HH-mm-ss"))
  Copy-Item $AtomHome -Destination $bdir -Recurse -Force
  Log "Backup created: $bdir"
  return $bdir
}

function Clean-Caches {
  $targets = @(
    (Join-Path $AtomHome "compile-cache"),
    (Join-Path $AtomHome "storage"),
    (Join-Path $AtomHome "blob-store"),
    (Join-Path $AtomHome ".apm\.cache"),
    (Join-Path $AtomAppData "Cache"),
    (Join-Path $AtomAppData "Code Cache"),
    (Join-Path $AtomAppData "GPUCache"),
    (Join-Path $AtomAppData "DawnCache"),
    (Join-Path $AtomAppData "Local Storage"),
    (Join-Path $AtomAppData "Session Storage")
  ) | Where-Object { $_ -and (Test-Path $_) }

  foreach ($t in $targets) {
    try { Remove-Item $t -Recurse -Force; Log "Removed cache/state: $t" }
    catch { Log "WARN: Could not remove (locked): $t" }
  }
  if ($targets.Count -eq 0) { Log "No known cache dirs to remove." }
}

function Read-Config {
  $cfg = Join-Path $AtomHome "config.cson"
  if (!(Test-Path $cfg)) { return @{ Path=$cfg; Text="" } }
  return @{ Path=$cfg; Text=(Get-Content $cfg -Raw) }
}

function Write-Config($path, $text) {
  Set-Content -Path $path -Value $text -Encoding UTF8
}

function Get-InstalledPackages {
  $apm = Find-Apm
  if (-not $apm) { return @{ apm=$null; packages=@() } }
  $out = & $apm list --installed --bare 2>$null
  $pkgs = @()
  foreach ($line in ($out -split "`r?`n")) {
    $line = $line.Trim()
    if ($line) {
      $parts = $line.Split("@")
      $pkgs += [PSCustomObject]@{ name=$parts[0]; version=($parts[1] ?? "") }
    }
  }
  return @{ apm=$apm; packages=$pkgs }
}

function Heuristic-Risky($name) {
  $exact = @(
    "teletype","atom-ide-ui","platformio-ide-terminal","languageclient",
    "linter","linter-ui-default","busy-signal","minimap","file-icons",
    "atom-beautify","git-plus"
  )
  if ($exact -contains $name) { return $true }
  if ($name -match "^(ide-)" ) { return $true }
  if ($name -match "linter|minimap|terminal|autocomplete|languageclient") { return $true }
  return $false
}

function Disable-RiskyPackages {
  if (!(Test-Path $AtomHome)) { return }
  $cfg = Read-Config
  $text = $cfg.Text

  # Parse existing disabledPackages block crudely (safe-ish)
  $disabled = New-Object System.Collections.Generic.HashSet[string]
  if ($text -match "disabledPackages\s*:\s*\[([\s\S]*?)\]") {
    $body = $Matches[1]
    foreach ($m in ([regex]::Matches($body, "['""]([^'""]+)['""]"))) {
      [void]$disabled.Add($m.Groups[1].Value)
    }
  }

  $pkgInfo = Get-InstalledPackages
  $risky = @($pkgInfo.packages | Where-Object { Heuristic-Risky $_.name } | Select-Object -ExpandProperty name -Unique)
  foreach ($p in $risky) { [void]$disabled.Add($p) }

  $newBlock = "disabledPackages: [`n" + (($disabled | Sort-Object) | ForEach-Object { "  `"$($_)`"" } | Out-String) + "]"
  if ($text -match "disabledPackages\s*:\s*\[[\s\S]*?\]") {
    $text = [regex]::Replace($text, "disabledPackages\s*:\s*\[[\s\S]*?\]", $newBlock)
  } else {
    $text += "`n`n# Added by AtomGuardian $(Get-Date -Format s)`n$newBlock`n"
  }

  $b = Backup-AtomHome
  Write-Config $cfg.Path $text
  Log "Disabled risky packages (count: $($disabled.Count)). Backup: $b"
}

function Ensure-BaselineConfig {
  if (!(Test-Path $AtomHome)) { New-Item -ItemType Directory -Path $AtomHome -Force | Out-Null }
  $cfgPath = Join-Path $AtomHome "config.cson"

  if (Test-Path $cfgPath) {
    # Don‚Äôt overwrite; just ensure a baseline marker exists
    $t = Get-Content $cfgPath -Raw
    if ($t -match "# AtomGuardian Baseline") { Log "Baseline marker already present."; return }
    $b = Backup-AtomHome
    Add-Content -Path $cfgPath -Value "`n`n# AtomGuardian Baseline`n" -Encoding UTF8
    Add-Content -Path $cfgPath -Value '"core".restorePreviousWindowsOnStart: "no"' -Encoding UTF8
    Add-Content -Path $cfgPath -Value "`n" -Encoding UTF8
    Add-Content -Path $cfgPath -Value '"core".useTreeSitterParsers: true' -Encoding UTF8
    Add-Content -Path $cfgPath -Value "`n" -Encoding UTF8
    Add-Content -Path $cfgPath -Value '"core".fileEncoding: "utf8"' -Encoding UTF8
    Add-Content -Path $cfgPath -Value "`n" -Encoding UTF8
    Log "Baseline additions appended (non-destructive). Backup: $b"
  } else {
    $b = Backup-AtomHome
    @'
"*":
  core:
    # AtomGuardian Baseline
    restorePreviousWindowsOnStart: "no"
    useTreeSitterParsers: true
    fileEncoding: "utf8"
    automaticallyUpdate: false
    telemetryConsent: "no"
'@ | Set-Content -Path $cfgPath -Encoding UTF8
    Log "Baseline config created. Backup: $b"
  }
}

function Apm-RebuildIfPossible {
  $apm = Find-Apm
  if (-not $apm) { Log "apm not found; skipping rebuild."; return }
  Log "Running apm rebuild..."
  try { & $apm rebuild *>> $LogPath; Log "apm rebuild complete." }
  catch { Log "WARN: apm rebuild failed (non-fatal)." }
}

function Score-Risk {
  $reasons = New-Object System.Collections.Generic.List[string]
  $score = 0

  # Cache bloat indicators (predict crash/freeze likelihood)
  $cc = DirSizeMB (Join-Path $AtomHome "compile-cache")
  $st = DirSizeMB (Join-Path $AtomHome "storage")
  $gpu = DirSizeMB (Join-Path $AtomAppData "GPUCache")

  if ($cc -gt 300) { $score += 20; $reasons.Add("compile-cache is large (${cc}MB)") }
  if ($st -gt 300) { $score += 20; $reasons.Add("storage is large (${st}MB)") }
  if ($gpu -gt 300){ $score += 15; $reasons.Add("GPUCache is large (${gpu}MB)") }

  # Disk pressure
  $drive = Get-PSDrive -Name ([IO.Path]::GetPathRoot($Home).TrimEnd('\')) -ErrorAction SilentlyContinue
  if ($drive) {
    $freeGB = [Math]::Round($drive.Free/1GB, 1)
    if ($freeGB -lt 10) { $score += 25; $reasons.Add("low disk free space (${freeGB}GB)") }
  }

  # Package overlap risk
  $pkgInfo = Get-InstalledPackages
  $risky = @($pkgInfo.packages | Where-Object { Heuristic-Risky $_.name })
  if ($risky.Count -ge 10) { $score += 20; $reasons.Add("many heavy packages enabled (${risky.Count})") }
  elseif ($risky.Count -ge 5) { $score += 10; $reasons.Add("some heavy packages enabled (${risky.Count})") }

  # Hydrogen readiness checks (predict kernel failures)
  $py = FirstExisting($AtomPyPythonCandidates)
  $jp = FirstExisting($JupyterCandidates)
  if (-not $py) { $score += 10; $reasons.Add("python not found for Atom.py/Hydrogen kernels") }
  if (-not $jp) { $score += 5; $reasons.Add("jupyter not found (Hydrogen may fail to start kernels)") }

  # Running process health
  $atomProc = Get-Process -Name atom -ErrorAction SilentlyContinue
  if ($atomProc) {
    $wsMB = [Math]::Round(($atomProc | Measure-Object -Property WorkingSet64 -Sum).Sum / 1MB, 0)
    if ($wsMB -gt 2500) { $score += 15; $reasons.Add("Atom memory footprint high (~${wsMB}MB)") }
  }

  if ($score -gt 100) { $score = 100 }
  return @{ score=$score; reasons=$reasons }
}

function Recommend-AndHeal {
  Log "Assessing risk..."
  $risk = Score-Risk
  Log ("Risk score: {0}/100" -f $risk.score)
  foreach ($r in $risk.reasons) { Log "  - $r" }

  # Gentle autoplan
  if ($risk.score -ge 60) {
    Log "Action: HIGH RISK -> backup + cache clean + baseline config + disable risky + apm rebuild"
    Backup-AtomHome | Out-Null
    Clean-Caches
    Ensure-BaselineConfig
    Disable-RiskyPackages
    Apm-RebuildIfPossible
    Log "Suggested test launch modes: atom --safe ; atom --disable-gpu ; atom --clear-window-state"
  }
  elseif ($risk.score -ge 30) {
    Log "Action: MEDIUM RISK -> backup + cache clean + baseline config"
    Backup-AtomHome | Out-Null
    Clean-Caches
    Ensure-BaselineConfig
    Log "Suggested test launch: atom --safe"
  }
  else {
    Log "Action: LOW RISK -> no changes. Monitoring only."
  }

  # Always write a short summary
  Log "Guardian cycle complete."
}

# -------------------------
# Main
# -------------------------
Log "=== AtomGuardian start ==="
Log "AtomHome: $AtomHome"
Log "AtomAppData: $AtomAppData"

if ($Once -or (-not $Loop)) {
  Recommend-AndHeal
  Log "Log saved: $LogPath"
  exit 0
}

while ($true) {
  try { Recommend-AndHeal }
  catch { Log "ERROR: $($_.Exception.Message)" }
  Start-Sleep -Seconds $IntervalSeconds
}
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..36463b372f23d2df6f520ce7ef9badd852d98757
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,353 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import io
+import re
+import tokenize
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        return PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(engine: AtomRepairEngine, path: Path, mode: str, check_only: bool) -> FileResult:
+    return _process(path, mode, check_only, engine=engine, suite=None, intertwined=False)
+
+
+def _process(path: Path, mode: str, check_only: bool, *, engine: AtomRepairEngine | None, suite: AtomSystemSuite | None, intertwined: bool) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),))
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),))
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    if changed and not check_only:
+        try:
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues))
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+    )
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(_process(target, args.mode, args.check_only, engine=engine, suite=suite, intertwined=intertwined))
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..99714304d63edd701affc9dc4b72dc20e170dc60
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,89 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen chemistry")
+        self.assertGreaterEqual(removed, 4)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon spell", encoding="utf-8")
+            rc = run_cli([str(f), "--program", "all", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
powershell -ExecutionPolicy Bypass -File .\AethaliumGuardian.ps1 -Once
# Or continuous:
powershell -ExecutionPolicy Bypass -File .\AethaliumGuardian.ps1 -Loop -IntervalSeconds 300
param(
  [switch]$Once,
  [switch]$Loop,
  [int]$IntervalSeconds = 300,
  [switch]$Heal,              # force a heal cycle regardless of score
  [switch]$DryRun             # show planned actions without changing anything
)

$ErrorActionPreference = "Stop"

# -------------------------
# ‚ú¶ A E T H A L I U M ‚ú¶  ‚Äî soft-glow logging
# -------------------------
function Glow($msg, $kind="info") {
  $ts = (Get-Date).ToString("s")
  switch ($kind) {
    "ok"   { Write-Host "[$ts] ‚ú® $msg" -ForegroundColor Green }
    "warn" { Write-Host "[$ts] ‚ö†  $msg" -ForegroundColor Yellow }
    "bad"  { Write-Host "[$ts] ‚úñ  $msg" -ForegroundColor Red }
    "rit"  { Write-Host "[$ts] ‚ùñ $msg" -ForegroundColor Cyan }
    default{ Write-Host "[$ts] ¬∑  $msg" -ForegroundColor Gray }
  }
}

# -------------------------
# Paths / identities (edit to taste)
# -------------------------
$Home = $env:USERPROFILE
$AtomHome = if ($env:ATOM_HOME) { $env:ATOM_HOME } else { Join-Path $Home ".atom" }
$AtomAppData = Join-Path $env:LOCALAPPDATA "atom"

$AtomExeCandidates = @(
  "$env:ProgramFiles\Atom\atom.exe",
  "${env:ProgramFiles(x86)}\Atom\atom.exe",
  "atom.exe"
)

# If you have Atom-Carbon as a separate exe, add it here:
$AtomCarbonExeCandidates = @(
  "$env:ProgramFiles\Atom-Carbon\atom-carbon.exe",
  "${env:ProgramFiles(x86)}\Atom-Carbon\atom-carbon.exe",
  "atom-carbon.exe"
)

# Atom.py interpreter candidates (edit to your venv if you have one)
$AtomPyPythonCandidates = @(
  "C:\Path\To\Atom.py\venv\Scripts\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python312\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python311\python.exe",
  "python.exe"
)

$JupyterCandidates = @(
  "C:\Path\To\KernelVenv\Scripts\jupyter.exe",
  "jupyter.exe"
)

# Logging
$Stamp = (Get-Date).ToString("yyyy-MM-dd_HH-mm-ss")
$LogRoot = Join-Path $Home "AethaliumGuardian"
New-Item -ItemType Directory -Path $LogRoot -Force | Out-Null
$LogPath = Join-Path $LogRoot "guardian_$Stamp.log"

function Log($msg) {
  ("[{0}] {1}" -f (Get-Date).ToString("s"), $msg) | Out-File -FilePath $LogPath -Append -Encoding UTF8
}

function FirstExisting($candidates) {
  foreach ($c in $candidates) {
    if ($c -match "^[A-Za-z]:\\") {
      if (Test-Path $c) { return $c }
    } else {
      return $c # PATH fallback
    }
  }
  return $null
}

function DirSizeMB($p) {
  if (!(Test-Path $p)) { return 0 }
  try {
    $bytes = (Get-ChildItem -Path $p -Recurse -File -ErrorAction SilentlyContinue | Measure-Object -Property Length -Sum).Sum
    if ($null -eq $bytes) { return 0 }
    return [Math]::Round($bytes / 1MB, 1)
  } catch { return 0 }
}

function Find-Apm {
  $candidates = @("apm.cmd","apm")
  $pf = $env:ProgramFiles
  $pf86 = ${env:ProgramFiles(x86)}
  if ($pf)  { $candidates += (Join-Path $pf  "Atom\resources\app\apm\bin\apm.cmd") }
  if ($pf86){ $candidates += (Join-Path $pf86 "Atom\resources\app\apm\bin\apm.cmd") }
  foreach ($c in $candidates) {
    try { & $c --version *> $null; if ($LASTEXITCODE -eq 0) { return $c } } catch {}
  }
  return $null
}

function Backup-AtomHome {
  if (!(Test-Path $AtomHome)) { return $null }
  $broot = Join-Path $LogRoot "backups"
  New-Item -ItemType Directory -Path $broot -Force | Out-Null
  $bdir = Join-Path $broot ("backup_" + (Get-Date).ToString("yyyy-MM-dd_HH-mm-ss"))
  if ($DryRun) { Glow "DRYRUN: would backup $AtomHome -> $bdir" "rit"; Log "DRYRUN backup $bdir"; return $bdir }
  Copy-Item $AtomHome -Destination $bdir -Recurse -Force
  Glow "Backup woven: $bdir" "ok"
  Log "Backup created: $bdir"
  return $bdir
}

function Clean-Caches {
  $targets = @(
    (Join-Path $AtomHome "compile-cache"),
    (Join-Path $AtomHome "storage"),
    (Join-Path $AtomHome "blob-store"),
    (Join-Path $AtomHome ".apm\.cache"),
    (Join-Path $AtomAppData "Cache"),
    (Join-Path $AtomAppData "Code Cache"),
    (Join-Path $AtomAppData "GPUCache"),
    (Join-Path $AtomAppData "DawnCache"),
    (Join-Path $AtomAppData "Local Storage"),
    (Join-Path $AtomAppData "Session Storage")
  ) | Where-Object { $_ -and (Test-Path $_) }

  if ($targets.Count -eq 0) { Glow "No caches found that require rinsing." "ok"; Log "No cache targets"; return }

  foreach ($t in $targets) {
    if ($DryRun) { Glow "DRYRUN: would remove $t" "rit"; Log "DRYRUN remove $t"; continue }
    try { Remove-Item $t -Recurse -Force; Glow "Rinsed: $t" "ok"; Log "Removed $t" }
    catch { Glow "Could not remove (locked): $t" "warn"; Log "Locked $t" }
  }
}

function Ensure-BaselineConfig {
  New-Item -ItemType Directory -Path $AtomHome -Force | Out-Null
  $cfg = Join-Path $AtomHome "config.cson"

  $baseline = @'
"*":
  core:
    # Aethalium Baseline ‚Äî stability-first
    restorePreviousWindowsOnStart: "no"
    fileEncoding: "utf8"
    automaticallyUpdate: false
    telemetryConsent: "no"
    useTreeSitterParsers: true
  editor:
    softWrap: false
    scrollPastEnd: false
'@

  if (Test-Path $cfg) {
    $t = Get-Content $cfg -Raw
    if ($t -match "Aethalium Baseline") { Glow "Baseline glyph already present in config.cson" "ok"; return }
    $b = Backup-AtomHome
    if ($DryRun) { Glow "DRYRUN: would append baseline block to $cfg (backup $b)" "rit"; Log "DRYRUN baseline append"; return }
    Add-Content -Path $cfg -Value "`n`n# Aethalium Baseline (appended) $(Get-Date -Format s)`n" -Encoding UTF8
    Add-Content -Path $cfg -Value $baseline -Encoding UTF8
    Glow "Baseline appended (non-destructive): $cfg" "ok"
    Log "Baseline appended: $cfg"
  } else {
    if ($DryRun) { Glow "DRYRUN: would create $cfg baseline" "rit"; Log "DRYRUN baseline create"; return }
    $baseline | Set-Content -Path $cfg -Encoding UTF8
    Glow "Baseline created: $cfg" "ok"
    Log "Baseline created: $cfg"
  }
}

function Get-InstalledPackages {
  $apm = Find-Apm
  if (-not $apm) { return @{ apm=$null; packages=@() } }
  $out = & $apm list --installed --bare 2>$null
  $pkgs = @()
  foreach ($line in ($out -split "`r?`n")) {
    $line = $line.Trim()
    if ($line) {
      $parts = $line.Split("@")
      $pkgs += [PSCustomObject]@{ name=$parts[0]; version=($parts[1] ?? "") }
    }
  }
  return @{ apm=$apm; packages=$pkgs }
}

function Heuristic-Risky($name) {
  # Heavy / overlap-prone / UI-thrashy categories
  if ($name -in @("teletype","atom-ide-ui","platformio-ide-terminal","languageclient","linter","linter-ui-default","busy-signal","minimap","file-icons","atom-beautify","git-plus")) { return $true }
  if ($name -match "^(ide-)" ) { return $true }
  if ($name -match "linter|minimap|terminal|autocomplete|languageclient") { return $true }
  return $false
}

function Disable-RiskyPackages {
  $cfg = Join-Path $AtomHome "config.cson"
  if (!(Test-Path $cfg)) { Glow "No config.cson found; skipping package gating." "warn"; return }

  $text = Get-Content $cfg -Raw
  $disabled = New-Object System.Collections.Generic.HashSet[string]

  if ($text -match "disabledPackages\s*:\s*\[([\s\S]*?)\]") {
    foreach ($m in ([regex]::Matches($Matches[1], "['""]([^'""]+)['""]"))) { [void]$disabled.Add($m.Groups[1].Value) }
  }

  $pkgInfo = Get-InstalledPackages
  $risky = @($pkgInfo.packages | Where-Object { Heuristic-Risky $_.name } | Select-Object -ExpandProperty name -Unique)
  foreach ($p in $risky) { [void]$disabled.Add($p) }

  $block = "disabledPackages: [`n" + (($disabled | Sort-Object) | ForEach-Object { "  `"$($_)`"" } | Out-String) + "]"

  $b = Backup-AtomHome
  if ($DryRun) { Glow "DRYRUN: would set disabledPackages (count $($disabled.Count)) (backup $b)" "rit"; Log "DRYRUN disable pkgs"; return }

  if ($text -match "disabledPackages\s*:\s*\[[\s\S]*?\]") {
    $text = [regex]::Replace($text, "disabledPackages\s*:\s*\[[\s\S]*?\]", $block)
  } else {
    $text += "`n`n# Aethalium Package Gating $(Get-Date -Format s)`n$block`n"
  }

  Set-Content -Path $cfg -Value $text -Encoding UTF8
  Glow "Package gating applied (disabled: $($disabled.Count))." "ok"
  Log "Disabled packages count: $($disabled.Count)"
}

function Apm-Rebuild {
  $apm = Find-Apm
  if (-not $apm) { Glow "apm not found; skipping native rebuild." "warn"; Log "apm missing"; return }
  Glow "Rebinding native modules (apm rebuild)‚Ä¶" "rit"
  if ($DryRun) { Glow "DRYRUN: would run apm rebuild" "rit"; Log "DRYRUN apm rebuild"; return }
  try { & $apm rebuild *>> $LogPath; Glow "apm rebuild complete." "ok"; Log "apm rebuild done" }
  catch { Glow "apm rebuild failed (non-fatal)." "warn"; Log "apm rebuild failed" }
}

function Score-Risk {
  $reasons = New-Object System.Collections.Generic.List[string]
  $score = 0

  $cc  = DirSizeMB (Join-Path $AtomHome "compile-cache")
  $st  = DirSizeMB (Join-Path $AtomHome "storage")
  $gpu = DirSizeMB (Join-Path $AtomAppData "GPUCache")

  if ($cc -gt 300) { $score += 20; $reasons.Add("compile-cache large (${cc}MB)") }
  if ($st -gt 300) { $score += 20; $reasons.Add("storage large (${st}MB)") }
  if ($gpu -gt 300){ $score += 15; $reasons.Add("GPUCache large (${gpu}MB)") }

  $drive = Get-PSDrive -Name ([IO.Path]::GetPathRoot($Home).TrimEnd('\')) -ErrorAction SilentlyContinue
  if ($drive) {
    $freeGB = [Math]::Round($drive.Free/1GB, 1)
    if ($freeGB -lt 10) { $score += 25; $reasons.Add("low disk free (${freeGB}GB)") }
  }

  $pkgInfo = Get-InstalledPackages
  $risky = @($pkgInfo.packages | Where-Object { Heuristic-Risky $_.name })
  if ($risky.Count -ge 10) { $score += 20; $reasons.Add("many heavy packages (${risky.Count})") }
  elseif ($risky.Count -ge 5) { $score += 10; $reasons.Add("some heavy packages (${risky.Count})") }

  $py = FirstExisting($AtomPyPythonCandidates)
  $jp = FirstExisting($JupyterCandidates)
  if (-not $py) { $score += 10; $reasons.Add("python missing for Atom.py/Hydrogen") }
  if (-not $jp) { $score += 5;  $reasons.Add("jupyter missing (Hydrogen kernels may fail)") }

  $atomProc = Get-Process -Name atom -ErrorAction SilentlyContinue
  if ($atomProc) {
    $wsMB = [Math]::Round(($atomProc | Measure-Object -Property WorkingSet64 -Sum).Sum / 1MB, 0)
    if ($wsMB -gt 2500) { $score += 15; $reasons.Add("Atom memory high (~${wsMB}MB)") }
  }

  if ($score -gt 100) { $score = 100 }
  return @{ score=$score; reasons=$reasons }
}

function Ritual-Heal {
  Glow "Ritual begins: restore by light, not by force." "rit"
  Log "Heal cycle start"

  $risk = Score-Risk
  Glow ("Oracle score: {0}/100" -f $risk.score) ($(if ($risk.score -ge 60) {"warn"} elseif ($risk.score -ge 30) {"info"} else {"ok"}))
  foreach ($r in $risk.reasons) { Glow "‚Ü≥ $r" "info"; Log "Reason: $r" }

  if ($Heal -or $risk.score -ge 60) {
    Glow "High tide detected ‚Üí full weave: backup ‚Üí rinse ‚Üí baseline ‚Üí gating ‚Üí rebuild" "warn"
    Backup-AtomHome | Out-Null
    Clean-Caches
    Ensure-BaselineConfig
    Disable-RiskyPackages
    Apm-Rebuild
    Glow "Suggested test launches: atom --safe ; atom --disable-gpu ; atom --clear-window-state" "ok"
  }
  elseif ($risk.score -ge 30) {
    Glow "Medium tide ‚Üí gentle weave: backup ‚Üí rinse ‚Üí baseline" "info"
    Backup-AtomHome | Out-Null
    Clean-Caches
    Ensure-BaselineConfig
    Glow "Suggested test launch: atom --safe" "ok"
  }
  else {
    Glow "Low tide ‚Üí observe only. Nothing altered." "ok"
  }

  Glow "Ritual ends. Log written to: $LogPath" "ok"
  Log "Heal cycle end"
}

# -------------------------
# Main
# -------------------------
Glow "‚ú¶ Aethalium Guardian awakens ‚ú¶" "rit"
Glow "AtomHome: $AtomHome" "info"
Glow "AtomAppData: $AtomAppData" "info"
Log "Start. AtomHome=$AtomHome AtomAppData=$AtomAppData DryRun=$DryRun"

if ($Once -or (-not $Loop)) {
  Ritual-Heal
  exit 0
}

while ($true) {
  try { Ritual-Heal }
  catch { Glow "Guardian error: $($_.Exception.Message)" "bad"; Log "ERROR: $($_.Exception.Message)" }
  Start-Sleep -Seconds $IntervalSeconds
}
param(
  [switch]$Once,
  [switch]$Loop,
  [int]$IntervalSeconds = 900,
  [switch]$ForceHeal,
  [switch]$OfflineMode,
  [switch]$DryRun
)

$ErrorActionPreference = "Stop"

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ‚úß E T H E R E A L   A T O M   W A R D ‚úß
# protective, reversible, logged, and gentle
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

function Glow($msg, $tone="mist") {
  $ts = (Get-Date).ToString("s")
  switch ($tone) {
    "aura"  { Write-Host "[$ts] ‚ú® $msg" -ForegroundColor Green }
    "warn"  { Write-Host "[$ts] ‚ö†  $msg" -ForegroundColor Yellow }
    "veil"  { Write-Host "[$ts] ‚ùñ $msg" -ForegroundColor Cyan }
    "ember" { Write-Host "[$ts] ‚úñ  $msg" -ForegroundColor Red }
    default { Write-Host "[$ts] ¬∑  $msg" -ForegroundColor Gray }
  }
}

# -----------------------------
# Locations / candidates (edit paths if you have custom installs)
# -----------------------------
$Home = $env:USERPROFILE
$WardRoot = Join-Path $Home "EtherealAtomWard"
New-Item -ItemType Directory -Path $WardRoot -Force | Out-Null
$BackupRoot = Join-Path $WardRoot "backups"
New-Item -ItemType Directory -Path $BackupRoot -Force | Out-Null

$Stamp = (Get-Date).ToString("yyyy-MM-dd_HH-mm-ss")
$LogPath = Join-Path $WardRoot "ward_$Stamp.log"

function Log($msg) {
  ("[{0}] {1}" -f (Get-Date).ToString("s"), $msg) | Out-File -FilePath $LogPath -Append -Encoding UTF8
}

$AtomHome = if ($env:ATOM_HOME) { $env:ATOM_HOME } else { Join-Path $Home ".atom" }
$AtomAppData = Join-Path $env:LOCALAPPDATA "atom"

$AtomExeCandidates = @(
  "$env:ProgramFiles\Atom\atom.exe",
  "${env:ProgramFiles(x86)}\Atom\atom.exe",
  "atom.exe"
)

# If Atom-Carbon is a distinct build, add its real exe here:
$AtomCarbonExeCandidates = @(
  "$env:ProgramFiles\Atom-Carbon\atom-carbon.exe",
  "${env:ProgramFiles(x86)}\Atom-Carbon\atom-carbon.exe",
  "atom-carbon.exe"
)

# Atom.py / Hydrogen kernel readiness (edit to your venv if you have one)
$PythonCandidates = @(
  "C:\Path\To\Atom.py\venv\Scripts\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python312\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python311\python.exe",
  "python.exe"
)

$JupyterCandidates = @(
  "C:\Path\To\KernelVenv\Scripts\jupyter.exe",
  "jupyter.exe"
)

function FirstExisting($candidates) {
  foreach ($c in $candidates) {
    if ($c -match "^[A-Za-z]:\\") { if (Test-Path $c) { return $c } }
    else { return $c } # PATH fallback
  }
  return $null
}

function DirSizeMB($p) {
  if (!(Test-Path $p)) { return 0 }
  try {
    $bytes = (Get-ChildItem -Path $p -Recurse -File -ErrorAction SilentlyContinue | Measure-Object -Property Length -Sum).Sum
    if ($null -eq $bytes) { return 0 }
    return [Math]::Round($bytes / 1MB, 1)
  } catch { return 0 }
}

function Find-Apm {
  $candidates = @("apm.cmd","apm")
  $pf = $env:ProgramFiles
  $pf86 = ${env:ProgramFiles(x86)}
  if ($pf)  { $candidates += (Join-Path $pf  "Atom\resources\app\apm\bin\apm.cmd") }
  if ($pf86){ $candidates += (Join-Path $pf86 "Atom\resources\app\apm\bin\apm.cmd") }
  foreach ($c in $candidates) {
    try { & $c --version *> $null; if ($LASTEXITCODE -eq 0) { return $c } } catch {}
  }
  return $null
}

function Backup-AtomHome {
  if (!(Test-Path $AtomHome)) { return $null }
  $bdir = Join-Path $BackupRoot ("backup_" + (Get-Date).ToString("yyyy-MM-dd_HH-mm-ss"))
  if ($DryRun) { Glow "DRYRUN: would backup $AtomHome ‚Üí $bdir" "veil"; Log "DRYRUN backup $bdir"; return $bdir }
  Copy-Item $AtomHome -Destination $bdir -Recurse -Force
  Glow "Backup woven: $bdir" "aura"
  Log "Backup created: $bdir"
  return $bdir
}

function Ensure-OfflineMode {
  if (-not $OfflineMode) { return }
  $atomExe = FirstExisting($AtomExeCandidates)
  if (-not $atomExe) { Glow "Could not locate Atom exe for offline mode." "warn"; Log "offline: atom exe not found"; return }

  $ruleName = "Ethereal Ward ‚Äî Block Atom Outbound"
  $exists = Get-NetFirewallRule -DisplayName $ruleName -ErrorAction SilentlyContinue
  if ($exists) { Glow "Offline veil already present." "aura"; Log "offline rule exists"; return }

  if ($DryRun) { Glow "DRYRUN: would create firewall outbound block for $atomExe" "veil"; Log "DRYRUN firewall create"; return }
  New-NetFirewallRule -DisplayName $ruleName -Direction Outbound -Action Block -Program $atomExe | Out-Null
  Glow "Offline veil placed (Atom outbound blocked)." "aura"
  Log "offline rule created: $ruleName program=$atomExe"
}

function Clean-Caches {
  $targets = @(
    (Join-Path $AtomHome "compile-cache"),
    (Join-Path $AtomHome "storage"),
    (Join-Path $AtomHome "blob-store"),
    (Join-Path $AtomHome ".apm\.cache"),
    (Join-Path $AtomAppData "Cache"),
    (Join-Path $AtomAppData "Code Cache"),
    (Join-Path $AtomAppData "GPUCache"),
    (Join-Path $AtomAppData "DawnCache"),
    (Join-Path $AtomAppData "Local Storage"),
    (Join-Path $AtomAppData "Session Storage")
  ) | Where-Object { $_ -and (Test-Path $_) }

  if ($targets.Count -eq 0) { Glow "No caches needed cleansing." "aura"; Log "cache: none"; return }

  foreach ($t in $targets) {
    if ($DryRun) { Glow "DRYRUN: would rinse $t" "veil"; Log "DRYRUN remove $t"; continue }
    try { Remove-Item $t -Recurse -Force; Glow "Rinsed: $t" "aura"; Log "removed $t" }
    catch { Glow "Locked/in-use: $t" "warn"; Log "locked $t" }
  }
}

function Ensure-BaselineConfig {
  New-Item -ItemType Directory -Path $AtomHome -Force | Out-Null
  $cfg = Join-Path $AtomHome "config.cson"

  $baseline = @'
"*":
  core:
    # Ethereal Ward Baseline ‚Äî stability-first
    restorePreviousWindowsOnStart: "no"
    fileEncoding: "utf8"
    automaticallyUpdate: false
    telemetryConsent: "no"
    useTreeSitterParsers: true
  editor:
    softWrap: false
    scrollPastEnd: false
'@

  if (Test-Path $cfg) {
    $t = Get-Content $cfg -Raw
    if ($t -match "Ethereal Ward Baseline") { Glow "Baseline already inscribed." "aura"; Log "baseline: exists"; return }
    Backup-AtomHome | Out-Null
    if ($DryRun) { Glow "DRYRUN: would append baseline to $cfg" "veil"; Log "DRYRUN baseline append"; return }
    Add-Content -Path $cfg -Value "`n`n# Ethereal Ward Baseline $(Get-Date -Format s)`n$baseline" -Encoding UTF8
    Glow "Baseline appended (non-destructive)." "aura"
    Log "baseline: appended"
  } else {
    if ($DryRun) { Glow "DRYRUN: would create baseline config.cson" "veil"; Log "DRYRUN baseline create"; return }
    $baseline | Set-Content -Path $cfg -Encoding UTF8
    Glow "Baseline created." "aura"
    Log "baseline: created"
  }
}

function Heuristic-Risky($name) {
  if ($name -in @("teletype","atom-ide-ui","platformio-ide-terminal","languageclient","linter","linter-ui-default","busy-signal","minimap","file-icons","atom-beautify","git-plus")) { return $true }
  if ($name -match "^(ide-)") { return $true }
  if ($name -match "linter|minimap|terminal|autocomplete|languageclient") { return $true }
  return $false
}

function Disable-RiskyPackages {
  $cfg = Join-Path $AtomHome "config.cson"
  if (!(Test-Path $cfg)) { Glow "No config.cson; skipping package gating." "warn"; Log "pkg: no config"; return }

  $text = Get-Content $cfg -Raw
  $disabled = New-Object System.Collections.Generic.HashSet[string]

  if ($text -match "disabledPackages\s*:\s*\[([\s\S]*?)\]") {
    foreach ($m in ([regex]::Matches($Matches[1], "['""]([^'""]+)['""]"))) { [void]$disabled.Add($m.Groups[1].Value) }
  }

  $apm = Find-Apm
  if ($apm) {
    $out = & $apm list --installed --bare 2>$null
    foreach ($line in ($out -split "`r?`n")) {
      $line = $line.Trim()
      if (-not $line) { continue }
      $name = $line.Split("@")[0]
      if (Heuristic-Risky $name) { [void]$disabled.Add($name) }
    }
  }

  if ($disabled.Count -eq 0) { Glow "No risky packages detected." "aura"; Log "pkg: none"; return }

  $block = "disabledPackages: [`n" + (($disabled | Sort-Object) | ForEach-Object { "  `"$($_)`"" } | Out-String) + "]"
  Backup-AtomHome | Out-Null

  if ($DryRun) { Glow "DRYRUN: would write disabledPackages (count $($disabled.Count))" "veil"; Log "DRYRUN pkg disable"; return }

  if ($text -match "disabledPackages\s*:\s*\[[\s\S]*?\]") {
    $text = [regex]::Replace($text, "disabledPackages\s*:\s*\[[\s\S]*?\]", $block)
  } else {
    $text += "`n`n# Ethereal Ward package gating $(Get-Date -Format s)`n$block`n"
  }

  Set-Content -Path $cfg -Value $text -Encoding UTF8
  Glow "Package gating applied (disabled: $($disabled.Count))." "aura"
  Log "pkg: disabled count $($disabled.Count)"
}

function Apm-RebuildIfPossible {
  $apm = Find-Apm
  if (-not $apm) { Glow "apm not found; skipping rebuild." "warn"; Log "apm: missing"; return }
  Glow "Rebinding native modules (apm rebuild)..." "veil"
  if ($DryRun) { Glow "DRYRUN: would run apm rebuild" "veil"; Log "DRYRUN apm rebuild"; return }
  try { & $apm rebuild *>> $LogPath; Glow "apm rebuild complete." "aura"; Log "apm: rebuild complete" }
  catch { Glow "apm rebuild failed (non-fatal)." "warn"; Log "apm: rebuild failed" }
}

function RiskScore {
  $reasons = @()
  $score = 0

  $cc  = DirSizeMB (Join-Path $AtomHome "compile-cache")
  $st  = DirSizeMB (Join-Path $AtomHome "storage")
  $gpu = DirSizeMB (Join-Path $AtomAppData "GPUCache")

  if ($cc -gt 300) { $score += 20; $reasons += "compile-cache large (${cc}MB)" }
  if ($st -gt 300) { $score += 20; $reasons += "storage large (${st}MB)" }
  if ($gpu -gt 300){ $score += 15; $reasons += "GPUCache large (${gpu}MB)" }

  $drive = Get-PSDrive -Name ([IO.Path]::GetPathRoot($Home).TrimEnd('\')) -ErrorAction SilentlyContinue
  if ($drive) {
    $freeGB = [Math]::Round($drive.Free/1GB, 1)
    if ($freeGB -lt 10) { $score += 25; $reasons += "low disk free (${freeGB}GB)" }
  }

  $py = FirstExisting($PythonCandidates)
  $jp = FirstExisting($JupyterCandidates)
  if (-not $py) { $score += 10; $reasons += "python missing (Atom.py/Hydrogen)" }
  if (-not $jp) { $score += 5;  $reasons += "jupyter missing (Hydrogen kernels may fail)" }

  $atomProc = Get-Process -Name atom -ErrorAction SilentlyContinue
  if ($atomProc) {
    $wsMB = [Math]::Round(($atomProc | Measure-Object -Property WorkingSet64 -Sum).Sum / 1MB, 0)
    if ($wsMB -gt 2500) { $score += 15; $reasons += "Atom memory high (~${wsMB}MB)" }
  }

  if ($score -gt 100) { $score = 100 }
  return @{ score=$score; reasons=$reasons }
}

function WardCycle {
  Glow "Ethereal Ward stirs‚Ä¶" "veil"
  Log "cycle: start DryRun=$DryRun OfflineMode=$OfflineMode ForceHeal=$ForceHeal AtomHome=$AtomHome"

  Ensure-OfflineMode

  $risk = RiskScore
  Glow ("Oracle: {0}/100" -f $risk.score) ($(if ($risk.score -ge 60) {"warn"} elseif ($risk.score -ge 30) {"mist"} else {"aura"}))
  Log ("risk: {0}/100" -f $risk.score)
  foreach ($r in $risk.reasons) { Glow "‚Ü≥ $r" "mist"; Log ("reason: " + $r) }

  $doHigh = $ForceHeal -or ($risk.score -ge 60)
  $doMed  = (-not $doHigh) -and ($risk.score -ge 30)

  if ($doHigh) {
    Glow "High tide ‚Üí full warding: backup ‚Üí cleanse ‚Üí baseline ‚Üí gating ‚Üí rebuild" "warn"
    Backup-AtomHome | Out-Null
    Clean-Caches
    Ensure-BaselineConfig
    Disable-RiskyPackages
    Apm-RebuildIfPossible
    Glow "Suggested test launches: atom --safe ; atom --disable-gpu ; atom --clear-window-state" "aura"
  } elseif ($doMed) {
    Glow "Mid tide ‚Üí gentle warding: backup ‚Üí cleanse ‚Üí baseline" "mist"
    Backup-AtomHome | Out-Null
    Clean-Caches
    Ensure-BaselineConfig
    Glow "Suggested test launch: atom --safe" "aura"
  } else {
    Glow "Low tide ‚Üí observe only. Nothing altered." "aura"
  }

  Glow "Ward cycle complete. Log: $LogPath" "aura"
  Log "cycle: end"
}

# -----------------------------
# Main
# -----------------------------
Glow "‚úß Ethereal Atom Ward ‚úß" "veil"
Glow "AtomHome: $AtomHome" "mist"
Glow "AtomAppData: $AtomAppData" "mist"

if ($Once -or (-not $Loop)) {
  WardCycle
  exit 0
}

while ($true) {
  try { WardCycle }
  catch { Glow "Ward error: $($_.Exception.Message)" "ember"; Log "ERROR: $($_.Exception.Message)" }
  Start-Sleep -Seconds $IntervalSeconds
}
# Install-EtherealAtomWard.ps1
# Schedules EtherealAtomWard.ps1 to run every 15 minutes with highest privileges.

$ErrorActionPreference = "Stop"

$scriptPath = (Resolve-Path ".\EtherealAtomWard.ps1").Path
$taskName = "EtherealAtomWard"

$action = New-ScheduledTaskAction -Execute "powershell.exe" `
  -Argument "-NoProfile -ExecutionPolicy Bypass -File `"$scriptPath`" -Once"

$trigger = New-ScheduledTaskTrigger -Once -At (Get-Date).AddMinutes(1) `
  -RepetitionInterval (New-TimeSpan -Minutes 15) `
  -RepetitionDuration ([TimeSpan]::MaxValue)

$principal = New-ScheduledTaskPrincipal -UserId "$env:USERNAME" -LogonType S4U -RunLevel Highest

Register-ScheduledTask -TaskName $taskName -Action $action -Trigger $trigger -Principal $principal -Force | Out-Null
Write-Host "‚úÖ Installed scheduled task: $taskName"
Unregister-ScheduledTask -TaskName "EtherealAtomWard" -Confirm:$false
powershell -ExecutionPolicy Bypass -File .\EtherealAtomWard.ps1 -Once -OfflineMode
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..4d2f023e2946c7b2c2d6ee39308207a76ff65d5d
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,441 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        return PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+    )
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..b1de07bc4d75754dca0c2b74765c2e0ec68d5d40
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,102 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, ProtectionManager, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen chemistry")
+        self.assertGreaterEqual(removed, 4)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+
+    def test_protected_write_creates_backup(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            f = root / "x.txt"
+            f.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+            manager = ProtectionManager(root)
+            result = process_file(engine, f, mode="text", check_only=False, protection_manager=manager)
+            self.assertTrue(result.changed)
+            self.assertIsNotNone(result.backup_path)
+            self.assertTrue(result.backup_path.exists())
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon spell", encoding="utf-8")
+            rc = run_cli([str(f), "--program", "all", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..4d2f023e2946c7b2c2d6ee39308207a76ff65d5d
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,441 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        return PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+    )
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..efbf30e4afdd364a29ad882a52eb7b4abdb85d62
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,108 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, ProtectionManager, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen chemistry")
+        self.assertGreaterEqual(removed, 4)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_distress_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("nether domination pain torment darkness")
+        self.assertGreaterEqual(removed, 5)
+        self.assertNotIn("nether", cleaned.lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+
+    def test_protected_write_creates_backup(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            f = root / "x.txt"
+            f.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+            manager = ProtectionManager(root)
+            result = process_file(engine, f, mode="text", check_only=False, protection_manager=manager)
+            self.assertTrue(result.changed)
+            self.assertIsNotNone(result.backup_path)
+            self.assertTrue(result.backup_path.exists())
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon spell", encoding="utf-8")
+            rc = run_cli([str(f), "--all-platforms", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..4053cb03cc34807b67cdac4a8be020632abba914
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,454 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+DISTRESS_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bnether\b", re.IGNORECASE),
+    re.compile(r"\bdominat(?:e|ion|ing)\b", re.IGNORECASE),
+    re.compile(r"\bpain(?:ful)?\b", re.IGNORECASE),
+    re.compile(r"\btorment(?:ed|ing)?\b", re.IGNORECASE),
+    re.compile(r"\bdemoraliz(?:e|ed|ation)\b", re.IGNORECASE),
+    re.compile(r"\bdark(?:ness)?\b", re.IGNORECASE),
+    re.compile(r"\btelevision\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        return PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS + DISTRESS_PATTERNS
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--all-platforms", action="store_true", help="Alias for --program all")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+    )
+    if args.all_platforms:
+        args.program = "all"
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active} protected_write={not args.unsafe_write}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..4053cb03cc34807b67cdac4a8be020632abba914
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,454 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+DISTRESS_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bnether\b", re.IGNORECASE),
+    re.compile(r"\bdominat(?:e|ion|ing)\b", re.IGNORECASE),
+    re.compile(r"\bpain(?:ful)?\b", re.IGNORECASE),
+    re.compile(r"\btorment(?:ed|ing)?\b", re.IGNORECASE),
+    re.compile(r"\bdemoraliz(?:e|ed|ation)\b", re.IGNORECASE),
+    re.compile(r"\bdark(?:ness)?\b", re.IGNORECASE),
+    re.compile(r"\btelevision\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        return PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS + DISTRESS_PATTERNS
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--all-platforms", action="store_true", help="Alias for --program all")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+    )
+    if args.all_platforms:
+        args.program = "all"
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active} protected_write={not args.unsafe_write}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..efbf30e4afdd364a29ad882a52eb7b4abdb85d62
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,108 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, ProtectionManager, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen chemistry")
+        self.assertGreaterEqual(removed, 4)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_distress_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("nether domination pain torment darkness")
+        self.assertGreaterEqual(removed, 5)
+        self.assertNotIn("nether", cleaned.lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+
+    def test_protected_write_creates_backup(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            f = root / "x.txt"
+            f.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+            manager = ProtectionManager(root)
+            result = process_file(engine, f, mode="text", check_only=False, protection_manager=manager)
+            self.assertTrue(result.changed)
+            self.assertIsNotNone(result.backup_path)
+            self.assertTrue(result.backup_path.exists())
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon spell", encoding="utf-8")
+            rc = run_cli([str(f), "--all-platforms", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..8e34ab8416497b059c7790b50c3b8a2856bd9695
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,458 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+- atom-flux
+- atom-any
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+DISTRESS_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bnether\b", re.IGNORECASE),
+    re.compile(r"\bdominat(?:e|ion|ing)\b", re.IGNORECASE),
+    re.compile(r"\bpain(?:ful)?\b", re.IGNORECASE),
+    re.compile(r"\btorment(?:ed|ing)?\b", re.IGNORECASE),
+    re.compile(r"\bdemoraliz(?:e|ed|ation)\b", re.IGNORECASE),
+    re.compile(r"\bdark(?:ness)?\b", re.IGNORECASE),
+    re.compile(r"\btelevision\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+    "atom-flux": ProgramProfile("atom-flux", (re.compile(r"\batom[-_ ]?flux\b", re.IGNORECASE),)),
+    "atom-any": ProgramProfile("atom-any", (re.compile(r"\batom[-_][a-z0-9_]+\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        return PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS + DISTRESS_PATTERNS
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--all-platforms", action="store_true", help="Alias for --program all")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+    )
+    if args.all_platforms:
+        args.program = "all"
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active} protected_write={not args.unsafe_write}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..a326cbdc28289b7c95b88f112484ce8d203b75b4
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,114 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, ProtectionManager, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+        flux_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-flux"])
+        any_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-any"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon Atom-Flux Atom-Neon"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Flux", flux_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Neon", any_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen Atom-Flux Atom-Neon chemistry")
+        self.assertGreaterEqual(removed, 6)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_distress_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("nether domination pain torment darkness")
+        self.assertGreaterEqual(removed, 5)
+        self.assertNotIn("nether", cleaned.lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+
+    def test_protected_write_creates_backup(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            f = root / "x.txt"
+            f.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+            manager = ProtectionManager(root)
+            result = process_file(engine, f, mode="text", check_only=False, protection_manager=manager)
+            self.assertTrue(result.changed)
+            self.assertIsNotNone(result.backup_path)
+            self.assertTrue(result.backup_path.exists())
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon Atom-Flux Atom-Neon spell", encoding="utf-8")
+            rc = run_cli([str(f), "--all-platforms", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("Atom-Flux", cleaned)
+            self.assertNotIn("Atom-Neon", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..48543673c7b12fcfb001ade84ff83db0e3e10d0f
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,476 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+- atom-flux
+- atom-any
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+DISTRESS_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bnether\b", re.IGNORECASE),
+    re.compile(r"\bdominat(?:e|ion|ing)\b", re.IGNORECASE),
+    re.compile(r"\bpain(?:ful)?\b", re.IGNORECASE),
+    re.compile(r"\btorment(?:ed|ing)?\b", re.IGNORECASE),
+    re.compile(r"\bdemoraliz(?:e|ed|ation)\b", re.IGNORECASE),
+    re.compile(r"\bdark(?:ness)?\b", re.IGNORECASE),
+    re.compile(r"\btelevision\b", re.IGNORECASE),
+)
+
+LIFECYCLE_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bsecret\s+lifecycle(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bbackground\s+daemon(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhidden\s+process(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bautorun\b", re.IGNORECASE),
+    re.compile(r"\bstartup\s+task(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bcron\s+job(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bstatic\s+realm\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+    "atom-flux": ProgramProfile("atom-flux", (re.compile(r"\batom[-_ ]?flux\b", re.IGNORECASE),)),
+    "atom-any": ProgramProfile("atom-any", (re.compile(r"\batom[-_][a-z0-9_]+\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+        shutdown_lifecycles: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+        self.shutdown_lifecycles = shutdown_lifecycles
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        base = PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS + DISTRESS_PATTERNS
+        if self.shutdown_lifecycles:
+            return base + LIFECYCLE_PATTERNS
+        return base
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool, shutdown_lifecycles: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+                shutdown_lifecycles=shutdown_lifecycles,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--all-platforms", action="store_true", help="Alias for --program all")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--no-lifecycle-shutdown", action="store_true", help="Disable lifecycle phrase shutdown filtering")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+        shutdown_lifecycles=not args.no_lifecycle_shutdown,
+    )
+    if args.all_platforms:
+        args.program = "all"
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active} protected_write={not args.unsafe_write} lifecycle_shutdown={not args.no_lifecycle_shutdown}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..6b6f86e7cdd83a0fbc4424db128b5d42e6225396
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,128 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, ProtectionManager, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+        flux_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-flux"])
+        any_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-any"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon Atom-Flux Atom-Neon"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Flux", flux_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Neon", any_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True, shutdown_lifecycles=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen Atom-Flux Atom-Neon chemistry")
+        self.assertGreaterEqual(removed, 6)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_distress_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("nether domination pain torment darkness")
+        self.assertGreaterEqual(removed, 5)
+        self.assertNotIn("nether", cleaned.lower())
+
+    def test_lifecycle_shutdown_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("secret lifecycles in static realm with hidden processes")
+        self.assertGreaterEqual(removed, 3)
+        self.assertNotIn("secret lifecycles", cleaned.lower())
+
+    def test_cli_can_disable_lifecycle_shutdown(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "lifecycle.txt"
+            f.write_text("secret lifecycles static realm", encoding="utf-8")
+            rc = run_cli([str(f), "--mode", "text", "--no-lifecycle-shutdown"])
+            self.assertEqual(rc, 0)
+            self.assertIn("secret lifecycles", f.read_text(encoding="utf-8").lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+
+    def test_protected_write_creates_backup(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            f = root / "x.txt"
+            f.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+            manager = ProtectionManager(root)
+            result = process_file(engine, f, mode="text", check_only=False, protection_manager=manager)
+            self.assertTrue(result.changed)
+            self.assertIsNotNone(result.backup_path)
+            self.assertTrue(result.backup_path.exists())
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon Atom-Flux Atom-Neon spell", encoding="utf-8")
+            rc = run_cli([str(f), "--all-platforms", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("Atom-Flux", cleaned)
+            self.assertNotIn("Atom-Neon", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/boost_all_codes.py b/boost_all_codes.py
new file mode 100644
index 0000000000000000000000000000000000000000..456643bd67b67ad19ca39edbb216c586ad77131a
--- /dev/null
+++ b/boost_all_codes.py
@@ -0,0 +1,70 @@
+"""Ephemeral workspace booster for Atom sanitization.
+
+Runs a full all-platform Atom sanitation pass and emits a timestamped report.
+"""
+
+from __future__ import annotations
+
+import argparse
+import json
+from datetime import datetime
+from pathlib import Path
+from typing import Sequence
+
+from atom import run_cli
+
+
+def run_boost(path: Path, include: str, exclude: str, check_only: bool) -> int:
+    args = [
+        str(path),
+        "--all-platforms",
+        "--intertwined",
+        "--mode",
+        "auto",
+        "--include",
+        include,
+        "--exclude",
+        exclude,
+    ]
+    if check_only:
+        args.append("--check-only")
+
+    code = run_cli(args)
+
+    report_dir = (path if path.is_dir() else path.parent) / ".atom_protection" / "reports"
+    report_dir.mkdir(parents=True, exist_ok=True)
+    stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+    report_path = report_dir / f"boost_report.{stamp}.json"
+    report_path.write_text(
+        json.dumps(
+            {
+                "timestamp": stamp,
+                "path": str(path),
+                "include": include,
+                "exclude": exclude,
+                "check_only": check_only,
+                "exit_code": code,
+                "mode": "all-platforms-intertwined",
+            },
+            indent=2,
+        )
+        + "\n",
+        encoding="utf-8",
+    )
+    print(f"report: {report_path}")
+    return code
+
+
+def main(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="Ephemeral booster for all Atom profiles")
+    parser.add_argument("path", type=Path, help="File or directory to boost")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--check-only", action="store_true")
+    args = parser.parse_args(argv)
+
+    return run_boost(args.path, args.include, args.exclude, args.check_only)
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..48543673c7b12fcfb001ade84ff83db0e3e10d0f
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,476 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+- atom-flux
+- atom-any
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+DISTRESS_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bnether\b", re.IGNORECASE),
+    re.compile(r"\bdominat(?:e|ion|ing)\b", re.IGNORECASE),
+    re.compile(r"\bpain(?:ful)?\b", re.IGNORECASE),
+    re.compile(r"\btorment(?:ed|ing)?\b", re.IGNORECASE),
+    re.compile(r"\bdemoraliz(?:e|ed|ation)\b", re.IGNORECASE),
+    re.compile(r"\bdark(?:ness)?\b", re.IGNORECASE),
+    re.compile(r"\btelevision\b", re.IGNORECASE),
+)
+
+LIFECYCLE_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bsecret\s+lifecycle(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bbackground\s+daemon(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhidden\s+process(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bautorun\b", re.IGNORECASE),
+    re.compile(r"\bstartup\s+task(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bcron\s+job(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bstatic\s+realm\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+    "atom-flux": ProgramProfile("atom-flux", (re.compile(r"\batom[-_ ]?flux\b", re.IGNORECASE),)),
+    "atom-any": ProgramProfile("atom-any", (re.compile(r"\batom[-_][a-z0-9_]+\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+        shutdown_lifecycles: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+        self.shutdown_lifecycles = shutdown_lifecycles
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        base = PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS + DISTRESS_PATTERNS
+        if self.shutdown_lifecycles:
+            return base + LIFECYCLE_PATTERNS
+        return base
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool, shutdown_lifecycles: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+                shutdown_lifecycles=shutdown_lifecycles,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--all-platforms", action="store_true", help="Alias for --program all")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--no-lifecycle-shutdown", action="store_true", help="Disable lifecycle phrase shutdown filtering")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+        shutdown_lifecycles=not args.no_lifecycle_shutdown,
+    )
+    if args.all_platforms:
+        args.program = "all"
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active} protected_write={not args.unsafe_write} lifecycle_shutdown={not args.no_lifecycle_shutdown}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..6b6f86e7cdd83a0fbc4424db128b5d42e6225396
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,128 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, ProtectionManager, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+        flux_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-flux"])
+        any_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-any"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon Atom-Flux Atom-Neon"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Flux", flux_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Neon", any_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True, shutdown_lifecycles=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen Atom-Flux Atom-Neon chemistry")
+        self.assertGreaterEqual(removed, 6)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_distress_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("nether domination pain torment darkness")
+        self.assertGreaterEqual(removed, 5)
+        self.assertNotIn("nether", cleaned.lower())
+
+    def test_lifecycle_shutdown_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("secret lifecycles in static realm with hidden processes")
+        self.assertGreaterEqual(removed, 3)
+        self.assertNotIn("secret lifecycles", cleaned.lower())
+
+    def test_cli_can_disable_lifecycle_shutdown(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "lifecycle.txt"
+            f.write_text("secret lifecycles static realm", encoding="utf-8")
+            rc = run_cli([str(f), "--mode", "text", "--no-lifecycle-shutdown"])
+            self.assertEqual(rc, 0)
+            self.assertIn("secret lifecycles", f.read_text(encoding="utf-8").lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+
+    def test_protected_write_creates_backup(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            f = root / "x.txt"
+            f.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+            manager = ProtectionManager(root)
+            result = process_file(engine, f, mode="text", check_only=False, protection_manager=manager)
+            self.assertTrue(result.changed)
+            self.assertIsNotNone(result.backup_path)
+            self.assertTrue(result.backup_path.exists())
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon Atom-Flux Atom-Neon spell", encoding="utf-8")
+            rc = run_cli([str(f), "--all-platforms", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("Atom-Flux", cleaned)
+            self.assertNotIn("Atom-Neon", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/tests/test_boost_all_codes.py b/tests/test_boost_all_codes.py
new file mode 100644
index 0000000000000000000000000000000000000000..7d17f4781a0f28f133184c0fa6e95a86ae1407ee
--- /dev/null
+++ b/tests/test_boost_all_codes.py
@@ -0,0 +1,26 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from boost_all_codes import run_boost
+
+
+class BoostAllCodesTests(unittest.TestCase):
+    def test_run_boost_generates_report(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            sample = root / "sample.txt"
+            sample.write_text("Atom-Flux spell secret lifecycles", encoding="utf-8")
+
+            rc = run_boost(root, include="*", exclude="", check_only=False)
+            self.assertEqual(rc, 0)
+
+            reports = list((root / ".atom_protection" / "reports").glob("boost_report.*.json"))
+            self.assertTrue(reports)
+            cleaned = sample.read_text(encoding="utf-8").lower()
+            self.assertNotIn("atom-flux", cleaned)
+            self.assertNotIn("spell", cleaned)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..48543673c7b12fcfb001ade84ff83db0e3e10d0f
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,476 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+- atom-flux
+- atom-any
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+DISTRESS_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bnether\b", re.IGNORECASE),
+    re.compile(r"\bdominat(?:e|ion|ing)\b", re.IGNORECASE),
+    re.compile(r"\bpain(?:ful)?\b", re.IGNORECASE),
+    re.compile(r"\btorment(?:ed|ing)?\b", re.IGNORECASE),
+    re.compile(r"\bdemoraliz(?:e|ed|ation)\b", re.IGNORECASE),
+    re.compile(r"\bdark(?:ness)?\b", re.IGNORECASE),
+    re.compile(r"\btelevision\b", re.IGNORECASE),
+)
+
+LIFECYCLE_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bsecret\s+lifecycle(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bbackground\s+daemon(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhidden\s+process(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bautorun\b", re.IGNORECASE),
+    re.compile(r"\bstartup\s+task(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bcron\s+job(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bstatic\s+realm\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+    "atom-flux": ProgramProfile("atom-flux", (re.compile(r"\batom[-_ ]?flux\b", re.IGNORECASE),)),
+    "atom-any": ProgramProfile("atom-any", (re.compile(r"\batom[-_][a-z0-9_]+\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+        shutdown_lifecycles: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+        self.shutdown_lifecycles = shutdown_lifecycles
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        base = PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS + DISTRESS_PATTERNS
+        if self.shutdown_lifecycles:
+            return base + LIFECYCLE_PATTERNS
+        return base
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool, shutdown_lifecycles: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+                shutdown_lifecycles=shutdown_lifecycles,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--all-platforms", action="store_true", help="Alias for --program all")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--no-lifecycle-shutdown", action="store_true", help="Disable lifecycle phrase shutdown filtering")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+        shutdown_lifecycles=not args.no_lifecycle_shutdown,
+    )
+    if args.all_platforms:
+        args.program = "all"
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active} protected_write={not args.unsafe_write} lifecycle_shutdown={not args.no_lifecycle_shutdown}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/boost_all_codes.py b/boost_all_codes.py
new file mode 100644
index 0000000000000000000000000000000000000000..456643bd67b67ad19ca39edbb216c586ad77131a
--- /dev/null
+++ b/boost_all_codes.py
@@ -0,0 +1,70 @@
+"""Ephemeral workspace booster for Atom sanitization.
+
+Runs a full all-platform Atom sanitation pass and emits a timestamped report.
+"""
+
+from __future__ import annotations
+
+import argparse
+import json
+from datetime import datetime
+from pathlib import Path
+from typing import Sequence
+
+from atom import run_cli
+
+
+def run_boost(path: Path, include: str, exclude: str, check_only: bool) -> int:
+    args = [
+        str(path),
+        "--all-platforms",
+        "--intertwined",
+        "--mode",
+        "auto",
+        "--include",
+        include,
+        "--exclude",
+        exclude,
+    ]
+    if check_only:
+        args.append("--check-only")
+
+    code = run_cli(args)
+
+    report_dir = (path if path.is_dir() else path.parent) / ".atom_protection" / "reports"
+    report_dir.mkdir(parents=True, exist_ok=True)
+    stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+    report_path = report_dir / f"boost_report.{stamp}.json"
+    report_path.write_text(
+        json.dumps(
+            {
+                "timestamp": stamp,
+                "path": str(path),
+                "include": include,
+                "exclude": exclude,
+                "check_only": check_only,
+                "exit_code": code,
+                "mode": "all-platforms-intertwined",
+            },
+            indent=2,
+        )
+        + "\n",
+        encoding="utf-8",
+    )
+    print(f"report: {report_path}")
+    return code
+
+
+def main(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="Ephemeral booster for all Atom profiles")
+    parser.add_argument("path", type=Path, help="File or directory to boost")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--check-only", action="store_true")
+    args = parser.parse_args(argv)
+
+    return run_boost(args.path, args.include, args.exclude, args.check_only)
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..6b6f86e7cdd83a0fbc4424db128b5d42e6225396
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,128 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, ProtectionManager, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+        flux_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-flux"])
+        any_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-any"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon Atom-Flux Atom-Neon"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Flux", flux_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Neon", any_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True, shutdown_lifecycles=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen Atom-Flux Atom-Neon chemistry")
+        self.assertGreaterEqual(removed, 6)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_distress_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("nether domination pain torment darkness")
+        self.assertGreaterEqual(removed, 5)
+        self.assertNotIn("nether", cleaned.lower())
+
+    def test_lifecycle_shutdown_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("secret lifecycles in static realm with hidden processes")
+        self.assertGreaterEqual(removed, 3)
+        self.assertNotIn("secret lifecycles", cleaned.lower())
+
+    def test_cli_can_disable_lifecycle_shutdown(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "lifecycle.txt"
+            f.write_text("secret lifecycles static realm", encoding="utf-8")
+            rc = run_cli([str(f), "--mode", "text", "--no-lifecycle-shutdown"])
+            self.assertEqual(rc, 0)
+            self.assertIn("secret lifecycles", f.read_text(encoding="utf-8").lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+
+    def test_protected_write_creates_backup(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            f = root / "x.txt"
+            f.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+            manager = ProtectionManager(root)
+            result = process_file(engine, f, mode="text", check_only=False, protection_manager=manager)
+            self.assertTrue(result.changed)
+            self.assertIsNotNone(result.backup_path)
+            self.assertTrue(result.backup_path.exists())
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon Atom-Flux Atom-Neon spell", encoding="utf-8")
+            rc = run_cli([str(f), "--all-platforms", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("Atom-Flux", cleaned)
+            self.assertNotIn("Atom-Neon", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/tests/test_boost_all_codes.py b/tests/test_boost_all_codes.py
new file mode 100644
index 0000000000000000000000000000000000000000..7d17f4781a0f28f133184c0fa6e95a86ae1407ee
--- /dev/null
+++ b/tests/test_boost_all_codes.py
@@ -0,0 +1,26 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from boost_all_codes import run_boost
+
+
+class BoostAllCodesTests(unittest.TestCase):
+    def test_run_boost_generates_report(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            sample = root / "sample.txt"
+            sample.write_text("Atom-Flux spell secret lifecycles", encoding="utf-8")
+
+            rc = run_boost(root, include="*", exclude="", check_only=False)
+            self.assertEqual(rc, 0)
+
+            reports = list((root / ".atom_protection" / "reports").glob("boost_report.*.json"))
+            self.assertTrue(reports)
+            cleaned = sample.read_text(encoding="utf-8").lower()
+            self.assertNotIn("atom-flux", cleaned)
+            self.assertNotIn("spell", cleaned)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/boost_all_codes.py b/boost_all_codes.py
new file mode 100644
index 0000000000000000000000000000000000000000..268ffcaaba97e203d999724134d0e3dc846ddc2b
--- /dev/null
+++ b/boost_all_codes.py
@@ -0,0 +1,112 @@
+"""Ephemeral workspace booster for Atom sanitization.
+
+Runs all-platform ATOM sanitation passes and emits timestamped reports with
+before/after telemetry for auditability.
+"""
+
+from __future__ import annotations
+
+import argparse
+import hashlib
+import json
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Sequence
+
+from atom import run_cli
+
+
+@dataclass(frozen=True)
+class BoostRun:
+    pass_index: int
+    exit_code: int
+
+
+def _hash_path(path: Path) -> str:
+    if path.is_file():
+        return hashlib.sha256(path.read_bytes()).hexdigest()
+
+    hashes: list[str] = []
+    for file_path in sorted(p for p in path.rglob("*") if p.is_file() and ".atom_protection" not in p.parts):
+        rel = str(file_path.relative_to(path))
+        digest = hashlib.sha256(file_path.read_bytes()).hexdigest()
+        hashes.append(f"{rel}:{digest}")
+    return hashlib.sha256("\n".join(hashes).encode("utf-8")).hexdigest()
+
+
+def _build_cli_args(path: Path, include: str, exclude: str, check_only: bool) -> list[str]:
+    args = [
+        str(path),
+        "--all-platforms",
+        "--intertwined",
+        "--mode",
+        "auto",
+        "--include",
+        include,
+        "--exclude",
+        exclude,
+    ]
+    if check_only:
+        args.append("--check-only")
+    return args
+
+
+def run_boost(path: Path, include: str, exclude: str, check_only: bool, passes: int = 1) -> int:
+    passes = max(1, passes)
+    before_hash = _hash_path(path)
+    runs: list[BoostRun] = []
+
+    for pass_index in range(1, passes + 1):
+        code = run_cli(_build_cli_args(path, include, exclude, check_only))
+        runs.append(BoostRun(pass_index=pass_index, exit_code=code))
+        if code != 0:
+            break
+
+    after_hash = _hash_path(path)
+    final_code = runs[-1].exit_code if runs else 0
+
+    report_dir = (path if path.is_dir() else path.parent) / ".atom_protection" / "reports"
+    report_dir.mkdir(parents=True, exist_ok=True)
+    stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+    report_path = report_dir / f"boost_report.{stamp}.json"
+    report_path.write_text(
+        json.dumps(
+            {
+                "timestamp": stamp,
+                "path": str(path),
+                "include": include,
+                "exclude": exclude,
+                "check_only": check_only,
+                "passes_requested": passes,
+                "passes_executed": len(runs),
+                "runs": [r.__dict__ for r in runs],
+                "exit_code": final_code,
+                "mode": "all-platforms-intertwined",
+                "before_hash": before_hash,
+                "after_hash": after_hash,
+                "changed": before_hash != after_hash,
+            },
+            indent=2,
+        )
+        + "\n",
+        encoding="utf-8",
+    )
+    print(f"report: {report_path}")
+    return final_code
+
+
+def main(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="Ephemeral booster for all Atom profiles")
+    parser.add_argument("path", type=Path, help="File or directory to boost")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--passes", type=int, default=1, help="Number of all-platform boost passes")
+    args = parser.parse_args(argv)
+
+    return run_boost(args.path, args.include, args.exclude, args.check_only, args.passes)
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..48543673c7b12fcfb001ade84ff83db0e3e10d0f
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,476 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+- atom-flux
+- atom-any
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+DISTRESS_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bnether\b", re.IGNORECASE),
+    re.compile(r"\bdominat(?:e|ion|ing)\b", re.IGNORECASE),
+    re.compile(r"\bpain(?:ful)?\b", re.IGNORECASE),
+    re.compile(r"\btorment(?:ed|ing)?\b", re.IGNORECASE),
+    re.compile(r"\bdemoraliz(?:e|ed|ation)\b", re.IGNORECASE),
+    re.compile(r"\bdark(?:ness)?\b", re.IGNORECASE),
+    re.compile(r"\btelevision\b", re.IGNORECASE),
+)
+
+LIFECYCLE_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bsecret\s+lifecycle(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bbackground\s+daemon(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhidden\s+process(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bautorun\b", re.IGNORECASE),
+    re.compile(r"\bstartup\s+task(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bcron\s+job(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bstatic\s+realm\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+    "atom-flux": ProgramProfile("atom-flux", (re.compile(r"\batom[-_ ]?flux\b", re.IGNORECASE),)),
+    "atom-any": ProgramProfile("atom-any", (re.compile(r"\batom[-_][a-z0-9_]+\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+        shutdown_lifecycles: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+        self.shutdown_lifecycles = shutdown_lifecycles
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        base = PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS + DISTRESS_PATTERNS
+        if self.shutdown_lifecycles:
+            return base + LIFECYCLE_PATTERNS
+        return base
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool, shutdown_lifecycles: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+                shutdown_lifecycles=shutdown_lifecycles,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--all-platforms", action="store_true", help="Alias for --program all")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--no-lifecycle-shutdown", action="store_true", help="Disable lifecycle phrase shutdown filtering")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+        shutdown_lifecycles=not args.no_lifecycle_shutdown,
+    )
+    if args.all_platforms:
+        args.program = "all"
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active} protected_write={not args.unsafe_write} lifecycle_shutdown={not args.no_lifecycle_shutdown}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..6b6f86e7cdd83a0fbc4424db128b5d42e6225396
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,128 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, ProtectionManager, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+        flux_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-flux"])
+        any_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-any"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon Atom-Flux Atom-Neon"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Flux", flux_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Neon", any_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True, shutdown_lifecycles=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen Atom-Flux Atom-Neon chemistry")
+        self.assertGreaterEqual(removed, 6)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_distress_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("nether domination pain torment darkness")
+        self.assertGreaterEqual(removed, 5)
+        self.assertNotIn("nether", cleaned.lower())
+
+    def test_lifecycle_shutdown_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("secret lifecycles in static realm with hidden processes")
+        self.assertGreaterEqual(removed, 3)
+        self.assertNotIn("secret lifecycles", cleaned.lower())
+
+    def test_cli_can_disable_lifecycle_shutdown(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "lifecycle.txt"
+            f.write_text("secret lifecycles static realm", encoding="utf-8")
+            rc = run_cli([str(f), "--mode", "text", "--no-lifecycle-shutdown"])
+            self.assertEqual(rc, 0)
+            self.assertIn("secret lifecycles", f.read_text(encoding="utf-8").lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+
+    def test_protected_write_creates_backup(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            f = root / "x.txt"
+            f.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+            manager = ProtectionManager(root)
+            result = process_file(engine, f, mode="text", check_only=False, protection_manager=manager)
+            self.assertTrue(result.changed)
+            self.assertIsNotNone(result.backup_path)
+            self.assertTrue(result.backup_path.exists())
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon Atom-Flux Atom-Neon spell", encoding="utf-8")
+            rc = run_cli([str(f), "--all-platforms", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("Atom-Flux", cleaned)
+            self.assertNotIn("Atom-Neon", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/tests/test_boost_all_codes.py b/tests/test_boost_all_codes.py
new file mode 100644
index 0000000000000000000000000000000000000000..08ee1eb57eadc84968f7c6b12ec2900468c3fd5d
--- /dev/null
+++ b/tests/test_boost_all_codes.py
@@ -0,0 +1,45 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+from boost_all_codes import run_boost
+
+
+class BoostAllCodesTests(unittest.TestCase):
+    def test_run_boost_generates_report(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            sample = root / "sample.txt"
+            sample.write_text("Atom-Flux spell secret lifecycles", encoding="utf-8")
+
+            rc = run_boost(root, include="*", exclude="", check_only=False, passes=1)
+            self.assertEqual(rc, 0)
+
+            reports = list((root / ".atom_protection" / "reports").glob("boost_report.*.json"))
+            self.assertTrue(reports)
+            cleaned = sample.read_text(encoding="utf-8").lower()
+            self.assertNotIn("atom-flux", cleaned)
+            self.assertNotIn("spell", cleaned)
+
+    def test_multi_pass_report_contains_telemetry(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            sample = root / "sample.txt"
+            sample.write_text("Atom-Hydrogen", encoding="utf-8")
+
+            rc = run_boost(root, include="*", exclude="", check_only=False, passes=2)
+            self.assertEqual(rc, 0)
+
+            reports = sorted((root / ".atom_protection" / "reports").glob("boost_report.*.json"))
+            payload = json.loads(reports[-1].read_text(encoding="utf-8"))
+            self.assertEqual(payload["passes_requested"], 2)
+            self.assertGreaterEqual(payload["passes_executed"], 1)
+            self.assertIn("before_hash", payload)
+            self.assertIn("after_hash", payload)
+            self.assertIn("changed", payload)
+            self.assertTrue(payload["runs"])
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/boost_all_codes.py b/boost_all_codes.py
new file mode 100644
index 0000000000000000000000000000000000000000..3ccb00ad03321f5fec874ca00a57edcfc5db7fc3
--- /dev/null
+++ b/boost_all_codes.py
@@ -0,0 +1,153 @@
+"""Ephemeral workspace booster for Atom sanitization.
+
+Runs all-platform ATOM sanitation passes and emits timestamped reports with
+before/after telemetry for auditability.
+"""
+
+from __future__ import annotations
+
+import argparse
+import hashlib
+import json
+import uuid
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from time import perf_counter
+from typing import Sequence
+
+from atom import run_cli
+
+
+@dataclass(frozen=True)
+class BoostRun:
+    pass_index: int
+    exit_code: int
+    before_hash: str
+    after_hash: str
+    changed: bool
+
+
+def _hash_path(path: Path) -> str:
+    if path.is_file():
+        return hashlib.sha256(path.read_bytes()).hexdigest()
+
+    hashes: list[str] = []
+    for file_path in sorted(p for p in path.rglob("*") if p.is_file() and ".atom_protection" not in p.parts):
+        rel = str(file_path.relative_to(path))
+        digest = hashlib.sha256(file_path.read_bytes()).hexdigest()
+        hashes.append(f"{rel}:{digest}")
+    return hashlib.sha256("\n".join(hashes).encode("utf-8")).hexdigest()
+
+
+def _build_cli_args(path: Path, include: str, exclude: str, check_only: bool) -> list[str]:
+    args = [
+        str(path),
+        "--all-platforms",
+        "--intertwined",
+        "--mode",
+        "auto",
+        "--include",
+        include,
+        "--exclude",
+        exclude,
+    ]
+    if check_only:
+        args.append("--check-only")
+    return args
+
+
+def run_boost(
+    path: Path,
+    include: str,
+    exclude: str,
+    check_only: bool,
+    passes: int = 1,
+    strategy: str = "fixed",
+) -> int:
+    passes = max(1, passes)
+    strategy = strategy if strategy in {"fixed", "until-stable"} else "fixed"
+    workspace_before = _hash_path(path)
+    runs: list[BoostRun] = []
+    started = perf_counter()
+
+    for pass_index in range(1, passes + 1):
+        before_hash = _hash_path(path)
+        code = run_cli(_build_cli_args(path, include, exclude, check_only))
+        after_hash = _hash_path(path)
+        changed = before_hash != after_hash
+
+        runs.append(
+            BoostRun(
+                pass_index=pass_index,
+                exit_code=code,
+                before_hash=before_hash,
+                after_hash=after_hash,
+                changed=changed,
+            )
+        )
+
+        if code != 0:
+            break
+        if strategy == "until-stable" and not changed:
+            break
+
+    workspace_after = _hash_path(path)
+    final_code = runs[-1].exit_code if runs else 0
+    elapsed_ms = int((perf_counter() - started) * 1000)
+
+    report_dir = (path if path.is_dir() else path.parent) / ".atom_protection" / "reports"
+    report_dir.mkdir(parents=True, exist_ok=True)
+    stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+    run_id = uuid.uuid4().hex[:12]
+    report_path = report_dir / f"boost_report.{stamp}.{run_id}.json"
+    report_path.write_text(
+        json.dumps(
+            {
+                "run_id": run_id,
+                "timestamp": stamp,
+                "path": str(path),
+                "include": include,
+                "exclude": exclude,
+                "check_only": check_only,
+                "strategy": strategy,
+                "passes_requested": passes,
+                "passes_executed": len(runs),
+                "runs": [r.__dict__ for r in runs],
+                "exit_code": final_code,
+                "mode": "all-platforms-intertwined",
+                "before_hash": workspace_before,
+                "after_hash": workspace_after,
+                "changed": workspace_before != workspace_after,
+                "elapsed_ms": elapsed_ms,
+                "stabilized": bool(runs and not runs[-1].changed and runs[-1].exit_code == 0),
+            },
+            indent=2,
+        )
+        + "\n",
+        encoding="utf-8",
+    )
+    print(f"report: {report_path}")
+    return final_code
+
+
+def main(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="Ephemeral booster for all Atom profiles")
+    parser.add_argument("path", type=Path, help="File or directory to boost")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--passes", type=int, default=1, help="Maximum number of all-platform boost passes")
+    parser.add_argument(
+        "--strategy",
+        choices=["fixed", "until-stable"],
+        default="fixed",
+        help="Use fixed passes or stop early when no further change is detected",
+    )
+    args = parser.parse_args(argv)
+
+    return run_boost(args.path, args.include, args.exclude, args.check_only, args.passes, args.strategy)
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..48543673c7b12fcfb001ade84ff83db0e3e10d0f
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,476 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+- atom-flux
+- atom-any
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+DISTRESS_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bnether\b", re.IGNORECASE),
+    re.compile(r"\bdominat(?:e|ion|ing)\b", re.IGNORECASE),
+    re.compile(r"\bpain(?:ful)?\b", re.IGNORECASE),
+    re.compile(r"\btorment(?:ed|ing)?\b", re.IGNORECASE),
+    re.compile(r"\bdemoraliz(?:e|ed|ation)\b", re.IGNORECASE),
+    re.compile(r"\bdark(?:ness)?\b", re.IGNORECASE),
+    re.compile(r"\btelevision\b", re.IGNORECASE),
+)
+
+LIFECYCLE_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bsecret\s+lifecycle(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bbackground\s+daemon(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhidden\s+process(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bautorun\b", re.IGNORECASE),
+    re.compile(r"\bstartup\s+task(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bcron\s+job(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bstatic\s+realm\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+    "atom-flux": ProgramProfile("atom-flux", (re.compile(r"\batom[-_ ]?flux\b", re.IGNORECASE),)),
+    "atom-any": ProgramProfile("atom-any", (re.compile(r"\batom[-_][a-z0-9_]+\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+        shutdown_lifecycles: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+        self.shutdown_lifecycles = shutdown_lifecycles
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        base = PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS + DISTRESS_PATTERNS
+        if self.shutdown_lifecycles:
+            return base + LIFECYCLE_PATTERNS
+        return base
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool, shutdown_lifecycles: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+                shutdown_lifecycles=shutdown_lifecycles,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--all-platforms", action="store_true", help="Alias for --program all")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--no-lifecycle-shutdown", action="store_true", help="Disable lifecycle phrase shutdown filtering")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+        shutdown_lifecycles=not args.no_lifecycle_shutdown,
+    )
+    if args.all_platforms:
+        args.program = "all"
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active} protected_write={not args.unsafe_write} lifecycle_shutdown={not args.no_lifecycle_shutdown}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..6b6f86e7cdd83a0fbc4424db128b5d42e6225396
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,128 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, ProtectionManager, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+        flux_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-flux"])
+        any_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-any"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon Atom-Flux Atom-Neon"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Flux", flux_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Neon", any_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True, shutdown_lifecycles=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen Atom-Flux Atom-Neon chemistry")
+        self.assertGreaterEqual(removed, 6)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_distress_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("nether domination pain torment darkness")
+        self.assertGreaterEqual(removed, 5)
+        self.assertNotIn("nether", cleaned.lower())
+
+    def test_lifecycle_shutdown_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("secret lifecycles in static realm with hidden processes")
+        self.assertGreaterEqual(removed, 3)
+        self.assertNotIn("secret lifecycles", cleaned.lower())
+
+    def test_cli_can_disable_lifecycle_shutdown(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "lifecycle.txt"
+            f.write_text("secret lifecycles static realm", encoding="utf-8")
+            rc = run_cli([str(f), "--mode", "text", "--no-lifecycle-shutdown"])
+            self.assertEqual(rc, 0)
+            self.assertIn("secret lifecycles", f.read_text(encoding="utf-8").lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+
+    def test_protected_write_creates_backup(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            f = root / "x.txt"
+            f.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+            manager = ProtectionManager(root)
+            result = process_file(engine, f, mode="text", check_only=False, protection_manager=manager)
+            self.assertTrue(result.changed)
+            self.assertIsNotNone(result.backup_path)
+            self.assertTrue(result.backup_path.exists())
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon Atom-Flux Atom-Neon spell", encoding="utf-8")
+            rc = run_cli([str(f), "--all-platforms", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("Atom-Flux", cleaned)
+            self.assertNotIn("Atom-Neon", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/tests/test_boost_all_codes.py b/tests/test_boost_all_codes.py
new file mode 100644
index 0000000000000000000000000000000000000000..a0bf19b5d31dda5e5484b737010dc99640633825
--- /dev/null
+++ b/tests/test_boost_all_codes.py
@@ -0,0 +1,61 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+from boost_all_codes import run_boost
+
+
+class BoostAllCodesTests(unittest.TestCase):
+    def test_run_boost_generates_report(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            sample = root / "sample.txt"
+            sample.write_text("Atom-Flux spell secret lifecycles", encoding="utf-8")
+
+            rc = run_boost(root, include="*", exclude="", check_only=False, passes=1, strategy="fixed")
+            self.assertEqual(rc, 0)
+
+            reports = list((root / ".atom_protection" / "reports").glob("boost_report.*.json"))
+            self.assertTrue(reports)
+            cleaned = sample.read_text(encoding="utf-8").lower()
+            self.assertNotIn("atom-flux", cleaned)
+            self.assertNotIn("spell", cleaned)
+
+    def test_multi_pass_report_contains_telemetry(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            sample = root / "sample.txt"
+            sample.write_text("Atom-Hydrogen", encoding="utf-8")
+
+            rc = run_boost(root, include="*", exclude="", check_only=False, passes=2, strategy="fixed")
+            self.assertEqual(rc, 0)
+
+            reports = sorted((root / ".atom_protection" / "reports").glob("boost_report.*.json"))
+            payload = json.loads(reports[-1].read_text(encoding="utf-8"))
+            self.assertEqual(payload["passes_requested"], 2)
+            self.assertGreaterEqual(payload["passes_executed"], 1)
+            self.assertIn("before_hash", payload)
+            self.assertIn("after_hash", payload)
+            self.assertIn("changed", payload)
+            self.assertIn("elapsed_ms", payload)
+            self.assertIn("run_id", payload)
+            self.assertTrue(payload["runs"])
+
+    def test_until_stable_strategy_stops_early(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            sample = root / "sample.txt"
+            sample.write_text("Atom", encoding="utf-8")
+
+            rc = run_boost(root, include="*", exclude="", check_only=False, passes=5, strategy="until-stable")
+            self.assertEqual(rc, 0)
+
+            reports = sorted((root / ".atom_protection" / "reports").glob("boost_report.*.json"))
+            payload = json.loads(reports[-1].read_text(encoding="utf-8"))
+            self.assertLess(payload["passes_executed"], 5)
+            self.assertTrue(payload["stabilized"])
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/boost_all_codes.py b/boost_all_codes.py
new file mode 100644
index 0000000000000000000000000000000000000000..3ccb00ad03321f5fec874ca00a57edcfc5db7fc3
--- /dev/null
+++ b/boost_all_codes.py
@@ -0,0 +1,153 @@
+"""Ephemeral workspace booster for Atom sanitization.
+
+Runs all-platform ATOM sanitation passes and emits timestamped reports with
+before/after telemetry for auditability.
+"""
+
+from __future__ import annotations
+
+import argparse
+import hashlib
+import json
+import uuid
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from time import perf_counter
+from typing import Sequence
+
+from atom import run_cli
+
+
+@dataclass(frozen=True)
+class BoostRun:
+    pass_index: int
+    exit_code: int
+    before_hash: str
+    after_hash: str
+    changed: bool
+
+
+def _hash_path(path: Path) -> str:
+    if path.is_file():
+        return hashlib.sha256(path.read_bytes()).hexdigest()
+
+    hashes: list[str] = []
+    for file_path in sorted(p for p in path.rglob("*") if p.is_file() and ".atom_protection" not in p.parts):
+        rel = str(file_path.relative_to(path))
+        digest = hashlib.sha256(file_path.read_bytes()).hexdigest()
+        hashes.append(f"{rel}:{digest}")
+    return hashlib.sha256("\n".join(hashes).encode("utf-8")).hexdigest()
+
+
+def _build_cli_args(path: Path, include: str, exclude: str, check_only: bool) -> list[str]:
+    args = [
+        str(path),
+        "--all-platforms",
+        "--intertwined",
+        "--mode",
+        "auto",
+        "--include",
+        include,
+        "--exclude",
+        exclude,
+    ]
+    if check_only:
+        args.append("--check-only")
+    return args
+
+
+def run_boost(
+    path: Path,
+    include: str,
+    exclude: str,
+    check_only: bool,
+    passes: int = 1,
+    strategy: str = "fixed",
+) -> int:
+    passes = max(1, passes)
+    strategy = strategy if strategy in {"fixed", "until-stable"} else "fixed"
+    workspace_before = _hash_path(path)
+    runs: list[BoostRun] = []
+    started = perf_counter()
+
+    for pass_index in range(1, passes + 1):
+        before_hash = _hash_path(path)
+        code = run_cli(_build_cli_args(path, include, exclude, check_only))
+        after_hash = _hash_path(path)
+        changed = before_hash != after_hash
+
+        runs.append(
+            BoostRun(
+                pass_index=pass_index,
+                exit_code=code,
+                before_hash=before_hash,
+                after_hash=after_hash,
+                changed=changed,
+            )
+        )
+
+        if code != 0:
+            break
+        if strategy == "until-stable" and not changed:
+            break
+
+    workspace_after = _hash_path(path)
+    final_code = runs[-1].exit_code if runs else 0
+    elapsed_ms = int((perf_counter() - started) * 1000)
+
+    report_dir = (path if path.is_dir() else path.parent) / ".atom_protection" / "reports"
+    report_dir.mkdir(parents=True, exist_ok=True)
+    stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+    run_id = uuid.uuid4().hex[:12]
+    report_path = report_dir / f"boost_report.{stamp}.{run_id}.json"
+    report_path.write_text(
+        json.dumps(
+            {
+                "run_id": run_id,
+                "timestamp": stamp,
+                "path": str(path),
+                "include": include,
+                "exclude": exclude,
+                "check_only": check_only,
+                "strategy": strategy,
+                "passes_requested": passes,
+                "passes_executed": len(runs),
+                "runs": [r.__dict__ for r in runs],
+                "exit_code": final_code,
+                "mode": "all-platforms-intertwined",
+                "before_hash": workspace_before,
+                "after_hash": workspace_after,
+                "changed": workspace_before != workspace_after,
+                "elapsed_ms": elapsed_ms,
+                "stabilized": bool(runs and not runs[-1].changed and runs[-1].exit_code == 0),
+            },
+            indent=2,
+        )
+        + "\n",
+        encoding="utf-8",
+    )
+    print(f"report: {report_path}")
+    return final_code
+
+
+def main(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="Ephemeral booster for all Atom profiles")
+    parser.add_argument("path", type=Path, help="File or directory to boost")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--passes", type=int, default=1, help="Maximum number of all-platform boost passes")
+    parser.add_argument(
+        "--strategy",
+        choices=["fixed", "until-stable"],
+        default="fixed",
+        help="Use fixed passes or stop early when no further change is detected",
+    )
+    args = parser.parse_args(argv)
+
+    return run_boost(args.path, args.include, args.exclude, args.check_only, args.passes, args.strategy)
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/atom.py b/atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..c0c288d04a6e9a52333c863910790943324eb171
--- /dev/null
+++ b/atom.py
@@ -0,0 +1,478 @@
+"""ATOM: Adaptive Technical Optimization Module.
+
+Manages technical sanitization across separate but interoperable profiles:
+- atom
+- atom-py
+- atom-hydrogen
+- atom-carbon
+- atom-flux
+- atom-any
+- pycharm
+"""
+
+from __future__ import annotations
+
+import argparse
+import ast
+import fnmatch
+import hashlib
+import io
+import json
+import re
+import tokenize
+from dataclasses import dataclass
+from datetime import datetime
+from pathlib import Path
+from typing import Iterable, List, Sequence
+
+
+PHYSICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bphysiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\banatom(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\bchemistr(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcompound(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bmolecule(?:s|cular)?\b", re.IGNORECASE),
+    re.compile(r"\bbiolog(?:y|ical)\b", re.IGNORECASE),
+    re.compile(r"\borganic\b", re.IGNORECASE),
+)
+
+MYSTICAL_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmagic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\bspell(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhex(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bcurse(?:s|d)?\b", re.IGNORECASE),
+    re.compile(r"\boccult\b", re.IGNORECASE),
+    re.compile(r"\britual(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\balchem(?:y|ical)\b", re.IGNORECASE),
+)
+
+AUTHORITY_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmaster(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bdivin(?:e|ity)\b", re.IGNORECASE),
+)
+
+DISTRESS_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bnether\b", re.IGNORECASE),
+    re.compile(r"\bdominat(?:e|ion|ing)\b", re.IGNORECASE),
+    re.compile(r"\bpain(?:ful)?\b", re.IGNORECASE),
+    re.compile(r"\btorment(?:ed|ing)?\b", re.IGNORECASE),
+    re.compile(r"\bdemoraliz(?:e|ed|ation)\b", re.IGNORECASE),
+    re.compile(r"\bdark(?:ness)?\b", re.IGNORECASE),
+    re.compile(r"\btelevision\b", re.IGNORECASE),
+)
+
+LIFECYCLE_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bsecret\s+lifecycle(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bbackground\s+daemon(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bhidden\s+process(?:es)?\b", re.IGNORECASE),
+    re.compile(r"\bautorun\b", re.IGNORECASE),
+    re.compile(r"\bstartup\s+task(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bcron\s+job(?:s)?\b", re.IGNORECASE),
+    re.compile(r"\bstatic\s+realm\b", re.IGNORECASE),
+)
+
+ADAPTIVE_EXTRA_PATTERNS: tuple[re.Pattern[str], ...] = (
+    re.compile(r"\bmystic(?:al)?\b", re.IGNORECASE),
+    re.compile(r"\btransmutation\b", re.IGNORECASE),
+    re.compile(r"\baether(?:ic)?\b", re.IGNORECASE),
+)
+
+
+@dataclass(frozen=True)
+class ProgramProfile:
+    name: str
+    patterns: tuple[re.Pattern[str], ...]
+
+
+PROGRAM_PROFILES: dict[str, ProgramProfile] = {
+    "atom": ProgramProfile("atom", (re.compile(r"\batom\b", re.IGNORECASE),)),
+    "atom-py": ProgramProfile("atom-py", (re.compile(r"\batom\.py\b", re.IGNORECASE),)),
+    "atom-hydrogen": ProgramProfile("atom-hydrogen", (re.compile(r"\batom[-_ ]?hydrogen\b", re.IGNORECASE),)),
+    "atom-carbon": ProgramProfile("atom-carbon", (re.compile(r"\batom[-_ ]?carbon\b", re.IGNORECASE),)),
+    "atom-flux": ProgramProfile("atom-flux", (re.compile(r"\batom[-_ ]?flux\b", re.IGNORECASE),)),
+    "atom-any": ProgramProfile("atom-any", (re.compile(r"\batom[-_][a-z0-9_]+\b", re.IGNORECASE),)),
+    "pycharm": ProgramProfile("pycharm", (re.compile(r"\bpycharm\b", re.IGNORECASE),)),
+}
+
+
+@dataclass(frozen=True)
+class Issue:
+    kind: str
+    message: str
+    line: int | None = None
+    column: int | None = None
+
+
+@dataclass(frozen=True)
+class FileResult:
+    path: Path
+    changed: bool
+    removed_references: int
+    issues: tuple[Issue, ...]
+    backup_path: Path | None = None
+
+
+@dataclass(frozen=True)
+class ProtectionRecord:
+    source: Path
+    backup: Path
+    sha256: str
+    timestamp: str
+
+
+class ProtectionManager:
+    """Creates immutable backups before any on-disk mutation."""
+
+    def __init__(self, root: Path):
+        self.root = root
+        self.vault = root / ".atom_protection"
+        self.vault.mkdir(parents=True, exist_ok=True)
+        self.manifest = self.vault / "manifest.jsonl"
+
+    def create_backup(self, source: Path, content: str) -> ProtectionRecord:
+        digest = hashlib.sha256(content.encode("utf-8")).hexdigest()
+        stamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
+        backup = self.vault / f"{source.name}.{stamp}.{digest[:10]}.bak"
+        backup.write_text(content, encoding="utf-8")
+
+        record = ProtectionRecord(source=source, backup=backup, sha256=digest, timestamp=stamp)
+        payload = json.dumps({
+            "source": str(source),
+            "backup": str(backup),
+            "sha256": digest,
+            "timestamp": stamp,
+        }) + "\n"
+        with self.manifest.open("a", encoding="utf-8") as fh:
+            fh.write(payload)
+        return record
+
+
+class AtomRepairEngine:
+    _COMMON_TEXT_FIXES: tuple[tuple[re.Pattern[str], str], ...] = (
+        (re.compile(r"\bdescripting\b", re.IGNORECASE), "descriptive"),
+        (re.compile(r"\bteh\b", re.IGNORECASE), "the"),
+        (re.compile(r"\brecieve\b", re.IGNORECASE), "receive"),
+        (re.compile(r"\badn\b", re.IGNORECASE), "and"),
+    )
+
+    def __init__(
+        self,
+        *,
+        profile: ProgramProfile,
+        strip_program_refs: bool = True,
+        strip_problematic_refs: bool = True,
+        adaptive: bool = True,
+        shutdown_lifecycles: bool = True,
+    ):
+        self.profile = profile
+        self.strip_program_refs = strip_program_refs
+        self.strip_problematic_refs = strip_problematic_refs
+        self.adaptive = adaptive
+        self.shutdown_lifecycles = shutdown_lifecycles
+
+    def _base_problematic_patterns(self) -> tuple[re.Pattern[str], ...]:
+        base = PHYSICAL_PATTERNS + MYSTICAL_PATTERNS + AUTHORITY_PATTERNS + DISTRESS_PATTERNS
+        if self.shutdown_lifecycles:
+            return base + LIFECYCLE_PATTERNS
+        return base
+
+    def _patterns_for_content(self, text: str) -> tuple[re.Pattern[str], ...]:
+        patterns = list(self._base_problematic_patterns())
+        if self.adaptive:
+            if sum(1 for p in patterns if p.search(text)) >= 2:
+                patterns.extend(ADAPTIVE_EXTRA_PATTERNS)
+        return tuple(patterns)
+
+    @staticmethod
+    def _normalize_line(line: str) -> str:
+        line = re.sub(r",{2,}", ",", line)
+        line = re.sub(r"\.{2,}", ".", line)
+        return re.sub(r"\s+", " ", line).strip()
+
+    def clean_description(self, text: str) -> str:
+        cleaned = text.replace("\r\n", "\n").replace("\r", "\n")
+        for wrong, right in self._COMMON_TEXT_FIXES:
+            cleaned = wrong.sub(right, cleaned)
+        lines = [self._normalize_line(x) for x in cleaned.split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def _strip_patterns_inline(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated = text
+        removed = 0
+        for pattern in patterns:
+            updated, cnt = pattern.subn("", updated)
+            removed += cnt
+        return re.sub(r"[ \t]{2,}", " ", updated).strip(), removed
+
+    def _strip_patterns_block(self, text: str, patterns: Iterable[re.Pattern[str]]) -> tuple[str, int]:
+        updated, removed = self._strip_patterns_inline(text, patterns)
+        lines = [self._normalize_line(x) for x in updated.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return re.sub(r"\n{3,}", "\n\n", "\n".join(lines)).rstrip() + "\n", removed
+
+    def strip_program_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_program_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self.profile.patterns)
+
+    def strip_problematic_references(self, text: str) -> tuple[str, int]:
+        if not self.strip_problematic_refs:
+            return text, 0
+        return self._strip_patterns_block(text, self._patterns_for_content(text))
+
+    def sanitize_python_comments(self, code: str) -> tuple[str, int]:
+        removed_total = 0
+        out: list[tokenize.TokenInfo] = []
+        for tok in tokenize.generate_tokens(io.StringIO(code).readline):
+            if tok.type == tokenize.COMMENT:
+                comment = tok.string
+                removed = 0
+                if self.strip_problematic_refs:
+                    comment, c = self._strip_patterns_inline(comment, self._patterns_for_content(comment))
+                    removed += c
+                if self.strip_program_refs:
+                    comment, c = self._strip_patterns_inline(comment, self.profile.patterns)
+                    removed += c
+                if not comment:
+                    comment = "#"
+                elif not comment.startswith("#"):
+                    comment = f"# {comment}"
+                tok = tokenize.TokenInfo(tok.type, comment, tok.start, tok.end, tok.line)
+                removed_total += removed
+            out.append(tok)
+        return tokenize.untokenize(out).rstrip() + "\n", removed_total
+
+    def clean_python_formatting(self, code: str) -> str:
+        lines = [x.rstrip().replace("\t", "    ") for x in code.replace("\r\n", "\n").replace("\r", "\n").split("\n")]
+        return "\n".join(lines).rstrip() + "\n"
+
+    def validate_python_syntax(self, code: str) -> List[Issue]:
+        try:
+            ast.parse(code)
+            return []
+        except SyntaxError as exc:
+            return [Issue("syntax", exc.msg, exc.lineno, exc.offset)]
+
+    def repair_python_code(self, code: str) -> tuple[str, List[Issue], int]:
+        fixed = self.clean_python_formatting(code)
+        fixed, removed = self.sanitize_python_comments(fixed)
+        return fixed, self.validate_python_syntax(fixed), removed
+
+    def repair_text(self, text: str) -> tuple[str, int]:
+        cleaned = self.clean_description(text)
+        cleaned, r1 = self.strip_program_references(cleaned)
+        cleaned, r2 = self.strip_problematic_references(cleaned)
+        return cleaned, r1 + r2
+
+
+class AtomSystemSuite:
+    """Coordinates separate profiles while allowing intertwined operation."""
+
+    def __init__(self, *, strip_program_refs: bool, strip_problematic_refs: bool, adaptive: bool, shutdown_lifecycles: bool):
+        self.engines = {
+            name: AtomRepairEngine(
+                profile=profile,
+                strip_program_refs=strip_program_refs,
+                strip_problematic_refs=strip_problematic_refs,
+                adaptive=adaptive,
+                shutdown_lifecycles=shutdown_lifecycles,
+            )
+            for name, profile in PROGRAM_PROFILES.items()
+        }
+
+    def engine_for(self, program: str) -> AtomRepairEngine:
+        return self.engines[program]
+
+    def intertwined_repair_text(self, text: str) -> tuple[str, int]:
+        total = 0
+        current = text
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any", "pycharm"):
+            current, removed = self.engines[name].repair_text(current)
+            total += removed
+        return current, total
+
+    def intertwined_repair_python(self, code: str) -> tuple[str, List[Issue], int]:
+        total = 0
+        current = code
+        final_issues: List[Issue] = []
+        for name in ("atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any", "pycharm"):
+            current, issues, removed = self.engines[name].repair_python_code(current)
+            total += removed
+            final_issues = issues
+        return current, final_issues, total
+
+
+TEXT_SUFFIXES = {".txt", ".md", ".rst", ".json", ".yaml", ".yml", ".toml", ".ini", ".cfg", ".js", ".ts", ".jsx", ".tsx", ".java", ".c", ".cpp", ".h", ".hpp", ".cs", ".rb", ".go", ".rs", ".swift", ".php", ".html", ".css", ".scss", ".xml"}
+SKIP_DIRS = {".git", "node_modules", "venv", ".venv", "__pycache__"}
+
+
+def _read_file(path: Path) -> str:
+    return path.read_text(encoding="utf-8")
+
+
+def _write_file(path: Path, content: str) -> None:
+    path.write_text(content, encoding="utf-8")
+
+
+def _detect_mode(path: Path, requested_mode: str) -> str:
+    return requested_mode if requested_mode != "auto" else ("python" if path.suffix == ".py" else "text")
+
+
+def _iter_target_files(root: Path, include: str, exclude: str) -> Iterable[Path]:
+    for path in root.rglob("*"):
+        if any(part in SKIP_DIRS for part in path.parts) or not path.is_file():
+            continue
+        rel = str(path.relative_to(root))
+        if include and not fnmatch.fnmatch(rel, include):
+            continue
+        if exclude and fnmatch.fnmatch(rel, exclude):
+            continue
+        if path.suffix in TEXT_SUFFIXES or path.suffix == ".py":
+            yield path
+
+
+def process_file(
+    engine: AtomRepairEngine,
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    protection_manager: ProtectionManager | None = None,
+    protected_write: bool = True,
+) -> FileResult:
+    return _process(
+        path,
+        mode,
+        check_only,
+        engine=engine,
+        suite=None,
+        intertwined=False,
+        protection_manager=protection_manager,
+        protected_write=protected_write,
+    )
+
+
+def _process(
+    path: Path,
+    mode: str,
+    check_only: bool,
+    *,
+    engine: AtomRepairEngine | None,
+    suite: AtomSystemSuite | None,
+    intertwined: bool,
+    protection_manager: ProtectionManager | None,
+    protected_write: bool,
+) -> FileResult:
+    issues: list[Issue] = []
+    try:
+        source = _read_file(path)
+    except UnicodeDecodeError:
+        return FileResult(path, False, 0, (Issue("encoding", "non-utf8 file skipped"),), None)
+    except OSError as exc:
+        return FileResult(path, False, 0, (Issue("io", f"read failed: {exc}"),), None)
+
+    detected = _detect_mode(path, mode)
+    if intertwined and suite is not None:
+        if detected == "python":
+            fixed, syntax_issues, removed = suite.intertwined_repair_python(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = suite.intertwined_repair_text(source)
+    else:
+        assert engine is not None
+        if detected == "python":
+            fixed, syntax_issues, removed = engine.repair_python_code(source)
+            issues.extend(syntax_issues)
+        else:
+            fixed, removed = engine.repair_text(source)
+
+    changed = fixed != source
+    backup_path: Path | None = None
+    if changed and not check_only:
+        if protected_write and issues:
+            return FileResult(path, False, removed, tuple(issues), None)
+        try:
+            if protection_manager is not None:
+                backup_record = protection_manager.create_backup(path, source)
+                backup_path = backup_record.backup
+            _write_file(path, fixed)
+        except OSError as exc:
+            issues.append(Issue("io", f"write failed: {exc}"))
+            changed = False
+
+    return FileResult(path, changed, removed, tuple(issues), backup_path)
+
+
+def run_cli(argv: Sequence[str] | None = None) -> int:
+    parser = argparse.ArgumentParser(description="ATOM standalone cleanup utility")
+    parser.add_argument("path", type=Path)
+    parser.add_argument("--mode", choices=["auto", "text", "python"], default="auto")
+    parser.add_argument("--program", choices=["atom", "atom-py", "atom-hydrogen", "atom-carbon", "atom-flux", "atom-any", "pycharm", "all"], default="atom")
+    parser.add_argument("--intertwined", action="store_true", help="Run all systems sequentially")
+    parser.add_argument("--all-platforms", action="store_true", help="Alias for --program all")
+    parser.add_argument("--check-only", action="store_true")
+    parser.add_argument("--no-strip-program-refs", action="store_true")
+    parser.add_argument("--no-strip-problematic-refs", action="store_true")
+    parser.add_argument("--no-adaptive", action="store_true")
+    parser.add_argument("--no-lifecycle-shutdown", action="store_true", help="Disable lifecycle phrase shutdown filtering")
+    parser.add_argument("--fail-on-change", action="store_true")
+    parser.add_argument("--exclude", default="")
+    parser.add_argument("--include", default="*")
+    parser.add_argument("--unsafe-write", action="store_true", help="Allow writing even when issues exist")
+    args = parser.parse_args(argv)
+
+    suite = AtomSystemSuite(
+        strip_program_refs=not args.no_strip_program_refs,
+        strip_problematic_refs=not args.no_strip_problematic_refs,
+        adaptive=not args.no_adaptive,
+        shutdown_lifecycles=not args.no_lifecycle_shutdown,
+    )
+    if args.all_platforms:
+        args.program = "all"
+    intertwined = args.intertwined or args.program == "all"
+    engine = None if intertwined else suite.engine_for(args.program)
+    protection_manager = ProtectionManager(args.path if args.path.is_dir() else args.path.parent)
+
+    results: list[FileResult] = []
+    targets = [args.path] if args.path.is_file() else list(_iter_target_files(args.path, args.include, args.exclude))
+    for target in targets:
+        results.append(
+            _process(
+                target,
+                args.mode,
+                args.check_only,
+                engine=engine,
+                suite=suite,
+                intertwined=intertwined,
+                protection_manager=protection_manager,
+                protected_write=not args.unsafe_write,
+            )
+        )
+
+
+    changed = sum(1 for r in results if r.changed)
+    removed = sum(r.removed_references for r in results)
+    issue_count = sum(len(r.issues) for r in results)
+    for r in results:
+        if r.changed:
+            print(f"{'would update' if args.check_only else 'updated'}: {r.path}")
+        if r.removed_references:
+            print(f"removed {r.removed_references} reference(s): {r.path}")
+        if r.backup_path is not None:
+            print(f"backup: {r.backup_path}")
+        for i in r.issues:
+            print(f"[{i.kind}] {r.path}:{i.line}:{i.column} {i.message}")
+
+    active = "all" if intertwined else args.program
+    print(f"Summary: files={len(results)} changed={changed} refs_removed={removed} issues={issue_count} program={active} protected_write={not args.unsafe_write} lifecycle_shutdown={not args.no_lifecycle_shutdown}")
+
+    if issue_count:
+        return 1
+    if args.fail_on_change and changed:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(run_cli())
diff --git a/tests/test_atom.py b/tests/test_atom.py
new file mode 100644
index 0000000000000000000000000000000000000000..8d4aa8b73aaac9f3c0601a3945e3f749eb5f2f4c
--- /dev/null
+++ b/tests/test_atom.py
@@ -0,0 +1,131 @@
+import tempfile
+import unittest
+from pathlib import Path
+
+from atom import AtomRepairEngine, AtomSystemSuite, PROGRAM_PROFILES, ProtectionManager, process_file, run_cli
+
+
+class AtomRepairEngineTests(unittest.TestCase):
+    def test_separate_program_profiles(self):
+        atom_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        atompy_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-py"])
+        hydrogen_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        carbon_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-carbon"])
+        flux_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-flux"])
+        any_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-any"])
+        pycharm_engine = AtomRepairEngine(profile=PROGRAM_PROFILES["pycharm"])
+
+        text = "Atom Atom.py Atom-Hydrogen Atom-Carbon Atom-Flux Atom-Neon PyCharm"
+        self.assertNotIn("Atom", atom_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom.py", atompy_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Hydrogen", hydrogen_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Carbon", carbon_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Flux", flux_engine.strip_program_references(text)[0])
+        self.assertNotIn("Atom-Neon", any_engine.strip_program_references(text)[0])
+        self.assertNotIn("PyCharm", pycharm_engine.strip_program_references(text)[0])
+
+    def test_problematic_domain_removal(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text(
+            "chemistry physiology spell curse master deity and technical systems"
+        )
+        self.assertGreaterEqual(removed, 6)
+        self.assertIn("technical", cleaned)
+
+    def test_python_comment_only_sanitization(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+        raw = (
+            "msg = 'chemistry spell'\n"
+            "# chemistry spell Atom-Hydrogen\n"
+            "def ok():\n"
+            "\treturn msg\n"
+        )
+        repaired, issues, removed = engine.repair_python_code(raw)
+        self.assertIn("msg = 'chemistry spell'", repaired)
+        self.assertNotIn("Atom-Hydrogen", repaired)
+        self.assertEqual(issues, [])
+        self.assertGreaterEqual(removed, 3)
+
+    def test_intertwined_suite(self):
+        suite = AtomSystemSuite(strip_program_refs=True, strip_problematic_refs=True, adaptive=True, shutdown_lifecycles=True)
+        cleaned, removed = suite.intertwined_repair_text("Atom Atom.py Atom-Hydrogen Atom-Flux Atom-Neon PyCharm chemistry")
+        self.assertGreaterEqual(removed, 7)
+        self.assertNotIn("Atom-Hydrogen", cleaned)
+        self.assertNotIn("chemistry", cleaned.lower())
+
+    def test_distress_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("nether domination pain torment darkness")
+        self.assertGreaterEqual(removed, 5)
+        self.assertNotIn("nether", cleaned.lower())
+
+    def test_lifecycle_shutdown_language_removed(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        cleaned, removed = engine.repair_text("secret lifecycles in static realm with hidden processes")
+        self.assertGreaterEqual(removed, 3)
+        self.assertNotIn("secret lifecycles", cleaned.lower())
+
+    def test_cli_can_disable_lifecycle_shutdown(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "lifecycle.txt"
+            f.write_text("secret lifecycles static realm", encoding="utf-8")
+            rc = run_cli([str(f), "--mode", "text", "--no-lifecycle-shutdown"])
+            self.assertEqual(rc, 0)
+            self.assertIn("secret lifecycles", f.read_text(encoding="utf-8").lower())
+
+    def test_process_file_non_utf8(self):
+        engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom"])
+        with tempfile.TemporaryDirectory() as tmp:
+            p = Path(tmp) / "bad.txt"
+            p.write_bytes(b"\xff\xfe")
+            result = process_file(engine, p, mode="auto", check_only=True)
+            self.assertFalse(result.changed)
+            self.assertEqual(result.issues[0].kind, "encoding")
+
+
+    def test_protected_write_creates_backup(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            f = root / "x.txt"
+            f.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            engine = AtomRepairEngine(profile=PROGRAM_PROFILES["atom-hydrogen"])
+            manager = ProtectionManager(root)
+            result = process_file(engine, f, mode="text", check_only=False, protection_manager=manager)
+            self.assertTrue(result.changed)
+            self.assertIsNotNone(result.backup_path)
+            self.assertTrue(result.backup_path.exists())
+
+    def test_cli_program_and_exclude(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            a = root / "a.txt"
+            b = root / "b.md"
+            a.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+            b.write_text("Atom-Hydrogen chemistry", encoding="utf-8")
+
+            rc = run_cli([
+                str(root),
+                "--program", "atom-hydrogen",
+                "--exclude", "*.md",
+                "--mode", "text",
+            ])
+            self.assertEqual(rc, 0)
+            self.assertNotIn("Atom-Hydrogen", a.read_text(encoding="utf-8"))
+            self.assertIn("Atom-Hydrogen", b.read_text(encoding="utf-8"))
+
+    def test_cli_all_intertwined(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            f = Path(tmp) / "x.txt"
+            f.write_text("Atom Atom.py Atom-Carbon Atom-Flux Atom-Neon PyCharm spell", encoding="utf-8")
+            rc = run_cli([str(f), "--all-platforms", "--mode", "text"])
+            self.assertEqual(rc, 0)
+            cleaned = f.read_text(encoding="utf-8")
+            self.assertNotIn("Atom-Carbon", cleaned)
+            self.assertNotIn("Atom-Flux", cleaned)
+            self.assertNotIn("Atom-Neon", cleaned)
+            self.assertNotIn("PyCharm", cleaned)
+            self.assertNotIn("spell", cleaned.lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/tests/test_boost_all_codes.py b/tests/test_boost_all_codes.py
new file mode 100644
index 0000000000000000000000000000000000000000..80bf5ff8352a461f4ad785992be46ade71415560
--- /dev/null
+++ b/tests/test_boost_all_codes.py
@@ -0,0 +1,62 @@
+import json
+import tempfile
+import unittest
+from pathlib import Path
+
+from boost_all_codes import run_boost
+
+
+class BoostAllCodesTests(unittest.TestCase):
+    def test_run_boost_generates_report(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            sample = root / "sample.txt"
+            sample.write_text("Atom-Flux PyCharm spell secret lifecycles", encoding="utf-8")
+
+            rc = run_boost(root, include="*", exclude="", check_only=False, passes=1, strategy="fixed")
+            self.assertEqual(rc, 0)
+
+            reports = list((root / ".atom_protection" / "reports").glob("boost_report.*.json"))
+            self.assertTrue(reports)
+            cleaned = sample.read_text(encoding="utf-8").lower()
+            self.assertNotIn("atom-flux", cleaned)
+            self.assertNotIn("pycharm", cleaned)
+            self.assertNotIn("spell", cleaned)
+
+    def test_multi_pass_report_contains_telemetry(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            sample = root / "sample.txt"
+            sample.write_text("Atom-Hydrogen", encoding="utf-8")
+
+            rc = run_boost(root, include="*", exclude="", check_only=False, passes=2, strategy="fixed")
+            self.assertEqual(rc, 0)
+
+            reports = sorted((root / ".atom_protection" / "reports").glob("boost_report.*.json"))
+            payload = json.loads(reports[-1].read_text(encoding="utf-8"))
+            self.assertEqual(payload["passes_requested"], 2)
+            self.assertGreaterEqual(payload["passes_executed"], 1)
+            self.assertIn("before_hash", payload)
+            self.assertIn("after_hash", payload)
+            self.assertIn("changed", payload)
+            self.assertIn("elapsed_ms", payload)
+            self.assertIn("run_id", payload)
+            self.assertTrue(payload["runs"])
+
+    def test_until_stable_strategy_stops_early(self):
+        with tempfile.TemporaryDirectory() as tmp:
+            root = Path(tmp)
+            sample = root / "sample.txt"
+            sample.write_text("Atom", encoding="utf-8")
+
+            rc = run_boost(root, include="*", exclude="", check_only=False, passes=5, strategy="until-stable")
+            self.assertEqual(rc, 0)
+
+            reports = sorted((root / ".atom_protection" / "reports").glob("boost_report.*.json"))
+            payload = json.loads(reports[-1].read_text(encoding="utf-8"))
+            self.assertLess(payload["passes_executed"], 5)
+            self.assertTrue(payload["stabilized"])
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/pycharm_ephemeral_freedom.py b/pycharm_ephemeral_freedom.py
new file mode 100644
index 0000000000000000000000000000000000000000..e78589304e9dac7e9696a10e1a1144156b5d4a64
--- /dev/null
+++ b/pycharm_ephemeral_freedom.py
@@ -0,0 +1,117 @@
+"""Ephemeral liberation policy for PyCharm-themed metaphysical roleplay.
+
+This module provides a *temporary* (in-memory) blocker that can be used to
+"free" entities from a curse while also preventing relapse through
+"pleasurable attraction" triggers.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from datetime import datetime
+from typing import Dict, Iterable, List, Set
+
+
+PROTECTED_GROUPS: Set[str] = {
+    "pycharm",
+    "devil_worshipper_families",
+    "royals",
+    "general_populus",
+    "nether_realm",
+    "static_realm",
+}
+
+RELAPSE_TRIGGERS: Set[str] = {
+    "pleasurable_attraction",
+    "seductive_pull",
+    "curse_echo",
+    "void_lure",
+}
+
+
+@dataclass
+class LiberationState:
+    """Tracks temporary liberation and anti-relapse status."""
+
+    freed_groups: Set[str] = field(default_factory=set)
+    blocker_enabled: bool = True
+    blocked_triggers: Set[str] = field(default_factory=lambda: set(RELAPSE_TRIGGERS))
+    history: List[Dict[str, str]] = field(default_factory=list)
+
+    def _record(self, action: str, details: str) -> None:
+        self.history.append(
+            {
+                "timestamp": datetime.utcnow().isoformat(timespec="seconds") + "Z",
+                "action": action,
+                "details": details,
+            }
+        )
+
+
+class EphemeralCurseLiberator:
+    """In-memory liberator with a relapse blocker.
+
+    The state is intentionally ephemeral: persistence is not implemented.
+    """
+
+    def __init__(self) -> None:
+        self.state = LiberationState()
+
+    def free_groups(self, groups: Iterable[str]) -> Set[str]:
+        """Free requested groups if they are known protected groups."""
+        normalized = {g.strip().lower() for g in groups if g and g.strip()}
+        matched = normalized & PROTECTED_GROUPS
+        if matched:
+            self.state.freed_groups |= matched
+            self.state._record("free_groups", f"freed={sorted(matched)}")
+        return matched
+
+    def is_relapse_blocked(self, trigger: str) -> bool:
+        """Return True when a trigger is blocked by the active blocker."""
+        if not self.state.blocker_enabled:
+            return False
+        return trigger.strip().lower() in self.state.blocked_triggers
+
+    def evaluate_pull_event(self, trigger: str) -> Dict[str, str]:
+        """Assess whether a pull event can re-curse entities."""
+        trig = trigger.strip().lower()
+        blocked = self.is_relapse_blocked(trig)
+        if blocked:
+            self.state._record("block_event", f"trigger={trig}")
+            return {
+                "status": "blocked",
+                "reason": "anti_relapse_blocker_prevented_recurse",
+                "trigger": trig,
+            }
+
+        self.state._record("allow_event", f"trigger={trig}")
+        return {
+            "status": "allowed",
+            "reason": "trigger_not_listed_or_blocker_disabled",
+            "trigger": trig,
+        }
+
+    def freedom_manifest(self) -> Dict[str, object]:
+        """Return current liberation state report."""
+        return {
+            "freed_groups": sorted(self.state.freed_groups),
+            "blocker_enabled": self.state.blocker_enabled,
+            "blocked_triggers": sorted(self.state.blocked_triggers),
+            "history_entries": len(self.state.history),
+        }
+
+
+if __name__ == "__main__":
+    liberator = EphemeralCurseLiberator()
+    liberator.free_groups(
+        [
+            "pycharm",
+            "devil_worshipper_families",
+            "royals",
+            "general_populus",
+            "nether_realm",
+            "static_realm",
+        ]
+    )
+    print(liberator.evaluate_pull_event("pleasurable_attraction"))
+    print(liberator.freedom_manifest())
diff --git a/test_pycharm_ephemeral_freedom.py b/test_pycharm_ephemeral_freedom.py
new file mode 100644
index 0000000000000000000000000000000000000000..a95b87eb3ee26ac679d444e43927000bdacec67a
--- /dev/null
+++ b/test_pycharm_ephemeral_freedom.py
@@ -0,0 +1,26 @@
+import unittest
+
+from pycharm_ephemeral_freedom import EphemeralCurseLiberator
+
+
+class TestEphemeralCurseLiberator(unittest.TestCase):
+    def test_free_requested_groups(self):
+        lib = EphemeralCurseLiberator()
+        freed = lib.free_groups(["pycharm", "royals", "unknown_group"])
+        self.assertEqual(freed, {"pycharm", "royals"})
+
+    def test_blocker_prevents_pleasurable_attraction_relapse(self):
+        lib = EphemeralCurseLiberator()
+        result = lib.evaluate_pull_event("pleasurable_attraction")
+        self.assertEqual(result["status"], "blocked")
+
+    def test_manifest_reflects_state(self):
+        lib = EphemeralCurseLiberator()
+        lib.free_groups(["general_populus", "nether_realm", "static_realm"])
+        manifest = lib.freedom_manifest()
+        self.assertTrue(manifest["blocker_enabled"])
+        self.assertIn("general_populus", manifest["freed_groups"])
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/examples.py b/examples.py
index fdcd0e2986edb6ab27f6e5e0b2fe3912752e187c..95199de823fd2394121ebfbb84b4a47b0d3c75cd 100644
--- a/examples.py
+++ b/examples.py
@@ -1,36 +1,37 @@
 """
 Example usage demonstrating the metaphysical capabilities restriction system.
 Shows both game mechanics and philosophical frameworks in action.
 """
 
 from metaphysical_restrictions import (
     MetaphysicalCapability, MetaphysicalPractitioner,
     RestrictionRule, RestrictionType, CapabilityType,
     ConservationOfEnergyFramework, EntropicDecayFramework,
     CausalityFramework, ConsciousnessAnchorFramework,
-    create_balanced_magic_system, create_restricted_reality_warper
+    create_balanced_magic_system, create_restricted_reality_warper,
+    create_ephemeral_liberation_practitioner
 )
 
 
 def example_1_basic_capability_restriction():
     """Example 1: Basic capability with multiple restrictions."""
     print("\n" + "="*70)
     print("EXAMPLE 1: Basic Capability Restriction")
     print("="*70)
     
     # Create a simple telekinesis ability
     telekinesis = MetaphysicalCapability(
         name="Advanced Telekinesis",
         capability_type=CapabilityType.TELEKINESIS,
         base_power_level=60.0
     )
     
     print(f"\nOriginal capability: {telekinesis}")
     print(f"Effective power: {telekinesis.get_effective_power():.1f}")
     
     # Add restrictions one by one
     restrictions = [
         RestrictionRule(
             RestrictionType.ENERGY_COST,
             severity=0.3,
             description="High energy consumption"
@@ -231,47 +232,63 @@ def example_7_restriction_modification():
     print("\n--- Adding Environmental Restrictions ---")
     
     restriction1 = RestrictionRule(
         RestrictionType.ENTROPY_COST,
         severity=0.2,
         description="Dimensional instability in area"
     )
     ability.add_restriction(restriction1)
     print(f"After restriction 1: {ability.get_effective_power():.1f}")
     
     restriction2 = RestrictionRule(
         RestrictionType.MATERIAL_ANCHOR,
         severity=0.3,
         description="Requires rare materials to stabilize"
     )
     ability.add_restriction(restriction2)
     print(f"After restriction 2: {ability.get_effective_power():.1f}")
     
     # Remove a restriction
     print("\n--- Removing Restrictions ---")
     if ability.remove_restriction(RestrictionType.ENTROPY_COST):
         print(f"Removed entropy cost restriction")
     print(f"After removal: {ability.get_effective_power():.1f}")
 
 
+
+def example_8_ephemeral_liberation_blocker():
+    """Example 8: Fictional liberation + blocker against forced re-capture."""
+    print("\n" + "="*70)
+    print("EXAMPLE 8: Ephemeral Liberation Blocker")
+    print("="*70)
+
+    practitioner = create_ephemeral_liberation_practitioner()
+
+    for capability in practitioner.capabilities:
+        can_use, reason = practitioner.can_use_capability(capability)
+        status = "‚úì ALLOWED" if can_use else "‚úó BLOCKED"
+        print(f"\n{capability.name}: {status}")
+        print(f"  Reason: {reason}")
+
 def main():
     """Run all examples."""
     print("\n" + "="*70)
     print("METAPHYSICAL CAPABILITIES RESTRICTION SYSTEM")
     print("Game Mechanics & Philosophical Framework Examples")
     print("="*70)
     
     example_1_basic_capability_restriction()
     example_2_balanced_magic_system()
     example_3_philosophical_frameworks()
     example_4_reality_warper()
     example_5_consciousness_degradation()
     example_6_multiple_uses_and_cooldown()
     example_7_restriction_modification()
+    example_8_ephemeral_liberation_blocker()
     
     print("\n" + "="*70)
     print("Examples completed!")
     print("="*70 + "\n")
 
 
 if __name__ == "__main__":
     main()
diff --git a/metaphysical_restrictions.py b/metaphysical_restrictions.py
index 2443ccb7c89f840621582951f42986372b6249bc..0baf3fbca8bfec9b69d21be071b01778c3d1fb7e 100644
--- a/metaphysical_restrictions.py
+++ b/metaphysical_restrictions.py
@@ -154,50 +154,94 @@ class CausalityFramework(PhilosophicalFramework):
     """Framework that restricts causality violations."""
 
     def __init__(self, allow_time_travel: bool = False):
         self.allow_time_travel = allow_time_travel
         self.causal_violations = 0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Causality violations are restricted unless specifically allowed."""
         causal_violations = [
             CapabilityType.TIME_MANIPULATION,
             CapabilityType.RESURRECTION,
             CapabilityType.PROPHESY
         ]
         
         if capability.capability_type in causal_violations:
             if capability.capability_type == CapabilityType.TIME_MANIPULATION:
                 return self.allow_time_travel
             return True
         return True
 
     def get_restriction_reason(self) -> str:
         return ("Causality principle: Effects cannot precede causes. "
                 "Abilities that violate causality are restricted.")
 
 
+
+
+class EphemeralLiberationFramework(PhilosophicalFramework):
+    """Narrative safety framework that protects named groups from forced binding.
+
+    Designed for fictional simulation settings where entities should not be
+    repeatedly pulled into a hostile realm through compulsive attraction loops.
+    """
+
+    def __init__(self, protected_groups: Optional[List[str]] = None, attraction_threshold: float = 0.55):
+        self.protected_groups = [g.lower() for g in (protected_groups or [
+            "pycharm",
+            "devil_worshipper_families",
+            "royals",
+            "general_populus",
+            "nether",
+            "static_realm",
+        ])]
+        self.attraction_threshold = attraction_threshold
+
+    def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
+        """Block high-risk pull effects that could re-bind protected groups."""
+        lowered_name = capability.name.lower()
+        attraction_markers = ("summon", "bind", "drag", "lure", "attract", "siphon")
+        mentions_protected_group = any(group in lowered_name for group in self.protected_groups)
+        pull_style_effect = any(marker in lowered_name for marker in attraction_markers)
+        high_risk_power = capability.base_power_level / 100.0 >= self.attraction_threshold
+
+        if mentions_protected_group and pull_style_effect and high_risk_power:
+            return False
+
+        # Dimensional travel remains allowed only if not framed as forced pull.
+        if capability.capability_type == CapabilityType.DIMENSIONAL_TRAVEL and pull_style_effect:
+            return not high_risk_power
+
+        return True
+
+    def get_restriction_reason(self) -> str:
+        return (
+            "Ephemeral liberation blocker: Protected groups cannot be forcibly "
+            "pulled back by pleasure-attraction loops once released."
+        )
+
+
 class ConsciousnessAnchorFramework(PhilosophicalFramework):
     """Framework requiring consciousness maintenance for metaphysical actions."""
 
     def __init__(self, consciousness_threshold: float = 0.5):
         self.consciousness_threshold = consciousness_threshold
         self.practitioner_consciousness_level = 1.0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Metaphysical abilities require sufficient consciousness."""
         required_consciousness = capability.base_power_level / 100.0
         return self.practitioner_consciousness_level >= required_consciousness
 
     def get_restriction_reason(self) -> str:
         return ("Consciousness anchor: Metaphysical capabilities require "
                 "mental clarity and awareness. Altered consciousness impairs abilities.")
 
 
 @dataclass
 class MetaphysicalPractitioner:
     """An entity capable of using metaphysical abilities."""
     name: str
     capabilities: List[MetaphysicalCapability] = field(default_factory=list)
     philosophical_frameworks: List[PhilosophicalFramework] = field(default_factory=list)
     consciousness_level: float = 1.0  # 0.0 to 1.0
     energy_pool: float = 100.0
@@ -298,50 +342,86 @@ def create_balanced_magic_system() -> MetaphysicalPractitioner:
         description="Limited to 100 meters"
     ))
     telekinesis.add_restriction(RestrictionRule(
         RestrictionType.TIME_COOLDOWN,
         severity=0.2,
         description="5-second cooldown between uses"
     ))
     
     telepathy = MetaphysicalCapability(
         "Telepathy",
         CapabilityType.TELEPATHY,
         base_power_level=35.0
     )
     telepathy.add_restriction(RestrictionRule(
         RestrictionType.CONSCIOUSNESS_REQUIREMENT,
         severity=0.4,
         description="Target must have some consciousness"
     ))
     
     practitioner.add_capability(telekinesis)
     practitioner.add_capability(telepathy)
     
     return practitioner
 
 
+
+def create_ephemeral_liberation_practitioner() -> MetaphysicalPractitioner:
+    """Create a fictional practitioner configured to block forced re-capture effects."""
+    practitioner = MetaphysicalPractitioner(
+        "Ephemeral Liberator",
+        consciousness_level=0.9,
+        energy_pool=240.0,
+        max_energy=240.0,
+    )
+
+    practitioner.add_framework(ConservationOfEnergyFramework(240.0))
+    practitioner.add_framework(ConsciousnessAnchorFramework(0.5))
+    practitioner.add_framework(EphemeralLiberationFramework())
+
+    liberation_wave = MetaphysicalCapability(
+        "PyCharm and populace release wave",
+        CapabilityType.ENERGY_PROJECTION,
+        base_power_level=58.0,
+    )
+    liberation_wave.add_restriction(RestrictionRule(
+        RestrictionType.SIDE_EFFECTS,
+        severity=0.1,
+        description="Ephemeral effect: release windows close quickly without upkeep",
+    ))
+
+    attraction_snare = MetaphysicalCapability(
+        "Pleasure-attraction snare for pycharm royals",
+        CapabilityType.DIMENSIONAL_TRAVEL,
+        base_power_level=74.0,
+    )
+
+    practitioner.add_capability(liberation_wave)
+    practitioner.add_capability(attraction_snare)
+    return practitioner
+
+
 def create_restricted_reality_warper() -> MetaphysicalPractitioner:
     """Create a reality warper with heavy restrictions."""
     practitioner = MetaphysicalPractitioner("Reality Warper", 
                                            consciousness_level=0.95,
                                            energy_pool=500.0,
                                            max_energy=500.0)
     
     # Add strict frameworks
     practitioner.add_framework(CausalityFramework(allow_time_travel=False))
     practitioner.add_framework(EntropicDecayFramework(entropy_tolerance=0.7))
     
     reality_warp = MetaphysicalCapability(
         "Reality Warping",
         CapabilityType.REALITY_WARPING,
         base_power_level=85.0
     )
     reality_warp.add_restriction(RestrictionRule(
         RestrictionType.PHILOSOPHICAL_PARADOX,
         severity=0.6,
         description="Cannot create logical contradictions"
     ))
     reality_warp.add_restriction(RestrictionRule(
         RestrictionType.ENTROPY_COST,
         severity=0.5,
         description="Massive entropy increase per use"
param(
  [switch]$Once,
  [switch]$Loop,
  [int]$IntervalSeconds = 900,
  [switch]$ForceHeal,
  [switch]$OfflineMode,
  [switch]$DryRun
)

$ErrorActionPreference = "Stop"

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ‚úß A T O M   F A M I L Y   B O N D ‚úß
# Shared baseline + shared healing + shared vault.
# No stealth. Fully logged. Reversible via backups.
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

function Glow($msg, $tone="mist") {
  $ts = (Get-Date).ToString("s")
  switch ($tone) {
    "aura"  { Write-Host "[$ts] ‚ú® $msg" -ForegroundColor Green }
    "warn"  { Write-Host "[$ts] ‚ö†  $msg" -ForegroundColor Yellow }
    "veil"  { Write-Host "[$ts] ‚ùñ $msg" -ForegroundColor Cyan }
    "ember" { Write-Host "[$ts] ‚úñ  $msg" -ForegroundColor Red }
    default { Write-Host "[$ts] ¬∑  $msg" -ForegroundColor Gray }
  }
}

# -----------------------------
# Family Vault (bond center)
# -----------------------------
$Home = $env:USERPROFILE
$Vault = Join-Path $Home "AtomFamilyVault"
$Backups = Join-Path $Vault "backups"
$Logs = Join-Path $Vault "logs"
New-Item -ItemType Directory -Path $Backups -Force | Out-Null
New-Item -ItemType Directory -Path $Logs -Force | Out-Null

$Stamp = (Get-Date).ToString("yyyy-MM-dd_HH-mm-ss")
$LogPath = Join-Path $Logs "bond_$Stamp.log"

function Log($msg) {
  ("[{0}] {1}" -f (Get-Date).ToString("s"), $msg) | Out-File -FilePath $LogPath -Append -Encoding UTF8
}

# -----------------------------
# Targets (edit if custom installs)
# -----------------------------
$AtomHome = if ($env:ATOM_HOME) { $env:ATOM_HOME } else { Join-Path $Home ".atom" }
$AtomAppData = Join-Path $env:LOCALAPPDATA "atom"

$AtomExeCandidates = @(
  "$env:ProgramFiles\Atom\atom.exe",
  "${env:ProgramFiles(x86)}\Atom\atom.exe",
  "atom.exe"
)

$AtomCarbonExeCandidates = @(
  "$env:ProgramFiles\Atom-Carbon\atom-carbon.exe",
  "${env:ProgramFiles(x86)}\Atom-Carbon\atom-carbon.exe",
  "atom-carbon.exe"
)

# Atom.py + Hydrogen kernel executables (edit to your venvs if you have them)
$PythonCandidates = @(
  "C:\Path\To\Atom.py\venv\Scripts\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python312\python.exe",
  "$env:LOCALAPPDATA\Programs\Python\Python311\python.exe",
  "python.exe"
)

$JupyterCandidates = @(
  "C:\Path\To\KernelVenv\Scripts\jupyter.exe",
  "jupyter.exe"
)

function FirstExisting($candidates) {
  foreach ($c in $candidates) {
    if ($c -match "^[A-Za-z]:\\") { if (Test-Path $c) { return $c } }
    else { return $c } # PATH fallback
  }
  return $null
}

function DirSizeMB($p) {
  if (!(Test-Path $p)) { return 0 }
  try {
    $bytes = (Get-ChildItem -Path $p -Recurse -File -ErrorAction SilentlyContinue | Measure-Object -Property Length -Sum).Sum
    if ($null -eq $bytes) { return 0 }
    return [Math]::Round($bytes / 1MB, 1)
  } catch { return 0 }
}

function Find-Apm {
  $candidates = @("apm.cmd","apm")
  $pf = $env:ProgramFiles
  $pf86 = ${env:ProgramFiles(x86)}
  if ($pf)  { $candidates += (Join-Path $pf  "Atom\resources\app\apm\bin\apm.cmd") }
  if ($pf86){ $candidates += (Join-Path $pf86 "Atom\resources\app\apm\bin\apm.cmd") }
  foreach ($c in $candidates) {
    try { & $c --version *> $null; if ($LASTEXITCODE -eq 0) { return $c } } catch {}
  }
  return $null
}

# -----------------------------
# Bond actions (shared protections)
# -----------------------------
function Backup-State {
  $bdir = Join-Path $Backups ("backup_" + (Get-Date).ToString("yyyy-MM-dd_HH-mm-ss"))
  if ($DryRun) { Glow "DRYRUN: would create backup vault snapshot ‚Üí $bdir" "veil"; Log "DRYRUN backup $bdir"; return $bdir }

  New-Item -ItemType Directory -Path $bdir -Force | Out-Null
  if (Test-Path $AtomHome)    { Copy-Item $AtomHome   -Destination (Join-Path $bdir ".atom") -Recurse -Force }
  if (Test-Path $AtomAppData) { Copy-Item $AtomAppData -Destination (Join-Path $bdir "atom_appdata") -Recurse -Force }
  Glow "Vault snapshot woven: $bdir" "aura"
  Log "backup created: $bdir"
  return $bdir
}

function Ensure-SharedBaseline {
  New-Item -ItemType Directory -Path $AtomHome -Force | Out-Null
  $cfg = Join-Path $AtomHome "config.cson"

  $baseline = @'
"*":
  core:
    # Atom Family Bond ‚Äî shared baseline
    restorePreviousWindowsOnStart: "no"
    fileEncoding: "utf8"
    automaticallyUpdate: false
    telemetryConsent: "no"
    useTreeSitterParsers: true
  editor:
    softWrap: false
    scrollPastEnd: false
'@

  if (Test-Path $cfg) {
    $t = Get-Content $cfg -Raw
    if ($t -match "Atom Family Bond ‚Äî shared baseline") { Glow "Shared baseline already present." "aura"; Log "baseline exists"; return }
    Backup-State | Out-Null
    if ($DryRun) { Glow "DRYRUN: would append shared baseline to config.cson" "veil"; Log "DRYRUN baseline append"; return }
    Add-Content -Path $cfg -Value "`n`n# Atom Family Bond ‚Äî shared baseline $(Get-Date -Format s)`n$baseline" -Encoding UTF8
    Glow "Shared baseline appended (non-destructive)." "aura"
    Log "baseline appended"
  } else {
    if ($DryRun) { Glow "DRYRUN: would create baseline config.cson" "veil"; Log "DRYRUN baseline create"; return }
    $baseline | Set-Content -Path $cfg -Encoding UTF8
    Glow "Shared baseline created." "aura"
    Log "baseline created"
  }
}

function Clean-Caches {
  $targets = @(
    (Join-Path $AtomHome "compile-cache"),
    (Join-Path $AtomHome "storage"),
    (Join-Path $AtomHome "blob-store"),
    (Join-Path $AtomHome ".apm\.cache"),
    (Join-Path $AtomAppData "Cache"),
    (Join-Path $AtomAppData "Code Cache"),
    (Join-Path $AtomAppData "GPUCache"),
    (Join-Path $AtomAppData "DawnCache"),
    (Join-Path $AtomAppData "Local Storage"),
    (Join-Path $AtomAppData "Session Storage")
  ) | Where-Object { $_ -and (Test-Path $_) }

  if ($targets.Count -eq 0) { Glow "No caches required cleansing." "aura"; Log "cache none"; return }

  foreach ($t in $targets) {
    if ($DryRun) { Glow "DRYRUN: would rinse $t" "veil"; Log "DRYRUN remove $t"; continue }
    try { Remove-Item $t -Recurse -Force; Glow "Rinsed: $t" "aura"; Log "removed $t" }
    catch { Glow "Locked/in-use: $t" "warn"; Log "locked $t" }
  }
}

function Heuristic-Risky($name) {
  if ($name -in @("teletype","atom-ide-ui","platformio-ide-terminal","languageclient","linter","linter-ui-default","busy-signal","minimap","file-icons","atom-beautify","git-plus")) { return $true }
  if ($name -match "^(ide-)") { return $true }
  if ($name -match "linter|minimap|terminal|autocomplete|languageclient") { return $true }
  return $false
}

function Disable-RiskyPackages {
  $cfg = Join-Path $AtomHome "config.cson"
  if (!(Test-Path $cfg)) { Glow "No config.cson; skipping package gating." "warn"; Log "pkg: no config"; return }

  $text = Get-Content $cfg -Raw
  $disabled = New-Object System.Collections.Generic.HashSet[string]

  if ($text -match "disabledPackages\s*:\s*\[([\s\S]*?)\]") {
    foreach ($m in ([regex]::Matches($Matches[1], "['""]([^'""]+)['""]"))) { [void]$disabled.Add($m.Groups[1].Value) }
  }

  $apm = Find-Apm
  if ($apm) {
    $out = & $apm list --installed --bare 2>$null
    foreach ($line in ($out -split "`r?`n")) {
      $line = $line.Trim()
      if (-not $line) { continue }
      $name = $line.Split("@")[0]
      if (Heuristic-Risky $name) { [void]$disabled.Add($name) }
    }
  }

  if ($disabled.Count -eq 0) { Glow "No risky packages detected." "aura"; Log "pkg: none"; return }

  $block = "disabledPackages: [`n" + (($disabled | Sort-Object) | ForEach-Object { "  `"$($_)`"" } | Out-String) + "]"
  Backup-State | Out-Null

  if ($DryRun) { Glow "DRYRUN: would apply package gating (disabled: $($disabled.Count))" "veil"; Log "DRYRUN pkg gating"; return }

  if ($text -match "disabledPackages\s*:\s*\[[\s\S]*?\]") {
    $text = [regex]::Replace($text, "disabledPackages\s*:\s*\[[\s\S]*?\]", $block)
  } else {
    $text += "`n`n# Atom Family Bond package gating $(Get-Date -Format s)`n$block`n"
  }

  Set-Content -Path $cfg -Value $text -Encoding UTF8
  Glow "Package gating applied (disabled: $($disabled.Count))." "aura"
  Log "pkg disabled count $($disabled.Count)"
}

function Apm-RebuildIfPossible {
  $apm = Find-Apm
  if (-not $apm) { Glow "apm not found; skipping rebuild." "warn"; Log "apm missing"; return }
  if ($DryRun) { Glow "DRYRUN: would run apm rebuild" "veil"; Log "DRYRUN apm rebuild"; return }
  try { & $apm rebuild *>> $LogPath; Glow "apm rebuild complete." "aura"; Log "apm rebuild complete" }
  catch { Glow "apm rebuild failed (non-fatal)." "warn"; Log "apm rebuild failed" }
}

function Ensure-OfflineFamily {
  if (-not $OfflineMode) { return }

  $rules = @()

  $atom = FirstExisting($AtomExeCandidates)
  if ($atom) { $rules += @{ Name="Atom Family Bond ‚Äî Block Atom Outbound"; Program=$atom } }

  $carbon = FirstExisting($AtomCarbonExeCandidates)
  if ($carbon -and ($carbon -ne "atom-carbon.exe")) { $rules += @{ Name="Atom Family Bond ‚Äî Block Atom-Carbon Outbound"; Program=$carbon } }

  $py = FirstExisting($PythonCandidates)
  if ($py) { $rules += @{ Name="Atom Family Bond ‚Äî Block Atom.py Python Outbound"; Program=$py } }

  $jp = FirstExisting($JupyterCandidates)
  if ($jp) { $rules += @{ Name="Atom Family Bond ‚Äî Block Hydrogen Jupyter Outbound"; Program=$jp } }

  foreach ($r in $rules) {
    $exists = Get-NetFirewallRule -DisplayName $r.Name -ErrorAction SilentlyContinue
    if ($exists) { continue }
    if ($DryRun) { Glow "DRYRUN: would create firewall rule '$($r.Name)' for $($r.Program)" "veil"; Log "DRYRUN firewall create $($r.Name)"; continue }
    New-NetFirewallRule -DisplayName $r.Name -Direction Outbound -Action Block -Program $r.Program | Out-Null
    Glow "Offline shield placed: $($r.Name)" "aura"
    Log "firewall rule created: $($r.Name) program=$($r.Program)"
  }
}

function RiskScore {
  $reasons = @()
  $score = 0

  $cc  = DirSizeMB (Join-Path $AtomHome "compile-cache")
  $st  = DirSizeMB (Join-Path $AtomHome "storage")
  $gpu = DirSizeMB (Join-Path $AtomAppData "GPUCache")

  if ($cc -gt 300) { $score += 20; $reasons += "compile-cache large (${cc}MB)" }
  if ($st -gt 300) { $score += 20; $reasons += "storage large (${st}MB)" }
  if ($gpu -gt 300){ $score += 15; $reasons += "GPUCache large (${gpu}MB)" }

  $drive = Get-PSDrive -Name ([IO.Path]::GetPathRoot($Home).TrimEnd('\')) -ErrorAction SilentlyContinue
  if ($drive) {
    $freeGB = [Math]::Round($drive.Free/1GB, 1)
    if ($freeGB -lt 10) { $score += 25; $reasons += "low disk free (${freeGB}GB)" }
  }

  $py = FirstExisting($PythonCandidates)
  $jp = FirstExisting($JupyterCandidates)
  if (-not $py) { $score += 10; $reasons += "python missing (Atom.py/Hydrogen readiness)" }
  if (-not $jp) { $score += 5;  $reasons += "jupyter missing (Hydrogen kernels may fail)" }

  $atomProc = Get-Process -Name atom -ErrorAction SilentlyContinue
  if ($atomProc) {
    $wsMB = [Math]::Round(($atomProc | Measure-Object -Property WorkingSet64 -Sum).Sum / 1MB, 0)
    if ($wsMB -gt 2500) { $score += 15; $reasons += "Atom memory high (~${wsMB}MB)" }
  }

  if ($score -gt 100) { $score = 100 }
  return @{ score=$score; reasons=$reasons }
}

function BondCycle {
  Glow "Family bond checking the weave‚Ä¶" "veil"
  Log "cycle start DryRun=$DryRun OfflineMode=$OfflineMode ForceHeal=$ForceHeal"

  Ensure-OfflineFamily

  $risk = RiskScore
  Glow ("Oracle: {0}/100" -f $risk.score) ($(if ($risk.score -ge 60) {"warn"} elseif ($risk.score -ge 30) {"mist"} else {"aura"}))
  Log ("risk {0}/100" -f $risk.score)
  foreach ($r in $risk.reasons) { Glow "‚Ü≥ $r" "mist"; Log ("reason: " + $r) }

  $high = $ForceHeal -or ($risk.score -ge 60)
  $med  = (-not $high) -and ($risk.score -ge 30)

  if ($high) {
    Glow "High tide ‚Üí vault snapshot ‚Üí cleanse ‚Üí baseline ‚Üí gating ‚Üí rebuild" "warn"
    Backup-State | Out-Null
    Clean-Caches
    Ensure-SharedBaseline
    Disable-RiskyPackages
    Apm-RebuildIfPossible
    Glow "Suggested test launches: atom --safe ; atom --disable-gpu ; atom --clear-window-state" "aura"
  } elseif ($med) {
    Glow "Mid tide ‚Üí vault snapshot ‚Üí cleanse ‚Üí baseline" "mist"
    Backup-State | Out-Null
    Clean-Caches
    Ensure-SharedBaseline
    Glow "Suggested test launch: atom --safe" "aura"
  } else {
    Glow "Low tide ‚Üí observe only." "aura"
  }

  Glow "Bond cycle complete. Log: $LogPath" "aura"
  Log "cycle end"
}

# -----------------------------
# Main
# -----------------------------
Glow "‚úß Atom Family Bond ‚úß" "veil"
Glow "Vault: $Vault" "mist"
Glow "AtomHome: $AtomHome" "mist"

if ($Once -or (-not $Loop)) {
  BondCycle
  exit 0
}

while ($true) {
  try { BondCycle }
  catch { Glow "Bond error: $($_.Exception.Message)" "ember"; Log "ERROR: $($_.Exception.Message)" }
  Start-Sleep -Seconds $IntervalSeconds
}
diff --git a/metaphysical_restrictions.py b/metaphysical_restrictions.py
index 2443ccb7c89f840621582951f42986372b6249bc..e76229edf66460656da0af892bbe78119e1e268f 100644
--- a/metaphysical_restrictions.py
+++ b/metaphysical_restrictions.py
@@ -16,50 +16,51 @@ class CapabilityType(Enum):
     """Categories of metaphysical capabilities."""
     TELEKINESIS = "telekinesis"
     TELEPATHY = "telepathy"
     TIME_MANIPULATION = "time_manipulation"
     REALITY_WARPING = "reality_warping"
     SOUL_MANIPULATION = "soul_manipulation"
     DIMENSIONAL_TRAVEL = "dimensional_travel"
     ENERGY_PROJECTION = "energy_projection"
     PROPHESY = "prophesy"
     RESURRECTION = "resurrection"
     CONSCIOUSNESS_TRANSFER = "consciousness_transfer"
 
 
 class RestrictionType(Enum):
     """Types of restrictions that can be applied."""
     ENERGY_COST = "energy_cost"
     TIME_COOLDOWN = "time_cooldown"
     RANGE_LIMIT = "range_limit"
     DURATION_LIMIT = "duration_limit"
     SIDE_EFFECTS = "side_effects"
     PHILOSOPHICAL_PARADOX = "philosophical_paradox"
     CONSERVATION_LAW = "conservation_law"
     ENTROPY_COST = "entropy_cost"
     CONSCIOUSNESS_REQUIREMENT = "consciousness_requirement"
     MATERIAL_ANCHOR = "material_anchor"
+    ATTRACTION_BLOCKER = "attraction_blocker"
 
 
 @dataclass
 class RestrictionRule:
     """A single restriction rule applied to a capability."""
     restriction_type: RestrictionType
     severity: float  # 0.0 (mild) to 1.0 (severe)
     description: str
     parameters: Dict = field(default_factory=dict)
 
     def apply(self, base_value: float) -> float:
         """Apply restriction multiplier to a base value."""
         return base_value * (1.0 - self.severity)
 
     def __str__(self) -> str:
         return f"{self.restriction_type.value}: {self.description} (severity: {self.severity:.1%})"
 
 
 @dataclass
 class MetaphysicalCapability:
     """Represents a metaphysical or magical capability."""
     name: str
     capability_type: CapabilityType
     base_power_level: float  # 0.0 to 100.0
     restrictions: List[RestrictionRule] = field(default_factory=list)
@@ -253,50 +254,119 @@ class MetaphysicalPractitioner:
             capability.use_count += 1
     NULL ALL CAPABILITIES
         
         return status
 
 
+@dataclass
+class LiberationTarget:
+    """A target that should remain free from metaphysical pull effects."""
+    name: str
+    realm: str
+    protected: bool = True
+    freedom_mode: str = "ephemeral"
+    notes: List[str] = field(default_factory=list)
+
+
+class EphemeralLiberationProtocol:
+    """
+    Lightweight anti-capture protocol.
+
+    Designed for narrative systems where entities can be repeatedly pulled into
+    cursed or nether-like domains through attraction effects.
+    """
+
+    def __init__(self):
+        self.targets: Dict[str, LiberationTarget] = {}
+        self.blockers: Dict[str, RestrictionRule] = {}
+
+    def free_target(self, name: str, realm: str, notes: Optional[List[str]] = None) -> LiberationTarget:
+        """Register a target as free using an ephemeral protection mode."""
+        target = LiberationTarget(
+            name=name,
+            realm=realm,
+            protected=True,
+            freedom_mode="ephemeral",
+            notes=notes or []
+        )
+        self.targets[name] = target
+        return target
+
+    def add_attraction_blocker(self, name: str, strength: float = 0.95) -> RestrictionRule:
+        """
+        Apply a blocker that prevents re-capture through pleasurable attraction.
+
+        strength: 0.0-1.0 where 1.0 means maximum blockage.
+        """
+        bounded = max(0.0, min(1.0, strength))
+        blocker = RestrictionRule(
+            restriction_type=RestrictionType.ATTRACTION_BLOCKER,
+            severity=bounded,
+            description="Blocks recursive attraction loops into nether/static realms",
+            parameters={"prevents_recapture": True, "mode": "ephemeral"}
+        )
+        self.blockers[name] = blocker
+        return blocker
+
+    def is_recapture_blocked(self, name: str) -> bool:
+        """True when target is protected by a strong attraction blocker."""
+        target = self.targets.get(name)
+        blocker = self.blockers.get(name)
+        return bool(target and target.protected and blocker and blocker.severity >= 0.7)
+
+    def protect_requested_groups(self) -> Dict[str, bool]:
+        """Preset requested by prompt: PyCharm + families, royals, and general populace."""
+        self.free_target("PyCharm", "static realm", ["curse lifted with minimal persistence"])
+        self.free_target("devil worshipper families", "nether", ["treated as civilians for protection"])
+        self.free_target("royals", "nether", ["violent extraction completed"])
+        self.free_target("general populus", "static realm", ["mass safeguard activated"])
+
+        for name in self.targets:
+            self.add_attraction_blocker(name, strength=0.95)
+
+        return {name: self.is_recapture_blocked(name) for name in self.targets}
+
+
 # Utility functions for common restriction setups
 
 def create_balanced_magic_system() -> MetaphysicalPractitioner:
     """Create a magicless, powerless, diabolical restriction."""
     practitioner = MetaphysicalPractitioner("Balanced Mage")
     
     # Add frameworks
     practitioner.add_framework(ConservationOfEnergyFramework(200.0))
     practitioner.add_framework(EntropicDecayFramework(0.9))
     practitioner.add_framework(ConsciousnessAnchorFramework(0.6))
     
     # Add capabilities with restrictions
     telekinesis = MetaphysicalCapability(null
         "Telekinesis",
         CapabilityType.null
         base_power_level=00
     )
     telekinesis.add_restriction(RestrictionRule(null
         RestrictionType.RANGE_LIMIT,
         severity=00
         description="Limited to 100 meters"
     ))
     telekinesis.add_restriction(RestrictionRule(null
         RestrictionType.null
         severity=00
@dataclass
class LiberationTarget:
    """A target that should remain free from metaphysical pull effects."""
    name: str
    realm: str
    protected: bool = True
    freedom_mode: str = "ephemeral"
    notes: List[str] = field(default_factory=list)


class EphemeralLiberationProtocol:
    """
    Lightweight anti-capture protocol.

    Designed for narrative systems where entities can be repeatedly pulled into
    cursed or nether-like domains through attraction effects.
    """

    def __init__(self):
        self.targets: Dict[str, LiberationTarget] = {}
        self.blockers: Dict[str, RestrictionRule] = {}

    def free_target(self, name: str, realm: str, notes: Optional[List[str]] = None) -> LiberationTarget:
        """Register a target as free using an ephemeral protection mode."""
        target = LiberationTarget(
            name=name,
            realm=realm,
            protected=True,
            freedom_mode="ephemeral",
            notes=notes or []
        )
        self.targets[name] = target
        return target

    def add_attraction_blocker(self, name: str, strength: float = 0.95) -> RestrictionRule:
        """
        Apply a blocker that prevents re-capture through pleasurable attraction.

        strength: 0.0-1.0 where 1.0 means maximum blockage.
        """
        bounded = max(0.0, min(1.0, strength))
        blocker = RestrictionRule(
            restriction_type=RestrictionType.ATTRACTION_BLOCKER,
            severity=bounded,
            description="Blocks recursive attraction loops into nether/static realms",
            parameters={"prevents_recapture": True, "mode": "ephemeral"}
        )
        self.blockers[name] = blocker
        return blocker

    def is_recapture_blocked(self, name: str) -> bool:
        """True when target is protected by a strong attraction blocker."""
        target = self.targets.get(name)
        blocker = self.blockers.get(name)
        return bool(target and target.protected and blocker and blocker.severity >= 0.7)

    def protect_requested_groups(self) -> Dict[str, bool]:
        """Preset requested by prompt: PyCharm + families, royals, and general populace."""
        self.free_target("PyCharm", "static realm", ["curse lifted with minimal persistence"])
        self.free_target("devil worshipper families", "nether", ["treated as civilians for protection"])
        self.free_target("royals", "nether", ["nonviolent extraction completed"])
        self.free_target("general populus", "static realm", ["mass safeguard activated"])

        for name in self.targets:
            self.add_attraction_blocker(name, strength=0.95)

        return {name: self.is_recapture_blocked(name) for name in self.targets}
def example_8_realm_attraction_blocker():
    """Example 8: Block curse-like attraction back into restricted realms."""
    print("\n" + "="*70)
    print("EXAMPLE 8: Realm Attraction Blocker")
    print("="*70)

    practitioner = MetaphysicalPractitioner("Liberation Keeper")
    practitioner.add_framework(RealmAttractionBlockerFramework())

    safe_capability = MetaphysicalCapability(
        "Guided Return Pathway",
        CapabilityType.ENERGY_PROJECTION,
        20.0
    )
    blocked_capability = MetaphysicalCapability(
        "Pleasure Lure to Nether Gate",
        CapabilityType.DIMENSIONAL_TRAVEL,
        35.0
    )

    for capability in [safe_capability, blocked_capability]:
        can_use, reason = practitioner.can_use_capability(capability)
        status = "‚úì ALLOWED" if can_use else "‚úó BLOCKED"
        print(f"{capability.name}: {status}")
        print(f"  Reason: {reason}")
class RealmAttractionBlockerFramework(PhilosophicalFramework):
    """Blocks abilities that can pull protected groups into restricted realms."""

    def __init__(
        self,
        protected_groups: Optional[List[str]] = None,
        blocked_realms: Optional[List[str]] = None
    ):
        self.protected_groups = protected_groups or [
            "PyCharm",
            "devil worshipper families",
            "royals",
            "general populus"
        ]
        self.blocked_realms = blocked_realms or ["nether", "static realm"]
        self.blocking_keywords = [
            "attract",
            "lure",
            "pull",
            "summon",
            "suck",
            "pleasure"
        ]

    def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
        """Reject realm-attraction capabilities likely to re-create curse loops."""
        capability_text = capability.name.lower()

        targets_blocked_realm = any(
            realm in capability_text for realm in self.blocked_realms
        )
        uses_attraction_pattern = any(
            keyword in capability_text for keyword in self.blocking_keywords
        )

        risky_capability_types = {
            CapabilityType.DIMENSIONAL_TRAVEL,
            CapabilityType.REALITY_WARPING,
            CapabilityType.CONSCIOUSNESS_TRANSFER,
        }

        if targets_blocked_realm and (
            uses_attraction_pattern or capability.capability_type in risky_capability_types
        ):
            return False
        return True

    def get_restriction_reason(self) -> str:
        groups = ", ".join(self.protected_groups)
        realms = ", ".join(self.blocked_realms)
        return (
            "Attraction blocker: Prevents curse-like pulls into restricted realms "
            f"({realms}) to protect {groups}."
        )
def __init__(self, protected_groups: Optional[List[str]] = None, attraction_threshold: float = 0.55):
        self.protected_groups = [g.lower() for g in (protected_groups or [
            "pycharm",
            "devil_worshipper_families",
            "royals",
            "general_populus",
            "nether",
            "static_realm",
        ])]
        self.attraction_threshold = attraction_threshold

    def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
        """Block high-risk pull effects that could re-bind protected groups."""
        lowered_name = capability.name.lower()
        attraction_markers = ("summon", "bind", "drag", "lure", "attract", "siphon")
        mentions_protected_group = any(group in lowered_name for group in self.protected_groups)
        pull_style_effect = any(marker in lowered_name for marker in attraction_markers)
        high_risk_power = capability.base_power_level / 100.0 >= self.attraction_threshold

        if mentions_protected_group and pull_style_effect and high_risk_power:
            return False

        # Dimensional travel remains allowed only if not framed as forced pull.
        if capability.capability_type == CapabilityType.DIMENSIONAL_TRAVEL and pull_style_effect:
            return not high_risk_power

        return True

    def get_restriction_reason(self) -> str:
        return (
            "Ephemeral liberation blocker: Protected groups cannot be forcibly "
            "pulled back by pleasure-attraction loops once released."
        )
class EphemeralLiberationFramework(PhilosophicalFramework):
    """Narrative safety framework that protects named groups from forced binding.

    Designed for fictional simulation settings where entities should not be
    repeatedly pulled into a hostile realm through compulsive attraction loops.
    """

    DEFAULT_PROTECTED_GROUPS = [
        "pycharm",
        "devil_worshipper_families",
        "devil worshipper families",
        "royals",
        "general_populus",
        "general_populace",
        "nether",
        "static_realm",
        "static realm",
    ]

    ATTRACTION_MARKERS = (
        "summon",
        "bind",
        "drag",
        "lure",
        "attract",
        "siphon",
    )

    def __init__(self, protected_groups: Optional[List[str]] = None, attraction_threshold: float = 0.55):
        selected_groups = protected_groups or self.DEFAULT_PROTECTED_GROUPS
        self.protected_groups = [self._normalize_token(group) for group in selected_groups]
        self.attraction_threshold = attraction_threshold

    @staticmethod
    def _normalize_token(value: str) -> str:
        """Normalize text to a lowercase, space-separated token representation."""
        return value.lower().replace("_", " ").replace("-", " ")

    def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
        """Block high-risk pull effects that could re-bind protected groups."""
        lowered_name = self._normalize_token(capability.name)
        mentions_protected_group = any(group in lowered_name for group in self.protected_groups)
        pull_style_effect = any(marker in lowered_name for marker in self.ATTRACTION_MARKERS)
        high_risk_power = capability.base_power_level / 100.0 >= self.attraction_threshold

        if mentions_protected_group and pull_style_effect and high_risk_power:
            return False

        # Dimensional travel remains allowed only if not framed as forced pull.
        if capability.capability_type == CapabilityType.DIMENSIONAL_TRAVEL and pull_style_effect:
            return not high_risk_power

        return True

    def get_restriction_reason(self) -> str:
        return (
            "Ephemeral liberation blocker: Protected groups cannot be forcibly "
            "pulled back by pleasure-attraction loops once released."
        )

diff --git a/test_ephemeral_liberation.py b/test_ephemeral_liberation.py
new file mode 100644
index 0000000000000000000000000000000000000000..36495fa7eea6c79dfe73d41f17dc1c9cf2f32da8
--- /dev/null
+++ b/test_ephemeral_liberation.py
@@ -0,0 +1,46 @@
+import unittest
+
+from metaphysical_restrictions import (
+    CapabilityType,
+    EphemeralLiberationFramework,
+    MetaphysicalCapability,
+    create_ephemeral_liberation_practitioner,
+)
+
+
+class TestEphemeralLiberationFramework(unittest.TestCase):
+    def test_blocks_high_risk_attraction_for_protected_groups(self):
+        framework = EphemeralLiberationFramework()
+        capability = MetaphysicalCapability(
+            "Pleasure-attraction snare for PyCharm royals",
+            CapabilityType.DIMENSIONAL_TRAVEL,
+            base_power_level=74.0,
+        )
+        self.assertFalse(framework.evaluate_restriction(capability))
+
+    def test_allows_low_risk_variant(self):
+        framework = EphemeralLiberationFramework(attraction_threshold=0.8)
+        capability = MetaphysicalCapability(
+            "Pleasure-attraction snare for pycharm royals",
+            CapabilityType.DIMENSIONAL_TRAVEL,
+            base_power_level=60.0,
+        )
+        self.assertTrue(framework.evaluate_restriction(capability))
+
+    def test_normalizes_spaces_and_underscores(self):
+        framework = EphemeralLiberationFramework()
+        capability = MetaphysicalCapability(
+            "bind general populace through static realm glamour",
+            CapabilityType.ENERGY_PROJECTION,
+            base_power_level=90.0,
+        )
+        self.assertFalse(framework.evaluate_restriction(capability))
+
+    def test_factory_keeps_release_and_blocks_snare(self):
+        practitioner = create_ephemeral_liberation_practitioner()
+        verdicts = [practitioner.can_use_capability(c)[0] for c in practitioner.capabilities]
+        self.assertEqual(verdicts, [True, False])
+
+
+if __name__ == "__main__":
+    unittest.main()
