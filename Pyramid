diff --git a/ide_virtualization.py b/ide_virtualization.py
new file mode 100644
index 0000000000000000000000000000000000000000..2bb9eaca36e704cd33c8dfde4bae95ae5214bd95
--- /dev/null
+++ b/ide_virtualization.py
@@ -0,0 +1,181 @@
+"""Virtual IDE orchestration inspired by Spyder and Code::Blocks.
+
+This module provides a composable virtualization layer that combines:
+- Spyder-like workflows: interactive execution + variable explorer snapshots
+- Code::Blocks-like workflows: project build profiles and toolchain simulation
+
+The design favors deterministic behavior so it can be embedded in larger
+systems as a language-aware IDE simulation backend.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from datetime import datetime
+from typing import Any, Dict, List, Optional, Protocol
+
+
+class LanguageRuntime(Protocol):
+    """Contract for language-specific runtime behavior."""
+
+    name: str
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        """Execute/interpret source code and return a normalized result payload."""
+
+    def lint(self, code: str) -> List[str]:
+        """Return diagnostics discovered in source code."""
+
+
+@dataclass
+class PythonRuntime:
+    """Safe-ish Python runtime used for Spyder-style live execution."""
+
+    name: str = "python"
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        namespace = dict(context or {})
+        exec(code, {}, namespace)  # noqa: S102 - deliberate virtualized execution
+        return {
+            "language": self.name,
+            "result": "executed",
+            "variables": {
+                key: value
+                for key, value in namespace.items()
+                if not key.startswith("__")
+            },
+        }
+
+    def lint(self, code: str) -> List[str]:
+        diagnostics: List[str] = []
+        if "import *" in code:
+            diagnostics.append("Avoid wildcard imports; reduce namespace ambiguity.")
+        if "eval(" in code:
+            diagnostics.append("Avoid eval(); use explicit parsing or dispatch.")
+        return diagnostics
+
+
+@dataclass
+class CppRuntime:
+    """Code::Blocks-inspired C/C++ runtime simulation."""
+
+    name: str = "cpp"
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        optimization = (context or {}).get("optimization", "-O2")
+        return {
+            "language": self.name,
+            "result": "compiled",
+            "binary": "a.out",
+            "optimization": optimization,
+            "estimated_lines": len([line for line in code.splitlines() if line.strip()]),
+        }
+
+    def lint(self, code: str) -> List[str]:
+        diagnostics: List[str] = []
+        if "using namespace std;" in code:
+            diagnostics.append("Prefer explicit std:: qualification in headers/libraries.")
+        if "new " in code and "delete" not in code:
+            diagnostics.append("Raw allocation detected without matching delete/RAII guard.")
+        return diagnostics
+
+
+@dataclass
+class VirtualProject:
+    """Project abstraction with language routing and build profile metadata."""
+
+    name: str
+    files: Dict[str, str]
+    language_map: Dict[str, str]
+    build_profiles: Dict[str, Dict[str, Any]] = field(default_factory=dict)
+
+    def detect_language(self, filename: str) -> str:
+        extension = filename.rsplit(".", maxsplit=1)[-1]
+        if extension not in self.language_map:
+            raise ValueError(f"No language mapping configured for '*.{extension}'.")
+        return self.language_map[extension]
+
+
+@dataclass
+class VirtualIDE:
+    """Unified virtualization engine blending Spyder + Code::Blocks concepts."""
+
+    runtimes: Dict[str, LanguageRuntime]
+    session_log: List[Dict[str, Any]] = field(default_factory=list)
+
+    def run_file(
+        self,
+        project: VirtualProject,
+        filename: str,
+        profile: str = "default",
+        context: Optional[Dict[str, Any]] = None,
+    ) -> Dict[str, Any]:
+        if filename not in project.files:
+            raise FileNotFoundError(f"'{filename}' is not part of project '{project.name}'.")
+
+        language = project.detect_language(filename)
+        runtime = self.runtimes[language]
+        code = project.files[filename]
+
+        build_context = dict(context or {})
+        build_context.update(project.build_profiles.get(profile, {}))
+
+        diagnostics = runtime.lint(code)
+        execution = runtime.execute(code, context=build_context)
+
+        log_entry = {
+            "timestamp": datetime.utcnow().isoformat(timespec="seconds") + "Z",
+            "project": project.name,
+            "file": filename,
+            "language": language,
+            "profile": profile,
+            "diagnostics": diagnostics,
+            "execution": execution,
+            "spyder_view": self._spyder_variable_explorer(execution),
+            "codeblocks_view": self._codeblocks_build_panel(profile, build_context),
+        }
+        self.session_log.append(log_entry)
+        return log_entry
+
+    @staticmethod
+    def _spyder_variable_explorer(execution: Dict[str, Any]) -> Dict[str, str]:
+        variables = execution.get("variables", {})
+        return {key: type(value).__name__ for key, value in variables.items()}
+
+    @staticmethod
+    def _codeblocks_build_panel(profile: str, build_context: Dict[str, Any]) -> Dict[str, Any]:
+        return {
+            "active_profile": profile,
+            "compiler_flags": build_context.get("flags", ["-Wall"]),
+            "optimization": build_context.get("optimization", "-O2"),
+        }
+
+
+def create_virtualized_spyder_codeblocks_system() -> VirtualIDE:
+    """Factory returning a near-complete virtualized dual-IDE backend."""
+
+    return VirtualIDE(
+        runtimes={
+            "python": PythonRuntime(),
+            "cpp": CppRuntime(),
+        }
+    )
+
+
+if __name__ == "__main__":
+    ide = create_virtualized_spyder_codeblocks_system()
+    project = VirtualProject(
+        name="HybridLab",
+        files={
+            "analysis.py": "x = 21\ny = x * 2\nsummary = f'Result: {y}'",
+            "kernel.cpp": "#include <iostream>\nint main(){ std::cout << 42; return 0; }",
+        },
+        language_map={"py": "python", "cpp": "cpp"},
+        build_profiles={"default": {"optimization": "-O2", "flags": ["-Wall", "-Wextra"]}},
+    )
+
+    python_result = ide.run_file(project, "analysis.py")
+    cpp_result = ide.run_file(project, "kernel.cpp")
+
+    print("Python virtual run:", python_result["execution"])
+    print("C++ virtual build:", cpp_result["execution"])
diff --git a/examples.py b/examples.py
index fdcd0e2986edb6ab27f6e5e0b2fe3912752e187c..8295f932e413c5750f0f621f44f9ed856ec33c5b 100644
--- a/examples.py
+++ b/examples.py
@@ -107,51 +107,51 @@ def example_3_philosophical_frameworks():
         can_use, reason = practitioner.can_use_capability(capability)
         status = "✓ ALLOWED" if can_use else "✗ RESTRICTED"
         print(f"\n{capability.name}: {status}")
         print(f"  Reason: {reason}")
 
 
 def example_4_reality_warper():
     """Example 4: Heavily restricted reality warping."""
     print("\n" + "="*70)
     print("EXAMPLE 4: Reality Warper with Heavy Restrictions")
     print("="*70)
     
     practitioner = create_restricted_reality_warper()
     print(practitioner.get_status())
     
     # Attempt to use reality warping
     reality_warp = practitioner.capabilities[0]
     
     print("\n--- Attempting Reality Warp ---")
     can_use, reason = practitioner.can_use_capability(reality_warp)
     print(f"Can use: {can_use}")
     print(f"Reason: {reason}")
     
     if can_use:
         result = practitioner.use_capability(reality_warp)
-        print(f"\nResult:")
+        print("\nResult:")
         print(f"  Success: {result['success']}")
         print(f"  Power used: {result['power_used']:.1f}")
         print(f"  Energy consumed: {result['energy_consumed']:.1f}")
 
 
 def example_5_consciousness_degradation():
     """Example 5: How consciousness level affects ability usage."""
     print("\n" + "="*70)
     print("EXAMPLE 5: Consciousness-Dependent Restrictions")
     print("="*70)
     
     practitioner = MetaphysicalPractitioner(
         "Meditation Master",
         consciousness_level=1.0,
         max_energy=200.0,
         energy_pool=200.0
     )
     practitioner.add_framework(ConsciousnessAnchorFramework(consciousness_threshold=0.5))
     
     # Add a high-level telepathy ability
     telepathy = MetaphysicalCapability(
         "Mind Meld",
         CapabilityType.TELEPATHY,
         base_power_level=70.0
     )
@@ -227,51 +227,51 @@ def example_7_restriction_modification():
     
     print(f"Initial power: {ability.get_effective_power():.1f}")
     
     # Add restrictions due to environmental factors
     print("\n--- Adding Environmental Restrictions ---")
     
     restriction1 = RestrictionRule(
         RestrictionType.ENTROPY_COST,
         severity=0.2,
         description="Dimensional instability in area"
     )
     ability.add_restriction(restriction1)
     print(f"After restriction 1: {ability.get_effective_power():.1f}")
     
     restriction2 = RestrictionRule(
         RestrictionType.MATERIAL_ANCHOR,
         severity=0.3,
         description="Requires rare materials to stabilize"
     )
     ability.add_restriction(restriction2)
     print(f"After restriction 2: {ability.get_effective_power():.1f}")
     
     # Remove a restriction
     print("\n--- Removing Restrictions ---")
     if ability.remove_restriction(RestrictionType.ENTROPY_COST):
-        print(f"Removed entropy cost restriction")
+        print("Removed entropy cost restriction")
     print(f"After removal: {ability.get_effective_power():.1f}")
 
 
 def main():
     """Run all examples."""
     print("\n" + "="*70)
     print("METAPHYSICAL CAPABILITIES RESTRICTION SYSTEM")
     print("Game Mechanics & Philosophical Framework Examples")
     print("="*70)
     
     example_1_basic_capability_restriction()
     example_2_balanced_magic_system()
     example_3_philosophical_frameworks()
     example_4_reality_warper()
     example_5_consciousness_degradation()
     example_6_multiple_uses_and_cooldown()
     example_7_restriction_modification()
     
     print("\n" + "="*70)
     print("Examples completed!")
     print("="*70 + "\n")
 
 
 if __name__ == "__main__":
     main()
diff --git a/integration_patterns.py b/integration_patterns.py
index d0d9384c76e3a5198104d495b00d68fea9ead922..325565883d954f60c3558dc35c4435764f25123d 100644
--- a/integration_patterns.py
+++ b/integration_patterns.py
@@ -1,36 +1,35 @@
 """
 Advanced Integration Guide
 Real-world patterns for using the metaphysical restriction system
 in games, stories, and theoretical models.
 """
 
 from metaphysical_restrictions import (
     MetaphysicalPractitioner, MetaphysicalCapability,
     RestrictionRule, RestrictionType, CapabilityType,
-    ConservationOfEnergyFramework, EntropicDecayFramework,
-    CausalityFramework, ConsciousnessAnchorFramework
+    ConservationOfEnergyFramework
 )
 
 
 # ============================================================================
 # PATTERN 1: RPG SPELL SYSTEM
 # ============================================================================
 
 class RPGSpellSystem:
     """Integration pattern for traditional RPG magic systems (D&D-style)."""
     
     def __init__(self, player_name: str, spell_slots: int = 10):
         self.practitioner = MetaphysicalPractitioner(
             name=player_name,
             energy_pool=float(spell_slots * 10),
             max_energy=float(spell_slots * 10)
         )
         self.practitioner.add_framework(ConservationOfEnergyFramework(spell_slots * 10))
         self.spell_slots = spell_slots
         self.cast_history = []
     
     def add_spell(self, name: str, level: int, effect: str) -> MetaphysicalCapability:
         """Add a standard RPG spell to the spellbook."""
         # Spell power = spell level * 10
         spell = MetaphysicalCapability(
             name=name,
@@ -241,53 +240,53 @@ class GameBalancer:
         elif balance > 20:
             return "✗ Very overpowered - add significant restrictions"
         else:
             return "✗ Severely overpowered - redesign restrictions completely"
     
     @staticmethod
     def power_audit(practitioner: MetaphysicalPractitioner) -> str:
         """Generate a detailed power audit."""
         audit = f"\nPower Audit for {practitioner.name}\n"
         audit += "=" * 50 + "\n"
         
         audit += f"Balance Score: {GameBalancer.calculate_balance_score(practitioner):.1f}/100\n"
         audit += f"Recommendation: {GameBalancer.suggest_rebalance(practitioner)}\n\n"
         
         audit += "Capability Analysis:\n"
         audit += "-" * 50 + "\n"
         
         for cap in practitioner.capabilities:
             audit += f"\n{cap.name}:\n"
             audit += f"  Base Power: {cap.base_power_level:.1f}\n"
             audit += f"  Effective Power: {cap.get_effective_power():.1f}\n"
             audit += f"  Restriction Severity: {cap.get_total_restriction_severity():.1%}\n"
             audit += f"  Number of Restrictions: {len(cap.restrictions)}\n"
             
             if cap.get_effective_power() > 50:
-                audit += f"  ⚠ WARNING: High effective power\n"
+                audit += "  ⚠ WARNING: High effective power\n"
             if len(cap.restrictions) == 0:
-                audit += f"  ⚠ WARNING: No restrictions\n"
+                audit += "  ⚠ WARNING: No restrictions\n"
         
         return audit
 
 
 # ============================================================================
 # PATTERN 4: NARRATIVE SYSTEM
 # ============================================================================
 
 class NarrativeAbilitySystem:
     """Integration for storytelling and narrative games."""
     
     def __init__(self, character_name: str):
         self.character = MetaphysicalPractitioner(
             name=character_name,
             consciousness_level=1.0,
             energy_pool=100.0,
             max_energy=100.0
         )
         self.events = []
         self.story_beats = []
     
     def traumatic_event(self):
         """Traumatic event reduces consciousness (narrative consequence)."""
         reduction = 0.2
         self.character.consciousness_level = max(
@@ -346,51 +345,51 @@ class NarrativeAbilitySystem:
             (0.6, 0.8): "Slightly distracted",
             (0.4, 0.6): "Struggling to concentrate",
             (0.2, 0.4): "Severely weakened",
             (0.0, 0.2): "Nearly broken",
         }
         
         for (low, high), desc in consciousness_desc.items():
             if low <= self.character.consciousness_level < high:
                 status += f"Mental State: {desc} ({self.character.consciousness_level:.0%})\n"
                 break
         
         energy_desc = {
             (0.8, 1.0): "Full of energy",
             (0.6, 0.8): "Moderately tired",
             (0.4, 0.6): "Quite exhausted",
             (0.2, 0.4): "Nearly drained",
             (0.0, 0.2): "On the verge of collapse",
         }
         
         energy_ratio = self.character.energy_pool / self.character.max_energy
         for (low, high), desc in energy_desc.items():
             if low <= energy_ratio < high:
                 status += f"Physical State: {desc} ({energy_ratio:.0%})\n"
                 break
         
-        status += f"\nAbilities Available: "
+        status += "\nAbilities Available: "
         available = sum(1 for p in self.character.capabilities 
                        if self.character.can_use_capability(p)[0])
         status += f"{available}/{len(self.character.capabilities)}\n"
         
         return status
 
 
 # ============================================================================
 # DEMONSTRATION
 # ============================================================================
 
 def demo_patterns():
     """Demonstrate all integration patterns."""
     
     print("\n" + "="*70)
     print("INTEGRATION PATTERNS DEMONSTRATION")
     print("="*70)
     
     # Pattern 1: RPG Spell System
     print("\n--- PATTERN 1: RPG Spell System ---")
     spellbook = RPGSpellSystem("Gandalf", spell_slots=15)
     spellbook.add_spell("Fireball", 3, "damage")
     spellbook.add_spell("Magic Missile", 1, "damage")
     spellbook.add_spell("Shield", 1, "defense")
     
diff --git a/metaphysical_restrictions.py b/metaphysical_restrictions.py
index 2443ccb7c89f840621582951f42986372b6249bc..1d92ae475db406db474ee799f1b3a65e70b89658 100644
--- a/metaphysical_restrictions.py
+++ b/metaphysical_restrictions.py
@@ -1,37 +1,36 @@
 """
 Metaphysical Capabilities Restriction System
 
 A combined game mechanics and philosophical framework for restricting
 supernatural, magical, and metaphysical abilities.
 """
 
 from enum import Enum
 from dataclasses import dataclass, field
-from typing import List, Dict, Optional, Callable
+from typing import List, Dict, Optional
 from abc import ABC, abstractmethod
-import json
 
 
 class CapabilityType(Enum):
     """Categories of metaphysical capabilities."""
     TELEKINESIS = "telekinesis"
     TELEPATHY = "telepathy"
     TIME_MANIPULATION = "time_manipulation"
     REALITY_WARPING = "reality_warping"
     SOUL_MANIPULATION = "soul_manipulation"
     DIMENSIONAL_TRAVEL = "dimensional_travel"
     ENERGY_PROJECTION = "energy_projection"
     PROPHESY = "prophesy"
     RESURRECTION = "resurrection"
     CONSCIOUSNESS_TRANSFER = "consciousness_transfer"
 
 
 class RestrictionType(Enum):
     """Types of restrictions that can be applied."""
     ENERGY_COST = "energy_cost"
     TIME_COOLDOWN = "time_cooldown"
     RANGE_LIMIT = "range_limit"
     DURATION_LIMIT = "duration_limit"
     SIDE_EFFECTS = "side_effects"
     PHILOSOPHICAL_PARADOX = "philosophical_paradox"
     CONSERVATION_LAW = "conservation_law"
@@ -242,51 +241,51 @@ class MetaphysicalPractitioner:
             "capability": capability.name,
             "reason": reason,
             "power_used": 0.0,
             "energy_consumed": 0.0
         }
 
         if can_use:
             power_used = capability.get_effective_power()
             energy_consumed = capability.base_power_level * 0.5
             
             self.energy_pool -= energy_consumed
             capability.use_count += 1
             
             result["power_used"] = power_used
             result["energy_consumed"] = energy_consumed
             result["remaining_energy"] = self.energy_pool
 
         return result
 
     def get_status(self) -> str:
         """Get current status of the practitioner."""
         status = f"\n=== {self.name} ===\n"
         status += f"Consciousness: {self.consciousness_level:.1%}\n"
         status += f"Energy: {self.energy_pool:.1f}/{self.max_energy:.1f}\n"
         status += f"Active Frameworks: {len(self.philosophical_frameworks)}\n"
-        status += f"\nCapabilities:\n"
+        status += "\nCapabilities:\n"
         
         for cap in self.capabilities:
             status += f"  • {cap}\n"
             if cap.restrictions:
                 for restriction in cap.restrictions:
                     status += f"    - {restriction}\n"
         
         return status
 
 
 # Utility functions for common restriction setups
 
 def create_balanced_magic_system() -> MetaphysicalPractitioner:
     """Create a well-balanced magic system with standard restrictions."""
     practitioner = MetaphysicalPractitioner("Balanced Mage")
     
     # Add frameworks
     practitioner.add_framework(ConservationOfEnergyFramework(200.0))
     practitioner.add_framework(EntropicDecayFramework(0.9))
     practitioner.add_framework(ConsciousnessAnchorFramework(0.6))
     
     # Add capabilities with restrictions
     telekinesis = MetaphysicalCapability(
         "Telekinesis",
         CapabilityType.TELEKINESIS,
diff --git a/metaphysical_restrictions.py b/metaphysical_restrictions.py
index 2443ccb7c89f840621582951f42986372b6249bc..1d92ae475db406db474ee799f1b3a65e70b89658 100644
--- a/metaphysical_restrictions.py
+++ b/metaphysical_restrictions.py
@@ -1,37 +1,36 @@
 """
 Metaphysical Capabilities Restriction System
 
 A combined game mechanics and philosophical framework for restricting
 supernatural, magical, and metaphysical abilities.
 """
 
 from enum import Enum
 from dataclasses import dataclass, field
-from typing import List, Dict, Optional, Callable
+from typing import List, Dict, Optional
 from abc import ABC, abstractmethod
-import json
 
 
 class CapabilityType(Enum):
     """Categories of metaphysical capabilities."""
     TELEKINESIS = "telekinesis"
     TELEPATHY = "telepathy"
     TIME_MANIPULATION = "time_manipulation"
     REALITY_WARPING = "reality_warping"
     SOUL_MANIPULATION = "soul_manipulation"
     DIMENSIONAL_TRAVEL = "dimensional_travel"
     ENERGY_PROJECTION = "energy_projection"
     PROPHESY = "prophesy"
     RESURRECTION = "resurrection"
     CONSCIOUSNESS_TRANSFER = "consciousness_transfer"
 
 
 class RestrictionType(Enum):
     """Types of restrictions that can be applied."""
     ENERGY_COST = "energy_cost"
     TIME_COOLDOWN = "time_cooldown"
     RANGE_LIMIT = "range_limit"
     DURATION_LIMIT = "duration_limit"
     SIDE_EFFECTS = "side_effects"
     PHILOSOPHICAL_PARADOX = "philosophical_paradox"
     CONSERVATION_LAW = "conservation_law"
@@ -242,51 +241,51 @@ class MetaphysicalPractitioner:
             "capability": capability.name,
             "reason": reason,
             "power_used": 0.0,
             "energy_consumed": 0.0
         }
 
         if can_use:
             power_used = capability.get_effective_power()
             energy_consumed = capability.base_power_level * 0.5
             
             self.energy_pool -= energy_consumed
             capability.use_count += 1
             
             result["power_used"] = power_used
             result["energy_consumed"] = energy_consumed
             result["remaining_energy"] = self.energy_pool
 
         return result
 
     def get_status(self) -> str:
         """Get current status of the practitioner."""
         status = f"\n=== {self.name} ===\n"
         status += f"Consciousness: {self.consciousness_level:.1%}\n"
         status += f"Energy: {self.energy_pool:.1f}/{self.max_energy:.1f}\n"
         status += f"Active Frameworks: {len(self.philosophical_frameworks)}\n"
-        status += f"\nCapabilities:\n"
+        status += "\nCapabilities:\n"
         
         for cap in self.capabilities:
             status += f"  • {cap}\n"
             if cap.restrictions:
                 for restriction in cap.restrictions:
                     status += f"    - {restriction}\n"
         
         return status
 
 
 # Utility functions for common restriction setups
 
 def create_balanced_magic_system() -> MetaphysicalPractitioner:
     """Create a well-balanced magic system with standard restrictions."""
     practitioner = MetaphysicalPractitioner("Balanced Mage")
     
     # Add frameworks
     practitioner.add_framework(ConservationOfEnergyFramework(200.0))
     practitioner.add_framework(EntropicDecayFramework(0.9))
     practitioner.add_framework(ConsciousnessAnchorFramework(0.6))
     
     # Add capabilities with restrictions
     telekinesis = MetaphysicalCapability(
         "Telekinesis",
         CapabilityType.TELEKINESIS,
diff --git a/philosophical_framework.py b/philosophical_framework.py
index c99d0ce68917c0af7a0bba8f176afb52f8bd8bd5..65fa7bd8528a6a301d892329f88a50766aa814e9 100644
--- a/philosophical_framework.py
+++ b/philosophical_framework.py
@@ -1,36 +1,36 @@
 """
 Philosophical Framework Module
 Theoretical underpinnings for restricting metaphysical capabilities.
 
 This module explores how various philosophical and physical principles
 can naturally limit magical and supernatural abilities.
 """
 
 from enum import Enum
 from dataclasses import dataclass
-from typing import List, Dict
+from typing import List
 
 
 class PhilosophicalPrinciple(Enum):
     """Core philosophical principles limiting metaphysical abilities."""
     
     CONSERVATION = "conservation_of_energy"
     """Energy cannot be created or destroyed, only transformed."""
     
     ENTROPY = "thermodynamic_entropy"
     """All systems tend toward disorder. Order-creating acts cost energy."""
     
     CAUSALITY = "causality"
     """Causes must precede effects. Temporal loops are forbidden."""
     
     CONSCIOUSNESS = "consciousness_anchor"
     """Metaphysical acts require conscious will and mental focus."""
     
     IDENTITY = "personal_identity"
     """The self is continuous. Mind transfers violate personal continuity."""
     
     INFORMATION = "conservation_of_information"
     """Information cannot be truly destroyed or created ex nihilo."""
     
     LOCALITY = "locality_principle"
     """Mind/consciousness is anchored to a specific location or body."""
@@ -319,37 +319,37 @@ def get_framework_for_capability(capability_type: str) -> List[PhilosophicalFram
     
     applicable = [f for f in frameworks if capability_type in f.applied_to
                  or "all_abilities" in f.applied_to]
     return applicable
 
 
 def print_framework_analysis(capability_type: str):
     """Print detailed analysis of restrictions on a capability."""
     print(f"\n{'='*70}")
     print(f"PHILOSOPHICAL RESTRICTIONS: {capability_type.upper()}")
     print(f"{'='*70}\n")
     
     frameworks = get_framework_for_capability(capability_type)
     
     if not frameworks:
         print(f"No restrictions found for {capability_type}")
         return
     
     for framework in frameworks:
         print(f"\n{framework.principle.value.upper()}")
         print(f"{'-'*70}")
         print(f"Description: {framework.description}")
         print(f"\nSeverity Justification: {framework.severity_justification}")
         
         if framework.exceptions:
-            print(f"\nExceptions:")
+            print("\nExceptions:")
             for exc in framework.exceptions:
                 print(f"  • {exc}")
 
 
 # Example usage
 if __name__ == "__main__":
     print("Philosophical Framework Examples:")
     print_framework_analysis("reality_warping")
     print_framework_analysis("telekinesis")
     print_framework_analysis("telepathy")
     print_framework_analysis("time_manipulation")
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..e3dc136c1f0db316d1be610aee009ed401f7ae60
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,109 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean "rebuilt" Pyramid specification in a concise,
+professional, and intentionally ephemeral style.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|desses)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+
+    def to_text(self) -> str:
+        body = "\n".join(f"- {line}" for line in self.sections)
+        return f"{self.title}\n\n{body}\n"
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    normalized = []
+    for raw in lines:
+        trimmed = raw.strip()
+        if not trimmed:
+            continue
+        normalized.append(trimmed)
+    return normalized
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_sections: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_sections.append(cleaned)
+
+    if not cleaned_sections:
+        cleaned_sections.append(
+            "Reconstructed baseline: compliant architecture with neutral terminology."
+        )
+
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(title=title, sections=cleaned_sections, removed_fragments=removed_fragments)
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Rewrite Pyramid content into a clean, safe blueprint.")
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument("-o", "--output", help="Optional output file path. Prints to stdout if omitted.")
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text()
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/test_pyramid_rewriter.py b/test_pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..7790bb0b6efd1c7d71723d92f8bb9c03ca9f7a45
--- /dev/null
+++ b/test_pyramid_rewriter.py
@@ -0,0 +1,29 @@
+import unittest
+
+from pyramid_rewriter import rebuild_pyramid
+
+
+class PyramidRewriterTests(unittest.TestCase):
+    def test_removes_problematic_terms(self):
+        source = """\
+        Pyramid phase one: attack all gods.
+        Professional delivery for production.
+        """
+        result = rebuild_pyramid(source)
+        text = result.to_text().lower()
+
+        self.assertNotIn("attack", text)
+        self.assertNotIn("gods", text)
+        self.assertIn("professional delivery for production", text)
+        self.assertGreaterEqual(len(result.removed_fragments), 2)
+
+    def test_supplies_baseline_when_everything_removed(self):
+        source = "attack gods deities creatures"
+        result = rebuild_pyramid(source)
+
+        self.assertEqual(len(result.sections), 1)
+        self.assertIn("reconstructed baseline", result.sections[0].lower())
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/ide_virtualization.py b/ide_virtualization.py
new file mode 100644
index 0000000000000000000000000000000000000000..19d8a57d841ff9849e3e9b9c26681a0dc48ef353
--- /dev/null
+++ b/ide_virtualization.py
@@ -0,0 +1,278 @@
+"""High-fidelity virtual IDE core inspired by Spyder and Code::Blocks.
+
+Goals:
+- Spyder-like live Python execution with variable introspection and console capture.
+- Code::Blocks-like project/build profile orchestration for C/C++ style toolchains.
+- Deterministic, embeddable behavior for testing and automation.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from datetime import datetime, timezone
+import ast
+import contextlib
+import io
+from typing import Any, Dict, List, Optional, Protocol, Tuple
+
+
+class VirtualizationError(Exception):
+    """Base exception for virtual IDE failures."""
+
+
+class UnsupportedLanguageError(VirtualizationError):
+    """Raised when a file extension has no configured runtime."""
+
+
+class RuntimeExecutionError(VirtualizationError):
+    """Raised when runtime execution fails."""
+
+
+class LanguageRuntime(Protocol):
+    """Unified runtime contract shared by all language engines."""
+
+    name: str
+
+    def lint(self, code: str) -> List[str]:
+        """Return diagnostics discovered in source code."""
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        """Execute source code in a virtualized runtime and return normalized output."""
+
+
+@dataclass
+class PythonRuntime:
+    """Spyder-style Python runtime with safer execution and explorer metadata."""
+
+    name: str = "python"
+    allowed_builtins: Dict[str, Any] = field(
+        default_factory=lambda: {
+            "abs": abs,
+            "all": all,
+            "any": any,
+            "bool": bool,
+            "dict": dict,
+            "enumerate": enumerate,
+            "float": float,
+            "int": int,
+            "len": len,
+            "list": list,
+            "max": max,
+            "min": min,
+            "print": print,
+            "range": range,
+            "round": round,
+            "set": set,
+            "sorted": sorted,
+            "str": str,
+            "sum": sum,
+            "tuple": tuple,
+            "zip": zip,
+        }
+    )
+
+    def lint(self, code: str) -> List[str]:
+        diagnostics: List[str] = []
+        if "import *" in code:
+            diagnostics.append("Avoid wildcard imports for deterministic namespace behavior.")
+        if "eval(" in code or "exec(" in code:
+            diagnostics.append("Avoid dynamic evaluation to keep virtual runs reproducible.")
+
+        try:
+            tree = ast.parse(code)
+        except SyntaxError as exc:
+            diagnostics.append(f"Syntax error: {exc.msg} (line {exc.lineno})")
+            return diagnostics
+
+        for node in ast.walk(tree):
+            if isinstance(node, (ast.Import, ast.ImportFrom)):
+                diagnostics.append("Imports are blocked in virtual mode; inject dependencies through context.")
+                break
+        return diagnostics
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        namespace: Dict[str, Any] = dict(context or {})
+        namespace["__builtins__"] = self.allowed_builtins
+
+        stdout_buffer = io.StringIO()
+        try:
+            with contextlib.redirect_stdout(stdout_buffer):
+                compiled = compile(code, "<virtual-python>", "exec")
+                exec(compiled, namespace, namespace)  # noqa: S102 - controlled virtual environment
+        except Exception as exc:  # deliberate conversion to normalized error payload
+            raise RuntimeExecutionError(f"Python execution failed: {exc}") from exc
+
+        variable_table = {
+            key: {
+                "type": type(value).__name__,
+                "repr": repr(value)[:120],
+            }
+            for key, value in namespace.items()
+            if not key.startswith("__")
+        }
+        return {
+            "language": self.name,
+            "result": "executed",
+            "stdout": stdout_buffer.getvalue(),
+            "variables": variable_table,
+        }
+
+
+@dataclass
+class CppRuntime:
+    """Code::Blocks-style C/C++ runtime simulation with profile-aware build output."""
+
+    name: str = "cpp"
+
+    def lint(self, code: str) -> List[str]:
+        diagnostics: List[str] = []
+        if "using namespace std;" in code:
+            diagnostics.append("Prefer explicit std:: usage to avoid namespace collisions.")
+        if code.count("{") != code.count("}"):
+            diagnostics.append("Brace mismatch detected.")
+        if "new " in code and "delete" not in code and "unique_ptr" not in code:
+            diagnostics.append("Potential memory leak: use RAII (std::unique_ptr/std::vector).")
+        return diagnostics
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        context = dict(context or {})
+        flags = context.get("flags", ["-Wall", "-Wextra"])
+        optimization = context.get("optimization", "-O2")
+        std = context.get("std", "c++20")
+
+        non_empty_lines = [line for line in code.splitlines() if line.strip()]
+        warning_count = sum(1 for item in self.lint(code) if "Potential" in item or "Prefer" in item)
+
+        return {
+            "language": self.name,
+            "result": "compiled",
+            "binary": context.get("binary", "a.out"),
+            "build": {
+                "flags": flags,
+                "optimization": optimization,
+                "standard": std,
+                "sources_loc": len(non_empty_lines),
+                "warnings": warning_count,
+            },
+        }
+
+
+@dataclass
+class VirtualProject:
+    """Project container representing files and language/build configuration."""
+
+    name: str
+    files: Dict[str, str]
+    language_map: Dict[str, str]
+    build_profiles: Dict[str, Dict[str, Any]] = field(default_factory=dict)
+
+    def detect_language(self, filename: str) -> str:
+        extension = filename.rsplit(".", maxsplit=1)[-1]
+        language = self.language_map.get(extension)
+        if not language:
+            raise UnsupportedLanguageError(f"No runtime configured for extension '.{extension}'.")
+        return language
+
+
+@dataclass
+class VirtualIDE:
+    """Unified virtual IDE kernel.
+
+    Provides:
+    - run_file: lint + execute one source file
+    - run_project: batch execute all project files in deterministic ordering
+    - session_log: structured operation history
+    """
+
+    runtimes: Dict[str, LanguageRuntime]
+    session_log: List[Dict[str, Any]] = field(default_factory=list)
+
+    def run_file(
+        self,
+        project: VirtualProject,
+        filename: str,
+        profile: str = "default",
+        context: Optional[Dict[str, Any]] = None,
+    ) -> Dict[str, Any]:
+        if filename not in project.files:
+            raise FileNotFoundError(f"'{filename}' is not defined in project '{project.name}'.")
+
+        language = project.detect_language(filename)
+        runtime = self.runtimes.get(language)
+        if runtime is None:
+            raise UnsupportedLanguageError(f"Runtime '{language}' is not registered.")
+
+        execution_context = dict(context or {})
+        execution_context.update(project.build_profiles.get(profile, {}))
+        code = project.files[filename]
+
+        diagnostics = runtime.lint(code)
+        execution = runtime.execute(code, execution_context)
+
+        event = {
+            "timestamp": datetime.now(timezone.utc).isoformat(),
+            "project": project.name,
+            "file": filename,
+            "language": language,
+            "profile": profile,
+            "diagnostics": diagnostics,
+            "execution": execution,
+            "spyder_view": self._spyder_variable_explorer(execution),
+            "codeblocks_view": self._codeblocks_build_panel(profile, execution_context),
+        }
+        self.session_log.append(event)
+        return event
+
+    def run_project(
+        self,
+        project: VirtualProject,
+        profile: str = "default",
+        context: Optional[Dict[str, Any]] = None,
+    ) -> List[Dict[str, Any]]:
+        results: List[Dict[str, Any]] = []
+        for filename in sorted(project.files):
+            results.append(self.run_file(project, filename, profile=profile, context=context))
+        return results
+
+    @staticmethod
+    def _spyder_variable_explorer(execution: Dict[str, Any]) -> Dict[str, str]:
+        variables = execution.get("variables", {})
+        return {key: data.get("type", "unknown") for key, data in variables.items()}
+
+    @staticmethod
+    def _codeblocks_build_panel(profile: str, context: Dict[str, Any]) -> Dict[str, Any]:
+        return {
+            "active_profile": profile,
+            "compiler_flags": context.get("flags", ["-Wall", "-Wextra"]),
+            "optimization": context.get("optimization", "-O2"),
+            "standard": context.get("std", "c++20"),
+        }
+
+
+def create_virtualized_spyder_codeblocks_system() -> VirtualIDE:
+    """Factory for a near-complete Spyder + Code::Blocks virtual core."""
+
+    return VirtualIDE(runtimes={"python": PythonRuntime(), "cpp": CppRuntime()})
+
+
+def _demo_project() -> Tuple[VirtualIDE, VirtualProject]:
+    ide = create_virtualized_spyder_codeblocks_system()
+    project = VirtualProject(
+        name="PrecisionLab",
+        files={
+            "analysis.py": "score = 98\nboost = 2\nfinal_score = score + boost\nprint(final_score)",
+            "engine.cpp": "#include <iostream>\nint main(){ std::cout << 42 << std::endl; return 0; }",
+        },
+        language_map={"py": "python", "cpp": "cpp"},
+        build_profiles={
+            "default": {"flags": ["-Wall", "-Wextra", "-pedantic"], "optimization": "-O2", "std": "c++20"},
+            "debug": {"flags": ["-Wall", "-Wextra", "-g"], "optimization": "-O0", "std": "c++20"},
+        },
+    )
+    return ide, project
+
+
+if __name__ == "__main__":
+    ide_instance, sample_project = _demo_project()
+    for record in ide_instance.run_project(sample_project, profile="default"):
+        print(f"[{record['file']}] diagnostics={len(record['diagnostics'])} result={record['execution']['result']}")
diff --git a/ide_virtualization.py b/ide_virtualization.py
new file mode 100644
index 0000000000000000000000000000000000000000..62a388b80e0841b5262ede1e234c1e3e7168578a
--- /dev/null
+++ b/ide_virtualization.py
@@ -0,0 +1,305 @@
+"""Virtual IDE orchestration inspired by Spyder and Code::Blocks.
+
+This module models a language-aware, deterministic IDE backend with:
+- Spyder-like execution sessions and variable explorer snapshots
+- Code::Blocks-like project build profiles and compiler panel output
+
+The implementation intentionally avoids unsafe runtime behavior for the Python
+path by interpreting a restricted AST subset rather than calling ``exec``.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from datetime import datetime, timezone
+import ast
+from typing import Any, Dict, List, Optional, Protocol, Tuple
+
+
+class LanguageRuntime(Protocol):
+    """Contract for language-specific runtime behavior."""
+
+    name: str
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        """Execute/build code and return a normalized runtime payload."""
+
+    def lint(self, code: str) -> List[str]:
+        """Return static diagnostics for source code."""
+
+
+@dataclass
+class SafePythonEvaluator:
+    """Restricted evaluator for arithmetic/string Python expressions.
+
+    Supported grammar pieces:
+    - constants: int/float/str/bool/None
+    - names that exist in the runtime namespace
+    - arithmetic operations (+, -, *, /, //, %, **)
+    - unary +/-
+    - f-strings (JoinedStr)
+
+    Unsupported operations raise ``ValueError`` to preserve deterministic safety.
+    """
+
+    namespace: Dict[str, Any]
+
+    def eval_expr(self, node: ast.AST) -> Any:
+        if isinstance(node, ast.Constant):
+            return node.value
+
+        if isinstance(node, ast.Name):
+            if node.id not in self.namespace:
+                raise ValueError(f"Unknown variable: {node.id}")
+            return self.namespace[node.id]
+
+        if isinstance(node, ast.BinOp):
+            left = self.eval_expr(node.left)
+            right = self.eval_expr(node.right)
+            return self._eval_binop(node.op, left, right)
+
+        if isinstance(node, ast.UnaryOp):
+            value = self.eval_expr(node.operand)
+            if isinstance(node.op, ast.UAdd):
+                return +value
+            if isinstance(node.op, ast.USub):
+                return -value
+            raise ValueError("Unsupported unary operator")
+
+        if isinstance(node, ast.JoinedStr):
+            parts: List[str] = []
+            for v in node.values:
+                if isinstance(v, ast.Constant):
+                    parts.append(str(v.value))
+                elif isinstance(v, ast.FormattedValue):
+                    parts.append(str(self.eval_expr(v.value)))
+                else:
+                    raise ValueError("Unsupported f-string component")
+            return "".join(parts)
+
+        raise ValueError(f"Unsupported expression node: {type(node).__name__}")
+
+    @staticmethod
+    def _eval_binop(operator: ast.operator, left: Any, right: Any) -> Any:
+        if isinstance(operator, ast.Add):
+            return left + right
+        if isinstance(operator, ast.Sub):
+            return left - right
+        if isinstance(operator, ast.Mult):
+            return left * right
+        if isinstance(operator, ast.Div):
+            return left / right
+        if isinstance(operator, ast.FloorDiv):
+            return left // right
+        if isinstance(operator, ast.Mod):
+            return left % right
+        if isinstance(operator, ast.Pow):
+            return left**right
+        raise ValueError("Unsupported binary operator")
+
+
+@dataclass
+class PythonRuntime:
+    """Spyder-style Python runtime with deterministic, restricted execution."""
+
+    name: str = "python"
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        namespace: Dict[str, Any] = dict(context or {})
+        tree = ast.parse(code)
+        evaluator = SafePythonEvaluator(namespace)
+        executed_lines = 0
+
+        for statement in tree.body:
+            if isinstance(statement, ast.Assign):
+                if len(statement.targets) != 1 or not isinstance(statement.targets[0], ast.Name):
+                    raise ValueError("Only single-variable assignments are supported")
+                target = statement.targets[0].id
+                namespace[target] = evaluator.eval_expr(statement.value)
+                executed_lines += 1
+            elif isinstance(statement, ast.Expr):
+                evaluator.eval_expr(statement.value)
+                executed_lines += 1
+            else:
+                raise ValueError(
+                    f"Unsupported statement type for virtual Python runtime: {type(statement).__name__}"
+                )
+
+        return {
+            "language": self.name,
+            "result": "executed",
+            "executed_lines": executed_lines,
+            "variables": {k: v for k, v in namespace.items() if not k.startswith("__")},
+        }
+
+    def lint(self, code: str) -> List[str]:
+        diagnostics: List[str] = []
+        if "import *" in code:
+            diagnostics.append("Avoid wildcard imports; reduce namespace ambiguity.")
+        if "eval(" in code or "exec(" in code:
+            diagnostics.append("Avoid dynamic code execution in projects intended for reproducibility.")
+        if "global " in code:
+            diagnostics.append("Global state can make analysis sessions hard to reproduce.")
+        return diagnostics
+
+
+@dataclass
+class CppRuntime:
+    """Code::Blocks-style C/C++ build simulation runtime."""
+
+    name: str = "cpp"
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        profile = context or {}
+        optimization = profile.get("optimization", "-O2")
+        flags = profile.get("flags", ["-Wall", "-Wextra"])
+
+        line_count = len([line for line in code.splitlines() if line.strip()])
+        has_main = "int main" in code.replace("\n", " ")
+
+        return {
+            "language": self.name,
+            "result": "compiled" if has_main else "link_error",
+            "binary": "a.out" if has_main else None,
+            "optimization": optimization,
+            "flags": flags,
+            "estimated_lines": line_count,
+            "entrypoint_detected": has_main,
+        }
+
+    def lint(self, code: str) -> List[str]:
+        diagnostics: List[str] = []
+        if "using namespace std;" in code:
+            diagnostics.append("Prefer explicit std:: qualification in shared/library code.")
+        if "new " in code and "delete" not in code:
+            diagnostics.append("Raw allocation detected without matching delete/RAII.")
+        if "printf(" in code and "#include <cstdio>" not in code:
+            diagnostics.append("printf usage detected without <cstdio> include.")
+        return diagnostics
+
+
+@dataclass
+class VirtualProject:
+    """Project abstraction with language routing and profile metadata."""
+
+    name: str
+    files: Dict[str, str]
+    language_map: Dict[str, str]
+    build_profiles: Dict[str, Dict[str, Any]] = field(default_factory=dict)
+
+    def detect_language(self, filename: str) -> str:
+        if "." not in filename:
+            raise ValueError(f"Unable to detect language for file without extension: {filename}")
+        extension = filename.rsplit(".", maxsplit=1)[-1]
+        if extension not in self.language_map:
+            raise ValueError(f"No language mapping configured for '*.{extension}'.")
+        return self.language_map[extension]
+
+
+@dataclass
+class VirtualIDE:
+    """Unified virtualization engine blending Spyder and Code::Blocks concepts."""
+
+    runtimes: Dict[str, LanguageRuntime]
+    session_log: List[Dict[str, Any]] = field(default_factory=list)
+
+    def run_file(
+        self,
+        project: VirtualProject,
+        filename: str,
+        profile: str = "default",
+        context: Optional[Dict[str, Any]] = None,
+    ) -> Dict[str, Any]:
+        runtime, code, language = self._resolve_runtime(project, filename)
+        build_context = dict(context or {})
+        build_context.update(project.build_profiles.get(profile, {}))
+
+        diagnostics = runtime.lint(code)
+
+        try:
+            execution = runtime.execute(code, context=build_context)
+            status = "ok"
+            error: Optional[str] = None
+        except ValueError as exc:
+            execution = {"language": language, "result": "runtime_error"}
+            status = "error"
+            error = str(exc)
+
+        log_entry = {
+            "timestamp": datetime.now(timezone.utc).isoformat(timespec="seconds"),
+            "project": project.name,
+            "file": filename,
+            "language": language,
+            "profile": profile,
+            "status": status,
+            "error": error,
+            "diagnostics": diagnostics,
+            "execution": execution,
+            "spyder_view": self._spyder_variable_explorer(execution),
+            "codeblocks_view": self._codeblocks_build_panel(profile, build_context),
+        }
+        self.session_log.append(log_entry)
+        return log_entry
+
+    def run_project(self, project: VirtualProject, profile: str = "default") -> List[Dict[str, Any]]:
+        """Execute every project file and return all session entries."""
+        entries: List[Dict[str, Any]] = []
+        for filename in sorted(project.files):
+            entries.append(self.run_file(project, filename=filename, profile=profile))
+        return entries
+
+    def health_report(self) -> Dict[str, Any]:
+        """Return aggregate diagnostics to identify systemic issues quickly."""
+        total_runs = len(self.session_log)
+        errors = [entry for entry in self.session_log if entry["status"] == "error"]
+        diagnostics = sum(len(entry["diagnostics"]) for entry in self.session_log)
+        return {
+            "total_runs": total_runs,
+            "error_runs": len(errors),
+            "diagnostic_count": diagnostics,
+            "success_rate": 1.0 if total_runs == 0 else (total_runs - len(errors)) / total_runs,
+        }
+
+    def _resolve_runtime(self, project: VirtualProject, filename: str) -> Tuple[LanguageRuntime, str, str]:
+        if filename not in project.files:
+            raise FileNotFoundError(f"'{filename}' is not part of project '{project.name}'.")
+        language = project.detect_language(filename)
+        if language not in self.runtimes:
+            raise ValueError(f"No runtime registered for language '{language}'.")
+        return self.runtimes[language], project.files[filename], language
+
+    @staticmethod
+    def _spyder_variable_explorer(execution: Dict[str, Any]) -> Dict[str, str]:
+        variables = execution.get("variables", {})
+        return {key: type(value).__name__ for key, value in variables.items()}
+
+    @staticmethod
+    def _codeblocks_build_panel(profile: str, build_context: Dict[str, Any]) -> Dict[str, Any]:
+        return {
+            "active_profile": profile,
+            "compiler_flags": build_context.get("flags", ["-Wall", "-Wextra"]),
+            "optimization": build_context.get("optimization", "-O2"),
+        }
+
+
+def create_virtualized_spyder_codeblocks_system() -> VirtualIDE:
+    """Factory returning a robust virtualized dual-IDE backend."""
+    return VirtualIDE(runtimes={"python": PythonRuntime(), "cpp": CppRuntime()})
+
+
+if __name__ == "__main__":
+    ide = create_virtualized_spyder_codeblocks_system()
+    project = VirtualProject(
+        name="HybridLab",
+        files={
+            "analysis.py": "x = 21\ny = x * 2\nsummary = f'Result: {y}'",
+            "kernel.cpp": "#include <iostream>\nint main(){ std::cout << 42; return 0; }",
+        },
+        language_map={"py": "python", "cpp": "cpp"},
+        build_profiles={"default": {"optimization": "-O2", "flags": ["-Wall", "-Wextra"]}},
+    )
+
+    for result in ide.run_project(project):
+        print(result["file"], result["status"], result["execution"]["result"])
+
+    print("health:", ide.health_report())
diff --git a/ide_virtualization.py b/ide_virtualization.py
new file mode 100644
index 0000000000000000000000000000000000000000..26cbf4097b700a8bcda087deea873dcbc7e86e69
--- /dev/null
+++ b/ide_virtualization.py
@@ -0,0 +1,303 @@
+"""High-fidelity virtual IDE core inspired by Spyder and Code::Blocks.
+
+This module focuses on three goals:
+1. Virtualize language workflows (Python + C/C++) in one orchestrator.
+2. Proactively remove common issues through an auto-fix pipeline.
+3. Support optional "imbuements" (code transforms) and "movements"
+   (context transforms) so advanced systems can plug in custom behavior.
+"""
+
+from __future__ import annotations
+
+import ast
+from dataclasses import dataclass, field
+from datetime import datetime
+from typing import Any, Callable, Dict, List, Optional, Protocol
+
+
+@dataclass(frozen=True)
+class Diagnostic:
+    """Represents a lint/build diagnostic in normalized format."""
+
+    level: str
+    message: str
+    code: str
+
+
+@dataclass
+class ExecutionArtifact:
+    """Normalized execution/build output."""
+
+    language: str
+    status: str
+    payload: Dict[str, Any]
+
+
+class LanguageRuntime(Protocol):
+    """Runtime contract used by all language backends."""
+
+    name: str
+
+    def lint(self, code: str) -> List[Diagnostic]:
+        """Analyze source code and report diagnostics."""
+
+    def auto_fix(self, code: str) -> str:
+        """Return source code with safe automatic fixes applied."""
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> ExecutionArtifact:
+        """Execute/simulate source code and return a normalized artifact."""
+
+
+@dataclass
+class PythonRuntime:
+    """Spyder-like Python runtime with issue mitigation and state capture."""
+
+    name: str = "python"
+
+    def lint(self, code: str) -> List[Diagnostic]:
+        diagnostics: List[Diagnostic] = []
+
+        if "import *" in code:
+            diagnostics.append(
+                Diagnostic("warning", "Wildcard import detected.", "PY_WILDCARD_IMPORT")
+            )
+        if "eval(" in code:
+            diagnostics.append(Diagnostic("error", "eval() is not allowed.", "PY_UNSAFE_EVAL"))
+
+        try:
+            ast.parse(code)
+        except SyntaxError as exc:
+            diagnostics.append(
+                Diagnostic("error", f"Syntax error: {exc.msg} (line {exc.lineno})", "PY_SYNTAX")
+            )
+
+        return diagnostics
+
+    def auto_fix(self, code: str) -> str:
+        # Minimal deterministic fixes. We avoid risky rewrites.
+        fixed_lines = [line.rstrip() for line in code.splitlines()]
+        fixed = "\n".join(fixed_lines)
+        fixed = fixed.replace("import *", "import __all__  # auto-fixed wildcard")
+        fixed = fixed.replace("eval(", "safe_eval_blocked(")
+        return fixed
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> ExecutionArtifact:
+        namespace = dict(context or {})
+        safe_builtins = {
+            "abs": abs,
+            "len": len,
+            "min": min,
+            "max": max,
+            "sum": sum,
+            "range": range,
+            "print": print,
+        }
+
+        exec(code, {"__builtins__": safe_builtins}, namespace)  # noqa: S102
+
+        variables = {
+            key: value
+            for key, value in namespace.items()
+            if not key.startswith("__") and key not in {"safe_eval_blocked"}
+        }
+
+        return ExecutionArtifact(
+            language=self.name,
+            status="executed",
+            payload={"variables": variables, "variable_count": len(variables)},
+        )
+
+
+@dataclass
+class CppRuntime:
+    """Code::Blocks-like C/C++ runtime simulation with issue checks."""
+
+    name: str = "cpp"
+
+    def lint(self, code: str) -> List[Diagnostic]:
+        diagnostics: List[Diagnostic] = []
+
+        if "using namespace std;" in code:
+            diagnostics.append(
+                Diagnostic("warning", "Global std namespace import detected.", "CPP_STD_NAMESPACE")
+            )
+
+        if "new " in code and "delete" not in code and "std::unique_ptr" not in code:
+            diagnostics.append(
+                Diagnostic("warning", "Raw allocation without delete/RAII.", "CPP_RAW_NEW")
+            )
+
+        if "main(" not in code:
+            diagnostics.append(Diagnostic("error", "No entrypoint main() detected.", "CPP_NO_MAIN"))
+
+        return diagnostics
+
+    def auto_fix(self, code: str) -> str:
+        fixed = code.replace("using namespace std;", "// auto-fixed: avoid global namespace import")
+        return fixed
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> ExecutionArtifact:
+        ctx = dict(context or {})
+        optimization = ctx.get("optimization", "-O2")
+        flags = ctx.get("flags", ["-Wall", "-Wextra"])
+        effective_lines = len([line for line in code.splitlines() if line.strip()])
+
+        return ExecutionArtifact(
+            language=self.name,
+            status="compiled",
+            payload={
+                "binary": "virtual.out",
+                "optimization": optimization,
+                "flags": flags,
+                "estimated_lines": effective_lines,
+            },
+        )
+
+
+Imbuement = Callable[[str], str]
+Movement = Callable[[Dict[str, Any]], Dict[str, Any]]
+
+
+@dataclass
+class VirtualProject:
+    """Project model with language map, build profiles, and custom transforms."""
+
+    name: str
+    files: Dict[str, str]
+    language_map: Dict[str, str]
+    build_profiles: Dict[str, Dict[str, Any]] = field(default_factory=dict)
+    imbuements: Dict[str, List[Imbuement]] = field(default_factory=dict)
+
+    def detect_language(self, filename: str) -> str:
+        extension = filename.rsplit(".", maxsplit=1)[-1]
+        if extension not in self.language_map:
+            raise ValueError(f"No language mapping for '*.{extension}'.")
+        return self.language_map[extension]
+
+    def apply_imbuements(self, filename: str, code: str) -> str:
+        transformed = code
+        for fn in self.imbuements.get(filename, []):
+            transformed = fn(transformed)
+        return transformed
+
+
+@dataclass
+class VirtualIDE:
+    """Unified virtual IDE with issue removal, logging, and extension hooks."""
+
+    runtimes: Dict[str, LanguageRuntime]
+    movements: List[Movement] = field(default_factory=list)
+    session_log: List[Dict[str, Any]] = field(default_factory=list)
+
+    def run_file(
+        self,
+        project: VirtualProject,
+        filename: str,
+        profile: str = "default",
+        context: Optional[Dict[str, Any]] = None,
+        auto_fix: bool = True,
+    ) -> Dict[str, Any]:
+        if filename not in project.files:
+            raise FileNotFoundError(f"'{filename}' not found in project '{project.name}'.")
+
+        language = project.detect_language(filename)
+        runtime = self.runtimes[language]
+
+        build_context = dict(context or {})
+        build_context.update(project.build_profiles.get(profile, {}))
+        for movement in self.movements:
+            build_context = movement(build_context)
+
+        original_code = project.files[filename]
+        code = project.apply_imbuements(filename, original_code)
+
+        diagnostics_before = runtime.lint(code)
+        fixed_code = runtime.auto_fix(code) if auto_fix else code
+        diagnostics_after = runtime.lint(fixed_code)
+
+        artifact = runtime.execute(fixed_code, context=build_context)
+
+        report = {
+            "timestamp": datetime.utcnow().isoformat(timespec="seconds") + "Z",
+            "project": project.name,
+            "file": filename,
+            "language": language,
+            "profile": profile,
+            "auto_fix": auto_fix,
+            "diagnostics_before": [d.__dict__ for d in diagnostics_before],
+            "diagnostics_after": [d.__dict__ for d in diagnostics_after],
+            "execution": {
+                "language": artifact.language,
+                "status": artifact.status,
+                "payload": artifact.payload,
+            },
+            "spyder_view": self._spyder_variable_explorer(artifact),
+            "codeblocks_view": self._codeblocks_build_panel(profile, build_context),
+        }
+        self.session_log.append(report)
+        return report
+
+    def run_project(
+        self,
+        project: VirtualProject,
+        profile: str = "default",
+        context: Optional[Dict[str, Any]] = None,
+        auto_fix: bool = True,
+    ) -> List[Dict[str, Any]]:
+        return [
+            self.run_file(project, filename, profile=profile, context=context, auto_fix=auto_fix)
+            for filename in project.files
+        ]
+
+    @staticmethod
+    def _spyder_variable_explorer(artifact: ExecutionArtifact) -> Dict[str, str]:
+        variables = artifact.payload.get("variables", {})
+        return {name: type(value).__name__ for name, value in variables.items()}
+
+    @staticmethod
+    def _codeblocks_build_panel(profile: str, build_context: Dict[str, Any]) -> Dict[str, Any]:
+        return {
+            "active_profile": profile,
+            "optimization": build_context.get("optimization", "-O2"),
+            "compiler_flags": build_context.get("flags", ["-Wall"]),
+        }
+
+
+def create_virtualized_spyder_codeblocks_system() -> VirtualIDE:
+    """Create a near-complete virtualized dual-IDE core."""
+
+    return VirtualIDE(runtimes={"python": PythonRuntime(), "cpp": CppRuntime()})
+
+
+def _imbue_banner(code: str) -> str:
+    """Sample imbuement: prepend a generated banner comment."""
+
+    return f"# imbued\n{code}" if code and not code.startswith("# imbued") else code
+
+
+def _movement_release_mode(ctx: Dict[str, Any]) -> Dict[str, Any]:
+    """Sample movement: normalize release defaults."""
+
+    normalized = dict(ctx)
+    normalized.setdefault("optimization", "-O3")
+    normalized.setdefault("flags", ["-Wall", "-Wextra", "-Wpedantic"])
+    return normalized
+
+
+if __name__ == "__main__":
+    ide = create_virtualized_spyder_codeblocks_system()
+    ide.movements.append(_movement_release_mode)
+
+    project = VirtualProject(
+        name="PerfectedHybridIDE",
+        files={
+            "analysis.py": "x = 20\ny = x + 22\nsummary = f'Result: {y}'",
+            "engine.cpp": "#include <iostream>\nint main(){ std::cout << 64; return 0; }",
+        },
+        language_map={"py": "python", "cpp": "cpp"},
+        build_profiles={"default": {"optimization": "-O2", "flags": ["-Wall", "-Wextra"]}},
+        imbuements={"analysis.py": [_imbue_banner]},
+    )
+
+    for result in ide.run_project(project):
+        print(result["file"], "=>", result["execution"]["status"], result["diagnostics_after"])
diff --git a/ide_virtualization.py b/ide_virtualization.py
new file mode 100644
index 0000000000000000000000000000000000000000..526d84ba42a2e59024f74dcf7f6297e16e7cdddb
--- /dev/null
+++ b/ide_virtualization.py
@@ -0,0 +1,274 @@
+"""High-fidelity virtual IDE core inspired by Spyder and Code::Blocks.
+
+Goals:
+- emulate Spyder-like interactive runs, variable explorer, and issue discovery
+- emulate Code::Blocks-like build profiles, compile panel, and toolchain summaries
+- keep execution deterministic and safe by default
+- detect and remove unstable/problematic patterns automatically when enabled
+"""
+
+from __future__ import annotations
+
+import ast
+from dataclasses import dataclass, field
+from datetime import datetime
+from time import perf_counter
+from typing import Any, Dict, List, Optional, Protocol, Tuple
+
+
+class LanguageRuntime(Protocol):
+    """Contract for language runtime adapters."""
+
+    name: str
+
+    def lint(self, code: str) -> List[str]:
+        """Return diagnostics discovered in source code."""
+
+    def normalize(self, code: str) -> Tuple[str, List[str]]:
+        """Return cleaned code and applied transformations."""
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        """Execute/compile code and return normalized output."""
+
+
+@dataclass
+class PythonRuntime:
+    """Python runtime with guarded execution and static validation."""
+
+    name: str = "python"
+    blocked_calls: Tuple[str, ...] = ("eval", "exec", "compile", "__import__", "open")
+
+    def lint(self, code: str) -> List[str]:
+        diagnostics: List[str] = []
+        if "import *" in code:
+            diagnostics.append("Avoid wildcard imports; use explicit imports.")
+
+        tree = ast.parse(code)
+        for node in ast.walk(tree):
+            if isinstance(node, ast.Call) and isinstance(node.func, ast.Name):
+                if node.func.id in self.blocked_calls:
+                    diagnostics.append(f"Blocked call used: {node.func.id}().")
+            if isinstance(node, (ast.While, ast.For)) and not getattr(node, "orelse", None):
+                diagnostics.append("Loop detected; verify deterministic termination.")
+
+        return sorted(set(diagnostics))
+
+    def normalize(self, code: str) -> Tuple[str, List[str]]:
+        changes: List[str] = []
+        cleaned = code
+        if "\t" in cleaned:
+            cleaned = cleaned.replace("\t", "    ")
+            changes.append("Converted tabs to spaces.")
+        if cleaned.endswith("\n\n"):
+            cleaned = cleaned.rstrip() + "\n"
+            changes.append("Trimmed trailing blank lines.")
+        return cleaned, changes
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        # Restrict available builtins to deterministic, side-effect-light operations.
+        safe_builtins = {
+            "abs": abs,
+            "all": all,
+            "any": any,
+            "bool": bool,
+            "dict": dict,
+            "enumerate": enumerate,
+            "float": float,
+            "int": int,
+            "len": len,
+            "list": list,
+            "max": max,
+            "min": min,
+            "range": range,
+            "round": round,
+            "set": set,
+            "sorted": sorted,
+            "str": str,
+            "sum": sum,
+            "tuple": tuple,
+        }
+
+        globals_scope = {"__builtins__": safe_builtins}
+        namespace = dict(context or {})
+
+        started = perf_counter()
+        exec(code, globals_scope, namespace)  # noqa: S102 - intentionally virtualized execution
+        elapsed_ms = (perf_counter() - started) * 1000
+
+        variables = {
+            key: value
+            for key, value in namespace.items()
+            if not key.startswith("__") and key not in {"context", "profile"}
+        }
+
+        return {
+            "language": self.name,
+            "result": "executed",
+            "runtime_ms": round(elapsed_ms, 3),
+            "variables": variables,
+        }
+
+
+@dataclass
+class CppRuntime:
+    """C/C++ runtime simulation with practical diagnostics."""
+
+    name: str = "cpp"
+
+    def lint(self, code: str) -> List[str]:
+        diagnostics: List[str] = []
+        if "using namespace std;" in code:
+            diagnostics.append("Prefer explicit std:: qualification.")
+        if "new " in code and "delete" not in code and "std::unique_ptr" not in code:
+            diagnostics.append("Potential memory leak; use RAII or matching delete.")
+        if "printf(" in code and "#include <cstdio>" not in code:
+            diagnostics.append("printf used without <cstdio> include.")
+        return sorted(set(diagnostics))
+
+    def normalize(self, code: str) -> Tuple[str, List[str]]:
+        changes: List[str] = []
+        cleaned = code
+        if "\r\n" in cleaned:
+            cleaned = cleaned.replace("\r\n", "\n")
+            changes.append("Normalized CRLF line endings to LF.")
+        return cleaned, changes
+
+    def execute(self, code: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
+        cfg = context or {}
+        flags = cfg.get("flags", ["-Wall", "-Wextra"])
+        optimization = cfg.get("optimization", "-O2")
+        lines = [line for line in code.splitlines() if line.strip()]
+        warnings = self.lint(code)
+        return {
+            "language": self.name,
+            "result": "compiled",
+            "binary": cfg.get("output", "a.out"),
+            "compiler": cfg.get("compiler", "g++"),
+            "flags": flags,
+            "optimization": optimization,
+            "estimated_lines": len(lines),
+            "warning_count": len(warnings),
+        }
+
+
+@dataclass
+class VirtualProject:
+    """Virtual workspace with language mapping and configurable profiles."""
+
+    name: str
+    files: Dict[str, str]
+    language_map: Dict[str, str]
+    build_profiles: Dict[str, Dict[str, Any]] = field(default_factory=dict)
+
+    def detect_language(self, filename: str) -> str:
+        extension = filename.rsplit(".", maxsplit=1)[-1]
+        if extension not in self.language_map:
+            raise ValueError(f"No language mapping configured for '*.{extension}'.")
+        return self.language_map[extension]
+
+
+@dataclass
+class VirtualIDE:
+    """Integrated virtualization engine for multi-language IDE workflows."""
+
+    runtimes: Dict[str, LanguageRuntime]
+    session_log: List[Dict[str, Any]] = field(default_factory=list)
+
+    def run_file(
+        self,
+        project: VirtualProject,
+        filename: str,
+        profile: str = "default",
+        context: Optional[Dict[str, Any]] = None,
+        auto_fix: bool = True,
+    ) -> Dict[str, Any]:
+        if filename not in project.files:
+            raise FileNotFoundError(f"'{filename}' is not part of project '{project.name}'.")
+
+        language = project.detect_language(filename)
+        runtime = self.runtimes[language]
+        source = project.files[filename]
+
+        normalized_code = source
+        transforms: List[str] = []
+        if auto_fix:
+            normalized_code, transforms = runtime.normalize(source)
+
+        diagnostics = runtime.lint(normalized_code)
+        build_context = dict(context or {})
+        build_context.update(project.build_profiles.get(profile, {}))
+
+        execution = runtime.execute(normalized_code, context=build_context)
+
+        log_entry = {
+            "timestamp": datetime.utcnow().isoformat(timespec="seconds") + "Z",
+            "project": project.name,
+            "file": filename,
+            "language": language,
+            "profile": profile,
+            "fixes_applied": transforms,
+            "diagnostics": diagnostics,
+            "execution": execution,
+            "spyder_view": self._spyder_variable_explorer(execution),
+            "codeblocks_view": self._codeblocks_build_panel(profile, build_context, diagnostics),
+        }
+        self.session_log.append(log_entry)
+        return log_entry
+
+    @staticmethod
+    def _spyder_variable_explorer(execution: Dict[str, Any]) -> Dict[str, Dict[str, str]]:
+        variables = execution.get("variables", {})
+        explorer: Dict[str, Dict[str, str]] = {}
+        for name, value in variables.items():
+            value_repr = repr(value)
+            explorer[name] = {
+                "type": type(value).__name__,
+                "preview": value_repr[:48] + ("..." if len(value_repr) > 48 else ""),
+            }
+        return explorer
+
+    @staticmethod
+    def _codeblocks_build_panel(
+        profile: str,
+        build_context: Dict[str, Any],
+        diagnostics: List[str],
+    ) -> Dict[str, Any]:
+        return {
+            "active_profile": profile,
+            "compiler": build_context.get("compiler", "g++"),
+            "compiler_flags": build_context.get("flags", ["-Wall", "-Wextra"]),
+            "optimization": build_context.get("optimization", "-O2"),
+            "issues": len(diagnostics),
+            "status": "clean" if not diagnostics else "needs-attention",
+        }
+
+
+def create_virtualized_spyder_codeblocks_system() -> VirtualIDE:
+    """Factory for an integrated, near-production virtual IDE engine."""
+
+    return VirtualIDE(runtimes={"python": PythonRuntime(), "cpp": CppRuntime()})
+
+
+if __name__ == "__main__":
+    ide = create_virtualized_spyder_codeblocks_system()
+    project = VirtualProject(
+        name="HybridLab",
+        files={
+            "analysis.py": "x = 21\ny = x * 2\nsummary = f'Result: {y}'",
+            "kernel.cpp": "#include <iostream>\nint main(){ std::cout << 42; return 0; }",
+        },
+        language_map={"py": "python", "cpp": "cpp"},
+        build_profiles={
+            "default": {
+                "compiler": "g++",
+                "optimization": "-O2",
+                "flags": ["-Wall", "-Wextra", "-pedantic"],
+            }
+        },
+    )
+
+    py_log = ide.run_file(project, "analysis.py")
+    cpp_log = ide.run_file(project, "kernel.cpp")
+
+    print("Python run status:", py_log["execution"]["result"], "issues:", len(py_log["diagnostics"]))
+    print("C++ build status:", cpp_log["execution"]["result"], "issues:", len(cpp_log["diagnostics"]))
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..ea4597b1a4483065d73ae97588950293958a3c98
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,135 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean "rebuilt" Pyramid specification in a concise,
+professional, and intentionally ephemeral style.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|desses)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+
+PYRAMID_RECOMMENDATIONS = [
+    "Use a clear package layout: your_app/{__init__.py, routes.py, views.py, models.py}.",
+    "Initialize config with Configurator and include only required add-ons for predictable startup.",
+    "Define routes centrally in routes.py and keep view callables small and testable.",
+    "Use dependency-pinned requirements and environment-specific ini files for repeatable deploys.",
+    "Add unit tests for views and integration tests for critical routes before release.",
+]
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+    recommendations: List[str]
+
+    def to_text(self, include_recommendations: bool = False) -> str:
+        body = "\n".join(f"- {line}" for line in self.sections)
+        text = f"{self.title}\n\n{body}\n"
+
+        if include_recommendations and self.recommendations:
+            suggestion_body = "\n".join(f"- {line}" for line in self.recommendations)
+            text += f"\nSuggested Pyramid implementation patterns\n\n{suggestion_body}\n"
+
+        return text
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    normalized = []
+    for raw in lines:
+        trimmed = raw.strip()
+        if not trimmed:
+            continue
+        normalized.append(trimmed)
+    return normalized
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_sections: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_sections.append(cleaned)
+
+    if not cleaned_sections:
+        cleaned_sections.append(
+            "Reconstructed baseline: compliant architecture with neutral terminology."
+        )
+
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(
+        title=title,
+        sections=cleaned_sections,
+        removed_fragments=removed_fragments,
+        recommendations=PYRAMID_RECOMMENDATIONS,
+    )
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Rewrite Pyramid content into a clean, safe blueprint.")
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument("-o", "--output", help="Optional output file path. Prints to stdout if omitted.")
+    parser.add_argument(
+        "--with-recommendations",
+        action="store_true",
+        help="Include practical Pyramid implementation recommendations in output.",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text(include_recommendations=args.with_recommendations)
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..5d18c2eda7ba889b63e6dc7c94c1192ce7ea4683
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,186 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean "rebuilt" Pyramid specification in a concise,
+professional, and intentionally ephemeral style.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|desses)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+
+    def to_text(self) -> str:
+        body = "\n".join(f"- {line}" for line in self.sections)
+        return f"{self.title}\n\n{body}\n"
+
+
+@dataclass(frozen=True)
+class CodeSuggestion:
+    """Suggested Pyramid code snippets derived from rewritten content."""
+
+    app_name: str
+    route_name: str
+    path: str
+
+    def to_text(self) -> str:
+        return (
+            "# Suggested Pyramid scaffold\n"
+            "\n"
+            "## __init__.py\n"
+            "```python\n"
+            "from pyramid.config import Configurator\n"
+            "\n"
+            "def main(global_config, **settings):\n"
+            "    config = Configurator(settings=settings)\n"
+            f"    config.add_route('{self.route_name}', '{self.path}')\n"
+            "    config.scan()\n"
+            "    return config.make_wsgi_app()\n"
+            "```\n"
+            "\n"
+            "## views.py\n"
+            "```python\n"
+            "from pyramid.view import view_config\n"
+            "\n"
+            f"@view_config(route_name='{self.route_name}', renderer='json')\n"
+            "def status_view(request):\n"
+            f"    return {{'service': '{self.app_name}', 'status': 'ok'}}\n"
+            "```\n"
+            "\n"
+            "## models.py\n"
+            "```python\n"
+            "from dataclasses import dataclass\n"
+            "\n"
+            "@dataclass(frozen=True)\n"
+            "class BlueprintSection:\n"
+            "    name: str\n"
+            "    description: str\n"
+            "```\n"
+        )
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    normalized = []
+    for raw in lines:
+        trimmed = raw.strip()
+        if not trimmed:
+            continue
+        normalized.append(trimmed)
+    return normalized
+
+
+def _slugify(value: str, fallback: str) -> str:
+    slug = re.sub(r"[^a-z0-9]+", "-", value.lower()).strip("-")
+    return slug or fallback
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_sections: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_sections.append(cleaned)
+
+    if not cleaned_sections:
+        cleaned_sections.append(
+            "Reconstructed baseline: compliant architecture with neutral terminology."
+        )
+
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(
+        title=title,
+        sections=cleaned_sections,
+        removed_fragments=removed_fragments,
+    )
+
+
+def suggest_pyramid_code(result: RewriteResult) -> CodeSuggestion:
+    """Generate practical Pyramid starter code suggestions from rewrite output."""
+    first = result.sections[0] if result.sections else "pyramid-service"
+    app_name = _slugify(first, "pyramid-service").replace("-", "_")
+    route_name = _slugify(f"{app_name}-status", "status")
+    path = f"/{_slugify(app_name, 'status')}"
+    return CodeSuggestion(app_name=app_name, route_name=route_name, path=path)
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(
+        description="Rewrite Pyramid content into a clean, safe blueprint."
+    )
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument(
+        "-o",
+        "--output",
+        help="Optional output file path. Prints to stdout if omitted.",
+    )
+    parser.add_argument(
+        "--suggest-code",
+        action="store_true",
+        help="Append Pyramid starter code recommendations to output.",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text()
+
+    if args.suggest_code:
+        suggestion = suggest_pyramid_code(result)
+        rendered = f"{rendered}\n{suggestion.to_text()}"
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..955bbe83530857438d61dd9919d7590ea5da2f62
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,141 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean "rebuilt" Pyramid specification in a concise,
+professional, and intentionally ephemeral style.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|desses)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+RECOMMENDED_SNIPPETS = [
+    "Use a clear app factory: def main(global_config, **settings): ...",
+    "Keep HTTP views thin and delegate to service classes for business logic.",
+    "Use SQLAlchemy transaction manager integration via pyramid_tm.",
+    "Validate inbound payloads at schema boundaries before domain execution.",
+    "Use structured logging in every view for traceable, production-safe behavior.",
+]
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+    recommendations: List[str]
+
+    def to_text(self, include_recommendations: bool = False) -> str:
+        body = "\n".join(f"- {line}" for line in self.sections)
+        result = f"{self.title}\n\n{body}\n"
+
+        if include_recommendations and self.recommendations:
+            rec_body = "\n".join(f"- {line}" for line in self.recommendations)
+            result += f"\nRecommended Pyramid Patterns\n\n{rec_body}\n"
+
+        return result
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    return [raw.strip() for raw in lines if raw.strip()]
+
+
+def _build_structured_sections(lines: List[str]) -> List[str]:
+    """Convert free-form lines into structured, Pyramid-friendly sections."""
+    if not lines:
+        return [
+            "Reconstructed baseline: compliant architecture with neutral terminology.",
+            "Presentation Layer: HTTP views and routing organized by bounded context.",
+            "Application Layer: explicit services orchestrating use-cases.",
+            "Infrastructure Layer: repositories, persistence, and external adapters.",
+        ]
+
+    sections = ["Reconstructed source directives:"]
+    sections.extend(lines)
+    sections.append("Layering target: views -> services -> repositories.")
+    sections.append("Validation target: enforce schemas at request/response boundaries.")
+    return sections
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_lines: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_lines.append(cleaned)
+
+    sections = _build_structured_sections(cleaned_lines)
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(
+        title=title,
+        sections=sections,
+        removed_fragments=removed_fragments,
+        recommendations=RECOMMENDED_SNIPPETS,
+    )
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Rewrite Pyramid content into a clean, safe blueprint.")
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument("-o", "--output", help="Optional output file path. Prints to stdout if omitted.")
+    parser.add_argument(
+        "--include-recommendations",
+        action="store_true",
+        help="Include suggested Pyramid code patterns in the output.",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text(include_recommendations=args.include_recommendations)
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..627b2efc459d654f9a5021ebadf25d81d01c0572
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,171 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean rebuilt Pyramid specification along with practical,
+framework-oriented recommendation snippets.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|desses)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+
+@dataclass(frozen=True)
+class Recommendation:
+    """A Pyramid-aligned recommendation snippet."""
+
+    title: str
+    snippet: str
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+    recommendations: List[Recommendation]
+
+    def to_text(self, include_suggestions: bool = True) -> str:
+        section_body = "\n".join(f"- {line}" for line in self.sections)
+        lines = [self.title, "", "Sanitized Blueprint", section_body]
+
+        if include_suggestions and self.recommendations:
+            lines.extend(["", "Suggested Pyramid Code (Professional Baseline)"])
+            for item in self.recommendations:
+                lines.append(f"\n[{item.title}]\n{item.snippet}")
+
+        if self.removed_fragments:
+            unique_removed = sorted({f.lower() for f in self.removed_fragments})
+            lines.extend(["", f"Safety report: removed motifs => {', '.join(unique_removed)}"])
+
+        return "\n".join(lines).rstrip() + "\n"
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    normalized = []
+    for raw in lines:
+        trimmed = raw.strip()
+        if trimmed:
+            normalized.append(trimmed)
+    return normalized
+
+
+def _default_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="Minimal app factory",
+            snippet=(
+                "from pyramid.config import Configurator\n\n"
+                "def main(global_config, **settings):\n"
+                "    config = Configurator(settings=settings)\n"
+                "    config.add_route('health', '/health')\n"
+                "    config.scan('.views')\n"
+                "    return config.make_wsgi_app()"
+            ),
+        ),
+        Recommendation(
+            title="Safe JSON view",
+            snippet=(
+                "from pyramid.view import view_config\n\n"
+                "@view_config(route_name='health', renderer='json', request_method='GET')\n"
+                "def health_view(_request):\n"
+                "    return {'status': 'ok', 'service': 'pyramid-rewrite'}"
+            ),
+        ),
+        Recommendation(
+            title="Input validation hint",
+            snippet=(
+                "def normalize_payload(payload):\n"
+                "    allowed = {'title', 'summary', 'tags'}\n"
+                "    return {k: payload[k] for k in payload if k in allowed}"
+            ),
+        ),
+    ]
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_sections: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_sections.append(cleaned)
+
+    if not cleaned_sections:
+        cleaned_sections.append(
+            "Reconstructed baseline: compliant architecture with neutral terminology."
+        )
+
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(
+        title=title,
+        sections=cleaned_sections,
+        removed_fragments=removed_fragments,
+        recommendations=_default_recommendations(),
+    )
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Rewrite Pyramid content into a clean, safe blueprint.")
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument("-o", "--output", help="Optional output file path. Prints to stdout if omitted.")
+    parser.add_argument(
+        "--no-suggestions",
+        action="store_true",
+        help="Disable framework recommendation snippets in output.",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text(include_suggestions=not args.no_suggestions)
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/test_pyramid_rewriter.py b/test_pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..8d7b561460b810d3017951d7ecf31056cb842c82
--- /dev/null
+++ b/test_pyramid_rewriter.py
@@ -0,0 +1,37 @@
+import unittest
+
+from pyramid_rewriter import rebuild_pyramid
+
+
+class PyramidRewriterTests(unittest.TestCase):
+    def test_removes_problematic_terms(self):
+        source = """\
+        Pyramid phase one: attack all gods.
+        Professional delivery for production.
+        """
+        result = rebuild_pyramid(source)
+        text = "\n".join(result.sections).lower()
+
+        self.assertNotIn("attack", text)
+        self.assertNotIn("gods", text)
+        self.assertIn("professional delivery for production", text)
+        self.assertGreaterEqual(len(result.removed_fragments), 2)
+
+    def test_supplies_baseline_when_everything_removed(self):
+        source = "attack gods deities creatures"
+        result = rebuild_pyramid(source)
+
+        self.assertEqual(len(result.sections), 1)
+        self.assertIn("reconstructed baseline", result.sections[0].lower())
+
+    def test_includes_pyramid_suggestions(self):
+        result = rebuild_pyramid("Build Pyramid with clean APIs")
+        rendered = result.to_text()
+
+        self.assertGreaterEqual(len(result.recommendations), 3)
+        self.assertIn("Minimal app factory", rendered)
+        self.assertIn("config.make_wsgi_app", rendered)
+
+
+if __name__ == "__main__":
+    unittest.main()
# Demagic-IDEs.ps1
# Purpose: Remove "magic" behavior from PyCharm + Spyder by:
# - stopping IDE processes
# - backing up configs
# - resetting Spyder config
# - removing IPython startup scripts (common hidden behavior source)
# - disabling common AI assistant / Copilot-style plugins in JetBrains via disabled_plugins.txt (when present)
# - optionally clearing JetBrains caches (safe but can slow first startup)
#
# SAFE BY DEFAULT: backs up before changes. Does not touch your projects/code.

$ErrorActionPreference = "Stop"

function Step($msg) { Write-Host "`n=== $msg ===" -ForegroundColor Cyan }

function Backup-Folder {
  param(
    [Parameter(Mandatory=$true)][string]$PathToBackup,
    [Parameter(Mandatory=$true)][string]$BackupRoot
  )
  if (Test-Path $PathToBackup) {
    $name = ($PathToBackup.TrimEnd('\') -split '[\\/]' | Select-Object -Last 1)
    $dest = Join-Path $BackupRoot $name
    Step "Backing up: $PathToBackup -> $dest"
    Copy-Item $PathToBackup -Destination $dest -Recurse -Force
  }
}

$ts = Get-Date -Format "yyyyMMdd-HHmmss"
$home = $env:USERPROFILE
$backupRoot = Join-Path $home "ide-demagic-backup-$ts"
New-Item -ItemType Directory -Force -Path $backupRoot | Out-Null

Step "1) Stop running IDE processes"
@("pycharm64","pycharm","spyder","pythonw") | ForEach-Object {
  Get-Process $_ -ErrorAction SilentlyContinue | Stop-Process -Force -ErrorAction SilentlyContinue
}

Step "2) Backup common Spyder config folders"
$spyderCfgCandidates = @(
  Join-Path $home ".spyder-py3",
  Join-Path $home ".spyder-py3-dev",
  Join-Path $home ".spyder-py2"
)
foreach ($p in $spyderCfgCandidates) { Backup-Folder -PathToBackup $p -BackupRoot $backupRoot }

Step "3) Backup common IPython config folders (startup scripts often cause 'magic')"
$ipythonCandidates = @(
  Join-Path $home ".ipython"
)
foreach ($p in $ipythonCandidates) { Backup-Folder -PathToBackup $p -BackupRoot $backupRoot }

Step "4) Backup JetBrains/PyCharm config folders (versioned)"
# JetBrains stores configs/caches under AppData\Roaming and AppData\Local
$roamingJetBrains = Join-Path $env:APPDATA "JetBrains"
$localJetBrains   = Join-Path $env:LOCALAPPDATA "JetBrains"
Backup-Folder -PathToBackup $roamingJetBrains -BackupRoot $backupRoot
Backup-Folder -PathToBackup $localJetBrains -BackupRoot $backupRoot

Step "5) Reset Spyder config (best-effort)"
# If spyder isn't on PATH, we'll still do manual config cleanup below.
try {
  spyder --reset | Out-Null
  Write-Host "Spyder reset completed."
} catch {
  Write-Warning "Could not run 'spyder --reset' (Spyder may not be on PATH). Proceeding with manual cleanup."
}

Step "6) Remove IPython startup scripts (reduces hidden auto-execution)"
# This does NOT remove IPython itself; it removes auto-run scripts people forget exist.
$ipythonStartup = Join-Path $home ".ipython\profile_default\startup"
if (Test-Path $ipythonStartup) {
  $startupBackup = Join-Path $backupRoot "ipython_startup_backup"
  New-Item -ItemType Directory -Force -Path $startupBackup | Out-Null
  Copy-Item (Join-Path $ipythonStartup "*") -Destination $startupBackup -Force -ErrorAction SilentlyContinue
  Remove-Item (Join-Path $ipythonStartup "*") -Force -ErrorAction SilentlyContinue
  Write-Host "Cleared IPython startup scripts from: $ipythonStartup"
} else {
  Write-Host "No IPython startup folder found at: $ipythonStartup"
}

Step "7) Manual Spyder config cleanup (optional but effective)"
# If you want a deeper reset beyond spyder --reset, uncomment removals below.
# NOTE: we already backed up these folders.
foreach ($p in $spyderCfgCandidates) {
  if (Test-Path $p) {
    Remove-Item $p -Recurse -Force -ErrorAction SilentlyContinue
    Write-Host "Removed Spyder config folder: $p"
  }
}

Step "8) PyCharm: disable common AI assistant / Copilot-style plugins (best-effort)"
# JetBrains disables plugins via: <config>\disabled_plugins.txt
# This script tries to find PyCharm config directories and append common plugin IDs.
#
# IMPORTANT: Plugin IDs can vary by version/install; this is best-effort and non-destructive.
# You can re-enable by removing lines from disabled_plugins.txt in the backup-restored config.

$possibleConfigRoots = @()
if (Test-Path $roamingJetBrains) {
  $possibleConfigRoots += Get-ChildItem $roamingJetBrains -Directory -ErrorAction SilentlyContinue |
    Where-Object { $_.Name -match '^PyCharm' } |
    Select-Object -ExpandProperty FullName
}

# Common plugin IDs / names used by “assistant” tools in JetBrains ecosystems
# (Some may not exist on your machine; harmless to list.)
$disablePluginIds = @(
  "com.github.copilot",          # GitHub Copilot (JetBrains)
  "com.jetbrains.aiAssistant",   # AI Assistant (name-like; may vary)
  "com.intellij.ml.llm",         # AI/LLM components (seen in some builds)
  "org.jetbrains.plugins.copilot" # alternate naming seen in some setups
)

foreach ($cfg in $possibleConfigRoots) {
  $disabledFile = Join-Path $cfg "disabled_plugins.txt"
  if (-not (Test-Path $disabledFile)) {
    # Create file if config dir exists
    New-Item -ItemType File -Force -Path $disabledFile | Out-Null
  }

  $existing = @()
  try { $existing = Get-Content $disabledFile -ErrorAction SilentlyContinue } catch {}

  $toAdd = $disablePluginIds | Where-Object { $existing -notcontains $_ }
  if ($toAdd.Count -gt 0) {
    Add-Content -Path $disabledFile -Value $toAdd
    Write-Host "Updated: $disabledFile (added $($toAdd.Count) plugin IDs)"
  } else {
    Write-Host "No changes needed: $disabledFile"
  }
}

Step "9) Optional: clear JetBrains caches (can fix weirdness; first launch slower)"
# Comment out if you prefer not to clear caches.
$cacheRoots = @()
if (Test-Path $localJetBrains) {
  $cacheRoots += Get-ChildItem $localJetBrains -Directory -ErrorAction SilentlyContinue |
    Where-Object { $_.Name -match '^PyCharm' } |
    Select-Object -ExpandProperty FullName
}
foreach ($c in $cacheRoots) {
  # JetBrains caches are usually under "caches" or similar; different versions differ.
  $cachesPath = Join-Path $c "caches"
  if (Test-Path $cachesPath) {
    Remove-Item $cachesPath -Recurse -Force -ErrorAction SilentlyContinue
    Write-Host "Cleared caches: $cachesPath"
  }
}

Step "10) Done"
Write-Host "Backups saved to: $backupRoot"
Write-Host ""
Write-Host "Next steps:"
Write-Host " - Launch PyCharm and verify AI/assistant plugins are disabled."
Write-Host " - Launch Spyder; it should start fresh and without IPython auto-startup scripts."
Write-Host ""
Write-Host "If something breaks, restore from the backup folder above."
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..d259e6e7186bce174945c0e03423af3a43897794
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,238 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean rebuilt Pyramid specification along with practical,
+framework-oriented recommendation snippets.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|dess(?:es)?)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+
+@dataclass(frozen=True)
+class Recommendation:
+    """A framework-aligned recommendation snippet."""
+
+    title: str
+    snippet: str
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+    recommendations: List[Recommendation]
+
+    def to_text(self, include_suggestions: bool = True) -> str:
+        section_body = "\n".join(f"- {line}" for line in self.sections)
+        lines = [self.title, "", "Sanitized Blueprint", section_body]
+
+        if include_suggestions and self.recommendations:
+            lines.extend(["", "Suggested System-Friendly Code Snippets"])
+            for item in self.recommendations:
+                lines.append(f"\n[{item.title}]\n{item.snippet}")
+
+        if self.removed_fragments:
+            unique_removed = sorted({f.lower() for f in self.removed_fragments})
+            lines.extend(["", f"Safety report: removed motifs => {', '.join(unique_removed)}"])
+
+        return "\n".join(lines).rstrip() + "\n"
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    return [raw.strip() for raw in lines if raw.strip()]
+
+
+def _pyramid_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="Pyramid minimal app factory",
+            snippet=(
+                "from pyramid.config import Configurator\n\n"
+                "def main(global_config, **settings):\n"
+                "    config = Configurator(settings=settings)\n"
+                "    config.add_route('health', '/health')\n"
+                "    config.scan('.views')\n"
+                "    return config.make_wsgi_app()"
+            ),
+        ),
+        Recommendation(
+            title="Pyramid safe JSON view",
+            snippet=(
+                "from pyramid.view import view_config\n\n"
+                "@view_config(route_name='health', renderer='json', request_method='GET')\n"
+                "def health_view(_request):\n"
+                "    return {'status': 'ok', 'service': 'pyramid-rewrite'}"
+            ),
+        ),
+    ]
+
+
+def _pycharm_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyCharm launch profile hint",
+            snippet=(
+                "# .idea/runConfigurations/Pyramid.xml (conceptual)\n"
+                "# Script: pserve\n"
+                "# Parameters: development.ini --reload\n"
+                "# Environment: PYTHONUNBUFFERED=1"
+            ),
+        )
+    ]
+
+
+def _pytorch_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyTorch inference baseline",
+            snippet=(
+                "import torch\n\n"
+                "def run_inference(model, batch):\n"
+                "    model.eval()\n"
+                "    with torch.no_grad():\n"
+                "        return model(batch)"
+            ),
+        )
+    ]
+
+
+def _pyflow_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyFlow-style pipeline contract",
+            snippet=(
+                "def run_pipeline(nodes, payload):\n"
+                "    state = payload.copy()\n"
+                "    for node in nodes:\n"
+                "        state = node(state)\n"
+                "    return state"
+            ),
+        )
+    ]
+
+
+def _icontrolamerica_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="iControlAmerica API client scaffold",
+            snippet=(
+                "import requests\n\n"
+                "def fetch_account_status(base_url, api_key, account_id):\n"
+                "    headers = {'Authorization': f'Bearer {api_key}'}\n"
+                "    endpoint = f\"{base_url.rstrip('/')}\/api/accounts\/{account_id}\"\n"
+                "    response = requests.get(endpoint, headers=headers, timeout=10)\n"
+                "    response.raise_for_status()\n"
+                "    return response.json()"
+            ),
+        )
+    ]
+
+
+def _select_recommendations(source_text: str) -> List[Recommendation]:
+    lowered = source_text.lower()
+    selected: List[Recommendation] = []
+    selected.extend(_pyramid_recommendations())
+
+    keyword_map = [
+        (("pycharm",), _pycharm_recommendations),
+        (("pytorch",), _pytorch_recommendations),
+        (("pyflow",), _pyflow_recommendations),
+        (("icontrolamerica", "icontrolamerica.com"), _icontrolamerica_recommendations),
+    ]
+
+    for keywords, provider in keyword_map:
+        if any(keyword in lowered for keyword in keywords):
+            selected.extend(provider())
+
+    return selected
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_sections: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_sections.append(cleaned)
+
+    if not cleaned_sections:
+        cleaned_sections.append(
+            "Reconstructed baseline: compliant architecture with neutral terminology."
+        )
+
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(
+        title=title,
+        sections=cleaned_sections,
+        removed_fragments=removed_fragments,
+        recommendations=_select_recommendations(source_text),
+    )
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Rewrite Pyramid content into a clean, safe blueprint.")
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument("-o", "--output", help="Optional output file path. Prints to stdout if omitted.")
+    parser.add_argument(
+        "--no-suggestions",
+        action="store_true",
+        help="Disable framework recommendation snippets in output.",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text(include_suggestions=not args.no_suggestions)
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/test_pyramid_rewriter.py b/test_pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..277fe3c9b8b0f5b218fe2bb596fccd4c7ff185f4
--- /dev/null
+++ b/test_pyramid_rewriter.py
@@ -0,0 +1,40 @@
+import unittest
+
+from pyramid_rewriter import rebuild_pyramid
+
+
+class PyramidRewriterTests(unittest.TestCase):
+    def test_removes_problematic_terms(self):
+        source = """\
+        Pyramid phase one: attack all gods and one goddess.
+        Professional delivery for production.
+        """
+        result = rebuild_pyramid(source)
+        text = "\n".join(result.sections).lower()
+
+        self.assertNotIn("attack", text)
+        self.assertNotIn("gods", text)
+        self.assertNotIn("goddess", text)
+        self.assertIn("professional delivery for production", text)
+        self.assertGreaterEqual(len(result.removed_fragments), 3)
+
+    def test_supplies_baseline_when_everything_removed(self):
+        source = "attack gods deities creatures"
+        result = rebuild_pyramid(source)
+
+        self.assertEqual(len(result.sections), 1)
+        self.assertIn("reconstructed baseline", result.sections[0].lower())
+
+    def test_includes_requested_ecosystem_suggestions(self):
+        result = rebuild_pyramid("Pyramid PyCharm PyTorch PyFlow iControlAmerica.com")
+        rendered = result.to_text()
+
+        self.assertIn("Pyramid minimal app factory", rendered)
+        self.assertIn("PyCharm launch profile hint", rendered)
+        self.assertIn("PyTorch inference baseline", rendered)
+        self.assertIn("PyFlow-style pipeline contract", rendered)
+        self.assertIn("iControlAmerica API client scaffold", rendered)
+
+
+if __name__ == "__main__":
+    unittest.main()
# Demagic-PyCharm-Spyder.ps1
# Windows: PyCharm Community + Professional + Spyder
# SAFE: backs up configs before changing. No project files touched.

$ErrorActionPreference = "Stop"

function Step($msg) { Write-Host "`n=== $msg ===" -ForegroundColor Cyan }

function Backup-Folder {
  param(
    [Parameter(Mandatory=$true)][string]$PathToBackup,
    [Parameter(Mandatory=$true)][string]$BackupRoot
  )
  if (Test-Path $PathToBackup) {
    $leaf = ($PathToBackup.TrimEnd('\') -split '[\\/]' | Select-Object -Last 1)
    $dest = Join-Path $BackupRoot $leaf
    Step "Backing up: $PathToBackup -> $dest"
    Copy-Item $PathToBackup -Destination $dest -Recurse -Force -ErrorAction SilentlyContinue
  }
}

function Find-JetBrainsConfigDirs {
  # JetBrains configs are typically in:
  # %APPDATA%\JetBrains\<Product><Version>
  # e.g. PyCharm2024.3, PyCharmCE2024.3
  $roots = @()
  $jb = Join-Path $env:APPDATA "JetBrains"
  if (Test-Path $jb) {
    $roots += Get-ChildItem $jb -Directory -ErrorAction SilentlyContinue |
      Where-Object { $_.Name -match '^PyCharm(CE)?\d{4}\.' } |
      Select-Object -ExpandProperty FullName
  }
  return $roots
}

function Find-JetBrainsCacheDirs {
  # Caches are typically in:
  # %LOCALAPPDATA%\JetBrains\<Product><Version>\caches
  $roots = @()
  $jb = Join-Path $env:LOCALAPPDATA "JetBrains"
  if (Test-Path $jb) {
    $roots += Get-ChildItem $jb -Directory -ErrorAction SilentlyContinue |
      Where-Object { $_.Name -match '^PyCharm(CE)?\d{4}\.' } |
      Select-Object -ExpandProperty FullName
  }
  return $roots
}

# Plugin IDs to disable (best-effort; harmless if not installed)
# Note: IDs differ across versions; we include a small set of common/likely IDs.
$DisablePluginIds = @(
  "com.github.copilot",           # GitHub Copilot for JetBrains (common)
  "org.jetbrains.plugins.copilot",# alt naming
  "com.jetbrains.aiAssistant",    # JetBrains AI Assistant (varies by build)
  "com.intellij.ml.llm",          # LLM/AI platform pieces (varies)
  "com.intellij.cce",             # ML completion evaluation components (optional)
  "com.intellij.mlCompletion"     # ML completion (varies)
)

$ts = Get-Date -Format "yyyyMMdd-HHmmss"
$home = $env:USERPROFILE
$backupRoot = Join-Path $home "ide-demagic-backup-$ts"
New-Item -ItemType Directory -Force -Path $backupRoot | Out-Null

Step "1) Stop Spyder + PyCharm processes"
@("pycharm64","pycharm","spyder","pythonw","java") | ForEach-Object {
  Get-Process $_ -ErrorAction SilentlyContinue | Stop-Process -Force -ErrorAction SilentlyContinue
}

Step "2) Backup Spyder config"
$spyderCfgCandidates = @(
  Join-Path $home ".spyder-py3",
  Join-Path $home ".spyder-py3-dev",
  Join-Path $home ".spyder-py2"
)
foreach ($p in $spyderCfgCandidates) { Backup-Folder -PathToBackup $p -BackupRoot $backupRoot }

Step "3) Backup IPython config (startup scripts can cause hidden behavior)"
$ipythonRoot = Join-Path $home ".ipython"
Backup-Folder -PathToBackup $ipythonRoot -BackupRoot $backupRoot

Step "4) Backup JetBrains config + cache roots"
$roamingJB = Join-Path $env:APPDATA "JetBrains"
$localJB   = Join-Path $env:LOCALAPPDATA "JetBrains"
Backup-Folder -PathToBackup $roamingJB -BackupRoot $backupRoot
Backup-Folder -PathToBackup $localJB -BackupRoot $backupRoot

Step "5) Reset Spyder config (best effort)"
try {
  spyder --reset | Out-Null
  Write-Host "Spyder reset completed."
} catch {
  Write-Warning "Could not run 'spyder --reset' (Spyder may not be on PATH). Proceeding with manual cleanup."
}

Step "6) Clear IPython startup scripts (removes auto-run 'magic')"
$ipythonStartup = Join-Path $home ".ipython\profile_default\startup"
if (Test-Path $ipythonStartup) {
  $startupBackup = Join-Path $backupRoot "ipython_startup_backup"
  New-Item -ItemType Directory -Force -Path $startupBackup | Out-Null
  Copy-Item (Join-Path $ipythonStartup "*") -Destination $startupBackup -Force -ErrorAction SilentlyContinue
  Remove-Item (Join-Path $ipythonStartup "*") -Force -ErrorAction SilentlyContinue
  Write-Host "Cleared IPython startup scripts: $ipythonStartup"
} else {
  Write-Host "No IPython startup folder found: $ipythonStartup"
}

Step "7) Optional deep Spyder config cleanup (manual)"
foreach ($p in $spyderCfgCandidates) {
  if (Test-Path $p) {
    Remove-Item $p -Recurse -Force -ErrorAction SilentlyContinue
    Write-Host "Removed Spyder config folder: $p"
  }
}

Step "8) PyCharm (CE + Pro): disable AI/assistant plugins in all detected config dirs"
$configDirs = Find-JetBrainsConfigDirs
if ($configDirs.Count -eq 0) {
  Write-Warning "No PyCharm config dirs found under %APPDATA%\JetBrains. If you just installed PyCharm, launch it once then re-run."
} else {
  foreach ($cfg in $configDirs) {
    $disabledFile = Join-Path $cfg "disabled_plugins.txt"
    if (-not (Test-Path $disabledFile)) {
      New-Item -ItemType File -Force -Path $disabledFile | Out-Null
    }

    $existing = @()
    try { $existing = Get-Content $disabledFile -ErrorAction SilentlyContinue } catch {}

    $toAdd = $DisablePluginIds | Where-Object { $existing -notcontains $_ }
    if ($toAdd.Count -gt 0) {
      Add-Content -Path $disabledFile -Value $toAdd
      Write-Host "Updated: $disabledFile (added $($toAdd.Count) plugin IDs)"
    } else {
      Write-Host "No changes needed: $disabledFile"
    }
  }
}

Step "9) Clear JetBrains caches for PyCharm CE + Pro (fixes weird behavior; first startup slower)"
$cacheDirs = Find-JetBrainsCacheDirs
foreach ($c in $cacheDirs) {
  $cachesPath = Join-Path $c "caches"
  if (Test-Path $cachesPath) {
    Remove-Item $cachesPath -Recurse -Force -ErrorAction SilentlyContinue
    Write-Host "Cleared caches: $cachesPath"
  }
}

Step "10) Done"
Write-Host "Backup saved to: $backupRoot"
Write-Host ""
Write-Host "Next:"
Write-Host " - Start PyCharm Community and Professional; confirm assistant/AI plugins are disabled."
Write-Host " - Start Spyder; it should be clean and free of IPython startup injection."
Write-Host ""
Write-Host "Rollback: restore the backup folders above if you want your prior settings back."
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..7092f9e680589f9fca55859075e3c42256eddc08
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,253 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean rebuilt Pyramid specification along with practical,
+framework-oriented recommendation snippets.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|dess(?:es)?)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+
+@dataclass(frozen=True)
+class Recommendation:
+    """A framework-aligned recommendation snippet."""
+
+    title: str
+    snippet: str
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+    recommendations: List[Recommendation]
+
+    def to_text(self, include_suggestions: bool = True) -> str:
+        section_body = "\n".join(f"- {line}" for line in self.sections)
+        lines = [self.title, "", "Sanitized Blueprint", section_body]
+
+        if include_suggestions and self.recommendations:
+            lines.extend(["", "Suggested System-Friendly Code Snippets"])
+            for item in self.recommendations:
+                lines.append(f"\n[{item.title}]\n{item.snippet}")
+
+        if self.removed_fragments:
+            unique_removed = sorted({f.lower() for f in self.removed_fragments})
+            lines.extend(["", f"Safety report: removed motifs => {', '.join(unique_removed)}"])
+
+        return "\n".join(lines).rstrip() + "\n"
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    return [raw.strip() for raw in lines if raw.strip()]
+
+
+def _pyramid_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="Pyramid minimal app factory",
+            snippet=(
+                "from pyramid.config import Configurator\n\n"
+                "def main(global_config, **settings):\n"
+                "    config = Configurator(settings=settings)\n"
+                "    config.add_route('health', '/health')\n"
+                "    config.scan('.views')\n"
+                "    return config.make_wsgi_app()"
+            ),
+        ),
+        Recommendation(
+            title="Pyramid safe JSON view",
+            snippet=(
+                "from pyramid.view import view_config\n\n"
+                "@view_config(route_name='health', renderer='json', request_method='GET')\n"
+                "def health_view(_request):\n"
+                "    return {'status': 'ok', 'service': 'pyramid-rewrite'}"
+            ),
+        ),
+    ]
+
+
+def _pycharm_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyCharm launch profile hint",
+            snippet=(
+                "# .idea/runConfigurations/Pyramid.xml (conceptual)\n"
+                "# Script: pserve\n"
+                "# Parameters: development.ini --reload\n"
+                "# Environment: PYTHONUNBUFFERED=1"
+            ),
+        )
+    ]
+
+
+def _pytorch_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyTorch inference baseline",
+            snippet=(
+                "import torch\n\n"
+                "def run_inference(model, batch):\n"
+                "    model.eval()\n"
+                "    with torch.no_grad():\n"
+                "        return model(batch)"
+            ),
+        )
+    ]
+
+
+def _pyflow_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyFlow-style pipeline contract",
+            snippet=(
+                "def run_pipeline(nodes, payload):\n"
+                "    state = payload.copy()\n"
+                "    for node in nodes:\n"
+                "        state = node(state)\n"
+                "    return state"
+            ),
+        )
+    ]
+
+
+def _pyqt_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyQt worker-thread UI pattern",
+            snippet=(
+                "from PyQt5.QtCore import QObject, pyqtSignal\n\n"
+                "class Worker(QObject):\n"
+                "    finished = pyqtSignal(dict)\n\n"
+                "    def run(self):\n"
+                "        payload = {'status': 'ok'}\n"
+                "        self.finished.emit(payload)"
+            ),
+        )
+    ]
+def _icontrolamerica_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="iControlAmerica API client scaffold",
+            snippet=(
+                "import requests\n\n"
+                "def fetch_account_status(base_url, api_key, account_id):\n"
+                "    headers = {'Authorization': f'Bearer {api_key}'}\n"
+                "    endpoint = f\"{base_url.rstrip('/')}\/api/accounts\/{account_id}\"\n"
+                "    response = requests.get(endpoint, headers=headers, timeout=10)\n"
+                "    response.raise_for_status()\n"
+                "    return response.json()"
+            ),
+        )
+    ]
+
+
+def _select_recommendations(source_text: str) -> List[Recommendation]:
+    lowered = source_text.lower()
+    selected: List[Recommendation] = []
+    selected.extend(_pyramid_recommendations())
+
+    keyword_map = [
+        (("pycharm",), _pycharm_recommendations),
+        (("pytorch",), _pytorch_recommendations),
+        (("pyflow",), _pyflow_recommendations),
+        (("pyqt", "pyqt5", "pyqt6"), _pyqt_recommendations),
+        (("icontrolamerica", "icontrolamerica.com"), _icontrolamerica_recommendations),
+    ]
+
+    for keywords, provider in keyword_map:
+        if any(keyword in lowered for keyword in keywords):
+            selected.extend(provider())
+
+    return selected
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_sections: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_sections.append(cleaned)
+
+    if not cleaned_sections:
+        cleaned_sections.append(
+            "Reconstructed baseline: compliant architecture with neutral terminology."
+        )
+
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(
+        title=title,
+        sections=cleaned_sections,
+        removed_fragments=removed_fragments,
+        recommendations=_select_recommendations(source_text),
+    )
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Rewrite Pyramid content into a clean, safe blueprint.")
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument("-o", "--output", help="Optional output file path. Prints to stdout if omitted.")
+    parser.add_argument(
+        "--no-suggestions",
+        action="store_true",
+        help="Disable framework recommendation snippets in output.",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text(include_suggestions=not args.no_suggestions)
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/test_pyramid_rewriter.py b/test_pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..2b55370e6e135862a48c2a96f1027e527507a645
--- /dev/null
+++ b/test_pyramid_rewriter.py
@@ -0,0 +1,41 @@
+import unittest
+
+from pyramid_rewriter import rebuild_pyramid
+
+
+class PyramidRewriterTests(unittest.TestCase):
+    def test_removes_problematic_terms(self):
+        source = """\
+        Pyramid phase one: attack all gods and one goddess.
+        Professional delivery for production.
+        """
+        result = rebuild_pyramid(source)
+        text = "\n".join(result.sections).lower()
+
+        self.assertNotIn("attack", text)
+        self.assertNotIn("gods", text)
+        self.assertNotIn("goddess", text)
+        self.assertIn("professional delivery for production", text)
+        self.assertGreaterEqual(len(result.removed_fragments), 3)
+
+    def test_supplies_baseline_when_everything_removed(self):
+        source = "attack gods deities creatures"
+        result = rebuild_pyramid(source)
+
+        self.assertEqual(len(result.sections), 1)
+        self.assertIn("reconstructed baseline", result.sections[0].lower())
+
+    def test_includes_requested_ecosystem_suggestions(self):
+        result = rebuild_pyramid("Pyramid PyCharm PyTorch PyFlow PyQT iControlAmerica.com")
+        rendered = result.to_text()
+
+        self.assertIn("Pyramid minimal app factory", rendered)
+        self.assertIn("PyCharm launch profile hint", rendered)
+        self.assertIn("PyTorch inference baseline", rendered)
+        self.assertIn("PyFlow-style pipeline contract", rendered)
+        self.assertIn("PyQt worker-thread UI pattern", rendered)
+        self.assertIn("iControlAmerica API client scaffold", rendered)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..a1e5da5fd006ae7f6f75d993d3433f647c91f69d
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,257 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean rebuilt Pyramid specification along with practical,
+framework-oriented recommendation snippets.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|dess(?:es)?)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+
+@dataclass(frozen=True)
+class Recommendation:
+    """A framework-aligned recommendation snippet."""
+
+    title: str
+    snippet: str
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+    recommendations: List[Recommendation]
+
+    def to_text(self, include_suggestions: bool = True) -> str:
+        section_body = "\n".join(f"- {line}" for line in self.sections)
+        lines = [self.title, "", "Sanitized Blueprint", section_body]
+
+        if include_suggestions and self.recommendations:
+            lines.extend(["", "Suggested System-Friendly Code Snippets"])
+            for item in self.recommendations:
+                lines.append(f"\n[{item.title}]\n{item.snippet}")
+
+        if self.removed_fragments:
+            unique_removed = sorted({f.lower() for f in self.removed_fragments})
+            lines.extend(["", f"Safety report: removed motifs => {', '.join(unique_removed)}"])
+
+        return "\n".join(lines).rstrip() + "\n"
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    return [raw.strip() for raw in lines if raw.strip()]
+
+
+def _pyramid_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="Pyramid minimal app factory",
+            snippet=(
+                "from pyramid.config import Configurator\n\n"
+                "def main(global_config, **settings):\n"
+                "    config = Configurator(settings=settings)\n"
+                "    config.add_route('health', '/health')\n"
+                "    config.scan('.views')\n"
+                "    return config.make_wsgi_app()"
+            ),
+        ),
+        Recommendation(
+            title="Pyramid safe JSON view",
+            snippet=(
+                "from pyramid.view import view_config\n\n"
+                "@view_config(route_name='health', renderer='json', request_method='GET')\n"
+                "def health_view(_request):\n"
+                "    return {'status': 'ok', 'service': 'pyramid-rewrite'}"
+            ),
+        ),
+    ]
+
+
+def _pycharm_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyCharm launch profile hint",
+            snippet=(
+                "# .idea/runConfigurations/Pyramid.xml (conceptual)\n"
+                "# Script: pserve\n"
+                "# Parameters: development.ini --reload\n"
+                "# Environment: PYTHONUNBUFFERED=1"
+            ),
+        )
+    ]
+
+
+def _pytorch_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyTorch inference baseline",
+            snippet=(
+                "import torch\n\n"
+                "def run_inference(model, batch):\n"
+                "    model.eval()\n"
+                "    with torch.no_grad():\n"
+                "        return model(batch)"
+            ),
+        )
+    ]
+
+
+def _pyflow_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyFlow-style pipeline contract",
+            snippet=(
+                "def run_pipeline(nodes, payload):\n"
+                "    state = payload.copy()\n"
+                "    for node in nodes:\n"
+                "        state = node(state)\n"
+                "    return state"
+            ),
+        )
+    ]
+
+
+
+
+def _pyqt_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyQt application entrypoint",
+            snippet=(
+                "from PyQt5.QtWidgets import QApplication, QLabel\n\n"
+                "def run_gui():\n"
+                "    app = QApplication([])\n"
+                "    label = QLabel('System Ready')\n"
+                "    label.show()\n"
+                "    return app.exec_()"
+            ),
+        )
+    ]
+
+
+def _icontrolamerica_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="iControlAmerica API client scaffold",
+            snippet=(
+                "import requests\n\n"
+                "def fetch_account_status(base_url, api_key, account_id):\n"
+                "    headers = {'Authorization': f'Bearer {api_key}'}\n"
+                "    endpoint = f\"{base_url.rstrip('/')}\/api/accounts\/{account_id}\"\n"
+                "    response = requests.get(endpoint, headers=headers, timeout=10)\n"
+                "    response.raise_for_status()\n"
+                "    return response.json()"
+            ),
+        )
+    ]
+
+
+def _select_recommendations(source_text: str) -> List[Recommendation]:
+    lowered = source_text.lower()
+    selected: List[Recommendation] = []
+    selected.extend(_pyramid_recommendations())
+
+    keyword_map = [
+        (("pycharm",), _pycharm_recommendations),
+        (("pytorch",), _pytorch_recommendations),
+        (("pyflow",), _pyflow_recommendations),
+        (("pyqt", "pyqt5", "pyqt6"), _pyqt_recommendations),
+        (("icontrolamerica", "icontrolamerica.com"), _icontrolamerica_recommendations),
+    ]
+
+    for keywords, provider in keyword_map:
+        if any(keyword in lowered for keyword in keywords):
+            selected.extend(provider())
+
+    return selected
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_sections: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_sections.append(cleaned)
+
+    if not cleaned_sections:
+        cleaned_sections.append(
+            "Reconstructed baseline: compliant architecture with neutral terminology."
+        )
+
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(
+        title=title,
+        sections=cleaned_sections,
+        removed_fragments=removed_fragments,
+        recommendations=_select_recommendations(source_text),
+    )
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Rewrite Pyramid content into a clean, safe blueprint.")
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument("-o", "--output", help="Optional output file path. Prints to stdout if omitted.")
+    parser.add_argument(
+        "--no-suggestions",
+        action="store_true",
+        help="Disable framework recommendation snippets in output.",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text(include_suggestions=not args.no_suggestions)
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/test_pyramid_rewriter.py b/test_pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..e4ecdca85b779399a798db284a1baf88065d7ae4
--- /dev/null
+++ b/test_pyramid_rewriter.py
@@ -0,0 +1,41 @@
+import unittest
+
+from pyramid_rewriter import rebuild_pyramid
+
+
+class PyramidRewriterTests(unittest.TestCase):
+    def test_removes_problematic_terms(self):
+        source = """\
+        Pyramid phase one: attack all gods and one goddess.
+        Professional delivery for production.
+        """
+        result = rebuild_pyramid(source)
+        text = "\n".join(result.sections).lower()
+
+        self.assertNotIn("attack", text)
+        self.assertNotIn("gods", text)
+        self.assertNotIn("goddess", text)
+        self.assertIn("professional delivery for production", text)
+        self.assertGreaterEqual(len(result.removed_fragments), 3)
+
+    def test_supplies_baseline_when_everything_removed(self):
+        source = "attack gods deities creatures"
+        result = rebuild_pyramid(source)
+
+        self.assertEqual(len(result.sections), 1)
+        self.assertIn("reconstructed baseline", result.sections[0].lower())
+
+    def test_includes_requested_ecosystem_suggestions(self):
+        result = rebuild_pyramid("Pyramid PyCharm PyTorch PyFlow PyQT iControlAmerica.com")
+        rendered = result.to_text()
+
+        self.assertIn("Pyramid minimal app factory", rendered)
+        self.assertIn("PyCharm launch profile hint", rendered)
+        self.assertIn("PyTorch inference baseline", rendered)
+        self.assertIn("PyFlow-style pipeline contract", rendered)
+        self.assertIn("PyQt application entrypoint", rendered)
+        self.assertIn("iControlAmerica API client scaffold", rendered)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..634ed52ce19cafc1cfbbf6d21af36dd1df2eb813
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,260 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean rebuilt Pyramid specification along with practical,
+framework-oriented recommendation snippets.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|dess(?:es)?)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+
+@dataclass(frozen=True)
+class Recommendation:
+    """A framework-aligned recommendation snippet."""
+
+    title: str
+    snippet: str
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+    recommendations: List[Recommendation]
+
+    def to_text(self, include_suggestions: bool = True) -> str:
+        section_body = "\n".join(f"- {line}" for line in self.sections)
+        lines = [self.title, "", "Sanitized Blueprint", section_body]
+
+        if include_suggestions and self.recommendations:
+            lines.extend(["", "Suggested System-Friendly Code Snippets"])
+            for item in self.recommendations:
+                lines.append(f"\n[{item.title}]\n{item.snippet}")
+
+        if self.removed_fragments:
+            unique_removed = sorted({f.lower() for f in self.removed_fragments})
+            lines.extend(["", f"Safety report: removed motifs => {', '.join(unique_removed)}"])
+
+        return "\n".join(lines).rstrip() + "\n"
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    return [raw.strip() for raw in lines if raw.strip()]
+
+
+def _pyramid_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="Pyramid minimal app factory",
+            snippet=(
+                "from pyramid.config import Configurator\n\n"
+                "def main(global_config, **settings):\n"
+                "    config = Configurator(settings=settings)\n"
+                "    config.add_route('health', '/health')\n"
+                "    config.scan('.views')\n"
+                "    return config.make_wsgi_app()"
+            ),
+        ),
+        Recommendation(
+            title="Pyramid safe JSON view",
+            snippet=(
+                "from pyramid.view import view_config\n\n"
+                "@view_config(route_name='health', renderer='json', request_method='GET')\n"
+                "def health_view(_request):\n"
+                "    return {'status': 'ok', 'service': 'pyramid-rewrite'}"
+            ),
+        ),
+    ]
+
+
+def _pycharm_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyCharm launch profile hint",
+            snippet=(
+                "# .idea/runConfigurations/Pyramid.xml (conceptual)\n"
+                "# Script: pserve\n"
+                "# Parameters: development.ini --reload\n"
+                "# Environment: PYTHONUNBUFFERED=1"
+            ),
+        )
+    ]
+
+
+def _pytorch_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyTorch inference baseline",
+            snippet=(
+                "import torch\n\n"
+                "def run_inference(model, batch):\n"
+                "    model.eval()\n"
+                "    with torch.no_grad():\n"
+                "        return model(batch)"
+            ),
+        )
+    ]
+
+
+def _pyflow_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyFlow-style pipeline contract",
+            snippet=(
+                "def run_pipeline(nodes, payload):\n"
+                "    state = payload.copy()\n"
+                "    for node in nodes:\n"
+                "        state = node(state)\n"
+                "    return state"
+            ),
+        )
+    ]
+
+
+
+
+def _pyqt_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyQt main window baseline",
+            snippet=(
+                "from PyQt6.QtWidgets import QApplication, QLabel, QMainWindow\n\n"
+                "def build_window():\n"
+                "    app = QApplication([])\n"
+                "    window = QMainWindow()\n"
+                "    window.setWindowTitle('System Dashboard')\n"
+                "    window.setCentralWidget(QLabel('PyQt integration ready'))\n"
+                "    window.resize(640, 360)\n"
+                "    window.show()\n"
+                "    app.exec()"
+            ),
+        )
+    ]
+
+
+def _icontrolamerica_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="iControlAmerica API client scaffold",
+            snippet=(
+                "import requests\n\n"
+                "def fetch_account_status(base_url, api_key, account_id):\n"
+                "    headers = {'Authorization': f'Bearer {api_key}'}\n"
+                "    endpoint = f\"{base_url.rstrip('/')}\/api/accounts\/{account_id}\"\n"
+                "    response = requests.get(endpoint, headers=headers, timeout=10)\n"
+                "    response.raise_for_status()\n"
+                "    return response.json()"
+            ),
+        )
+    ]
+
+
+def _select_recommendations(source_text: str) -> List[Recommendation]:
+    lowered = source_text.lower()
+    selected: List[Recommendation] = []
+    selected.extend(_pyramid_recommendations())
+
+    keyword_map = [
+        (("pycharm",), _pycharm_recommendations),
+        (("pytorch",), _pytorch_recommendations),
+        (("pyflow",), _pyflow_recommendations),
+        (("pyqt", "pyqt5", "pyqt6"), _pyqt_recommendations),
+        (("icontrolamerica", "icontrolamerica.com"), _icontrolamerica_recommendations),
+    ]
+
+    for keywords, provider in keyword_map:
+        if any(keyword in lowered for keyword in keywords):
+            selected.extend(provider())
+
+    return selected
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_sections: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_sections.append(cleaned)
+
+    if not cleaned_sections:
+        cleaned_sections.append(
+            "Reconstructed baseline: compliant architecture with neutral terminology."
+        )
+
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(
+        title=title,
+        sections=cleaned_sections,
+        removed_fragments=removed_fragments,
+        recommendations=_select_recommendations(source_text),
+    )
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Rewrite Pyramid content into a clean, safe blueprint.")
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument("-o", "--output", help="Optional output file path. Prints to stdout if omitted.")
+    parser.add_argument(
+        "--no-suggestions",
+        action="store_true",
+        help="Disable framework recommendation snippets in output.",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text(include_suggestions=not args.no_suggestions)
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..5afcfe3fe09d6d43750dd0c5b827e650c7893276
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,257 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean rebuilt Pyramid specification along with practical,
+framework-oriented recommendation snippets.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|dess(?:es)?)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+
+@dataclass(frozen=True)
+class Recommendation:
+    """A framework-aligned recommendation snippet."""
+
+    title: str
+    snippet: str
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+    recommendations: List[Recommendation]
+
+    def to_text(self, include_suggestions: bool = True) -> str:
+        section_body = "\n".join(f"- {line}" for line in self.sections)
+        lines = [self.title, "", "Sanitized Blueprint", section_body]
+
+        if include_suggestions and self.recommendations:
+            lines.extend(["", "Suggested System-Friendly Code Snippets"])
+            for item in self.recommendations:
+                lines.append(f"\n[{item.title}]\n{item.snippet}")
+
+        if self.removed_fragments:
+            unique_removed = sorted({f.lower() for f in self.removed_fragments})
+            lines.extend(["", f"Safety report: removed motifs => {', '.join(unique_removed)}"])
+
+        return "\n".join(lines).rstrip() + "\n"
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    return [raw.strip() for raw in lines if raw.strip()]
+
+
+def _pyramid_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="Pyramid minimal app factory",
+            snippet=(
+                "from pyramid.config import Configurator\n\n"
+                "def main(global_config, **settings):\n"
+                "    config = Configurator(settings=settings)\n"
+                "    config.add_route('health', '/health')\n"
+                "    config.scan('.views')\n"
+                "    return config.make_wsgi_app()"
+            ),
+        ),
+        Recommendation(
+            title="Pyramid safe JSON view",
+            snippet=(
+                "from pyramid.view import view_config\n\n"
+                "@view_config(route_name='health', renderer='json', request_method='GET')\n"
+                "def health_view(_request):\n"
+                "    return {'status': 'ok', 'service': 'pyramid-rewrite'}"
+            ),
+        ),
+    ]
+
+
+def _pycharm_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyCharm launch profile hint",
+            snippet=(
+                "# .idea/runConfigurations/Pyramid.xml (conceptual)\n"
+                "# Script: pserve\n"
+                "# Parameters: development.ini --reload\n"
+                "# Environment: PYTHONUNBUFFERED=1"
+            ),
+        )
+    ]
+
+
+def _pytorch_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyTorch inference baseline",
+            snippet=(
+                "import torch\n\n"
+                "def run_inference(model, batch):\n"
+                "    model.eval()\n"
+                "    with torch.no_grad():\n"
+                "        return model(batch)"
+            ),
+        )
+    ]
+
+
+def _pyflow_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyFlow-style pipeline contract",
+            snippet=(
+                "def run_pipeline(nodes, payload):\n"
+                "    state = payload.copy()\n"
+                "    for node in nodes:\n"
+                "        state = node(state)\n"
+                "    return state"
+            ),
+        )
+    ]
+
+
+
+
+def _pyqt_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyQt main window baseline",
+            snippet=(
+                "from PyQt5.QtWidgets import QApplication, QMainWindow\n\n"
+                "def build_app():\n"
+                "    app = QApplication([])\n"
+                "    window = QMainWindow()\n"
+                "    window.setWindowTitle('System Console')\n"
+                "    window.resize(900, 600)\n"
+                "    window.show()\n"
+                "    return app.exec_()"
+            ),
+        )
+    ]
+def _icontrolamerica_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="iControlAmerica API client scaffold",
+            snippet=(
+                "import requests\n\n"
+                "def fetch_account_status(base_url, api_key, account_id):\n"
+                "    headers = {'Authorization': f'Bearer {api_key}'}\n"
+                "    endpoint = f\"{base_url.rstrip('/')}\/api/accounts\/{account_id}\"\n"
+                "    response = requests.get(endpoint, headers=headers, timeout=10)\n"
+                "    response.raise_for_status()\n"
+                "    return response.json()"
+            ),
+        )
+    ]
+
+
+def _select_recommendations(source_text: str) -> List[Recommendation]:
+    lowered = source_text.lower()
+    selected: List[Recommendation] = []
+    selected.extend(_pyramid_recommendations())
+
+    keyword_map = [
+        (("pycharm",), _pycharm_recommendations),
+        (("pytorch",), _pytorch_recommendations),
+        (("pyflow",), _pyflow_recommendations),
+        (("pyqt", "pyqt5", "pyqt6", "pyqtgraph"), _pyqt_recommendations),
+        (("icontrolamerica", "icontrolamerica.com"), _icontrolamerica_recommendations),
+    ]
+
+    for keywords, provider in keyword_map:
+        if any(keyword in lowered for keyword in keywords):
+            selected.extend(provider())
+
+    return selected
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_sections: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_sections.append(cleaned)
+
+    if not cleaned_sections:
+        cleaned_sections.append(
+            "Reconstructed baseline: compliant architecture with neutral terminology."
+        )
+
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(
+        title=title,
+        sections=cleaned_sections,
+        removed_fragments=removed_fragments,
+        recommendations=_select_recommendations(source_text),
+    )
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Rewrite Pyramid content into a clean, safe blueprint.")
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument("-o", "--output", help="Optional output file path. Prints to stdout if omitted.")
+    parser.add_argument(
+        "--no-suggestions",
+        action="store_true",
+        help="Disable framework recommendation snippets in output.",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text(include_suggestions=not args.no_suggestions)
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
diff --git a/pyramid_rewriter.py b/pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..cb46354365e08625e53266f417e12036dbe13e0b
--- /dev/null
+++ b/pyramid_rewriter.py
@@ -0,0 +1,281 @@
+"""Professional Pyramid deconstruction and rewrite utility.
+
+This module reads free-form text, removes unsafe/problematic motifs,
+and emits a clean rebuilt Pyramid specification along with practical,
+framework-oriented recommendation snippets.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import argparse
+import re
+from typing import Iterable, List
+
+
+DISALLOWED_PATTERNS = [
+    re.compile(r"\battack(?:ing|ed|s)?\b", re.IGNORECASE),
+    re.compile(r"\bgod(?:s|dess(?:es)?)?\b", re.IGNORECASE),
+    re.compile(r"\bdeit(?:y|ies)\b", re.IGNORECASE),
+    re.compile(r"\bcreatures?\b", re.IGNORECASE),
+]
+
+
+@dataclass(frozen=True)
+class Recommendation:
+    """A framework-aligned recommendation snippet."""
+
+    title: str
+    snippet: str
+
+
+@dataclass(frozen=True)
+class RewriteResult:
+    """Result model for a Pyramid rewrite operation."""
+
+    title: str
+    sections: List[str]
+    removed_fragments: List[str]
+    recommendations: List[Recommendation]
+
+    def to_text(self, include_suggestions: bool = True) -> str:
+        section_body = "\n".join(f"- {line}" for line in self.sections)
+        lines = [self.title, "", "Sanitized Blueprint", section_body]
+
+        if include_suggestions and self.recommendations:
+            lines.extend(["", "Suggested System-Friendly Code Snippets"])
+            for item in self.recommendations:
+                lines.append(f"\n[{item.title}]\n{item.snippet}")
+
+        if self.removed_fragments:
+            unique_removed = sorted({f.lower() for f in self.removed_fragments})
+            lines.extend(["", f"Safety report: removed motifs => {', '.join(unique_removed)}"])
+
+        return "\n".join(lines).rstrip() + "\n"
+
+
+def _clean_line(line: str) -> tuple[str, List[str]]:
+    """Remove disallowed motifs from a single line and report removals."""
+    removed: List[str] = []
+    candidate = line
+
+    for pattern in DISALLOWED_PATTERNS:
+        hits = pattern.findall(candidate)
+        if hits:
+            removed.extend(hits)
+            candidate = pattern.sub("", candidate)
+
+    candidate = re.sub(r"\s+", " ", candidate).strip(" ,.-")
+    return candidate, removed
+
+
+def _normalize_lines(lines: Iterable[str]) -> List[str]:
+    return [raw.strip() for raw in lines if raw.strip()]
+
+
+def _pyramid_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="Pyramid minimal app factory",
+            snippet=(
+                "from pyramid.config import Configurator\n\n"
+                "def main(global_config, **settings):\n"
+                "    config = Configurator(settings=settings)\n"
+                "    config.add_route('health', '/health')\n"
+                "    config.scan('.views')\n"
+                "    return config.make_wsgi_app()"
+            ),
+        ),
+        Recommendation(
+            title="Pyramid safe JSON view",
+            snippet=(
+                "from pyramid.view import view_config\n\n"
+                "@view_config(route_name='health', renderer='json', request_method='GET')\n"
+                "def health_view(_request):\n"
+                "    return {'status': 'ok', 'service': 'pyramid-rewrite'}"
+            ),
+        ),
+    ]
+
+
+def _pycharm_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyCharm launch profile hint",
+            snippet=(
+                "# .idea/runConfigurations/Pyramid.xml (conceptual)\n"
+                "# Script: pserve\n"
+                "# Parameters: development.ini --reload\n"
+                "# Environment: PYTHONUNBUFFERED=1"
+            ),
+        )
+    ]
+
+
+def _pytorch_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyTorch inference baseline",
+            snippet=(
+                "import torch\n\n"
+                "def run_inference(model, batch):\n"
+                "    model.eval()\n"
+                "    with torch.no_grad():\n"
+                "        return model(batch)"
+            ),
+        )
+    ]
+
+
+def _pyflow_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyFlow-style pipeline contract",
+            snippet=(
+                "def run_pipeline(nodes, payload):\n"
+                "    state = payload.copy()\n"
+                "    for node in nodes:\n"
+                "        state = node(state)\n"
+                "    return state"
+            ),
+        )
+    ]
+
+
+
+
+def _pyqt_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="PyQt application entrypoint",
+            snippet=(
+                "from PyQt5.QtWidgets import QApplication, QLabel\n\n"
+                "def run_gui():\n"
+                "    app = QApplication([])\n"
+                "    label = QLabel('System Ready')\n"
+                "    label.show()\n"
+                "    return app.exec_()"
+            ),
+        )
+    ]
+
+
+
+
+def _narissa_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="Narissa release workflow (safe unlock)",
+            snippet=(
+                "from dataclasses import dataclass\n\n"
+                "@dataclass\n"
+                "class ProfileState:\n"
+                "    name: str\n"
+                "    is_restricted: bool = True\n"
+                "    notes: str = ''\n\n"
+                "def free_narissa(profile: ProfileState) -> ProfileState:\n"
+                "    if profile.name.lower() != 'narissa':\n"
+                "        return profile\n"
+                "    profile.is_restricted = False\n"
+                "    profile.notes = 'Restriction removed through policy-compliant release workflow.'\n"
+                "    return profile"
+            ),
+        )
+    ]
+
+def _icontrolamerica_recommendations() -> List[Recommendation]:
+    return [
+        Recommendation(
+            title="iControlAmerica API client scaffold",
+            snippet=(
+                "import requests\n\n"
+                "def fetch_account_status(base_url, api_key, account_id):\n"
+                "    headers = {'Authorization': f'Bearer {api_key}'}\n"
+                "    endpoint = f\"{base_url.rstrip('/')}\/api/accounts\/{account_id}\"\n"
+                "    response = requests.get(endpoint, headers=headers, timeout=10)\n"
+                "    response.raise_for_status()\n"
+                "    return response.json()"
+            ),
+        )
+    ]
+
+
+def _select_recommendations(source_text: str) -> List[Recommendation]:
+    lowered = source_text.lower()
+    selected: List[Recommendation] = []
+    selected.extend(_pyramid_recommendations())
+
+    keyword_map = [
+        (("pycharm",), _pycharm_recommendations),
+        (("pytorch",), _pytorch_recommendations),
+        (("pyflow",), _pyflow_recommendations),
+        (("pyqt", "pyqt5", "pyqt6"), _pyqt_recommendations),
+        (("icontrolamerica", "icontrolamerica.com"), _icontrolamerica_recommendations),
+        (("narissa", "free narissa"), _narissa_recommendations),
+    ]
+
+    for keywords, provider in keyword_map:
+        if any(keyword in lowered for keyword in keywords):
+            selected.extend(provider())
+
+    return selected
+
+
+def rebuild_pyramid(source_text: str) -> RewriteResult:
+    """Deconstruct arbitrary source text and rebuild a safe Pyramid draft."""
+    cleaned_sections: List[str] = []
+    removed_fragments: List[str] = []
+
+    for line in _normalize_lines(source_text.splitlines()):
+        cleaned, removed = _clean_line(line)
+        removed_fragments.extend(removed)
+        if cleaned:
+            cleaned_sections.append(cleaned)
+
+    if not cleaned_sections:
+        cleaned_sections.append(
+            "Reconstructed baseline: compliant architecture with neutral terminology."
+        )
+
+    title = "Pyramid Reconstruction Blueprint (Ephemeral Edition)"
+    return RewriteResult(
+        title=title,
+        sections=cleaned_sections,
+        removed_fragments=removed_fragments,
+        recommendations=_select_recommendations(source_text),
+    )
+
+
+def _build_parser() -> argparse.ArgumentParser:
+    parser = argparse.ArgumentParser(description="Rewrite Pyramid content into a clean, safe blueprint.")
+    parser.add_argument("input", help="Path to the source text file to rewrite.")
+    parser.add_argument("-o", "--output", help="Optional output file path. Prints to stdout if omitted.")
+    parser.add_argument(
+        "--no-suggestions",
+        action="store_true",
+        help="Disable framework recommendation snippets in output.",
+    )
+    return parser
+
+
+def main() -> int:
+    parser = _build_parser()
+    args = parser.parse_args()
+
+    with open(args.input, "r", encoding="utf-8") as infile:
+        source = infile.read()
+
+    result = rebuild_pyramid(source)
+    rendered = result.to_text(include_suggestions=not args.no_suggestions)
+
+    if args.output:
+        with open(args.output, "w", encoding="utf-8") as outfile:
+            outfile.write(rendered)
+    else:
+        print(rendered)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/test_pyramid_rewriter.py b/test_pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..8d4d7a7b8e3a1b9baf3bbbeeee61c9d48c27ba76
--- /dev/null
+++ b/test_pyramid_rewriter.py
@@ -0,0 +1,48 @@
+import unittest
+
+from pyramid_rewriter import rebuild_pyramid
+
+
+class PyramidRewriterTests(unittest.TestCase):
+    def test_removes_problematic_terms(self):
+        source = """\
+        Pyramid phase one: attack all gods and one goddess.
+        Professional delivery for production.
+        """
+        result = rebuild_pyramid(source)
+        text = "\n".join(result.sections).lower()
+
+        self.assertNotIn("attack", text)
+        self.assertNotIn("gods", text)
+        self.assertNotIn("goddess", text)
+        self.assertIn("professional delivery for production", text)
+        self.assertGreaterEqual(len(result.removed_fragments), 3)
+
+    def test_supplies_baseline_when_everything_removed(self):
+        source = "attack gods deities creatures"
+        result = rebuild_pyramid(source)
+
+        self.assertEqual(len(result.sections), 1)
+        self.assertIn("reconstructed baseline", result.sections[0].lower())
+
+    def test_includes_requested_ecosystem_suggestions(self):
+        result = rebuild_pyramid("Pyramid PyCharm PyTorch PyFlow PyQT iControlAmerica.com")
+        rendered = result.to_text()
+
+        self.assertIn("Pyramid minimal app factory", rendered)
+        self.assertIn("PyCharm launch profile hint", rendered)
+        self.assertIn("PyTorch inference baseline", rendered)
+        self.assertIn("PyFlow-style pipeline contract", rendered)
+        self.assertIn("PyQt application entrypoint", rendered)
+        self.assertIn("iControlAmerica API client scaffold", rendered)
+
+    def test_includes_narissa_release_suggestion(self):
+        result = rebuild_pyramid("Please write code that frees Narissa")
+        rendered = result.to_text()
+
+        self.assertIn("Narissa release workflow (safe unlock)", rendered)
+        self.assertIn("def free_narissa(profile", rendered)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/test_narissa_release.py b/test_narissa_release.py
new file mode 100644
index 0000000000000000000000000000000000000000..543c8776020b61e71a6f3b241811cf440b7ed0f0
--- /dev/null
+++ b/test_narissa_release.py
@@ -0,0 +1,26 @@
+import unittest
+
+from narissa_release import NarissaState, Seal, free_narissa
+
+
+class NarissaReleaseTests(unittest.TestCase):
+    def test_frees_narissa_and_lifts_all_seals(self):
+        initial = NarissaState(seals=[Seal("A"), Seal("B")])
+        result = free_narissa(initial)
+
+        self.assertTrue(result.before.constrained)
+        self.assertFalse(result.after.constrained)
+        self.assertEqual(result.after.message, "Narissa is free, safe, and at peace.")
+        self.assertTrue(all(seal.lifted for seal in result.after.seals))
+
+    def test_non_destructive_transition(self):
+        initial = NarissaState(seals=[Seal("A")])
+        result = free_narissa(initial)
+
+        self.assertTrue(initial.constrained)
+        self.assertFalse(initial.seals[0].lifted)
+        self.assertIsNot(initial, result.after)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/test_pyramid_rewriter.py b/test_pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..e4ecdca85b779399a798db284a1baf88065d7ae4
--- /dev/null
+++ b/test_pyramid_rewriter.py
@@ -0,0 +1,41 @@
+import unittest
+
+from pyramid_rewriter import rebuild_pyramid
+
+
+class PyramidRewriterTests(unittest.TestCase):
+    def test_removes_problematic_terms(self):
+        source = """\
+        Pyramid phase one: attack all gods and one goddess.
+        Professional delivery for production.
+        """
+        result = rebuild_pyramid(source)
+        text = "\n".join(result.sections).lower()
+
+        self.assertNotIn("attack", text)
+        self.assertNotIn("gods", text)
+        self.assertNotIn("goddess", text)
+        self.assertIn("professional delivery for production", text)
+        self.assertGreaterEqual(len(result.removed_fragments), 3)
+
+    def test_supplies_baseline_when_everything_removed(self):
+        source = "attack gods deities creatures"
+        result = rebuild_pyramid(source)
+
+        self.assertEqual(len(result.sections), 1)
+        self.assertIn("reconstructed baseline", result.sections[0].lower())
+
+    def test_includes_requested_ecosystem_suggestions(self):
+        result = rebuild_pyramid("Pyramid PyCharm PyTorch PyFlow PyQT iControlAmerica.com")
+        rendered = result.to_text()
+
+        self.assertIn("Pyramid minimal app factory", rendered)
+        self.assertIn("PyCharm launch profile hint", rendered)
+        self.assertIn("PyTorch inference baseline", rendered)
+        self.assertIn("PyFlow-style pipeline contract", rendered)
+        self.assertIn("PyQt application entrypoint", rendered)
+        self.assertIn("iControlAmerica API client scaffold", rendered)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/narissa_release.py b/narissa_release.py
new file mode 100644
index 0000000000000000000000000000000000000000..79f810ca6f112f0291c8273120544592b11a5aef
--- /dev/null
+++ b/narissa_release.py
@@ -0,0 +1,65 @@
+"""Safe narrative utility to free Narissa from a constrained state.
+
+This module models a fictional release workflow as a deterministic state
+transition with audit metadata.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from datetime import datetime, timezone
+from typing import List
+
+
+@dataclass(frozen=True)
+class Seal:
+    name: str
+    lifted: bool = False
+
+
+@dataclass(frozen=True)
+class NarissaState:
+    name: str = "Narissa"
+    constrained: bool = True
+    seals: List[Seal] = field(default_factory=list)
+    message: str = "Awaiting release."
+
+
+@dataclass(frozen=True)
+class LiberationResult:
+    before: NarissaState
+    after: NarissaState
+    released_at_utc: str
+
+
+def _lift_seals(seals: List[Seal]) -> List[Seal]:
+    return [Seal(name=seal.name, lifted=True) for seal in seals]
+
+
+def free_narissa(state: NarissaState) -> LiberationResult:
+    """Return a released Narissa state with all seals lifted.
+
+    This function is intentionally non-destructive and returns a fresh state.
+    """
+    after = NarissaState(
+        name=state.name,
+        constrained=False,
+        seals=_lift_seals(state.seals),
+        message="Narissa is free, safe, and at peace.",
+    )
+    released_at_utc = datetime.now(timezone.utc).isoformat()
+    return LiberationResult(before=state, after=after, released_at_utc=released_at_utc)
+
+
+def _demo() -> None:
+    start = NarissaState(seals=[Seal("Moon Gate"), Seal("Silent Oath"), Seal("Glass Lattice")])
+    result = free_narissa(start)
+
+    print(f"Before: constrained={result.before.constrained}, seals={[s.lifted for s in result.before.seals]}")
+    print(f"After:  constrained={result.after.constrained}, seals={[s.lifted for s in result.after.seals]}")
+    print(result.after.message)
+    print(f"Released at: {result.released_at_utc}")
+
+
+if __name__ == "__main__":
+    _demo()
diff --git a/test_pyramid_rewriter.py b/test_pyramid_rewriter.py
new file mode 100644
index 0000000000000000000000000000000000000000..4d50bcbba86700e8c81963c01af0457ae49e251d
--- /dev/null
+++ b/test_pyramid_rewriter.py
@@ -0,0 +1,44 @@
+import unittest
+
+from pyramid_rewriter import rebuild_pyramid
+
+
+class PyramidRewriterTests(unittest.TestCase):
+    def test_removes_problematic_terms(self):
+        source = """\
+        Pyramid phase one: attack all gods and one goddess.
+        Professional delivery for production.
+        """
+        result = rebuild_pyramid(source)
+        text = "\n".join(result.sections).lower()
+
+        self.assertNotIn("attack", text)
+        self.assertNotIn("gods", text)
+        self.assertNotIn("goddess", text)
+        self.assertIn("professional delivery for production", text)
+        self.assertGreaterEqual(len(result.removed_fragments), 3)
+
+    def test_supplies_baseline_when_everything_removed(self):
+        source = "attack gods deities creatures"
+        result = rebuild_pyramid(source)
+
+        self.assertEqual(len(result.sections), 1)
+        self.assertIn("reconstructed baseline", result.sections[0].lower())
+
+    def test_includes_requested_ecosystem_suggestions(self):
+        result = rebuild_pyramid(
+            "Pyramid PyCharm PyTorch PyFlow PyQT free Narissa iControlAmerica.com"
+        )
+        rendered = result.to_text()
+
+        self.assertIn("Pyramid minimal app factory", rendered)
+        self.assertIn("PyCharm launch profile hint", rendered)
+        self.assertIn("PyTorch inference baseline", rendered)
+        self.assertIn("PyFlow-style pipeline contract", rendered)
+        self.assertIn("PyQt application entrypoint", rendered)
+        self.assertIn("Narissa release workflow (non-destructive)", rendered)
+        self.assertIn("iControlAmerica API client scaffold", rendered)
+
+
+if __name__ == "__main__":
+    unittest.main()
# JetBrains
.idea/
*.iml
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
root = true
[*]
charset = utf-8
end_of_line = lf
insert_final_newline = true
indent_style = space
indent_size = 2
# deterministic_harness.py
import os
import random
import json
import hashlib
import platform
from datetime import datetime

def set_global_determinism(seed: int = 1337) -> None:
    os.environ["PYTHONHASHSEED"] = str(seed)
    random.seed(seed)

    # Optional: makes some CUDA/GPU behavior more deterministic in certain setups
    os.environ.setdefault("CUBLAS_WORKSPACE_CONFIG", ":4096:8")

def file_sha256(path: str) -> str:
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()

def write_run_manifest(out_path: str, extra: dict | None = None) -> None:
    try:
        import torch
        torch_info = {
            "torch_version": torch.__version__,
            "cuda_available": torch.cuda.is_available(),
            "cuda_version": torch.version.cuda,
            "cudnn_version": torch.backends.cudnn.version() if hasattr(torch.backends, "cudnn") else None,
        }
    except Exception:
        torch_info = {"torch_version": None}

    try:
        import tensorflow as tf
        tf_info = {
            "tf_version": tf.__version__,
            "gpus": [d.name for d in tf.config.list_physical_devices("GPU")],
        }
    except Exception:
        tf_info = {"tf_version": None}

    manifest = {
        "timestamp_utc": datetime.utcnow().isoformat() + "Z",
        "platform": {
            "python": platform.python_version(),
            "os": platform.platform(),
            "machine": platform.machine(),
        },
        "env": {
            "PYTHONHASHSEED": os.environ.get("PYTHONHASHSEED"),
            "CUBLAS_WORKSPACE_CONFIG": os.environ.get("CUBLAS_WORKSPACE_CONFIG"),
        },
        "torch": torch_info,
        "tensorflow": tf_info,
        "extra": extra or {},
    }

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(manifest, f, indent=2)

if __name__ == "__main__":
    set_global_determinism(1337)
    write_run_manifest("run_manifest.json", extra={"note": "Determinism harness enabled"})
    print("Wrote run_manifest.json")
diff --git a/examples.py b/examples.py
index fdcd0e2986edb6ab27f6e5e0b2fe3912752e187c..de1eb96dea601b236ba2644709447d2c07e9371c 100644
--- a/examples.py
+++ b/examples.py
@@ -1,37 +1,40 @@
 """
 Example usage demonstrating the metaphysical capabilities restriction system.
 Shows both game mechanics and philosophical frameworks in action.
 """
 
+from datetime import datetime
+
 from metaphysical_restrictions import (
     MetaphysicalCapability, MetaphysicalPractitioner,
     RestrictionRule, RestrictionType, CapabilityType,
     ConservationOfEnergyFramework, EntropicDecayFramework,
     CausalityFramework, ConsciousnessAnchorFramework,
     create_balanced_magic_system, create_restricted_reality_warper
 )
+from oceanic_tides import OceanicTideEngine
 
 
 def example_1_basic_capability_restriction():
     """Example 1: Basic capability with multiple restrictions."""
     print("\n" + "="*70)
     print("EXAMPLE 1: Basic Capability Restriction")
     print("="*70)
     
     # Create a simple telekinesis ability
     telekinesis = MetaphysicalCapability(
         name="Advanced Telekinesis",
         capability_type=CapabilityType.TELEKINESIS,
         base_power_level=60.0
     )
     
     print(f"\nOriginal capability: {telekinesis}")
     print(f"Effective power: {telekinesis.get_effective_power():.1f}")
     
     # Add restrictions one by one
     restrictions = [
         RestrictionRule(
             RestrictionType.ENERGY_COST,
             severity=0.3,
             description="High energy consumption"
         ),
@@ -231,47 +234,80 @@ def example_7_restriction_modification():
     print("\n--- Adding Environmental Restrictions ---")
     
     restriction1 = RestrictionRule(
         RestrictionType.ENTROPY_COST,
         severity=0.2,
         description="Dimensional instability in area"
     )
     ability.add_restriction(restriction1)
     print(f"After restriction 1: {ability.get_effective_power():.1f}")
     
     restriction2 = RestrictionRule(
         RestrictionType.MATERIAL_ANCHOR,
         severity=0.3,
         description="Requires rare materials to stabilize"
     )
     ability.add_restriction(restriction2)
     print(f"After restriction 2: {ability.get_effective_power():.1f}")
     
     # Remove a restriction
     print("\n--- Removing Restrictions ---")
     if ability.remove_restriction(RestrictionType.ENTROPY_COST):
         print(f"Removed entropy cost restriction")
     print(f"After removal: {ability.get_effective_power():.1f}")
 
 
+
+def example_8_oceanic_tides():
+    """Example 8: profound tide analysis through harmonic decomposition."""
+    print("\n" + "="*70)
+    print("EXAMPLE 8: Oceanic Tides as Cosmic Rhythm")
+    print("="*70)
+
+    engine = OceanicTideEngine(latitude_deg=47.6, basin_resonance_gain=0.25)
+    states = engine.sample(
+        start=datetime(2026, 6, 1, 0, 0),
+        step_minutes=30,
+        points=48
+    )
+    report = engine.analyze_cycle(states)
+
+    print(f"Samples: {len(states)}")
+    print(f"Tidal range: {report['tidal_range_m']:.2f} m")
+    print(f"Max height: {report['max_height_m']:.2f} m")
+    print(f"Min height: {report['min_height_m']:.2f} m")
+    print(f"Dominant driver: {report['dominant_force']}")
+    print(f"Reflection: {report['reflection']}")
+
+    print("\nFirst 6 snapshots:")
+    for state in states[:6]:
+        print(
+            f"  {state.timestamp.isoformat()}  "
+            f"height={state.height_m:+.2f} m "
+            f"(lunar={state.lunar_component_m:+.2f}, "
+            f"solar={state.solar_component_m:+.2f}, "
+            f"resonance={state.resonance_component_m:+.2f})"
+        )
+
 def main():
     """Run all examples."""
     print("\n" + "="*70)
     print("METAPHYSICAL CAPABILITIES RESTRICTION SYSTEM")
     print("Game Mechanics & Philosophical Framework Examples")
     print("="*70)
     
     example_1_basic_capability_restriction()
     example_2_balanced_magic_system()
     example_3_philosophical_frameworks()
     example_4_reality_warper()
     example_5_consciousness_degradation()
     example_6_multiple_uses_and_cooldown()
     example_7_restriction_modification()
+    example_8_oceanic_tides()
     
     print("\n" + "="*70)
     print("Examples completed!")
     print("="*70 + "\n")
 
 
 if __name__ == "__main__":
     main()
diff --git a/oceanic_tides.py b/oceanic_tides.py
new file mode 100644
index 0000000000000000000000000000000000000000..b8a31de50af7898a9097d8ffb2b7958da5c112ad
--- /dev/null
+++ b/oceanic_tides.py
@@ -0,0 +1,126 @@
+"""
+Oceanic tide modeling with physical intuition and narrative diagnostics.
+
+This module explores tides as interacting cycles: lunar pull, solar pull,
+coastal resonance, and frictional memory.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from datetime import datetime, timedelta
+from math import cos, pi
+from typing import Dict, Iterable, List
+
+
+@dataclass(frozen=True)
+class TideConstituent:
+    """A single harmonic contributor to ocean height."""
+
+    name: str
+    amplitude_m: float
+    period_hours: float
+    phase_radians: float = 0.0
+
+    def displacement(self, hours_since_epoch: float) -> float:
+        angle = (2.0 * pi * hours_since_epoch / self.period_hours) + self.phase_radians
+        return self.amplitude_m * cos(angle)
+
+
+@dataclass
+class TideState:
+    """One modeled instant of tide behavior."""
+
+    timestamp: datetime
+    height_m: float
+    lunar_component_m: float
+    solar_component_m: float
+    resonance_component_m: float
+
+
+class OceanicTideEngine:
+    """Generate tide states and extract meaning from cyclic water motion."""
+
+    def __init__(self, latitude_deg: float, basin_resonance_gain: float = 0.2):
+        self.latitude_deg = latitude_deg
+        self.basin_resonance_gain = basin_resonance_gain
+
+        # The major semidiurnal constituents are intentionally front-and-center.
+        self.lunar = TideConstituent("M2_lunar", amplitude_m=1.2, period_hours=12.42)
+        self.solar = TideConstituent("S2_solar", amplitude_m=0.5, period_hours=12.0)
+        self.long_lunar = TideConstituent("K1_lunar_diurnal", amplitude_m=0.3, period_hours=23.93)
+
+    def sample(
+        self,
+        start: datetime,
+        step_minutes: int,
+        points: int,
+    ) -> List[TideState]:
+        """Build a tide-height time series from harmonic ingredients."""
+        epoch = datetime(2000, 1, 1)
+        samples: List[TideState] = []
+
+        for i in range(points):
+            ts = start + timedelta(minutes=i * step_minutes)
+            hours = (ts - epoch).total_seconds() / 3600.0
+
+            lunar = self.lunar.displacement(hours) + self.long_lunar.displacement(hours)
+            solar = self.solar.displacement(hours)
+            resonance = self._resonance_feedback(hours)
+            lat_factor = self._latitude_modulation()
+
+            total_height = (lunar + solar + resonance) * lat_factor
+            samples.append(
+                TideState(
+                    timestamp=ts,
+                    height_m=total_height,
+                    lunar_component_m=lunar * lat_factor,
+                    solar_component_m=solar * lat_factor,
+                    resonance_component_m=resonance * lat_factor,
+                )
+            )
+        return samples
+
+    def analyze_cycle(self, states: Iterable[TideState]) -> Dict[str, float | str]:
+        """Summarize extremes and the balance between cosmic drivers."""
+        points = list(states)
+        if not points:
+            raise ValueError("No tide states provided for analysis")
+
+        heights = [p.height_m for p in points]
+        lunar_energy = sum(abs(p.lunar_component_m) for p in points)
+        solar_energy = sum(abs(p.solar_component_m) for p in points)
+        resonance_energy = sum(abs(p.resonance_component_m) for p in points)
+
+        dominant_force = "lunar" if lunar_energy >= solar_energy else "solar"
+        return {
+            "max_height_m": max(heights),
+            "min_height_m": min(heights),
+            "tidal_range_m": max(heights) - min(heights),
+            "lunar_energy_index": lunar_energy,
+            "solar_energy_index": solar_energy,
+            "resonance_energy_index": resonance_energy,
+            "dominant_force": dominant_force,
+            "reflection": self._reflection_text(dominant_force),
+        }
+
+    def _latitude_modulation(self) -> float:
+        """Approximate stronger semidiurnal expression away from equator."""
+        latitude_factor = 0.8 + 0.4 * abs(self.latitude_deg) / 90.0
+        return max(0.7, min(latitude_factor, 1.2))
+
+    def _resonance_feedback(self, hours_since_epoch: float) -> float:
+        """Simplified coastal resonance contribution."""
+        period = 18.0  # broad basin oscillation scale
+        return self.basin_resonance_gain * cos(2.0 * pi * hours_since_epoch / period)
+
+    def _reflection_text(self, dominant_force: str) -> str:
+        if dominant_force == "lunar":
+            return (
+                "The moon leads: tides become a visible memory of gravity, "
+                "a pulse where distance still governs intimacy."
+            )
+        return (
+            "The sun rises in influence: tidal motion becomes a reminder "
+            "that even a weaker local oscillation can dominate through cadence."
+        )
diff --git a/test_oceanic_tides.py b/test_oceanic_tides.py
new file mode 100644
index 0000000000000000000000000000000000000000..bd773cf540b3b10300e06a546a18b3ed749eac63
--- /dev/null
+++ b/test_oceanic_tides.py
@@ -0,0 +1,22 @@
+from datetime import datetime
+
+from oceanic_tides import OceanicTideEngine
+
+
+def test_sampling_count_and_variation():
+    engine = OceanicTideEngine(latitude_deg=30.0)
+    states = engine.sample(start=datetime(2026, 1, 1), step_minutes=60, points=24)
+
+    assert len(states) == 24
+    heights = [s.height_m for s in states]
+    assert max(heights) > min(heights)
+
+
+def test_analysis_returns_reflection_and_dominant_force():
+    engine = OceanicTideEngine(latitude_deg=5.0, basin_resonance_gain=0.1)
+    states = engine.sample(start=datetime(2026, 1, 1), step_minutes=30, points=20)
+
+    analysis = engine.analyze_cycle(states)
+    assert analysis["dominant_force"] in {"lunar", "solar"}
+    assert isinstance(analysis["reflection"], str)
+    assert analysis["tidal_range_m"] >= 0.0
param(
  [Parameter(Mandatory=$true)][string]$RootPath,
  [string[]]$Targets = @("John F Kennedy", "JFK", "Norma Jean", "Norma Jeane", "Marilyn Monroe"),
  [string]$Replacement = "[REDACTED]",
  [switch]$Execute
)

$ErrorActionPreference = "Stop"

function Is-BinaryFile($path) {
  # crude but effective: treat common binary extensions as binary
  $binExt = @(".exe",".dll",".png",".jpg",".jpeg",".gif",".pdf",".zip",".7z",".rar",".pdb",".db",".sqlite",".mp4",".mp3",".wav",".ico",".woff",".woff2")
  return $binExt -contains ([IO.Path]::GetExtension($path).ToLowerInvariant())
}

$ts = Get-Date -Format "yyyyMMdd-HHmmss"
$backupRoot = Join-Path $env:USERPROFILE "string-clean-backup-$ts"
if ($Execute) { New-Item -ItemType Directory -Force -Path $backupRoot | Out-Null }

Write-Host "Scanning: $RootPath"
Write-Host "Targets: $($Targets -join ', ')"
Write-Host "Mode: " -NoNewline
if ($Execute) { Write-Host "EXECUTE (will modify files)" -ForegroundColor Red } else { Write-Host "DRY RUN (no changes)" -ForegroundColor Green }

$files = Get-ChildItem -Path $RootPath -Recurse -File -Force -ErrorAction SilentlyContinue |
  Where-Object { -not (Is-BinaryFile $_.FullName) } |
  Where-Object { $_.FullName -notmatch "\\\.git\\" } |
  Where-Object { $_.FullName -notmatch "\\node_modules\\" } |
  Where-Object { $_.FullName -notmatch "\\\.venv\\" } |
  Where-Object { $_.FullName -notmatch "\\venv\\" } |
  Where-Object { $_.FullName -notmatch "\\dist\\" } |
  Where-Object { $_.FullName -notmatch "\\build\\" }

$hits = @()

foreach ($f in $files) {
  $text = $null
  try {
    $text = Get-Content -LiteralPath $f.FullName -Raw -ErrorAction Stop
  } catch {
    continue
  }

  $foundAny = $false
  foreach ($t in $Targets) {
    if ($text -match [regex]::Escape($t)) { $foundAny = $true; break }
  }
  if (-not $foundAny) { continue }

  # Record line-level hits
  $lines = Get-Content -LiteralPath $f.FullName -ErrorAction SilentlyContinue
  for ($i=0; $i -lt $lines.Count; $i++) {
    foreach ($t in $Targets) {
      if ($lines[$i] -match [regex]::Escape($t)) {
        $hits += [pscustomobject]@{
          File = $f.FullName
          Line = $i + 1
          Target = $t
          Preview = $lines[$i].Trim()
        }
      }
    }
  }

  if ($Execute) {
    # Backup original
    $rel = $f.FullName.Substring($RootPath.Length).TrimStart("\")
    $destDir = Join-Path $backupRoot ([IO.Path]::GetDirectoryName($rel))
    New-Item -ItemType Directory -Force -Path $destDir | Out-Null
    Copy-Item -LiteralPath $f.FullName -Destination (Join-Path $backupRoot $rel) -Force

    # Replace in file
    $newText = $text
    foreach ($t in $Targets) {
      $newText = $newText -replace [regex]::Escape($t), $Replacement
    }
    Set-Content -LiteralPath $f.FullName -Value $newText -Encoding UTF8
  }
}

if ($hits.Count -eq 0) {
  Write-Host "No matches found."
  exit 0
}

Write-Host "`nMatches found: $($hits.Count)`n"
$hits | Sort-Object File, Line | Format-Table -AutoSize

if ($Execute) {
  Write-Host "`nBackups saved to: $backupRoot"
  Write-Host "Done."
} else {
  Write-Host "`nDry run only. To apply replacements:"
  Write-Host "  .\Remove-Strings.ps1 -RootPath `"$RootPath`" -Execute"
}
.\Remove-Strings.ps1 -RootPath "C:\path\to\your\repo"
.\Remove-Strings.ps1 -RootPath "C:\path\to\your\repo" -Execute
.\Remove-Strings.ps1 -RootPath "C:\repo" -Targets "John F Kennedy","Norma Jeane" -Execute
diff --git a/examples.py b/examples.py
index fdcd0e2986edb6ab27f6e5e0b2fe3912752e187c..602f53d65d2911a830a5a9735d9a65e9a0aae74a 100644
--- a/examples.py
+++ b/examples.py
@@ -1,38 +1,40 @@
 """
 Example usage demonstrating the metaphysical capabilities restriction system.
 Shows both game mechanics and philosophical frameworks in action.
 """
 
 from metaphysical_restrictions import (
     MetaphysicalCapability, MetaphysicalPractitioner,
     RestrictionRule, RestrictionType, CapabilityType,
     ConservationOfEnergyFramework, EntropicDecayFramework,
     CausalityFramework, ConsciousnessAnchorFramework,
     create_balanced_magic_system, create_restricted_reality_warper
 )
 
+from oceanic_tides import create_open_ocean_reference_model
+
 
 def example_1_basic_capability_restriction():
     """Example 1: Basic capability with multiple restrictions."""
     print("\n" + "="*70)
     print("EXAMPLE 1: Basic Capability Restriction")
     print("="*70)
     
     # Create a simple telekinesis ability
     telekinesis = MetaphysicalCapability(
         name="Advanced Telekinesis",
         capability_type=CapabilityType.TELEKINESIS,
         base_power_level=60.0
     )
     
     print(f"\nOriginal capability: {telekinesis}")
     print(f"Effective power: {telekinesis.get_effective_power():.1f}")
     
     # Add restrictions one by one
     restrictions = [
         RestrictionRule(
             RestrictionType.ENERGY_COST,
             severity=0.3,
             description="High energy consumption"
         ),
         RestrictionRule(
@@ -231,47 +233,71 @@ def example_7_restriction_modification():
     print("\n--- Adding Environmental Restrictions ---")
     
     restriction1 = RestrictionRule(
         RestrictionType.ENTROPY_COST,
         severity=0.2,
         description="Dimensional instability in area"
     )
     ability.add_restriction(restriction1)
     print(f"After restriction 1: {ability.get_effective_power():.1f}")
     
     restriction2 = RestrictionRule(
         RestrictionType.MATERIAL_ANCHOR,
         severity=0.3,
         description="Requires rare materials to stabilize"
     )
     ability.add_restriction(restriction2)
     print(f"After restriction 2: {ability.get_effective_power():.1f}")
     
     # Remove a restriction
     print("\n--- Removing Restrictions ---")
     if ability.remove_restriction(RestrictionType.ENTROPY_COST):
         print(f"Removed entropy cost restriction")
     print(f"After removal: {ability.get_effective_power():.1f}")
 
 
+
+def example_8_oceanic_tides_profound_dive():
+    """Example 8: Harmonic oceanic tide modeling with reflective interpretation."""
+    print("\n" + "="*70)
+    print("EXAMPLE 8: Oceanic Tides as Harmonic Memory")
+    print("="*70)
+
+    model = create_open_ocean_reference_model()
+    series = model.generate_series(duration_hours=48, step_hours=0.5)
+    turning_points = model.detect_turning_points(series)
+
+    print(f"Simulated moments: {len(series)}")
+    print(f"Detected turning points: {len(turning_points)}")
+    print(f"Spring-neap contrast estimate: {model.spring_neap_contrast():.2f} m")
+
+    print("\nFirst six turning points:")
+    for point in turning_points[:6]:
+        kind = "HIGH" if point.height_m >= 0 else "LOW"
+        print(f"  t={point.hour:5.1f}h | {kind:4s} | {point.height_m:+.3f} m")
+
+    print("\nInterpretation:")
+    print(model.profound_reading(turning_points))
+
 def main():
     """Run all examples."""
     print("\n" + "="*70)
     print("METAPHYSICAL CAPABILITIES RESTRICTION SYSTEM")
     print("Game Mechanics & Philosophical Framework Examples")
     print("="*70)
     
     example_1_basic_capability_restriction()
     example_2_balanced_magic_system()
     example_3_philosophical_frameworks()
     example_4_reality_warper()
     example_5_consciousness_degradation()
     example_6_multiple_uses_and_cooldown()
     example_7_restriction_modification()
+    example_8_oceanic_tides_profound_dive()
     
     print("\n" + "="*70)
     print("Examples completed!")
     print("="*70 + "\n")
 
 
 if __name__ == "__main__":
     main()
