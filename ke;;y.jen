.idea/
.venv/
__pycache__/
*.pyc
conda create -n myapi python=3.11 -y
conda activate myapi
pip install -U pip
pip install flask fastapi uvicorn[standard] python-dotenv
param(
  [int]$Port = 8000
)
conda activate myapi
python -m uvicorn app.main:app --reload --host 127.0.0.1 --port $Port
diff --git a/examples.py b/examples.py
index fdcd0e2986edb6ab27f6e5e0b2fe3912752e187c..602f53d65d2911a830a5a9735d9a65e9a0aae74a 100644
--- a/examples.py
+++ b/examples.py
@@ -1,38 +1,40 @@
 """
 Example usage demonstrating the metaphysical capabilities restriction system.
 Shows both game mechanics and philosophical frameworks in action.
 """
 
 from metaphysical_restrictions import (
     MetaphysicalCapability, MetaphysicalPractitioner,
     RestrictionRule, RestrictionType, CapabilityType,
     ConservationOfEnergyFramework, EntropicDecayFramework,
     CausalityFramework, ConsciousnessAnchorFramework,
     create_balanced_magic_system, create_restricted_reality_warper
 )
 
+from oceanic_tides import create_open_ocean_reference_model
+
 
 def example_1_basic_capability_restriction():
     """Example 1: Basic capability with multiple restrictions."""
     print("\n" + "="*70)
     print("EXAMPLE 1: Basic Capability Restriction")
     print("="*70)
     
     # Create a simple telekinesis ability
     telekinesis = MetaphysicalCapability(
         name="Advanced Telekinesis",
         capability_type=CapabilityType.TELEKINESIS,
         base_power_level=60.0
     )
     
     print(f"\nOriginal capability: {telekinesis}")
     print(f"Effective power: {telekinesis.get_effective_power():.1f}")
     
     # Add restrictions one by one
     restrictions = [
         RestrictionRule(
             RestrictionType.ENERGY_COST,
             severity=0.3,
             description="High energy consumption"
         ),
         RestrictionRule(
@@ -231,47 +233,71 @@ def example_7_restriction_modification():
     print("\n--- Adding Environmental Restrictions ---")
     
     restriction1 = RestrictionRule(
         RestrictionType.ENTROPY_COST,
         severity=0.2,
         description="Dimensional instability in area"
     )
     ability.add_restriction(restriction1)
     print(f"After restriction 1: {ability.get_effective_power():.1f}")
     
     restriction2 = RestrictionRule(
         RestrictionType.MATERIAL_ANCHOR,
         severity=0.3,
         description="Requires rare materials to stabilize"
     )
     ability.add_restriction(restriction2)
     print(f"After restriction 2: {ability.get_effective_power():.1f}")
     
     # Remove a restriction
     print("\n--- Removing Restrictions ---")
     if ability.remove_restriction(RestrictionType.ENTROPY_COST):
         print(f"Removed entropy cost restriction")
     print(f"After removal: {ability.get_effective_power():.1f}")
 
 
+
+def example_8_oceanic_tides_profound_dive():
+    """Example 8: Harmonic oceanic tide modeling with reflective interpretation."""
+    print("\n" + "="*70)
+    print("EXAMPLE 8: Oceanic Tides as Harmonic Memory")
+    print("="*70)
+
+    model = create_open_ocean_reference_model()
+    series = model.generate_series(duration_hours=48, step_hours=0.5)
+    turning_points = model.detect_turning_points(series)
+
+    print(f"Simulated moments: {len(series)}")
+    print(f"Detected turning points: {len(turning_points)}")
+    print(f"Spring-neap contrast estimate: {model.spring_neap_contrast():.2f} m")
+
+    print("\nFirst six turning points:")
+    for point in turning_points[:6]:
+        kind = "HIGH" if point.height_m >= 0 else "LOW"
+        print(f"  t={point.hour:5.1f}h | {kind:4s} | {point.height_m:+.3f} m")
+
+    print("\nInterpretation:")
+    print(model.profound_reading(turning_points))
+
 def main():
     """Run all examples."""
     print("\n" + "="*70)
     print("METAPHYSICAL CAPABILITIES RESTRICTION SYSTEM")
     print("Game Mechanics & Philosophical Framework Examples")
     print("="*70)
     
     example_1_basic_capability_restriction()
     example_2_balanced_magic_system()
     example_3_philosophical_frameworks()
     example_4_reality_warper()
     example_5_consciousness_degradation()
     example_6_multiple_uses_and_cooldown()
     example_7_restriction_modification()
+    example_8_oceanic_tides_profound_dive()
     
     print("\n" + "="*70)
     print("Examples completed!")
     print("="*70 + "\n")
 
 
 if __name__ == "__main__":
     main()
diff --git a/flask_benevolence.py b/flask_benevolence.py
new file mode 100644
index 0000000000000000000000000000000000000000..5680f4f239497100710f1a74283687f90d6a922a
--- /dev/null
+++ b/flask_benevolence.py
@@ -0,0 +1,167 @@
+"""Explore and gently transform Flask API snippets into benevolent patterns.
+
+This utility scans repository files for Flask-style API routes and emits:
+1) A discovery report (what was found).
+2) A softened transformation suggestion that promotes:
+   - compassionate error messages
+   - consistent JSON envelopes
+   - reduced exception leakage
+   - explicit health and kindness framing
+
+It does not overwrite source files by default; it produces an interpretive,
+review-friendly output.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from pathlib import Path
+import re
+from typing import Iterable, List
+
+
+ROUTE_PATTERN = re.compile(r"@(?:app|[a-zA-Z_][a-zA-Z0-9_]*)\.route\((.*?)\)")
+FLASK_IMPORT_PATTERN = re.compile(r"\bfrom\s+flask\s+import\b|\bimport\s+flask\b")
+ABORT_PATTERN = re.compile(r"\babort\((\d{3})")
+
+
+@dataclass(frozen=True)
+class FlaskArtifact:
+    path: str
+    route_count: int
+    has_flask_import: bool
+    abort_statuses: List[int]
+
+
+@dataclass(frozen=True)
+class BenevolenceReport:
+    scanned_files: int
+    artifacts: List[FlaskArtifact]
+
+    @property
+    def total_routes(self) -> int:
+        return sum(a.route_count for a in self.artifacts)
+
+    @property
+    def total_abort_calls(self) -> int:
+        return sum(len(a.abort_statuses) for a in self.artifacts)
+
+    def kindness_index(self) -> float:
+        if not self.artifacts:
+            return 1.0
+        friction = self.total_abort_calls * 0.07
+        density = min(self.total_routes / 100.0, 0.35)
+        return max(0.0, min(1.0, 1.0 - friction + density))
+
+
+class FlaskBenevolenceExplorer:
+    """Search for Flask APIs and create softened transformation guidance."""
+
+    def __init__(self, root: Path):
+        self.root = root
+
+    def _candidate_files(self) -> Iterable[Path]:
+        for pattern in ("*.py", "*.md"):
+            yield from self.root.rglob(pattern)
+
+    def explore(self) -> BenevolenceReport:
+        artifacts: List[FlaskArtifact] = []
+        scanned = 0
+
+        for file_path in self._candidate_files():
+            if file_path.name == "flask_benevolence.py":
+                continue
+            scanned += 1
+            text = file_path.read_text(errors="ignore")
+            has_flask = bool(FLASK_IMPORT_PATTERN.search(text))
+            routes = ROUTE_PATTERN.findall(text)
+            aborts = [int(x) for x in ABORT_PATTERN.findall(text)]
+
+            if has_flask or routes:
+                artifacts.append(
+                    FlaskArtifact(
+                        path=str(file_path.relative_to(self.root)),
+                        route_count=len(routes),
+                        has_flask_import=has_flask,
+                        abort_statuses=aborts,
+                    )
+                )
+
+        return BenevolenceReport(scanned_files=scanned, artifacts=artifacts)
+
+    @staticmethod
+    def benevolent_flask_template() -> str:
+        return '''from flask import Flask, jsonify, request
+
+app = Flask(__name__)
+
+
+def gentle_response(message: str, data=None, status: int = 200):
+    payload = {
+        "message": message,
+        "status": "kind",
+        "data": data or {},
+        "guidance": "If this response is unclear, the service will help you recover safely."
+    }
+    return jsonify(payload), status
+
+
+@app.errorhandler(Exception)
+def handle_unexpected_error(_err):
+    # Avoid leaking internals while staying humane.
+    return gentle_response(
+        "Something went wrong, but your request is safe with us. Please try again.",
+        status=500,
+    )
+
+
+@app.route("/health", methods=["GET"])
+def health():
+    return gentle_response("Service is calm, available, and ready to help.", {"ok": True})
+
+
+@app.route("/reflect", methods=["POST"])
+def reflect():
+    body = request.get_json(silent=True) or {}
+    subject = body.get("subject", "the world")
+    return gentle_response(
+        f"We received your request about {subject} and will answer with care.",
+        {"subject": subject},
+        status=200,
+    )
+
+
+if __name__ == "__main__":
+    app.run(host="0.0.0.0", port=5000, debug=False)
+'''
+
+
+def run_ephemeral_benevolence(root: str = ".") -> BenevolenceReport:
+    explorer = FlaskBenevolenceExplorer(Path(root))
+    report = explorer.explore()
+
+    print("ðŸŒŠ Flask API Benevolence Exploration")
+    print("-" * 44)
+    print(f"Scanned files: {report.scanned_files}")
+    print(f"Flask artifacts found: {len(report.artifacts)}")
+    print(f"Route decorators found: {report.total_routes}")
+    print(f"Direct abort() calls found: {report.total_abort_calls}")
+    print(f"Ephemeral Kindness Index: {report.kindness_index():.2f}")
+
+    if report.artifacts:
+        print("\nArtifacts:")
+        for artifact in report.artifacts[:10]:
+            print(
+                f"  - {artifact.path} | routes={artifact.route_count} | "
+                f"abort_calls={len(artifact.abort_statuses)}"
+            )
+    else:
+        print("\nNo concrete Flask API artifacts detected in scanned source files.")
+
+    print("\nSuggested Benevolent Flask Template:\n")
+    print(FlaskBenevolenceExplorer.benevolent_flask_template())
+    return report
+
+
+if __name__ == "__main__":
+    run_ephemeral_benevolence(".")
diff --git a/oceanic_tides.py b/oceanic_tides.py
new file mode 100644
index 0000000000000000000000000000000000000000..fae24c34b93db4ee78608860a34152afb1230ed3
--- /dev/null
+++ b/oceanic_tides.py
@@ -0,0 +1,133 @@
+"""Oceanic tide dynamics with harmonic synthesis and celestial context.
+
+This module models tides as a conversation between gravitational mechanics,
+coastal geometry, and time. It is intentionally both scientific and reflective:
+we compute useful predictions while surfacing the deeper rhythms that produce
+spring and neap cycles.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from math import cos, pi
+from statistics import mean
+from typing import Iterable, List
+
+
+@dataclass(frozen=True)
+class TideConstituent:
+    """A harmonic building block of observed sea-level variation.
+
+    Attributes:
+        name: Standard constituent symbol (e.g. M2, S2, K1).
+        amplitude_m: Amplitude contribution in meters.
+        period_hours: Oscillation period in hours.
+        phase_radians: Phase lag in radians.
+    """
+
+    name: str
+    amplitude_m: float
+    period_hours: float
+    phase_radians: float = 0.0
+
+    def height_contribution(self, hours_since_epoch: float) -> float:
+        """Return vertical sea-level contribution in meters at a given time."""
+        angle = 2.0 * pi * (hours_since_epoch / self.period_hours) + self.phase_radians
+        return self.amplitude_m * cos(angle)
+
+
+@dataclass(frozen=True)
+class TideMoment:
+    """A single modeled tide moment."""
+
+    hour: float
+    height_m: float
+
+
+class OceanicTideModel:
+    """Harmonic tide model with lightweight interpretation helpers."""
+
+    def __init__(self, constituents: Iterable[TideConstituent], datum_offset_m: float = 0.0):
+        self.constituents = list(constituents)
+        self.datum_offset_m = datum_offset_m
+
+    def tide_height(self, hour: float) -> float:
+        """Compute total sea level (meters relative to datum) at the given hour."""
+        return self.datum_offset_m + sum(c.height_contribution(hour) for c in self.constituents)
+
+    def generate_series(self, duration_hours: float, step_hours: float = 0.5) -> List[TideMoment]:
+        """Generate modeled tide moments over a time window."""
+        if step_hours <= 0:
+            raise ValueError("step_hours must be positive")
+
+        moments: List[TideMoment] = []
+        t = 0.0
+        while t <= duration_hours + 1e-9:
+            moments.append(TideMoment(hour=t, height_m=self.tide_height(t)))
+            t += step_hours
+        return moments
+
+    def detect_turning_points(self, series: List[TideMoment]) -> List[TideMoment]:
+        """Approximate high and low tides by local extrema in a sampled series."""
+        if len(series) < 3:
+            return []
+
+        turning_points: List[TideMoment] = []
+        for i in range(1, len(series) - 1):
+            previous, current, nxt = series[i - 1], series[i], series[i + 1]
+            rising_then_falling = previous.height_m < current.height_m > nxt.height_m
+            falling_then_rising = previous.height_m > current.height_m < nxt.height_m
+            if rising_then_falling or falling_then_rising:
+                turning_points.append(current)
+        return turning_points
+
+    def spring_neap_contrast(self, hours: float = 28 * 24, step_hours: float = 1.0) -> float:
+        """Measure range contrast over about one lunar cycle.
+
+        Higher values imply stronger spring-neap modulation.
+        """
+        series = self.generate_series(duration_hours=hours, step_hours=step_hours)
+        heights = [m.height_m for m in series]
+        return max(heights) - min(heights)
+
+    def profound_reading(self, turning_points: List[TideMoment]) -> str:
+        """Return an interpretation of model output in concise poetic prose."""
+        if not turning_points:
+            return "No turning points detected. Increase duration or reduce step size."
+
+        amplitudes = [abs(p.height_m) for p in turning_points]
+        avg_extremum = mean(amplitudes)
+        return (
+            "The shoreline is not a boundary but a pulse. "
+            f"Across {len(turning_points)} turning points, the mean extremal magnitude "
+            f"is {avg_extremum:.3f} m. "
+            "Each high tide is celestial insistence; each low tide, geological memory."
+        )
+
+
+def create_open_ocean_reference_model() -> OceanicTideModel:
+    """Return a reference model using major global constituents.
+
+    Values are representative and simplified for educational simulations.
+    """
+    constituents = [
+        TideConstituent("M2", amplitude_m=0.92, period_hours=12.4206, phase_radians=0.2),
+        TideConstituent("S2", amplitude_m=0.44, period_hours=12.0, phase_radians=1.1),
+        TideConstituent("N2", amplitude_m=0.20, period_hours=12.6583, phase_radians=0.5),
+        TideConstituent("K1", amplitude_m=0.30, period_hours=23.9345, phase_radians=1.7),
+        TideConstituent("O1", amplitude_m=0.21, period_hours=25.8193, phase_radians=0.9),
+    ]
+    return OceanicTideModel(constituents=constituents, datum_offset_m=0.0)
+
+
+if __name__ == "__main__":
+    model = create_open_ocean_reference_model()
+    series = model.generate_series(duration_hours=72, step_hours=0.5)
+    turning_points = model.detect_turning_points(series)
+
+    print("Oceanic Tide Harmonic Synthesis")
+    print("-" * 40)
+    print(f"Simulated points: {len(series)}")
+    print(f"Detected highs/lows: {len(turning_points)}")
+    print(f"Spring-neap contrast estimate: {model.spring_neap_contrast():.2f} m")
+    print(model.profound_reading(turning_points))
diff --git a/flaskapi_benevolence.py b/flaskapi_benevolence.py
new file mode 100644
index 0000000000000000000000000000000000000000..ed61130c238c6620300f473ec3ee1e1af0a99338
--- /dev/null
+++ b/flaskapi_benevolence.py
@@ -0,0 +1,137 @@
+"""Ephemeral benevolence pass for Flask-style API code.
+
+The goal is to *explore* API surface area and *dilute* hard-edged language into
+constructive, humane phrasing while preserving technical meaning.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+import re
+from typing import Iterable, List
+
+
+ROUTE_RE = re.compile(
+    r"@app\.route\(\s*['\"](?P<path>[^'\"]+)['\"](?:\s*,\s*methods\s*=\s*\[(?P<methods>[^\]]+)\])?"
+)
+
+
+@dataclass(frozen=True)
+class EndpointReading:
+    """Describes one discovered Flask endpoint and its benevolence-adjusted form."""
+
+    path: str
+    methods: tuple[str, ...]
+    original_handler_name: str | None
+    benevolent_handler_name: str | None
+
+
+class FlaskBenevolenceEngine:
+    """Extract route signatures and soften naming/phrasing into constructive language."""
+
+    def __init__(self, source_text: str):
+        self.source_text = source_text
+
+    @staticmethod
+    def _normalize_methods(raw_methods: str | None) -> tuple[str, ...]:
+        if not raw_methods:
+            return ("GET",)
+        methods = [m.strip().strip("'\"") for m in raw_methods.split(",") if m.strip()]
+        return tuple(m.upper() for m in methods) if methods else ("GET",)
+
+    @staticmethod
+    def _soften_phrase(text: str) -> str:
+        replacements = {
+            'delete': 'release',
+            'remove': 'gently_remove',
+            'block': 'protect',
+            'deny': 'guide_away',
+            'kill': 'gracefully_stop',
+            'error': 'guidance',
+            'failed': 'recoverable_state',
+            'failure': 'recoverable_state',
+            'fail': 'recoverable_state',
+            'ban': 'cooldown',
+        }
+        softened = text
+        for harsh, gentle in replacements.items():
+            softened = re.sub(
+                rf"(?i)(?<![a-z0-9]){harsh}(?![a-z0-9])",
+                gentle,
+                softened,
+            )
+        return softened
+
+    def discover_endpoints(self) -> List[EndpointReading]:
+        lines = self.source_text.splitlines()
+        findings: List[EndpointReading] = []
+
+        for idx, line in enumerate(lines):
+            m = ROUTE_RE.search(line)
+            if not m:
+                continue
+
+            path = m.group("path")
+            methods = self._normalize_methods(m.group("methods"))
+
+            handler_name = None
+            for look_ahead in range(idx + 1, min(idx + 6, len(lines))):
+                stripped = lines[look_ahead].strip()
+                if stripped.startswith("def ") and "(" in stripped:
+                    handler_name = stripped[4:stripped.index("(")]
+                    break
+
+            findings.append(
+                EndpointReading(
+                    path=path,
+                    methods=methods,
+                    original_handler_name=handler_name,
+                    benevolent_handler_name=self._soften_phrase(handler_name or "kind_handler"),
+                )
+            )
+
+        return findings
+
+    def create_ephemeral_manifesto(self, endpoints: Iterable[EndpointReading]) -> str:
+        endpoints = list(endpoints)
+        if not endpoints:
+            return (
+                "No Flask routes were detected. The system remains an open sea of potential, "
+                "awaiting kind interfaces."
+            )
+
+        lines = [
+            "Ephemeral Benevolence Manifesto for Flask API",
+            "-" * 48,
+        ]
+        for ep in endpoints:
+            methods = "/".join(ep.methods)
+            lines.append(
+                f"{methods:12s} {ep.path:24s} "
+                f"{(ep.original_handler_name or 'unknown')} -> {ep.benevolent_handler_name}"
+            )
+
+        lines.append(
+            "\nPrinciple: endpoints should not punish users; they should reroute confusion "
+            "toward clarity, safety, and restoration."
+        )
+        return "\n".join(lines)
+
+
+if __name__ == "__main__":
+    demo_flask_api = '''
+from flask import Flask, jsonify
+app = Flask(__name__)
+
+@app.route('/api/block-user', methods=['POST'])
+def block_user():
+    return jsonify({'status': 'blocked'})
+
+@app.route('/api/delete-session', methods=['DELETE'])
+def delete_session():
+    return jsonify({'status': 'deleted'})
+'''
+
+    engine = FlaskBenevolenceEngine(demo_flask_api)
+    endpoints = engine.discover_endpoints()
+    print(engine.create_ephemeral_manifesto(endpoints))
diff --git a/oceanic_tides.py b/oceanic_tides.py
new file mode 100644
index 0000000000000000000000000000000000000000..fae24c34b93db4ee78608860a34152afb1230ed3
--- /dev/null
+++ b/oceanic_tides.py
@@ -0,0 +1,133 @@
+"""Oceanic tide dynamics with harmonic synthesis and celestial context.
+
+This module models tides as a conversation between gravitational mechanics,
+coastal geometry, and time. It is intentionally both scientific and reflective:
+we compute useful predictions while surfacing the deeper rhythms that produce
+spring and neap cycles.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from math import cos, pi
+from statistics import mean
+from typing import Iterable, List
+
+
+@dataclass(frozen=True)
+class TideConstituent:
+    """A harmonic building block of observed sea-level variation.
+
+    Attributes:
+        name: Standard constituent symbol (e.g. M2, S2, K1).
+        amplitude_m: Amplitude contribution in meters.
+        period_hours: Oscillation period in hours.
+        phase_radians: Phase lag in radians.
+    """
+
+    name: str
+    amplitude_m: float
+    period_hours: float
+    phase_radians: float = 0.0
+
+    def height_contribution(self, hours_since_epoch: float) -> float:
+        """Return vertical sea-level contribution in meters at a given time."""
+        angle = 2.0 * pi * (hours_since_epoch / self.period_hours) + self.phase_radians
+        return self.amplitude_m * cos(angle)
+
+
+@dataclass(frozen=True)
+class TideMoment:
+    """A single modeled tide moment."""
+
+    hour: float
+    height_m: float
+
+
+class OceanicTideModel:
+    """Harmonic tide model with lightweight interpretation helpers."""
+
+    def __init__(self, constituents: Iterable[TideConstituent], datum_offset_m: float = 0.0):
+        self.constituents = list(constituents)
+        self.datum_offset_m = datum_offset_m
+
+    def tide_height(self, hour: float) -> float:
+        """Compute total sea level (meters relative to datum) at the given hour."""
+        return self.datum_offset_m + sum(c.height_contribution(hour) for c in self.constituents)
+
+    def generate_series(self, duration_hours: float, step_hours: float = 0.5) -> List[TideMoment]:
+        """Generate modeled tide moments over a time window."""
+        if step_hours <= 0:
+            raise ValueError("step_hours must be positive")
+
+        moments: List[TideMoment] = []
+        t = 0.0
+        while t <= duration_hours + 1e-9:
+            moments.append(TideMoment(hour=t, height_m=self.tide_height(t)))
+            t += step_hours
+        return moments
+
+    def detect_turning_points(self, series: List[TideMoment]) -> List[TideMoment]:
+        """Approximate high and low tides by local extrema in a sampled series."""
+        if len(series) < 3:
+            return []
+
+        turning_points: List[TideMoment] = []
+        for i in range(1, len(series) - 1):
+            previous, current, nxt = series[i - 1], series[i], series[i + 1]
+            rising_then_falling = previous.height_m < current.height_m > nxt.height_m
+            falling_then_rising = previous.height_m > current.height_m < nxt.height_m
+            if rising_then_falling or falling_then_rising:
+                turning_points.append(current)
+        return turning_points
+
+    def spring_neap_contrast(self, hours: float = 28 * 24, step_hours: float = 1.0) -> float:
+        """Measure range contrast over about one lunar cycle.
+
+        Higher values imply stronger spring-neap modulation.
+        """
+        series = self.generate_series(duration_hours=hours, step_hours=step_hours)
+        heights = [m.height_m for m in series]
+        return max(heights) - min(heights)
+
+    def profound_reading(self, turning_points: List[TideMoment]) -> str:
+        """Return an interpretation of model output in concise poetic prose."""
+        if not turning_points:
+            return "No turning points detected. Increase duration or reduce step size."
+
+        amplitudes = [abs(p.height_m) for p in turning_points]
+        avg_extremum = mean(amplitudes)
+        return (
+            "The shoreline is not a boundary but a pulse. "
+            f"Across {len(turning_points)} turning points, the mean extremal magnitude "
+            f"is {avg_extremum:.3f} m. "
+            "Each high tide is celestial insistence; each low tide, geological memory."
+        )
+
+
+def create_open_ocean_reference_model() -> OceanicTideModel:
+    """Return a reference model using major global constituents.
+
+    Values are representative and simplified for educational simulations.
+    """
+    constituents = [
+        TideConstituent("M2", amplitude_m=0.92, period_hours=12.4206, phase_radians=0.2),
+        TideConstituent("S2", amplitude_m=0.44, period_hours=12.0, phase_radians=1.1),
+        TideConstituent("N2", amplitude_m=0.20, period_hours=12.6583, phase_radians=0.5),
+        TideConstituent("K1", amplitude_m=0.30, period_hours=23.9345, phase_radians=1.7),
+        TideConstituent("O1", amplitude_m=0.21, period_hours=25.8193, phase_radians=0.9),
+    ]
+    return OceanicTideModel(constituents=constituents, datum_offset_m=0.0)
+
+
+if __name__ == "__main__":
+    model = create_open_ocean_reference_model()
+    series = model.generate_series(duration_hours=72, step_hours=0.5)
+    turning_points = model.detect_turning_points(series)
+
+    print("Oceanic Tide Harmonic Synthesis")
+    print("-" * 40)
+    print(f"Simulated points: {len(series)}")
+    print(f"Detected highs/lows: {len(turning_points)}")
+    print(f"Spring-neap contrast estimate: {model.spring_neap_contrast():.2f} m")
+    print(model.profound_reading(turning_points))
diff --git a/oceanic_tides.py b/oceanic_tides.py
new file mode 100644
index 0000000000000000000000000000000000000000..fae24c34b93db4ee78608860a34152afb1230ed3
--- /dev/null
+++ b/oceanic_tides.py
@@ -0,0 +1,133 @@
+"""Oceanic tide dynamics with harmonic synthesis and celestial context.
+
+This module models tides as a conversation between gravitational mechanics,
+coastal geometry, and time. It is intentionally both scientific and reflective:
+we compute useful predictions while surfacing the deeper rhythms that produce
+spring and neap cycles.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass
+from math import cos, pi
+from statistics import mean
+from typing import Iterable, List
+
+
+@dataclass(frozen=True)
+class TideConstituent:
+    """A harmonic building block of observed sea-level variation.
+
+    Attributes:
+        name: Standard constituent symbol (e.g. M2, S2, K1).
+        amplitude_m: Amplitude contribution in meters.
+        period_hours: Oscillation period in hours.
+        phase_radians: Phase lag in radians.
+    """
+
+    name: str
+    amplitude_m: float
+    period_hours: float
+    phase_radians: float = 0.0
+
+    def height_contribution(self, hours_since_epoch: float) -> float:
+        """Return vertical sea-level contribution in meters at a given time."""
+        angle = 2.0 * pi * (hours_since_epoch / self.period_hours) + self.phase_radians
+        return self.amplitude_m * cos(angle)
+
+
+@dataclass(frozen=True)
+class TideMoment:
+    """A single modeled tide moment."""
+
+    hour: float
+    height_m: float
+
+
+class OceanicTideModel:
+    """Harmonic tide model with lightweight interpretation helpers."""
+
+    def __init__(self, constituents: Iterable[TideConstituent], datum_offset_m: float = 0.0):
+        self.constituents = list(constituents)
+        self.datum_offset_m = datum_offset_m
+
+    def tide_height(self, hour: float) -> float:
+        """Compute total sea level (meters relative to datum) at the given hour."""
+        return self.datum_offset_m + sum(c.height_contribution(hour) for c in self.constituents)
+
+    def generate_series(self, duration_hours: float, step_hours: float = 0.5) -> List[TideMoment]:
+        """Generate modeled tide moments over a time window."""
+        if step_hours <= 0:
+            raise ValueError("step_hours must be positive")
+
+        moments: List[TideMoment] = []
+        t = 0.0
+        while t <= duration_hours + 1e-9:
+            moments.append(TideMoment(hour=t, height_m=self.tide_height(t)))
+            t += step_hours
+        return moments
+
+    def detect_turning_points(self, series: List[TideMoment]) -> List[TideMoment]:
+        """Approximate high and low tides by local extrema in a sampled series."""
+        if len(series) < 3:
+            return []
+
+        turning_points: List[TideMoment] = []
+        for i in range(1, len(series) - 1):
+            previous, current, nxt = series[i - 1], series[i], series[i + 1]
+            rising_then_falling = previous.height_m < current.height_m > nxt.height_m
+            falling_then_rising = previous.height_m > current.height_m < nxt.height_m
+            if rising_then_falling or falling_then_rising:
+                turning_points.append(current)
+        return turning_points
+
+    def spring_neap_contrast(self, hours: float = 28 * 24, step_hours: float = 1.0) -> float:
+        """Measure range contrast over about one lunar cycle.
+
+        Higher values imply stronger spring-neap modulation.
+        """
+        series = self.generate_series(duration_hours=hours, step_hours=step_hours)
+        heights = [m.height_m for m in series]
+        return max(heights) - min(heights)
+
+    def profound_reading(self, turning_points: List[TideMoment]) -> str:
+        """Return an interpretation of model output in concise poetic prose."""
+        if not turning_points:
+            return "No turning points detected. Increase duration or reduce step size."
+
+        amplitudes = [abs(p.height_m) for p in turning_points]
+        avg_extremum = mean(amplitudes)
+        return (
+            "The shoreline is not a boundary but a pulse. "
+            f"Across {len(turning_points)} turning points, the mean extremal magnitude "
+            f"is {avg_extremum:.3f} m. "
+            "Each high tide is celestial insistence; each low tide, geological memory."
+        )
+
+
+def create_open_ocean_reference_model() -> OceanicTideModel:
+    """Return a reference model using major global constituents.
+
+    Values are representative and simplified for educational simulations.
+    """
+    constituents = [
+        TideConstituent("M2", amplitude_m=0.92, period_hours=12.4206, phase_radians=0.2),
+        TideConstituent("S2", amplitude_m=0.44, period_hours=12.0, phase_radians=1.1),
+        TideConstituent("N2", amplitude_m=0.20, period_hours=12.6583, phase_radians=0.5),
+        TideConstituent("K1", amplitude_m=0.30, period_hours=23.9345, phase_radians=1.7),
+        TideConstituent("O1", amplitude_m=0.21, period_hours=25.8193, phase_radians=0.9),
+    ]
+    return OceanicTideModel(constituents=constituents, datum_offset_m=0.0)
+
+
+if __name__ == "__main__":
+    model = create_open_ocean_reference_model()
+    series = model.generate_series(duration_hours=72, step_hours=0.5)
+    turning_points = model.detect_turning_points(series)
+
+    print("Oceanic Tide Harmonic Synthesis")
+    print("-" * 40)
+    print(f"Simulated points: {len(series)}")
+    print(f"Detected highs/lows: {len(turning_points)}")
+    print(f"Spring-neap contrast estimate: {model.spring_neap_contrast():.2f} m")
+    print(model.profound_reading(turning_points))
[project]
name = "pyramid-prosper"
version = "0.1.0"
requires-python = ">=3.10"
dependencies = [
  "pyramid>=2.0",
  "waitress>=2.1",
  "python-dotenv>=1.0",
  "requests>=2.31",
  "opentelemetry-api>=1.24.0",
  "opentelemetry-sdk>=1.24.0",
  "opentelemetry-exporter-otlp>=1.24.0",
  "opentelemetry-instrumentation-wsgi>=0.45b0",
import json
import os
import time
import uuid
from dataclasses import dataclass
from typing import Any, Dict, Optional

from dotenv import load_dotenv
from pyramid.config import Configurator
from pyramid.response import Response
from pyramid.view import view_config
from waitress import serve

# Optional OpenTelemetry (safe if deps installed)
OTEL_ENABLED = os.getenv("OTEL_ENABLED", "false").lower() == "true"
if OTEL_ENABLED:
    from opentelemetry import trace
    from opentelemetry.sdk.resources import Resource
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.trace.export import BatchSpanProcessor
    from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
    from opentelemetry.instrumentation.wsgi import OpenTelemetryMiddleware

load_dotenv()

@dataclass(frozen=True)
class Settings:
    env: str
    host: str
    port: int
    json_logs: bool
    request_timeout_seconds: int

def get_settings() -> Settings:
    return Settings(
        env=os.getenv("APP_ENV", "dev"),
        host=os.getenv("APP_HOST", "127.0.0.1"),
        port=int(os.getenv("APP_PORT", "6543")),
        json_logs=os.getenv("JSON_LOGS", "true").lower() == "true",
        request_timeout_seconds=int(os.getenv("REQUEST_TIMEOUT_SECONDS", "30")),
    )

def now_ms() -> int:
    return int(time.time() * 1000)

def log_event(event: str, **fields: Any) -> None:
    # Structured logging for easier operations at scale
    payload = {"ts": now_ms(), "event": event, **fields}
    print(json.dumps(payload, ensure_ascii=False))

def setup_otel(service_name: str = "pyramid-prosper") -> None:
    if not OTEL_ENABLED:
        return
    resource = Resource.create({"service.name": service_name})
    provider = TracerProvider(resource=resource)
    exporter = OTLPSpanExporter(endpoint=os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT"))
    provider.add_span_processor(BatchSpanProcessor(exporter))
    trace.set_tracer_provider(provider)

def security_headers_factory(handler):
    """
    Adds strong security headers to every response.
    """
    def _wrapped(request):
        resp = handler(request)
        # Basic hardening headers (adjust CSP to your app)
        resp.headers.setdefault("X-Content-Type-Options", "nosniff")
        resp.headers.setdefault("X-Frame-Options", "DENY")
        resp.headers.setdefault("Referrer-Policy", "no-referrer")
        resp.headers.setdefault("Permissions-Policy", "geolocation=(), microphone=(), camera=()")
        resp.headers.setdefault("Content-Security-Policy", "default-src 'none'; frame-ancestors 'none'; base-uri 'none'")
        resp.headers.setdefault("Strict-Transport-Security", "max-age=63072000; includeSubDomains; preload")
        return resp
    return _wrapped

def request_context_tween_factory(handler, registry):
    """
    Adds:
    - request_id correlation
    - timing
    - error-safe logging
    """
    def _tween(request):
        request_id = request.headers.get("X-Request-ID") or str(uuid.uuid4())
        request.request_id = request_id  # attach
        start = time.time()

        try:
            resp = handler(request)
            duration_ms = int((time.time() - start) * 1000)
            resp.headers["X-Request-ID"] = request_id

            log_event(
                "http_request",
                request_id=request_id,
                method=request.method,
                path=request.path_qs,
                status=getattr(resp, "status_code", None),
                duration_ms=duration_ms,
                remote_addr=request.remote_addr,
            )
            return resp

        except Exception as exc:
            duration_ms = int((time.time() - start) * 1000)
            log_event(
                "http_error",
                request_id=request_id,
                method=request.method,
                path=request.path_qs,
                duration_ms=duration_ms,
                error_type=type(exc).__name__,
                error=str(exc),
            )
            # Don't leak internal errors to clients
            resp = Response(
                json_body={"error": "internal_error", "request_id": request_id},
                status=500,
                content_type="application/json",
            )
            resp.headers["X-Request-ID"] = request_id
            return resp

    return _tween

@view_config(route_name="health", renderer="json", request_method="GET")
def health_view(request):
    return {"ok": True, "service": "pyramid-prosper", "request_id": getattr(request, "request_id", None)}

@view_config(route_name="hello", renderer="json", request_method="GET")
def hello_view(request):
    name = request.params.get("name", "world")
    return {"message": f"hello, {name}", "request_id": getattr(request, "request_id", None)}

def make_wsgi_app():
    settings = get_settings()
    setup_otel()

    with Configurator(settings={}) as config:
        config.add_route("health", "/health")
        config.add_route("hello", "/hello")

        config.add_tween("app.request_context_tween_factory", over=None)

        # Default views
        config.scan()

        app = config.make_wsgi_app()

    # Add security headers wrapper
    app = security_headers_factory(app)

    # Add OpenTelemetry middleware (if enabled)
    if OTEL_ENABLED:
        app = OpenTelemetryMiddleware(app)

    log_event("startup", env=settings.env, host=settings.host, port=settings.port, otel=OTEL_ENABLED)
    return app, settings

def main():
    app, settings = make_wsgi_app()
    serve(app, host=settings.host, port=settings.port, threads=8)

if __name__ == "__main__":
    main()
pip install -e .
python app.py
set OTEL_ENABLED=true
set OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318/v1/traces
python app.py
set OTEL_ENABLED=true
set OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318/v1/traces
python app.py
<#
EphemeralClean.ps1
Ephemeral cleanup: temp + caches + optional browser cache cleanup.
SAFE BY DEFAULT:
- Dry-run unless -Execute is provided
- Backs up nothing (because we only target cache/temp), but logs everything
- Does NOT delete Documents/Desktop/Projects
- Browser cleanup targets cache folders only (not Login Data / cookies DB by default)

Usage:
  .\EphemeralClean.ps1
  .\EphemeralClean.ps1 -Execute -ClearBrowserCaches
  .\EphemeralClean.ps1 -Execute -ClearBrowserCaches -ClearRecycleBin -ClearThumbCache -FlushDns
#>

param(
  [switch]$Execute,
  [switch]$FlushDns,
  [switch]$ClearRecycleBin,
  [switch]$ClearThumbCache,
  [switch]$ClearWindowsUpdateCache,
  [switch]$ClearBrowserCaches
)

$ErrorActionPreference = "Stop"

function Step($msg) { Write-Host "`n=== $msg ===" -ForegroundColor Cyan }

$ts = Get-Date -Format "yyyyMMdd-HHmmss"
$logDir = Join-Path $env:USERPROFILE "ephemeral-clean-logs"
New-Item -ItemType Directory -Force -Path $logDir | Out-Null
$logPath = Join-Path $logDir "clean-$ts.log"

function Log($msg) {
  $line = "[{0}] {1}" -f (Get-Date -Format "s"), $msg
  Add-Content -Path $logPath -Value $line
}

function Remove-ContentsSafe {
  param([Parameter(Mandatory=$true)][string]$Path)

  if (-not (Test-Path $Path)) {
    Log "SKIP (missing): $Path"
    return
  }

  if (-not $Execute) {
    Log "DRY-RUN would clear: $Path"
    return
  }

  try {
    Get-ChildItem -LiteralPath $Path -Force -ErrorAction SilentlyContinue |
      Remove-Item -Recurse -Force -ErrorAction SilentlyContinue
    Log "CLEARED: $Path"
  } catch {
    Log "ERROR clearing $Path :: $($_.Exception.Message)"
  }
}

function Remove-FilesMatching {
  param(
    [Parameter(Mandatory=$true)][string]$Folder,
    [Parameter(Mandatory=$true)][string]$Pattern
  )

  if (-not (Test-Path $Folder)) {
    Log "SKIP (missing): $Folder"
    return
  }

  if (-not $Execute) {
    Log "DRY-RUN would delete '$Pattern' in: $Folder"
    return
  }

  try {
    Get-ChildItem -LiteralPath $Folder -Filter $Pattern -Force -ErrorAction SilentlyContinue |
      Remove-Item -Force -ErrorAction SilentlyContinue
    Log "CLEARED files matching '$Pattern' in: $Folder"
  } catch {
    Log "ERROR deleting '$Pattern' in $Folder :: $($_.Exception.Message)"
  }
}

Step "Mode"
if ($Execute) {
  Write-Host "EXECUTE (will delete temp/cache files)" -ForegroundColor Red
  Log "Mode=EXECUTE"
} else {
  Write-Host "DRY-RUN (no changes)" -ForegroundColor Green
  Log "Mode=DRY-RUN"
}

Step "1) Close apps that commonly lock caches (best effort)"
@("Code","pycharm64","pycharm","spyder","chrome","msedge","firefox","Teams") | ForEach-Object {
  Get-Process $_ -ErrorAction SilentlyContinue | Stop-Process -Force -ErrorAction SilentlyContinue
}
Log "Attempted to close common apps (best-effort)."

Step "2) Clear user + system temp folders"
Remove-ContentsSafe -Path $env:TEMP
Remove-ContentsSafe -Path (Join-Path $env:WINDIR "Temp")

Step "3) Clear Windows error reporting & crash dumps"
Remove-ContentsSafe -Path (Join-Path $env:PROGRAMDATA "Microsoft\Windows\WER")
Remove-ContentsSafe -Path (Join-Path $env:LOCALAPPDATA "CrashDumps")

Step "4) Clear recent items (ephemeral UX clutter only)"
Remove-ContentsSafe -Path (Join-Path $env:APPDATA "Microsoft\Windows\Recent")

Step "5) Optional: Clear Recycle Bin"
if ($ClearRecycleBin) {
  if (-not $Execute) {
    Log "DRY-RUN would clear Recycle Bin"
  } else {
    try {
      Clear-RecycleBin -Force -ErrorAction SilentlyContinue | Out-Null
      Log "CLEARED: Recycle Bin"
    } catch {
      Log "ERROR clearing Recycle Bin :: $($_.Exception.Message)"
    }
  }
} else {
  Log "SKIP: Recycle Bin (not requested)"
}

Step "6) Optional: Clear thumbnail cache"
if ($ClearThumbCache) {
  $explorerDir = Join-Path $env:LOCALAPPDATA "Microsoft\Windows\Explorer"
  if (Test-Path $explorerDir) {
    if (-not $Execute) {
      Log "DRY-RUN would delete thumbcache_*.db in: $explorerDir"
    } else {
      Get-ChildItem $explorerDir -Filter "thumbcache_*.db" -Force -ErrorAction SilentlyContinue |
        Remove-Item -Force -ErrorAction SilentlyContinue
      Log "CLEARED: thumbcache db files in $explorerDir"
    }
  } else {
    Log "SKIP (missing): $explorerDir"
  }
} else {
  Log "SKIP: Thumbnail cache (not requested)"
}

Step "7) Optional: Flush DNS cache"
if ($FlushDns) {
  if (-not $Execute) {
    Log "DRY-RUN would flush DNS cache"
  } else {
    try { ipconfig /flushdns | Out-Null; Log "DONE: DNS cache flushed" } catch { Log "ERROR flushing DNS :: $($_.Exception.Message)" }
  }
} else {
  Log "SKIP: DNS flush (not requested)"
}

Step "8) Optional: Clear Windows Update download cache (advanced)"
if ($ClearWindowsUpdateCache) {
  if (-not $Execute) {
    Log "DRY-RUN would clear Windows Update cache"
  } else {
    try {
      Stop-Service wuauserv -Force -ErrorAction SilentlyContinue
      Stop-Service bits -Force -ErrorAction SilentlyContinue

      Remove-ContentsSafe -Path (Join-Path $env:WINDIR "SoftwareDistribution\Download")

      Start-Service bits -ErrorAction SilentlyContinue
      Start-Service wuauserv -ErrorAction SilentlyContinue

      Log "DONE: Windows Update cache cleared"
    } catch {
      Log "ERROR clearing Windows Update cache :: $($_.Exception.Message)"
    }
  }
} else {
  Log "SKIP: Windows Update cache (not requested)"
}

Step "9) Optional: Clear browser caches (Edge, Chrome, Firefox)"
if ($ClearBrowserCaches) {
  # Chromium caches: remove cache folders only (not Login Data)
  $chromeBase = Join-Path $env:LOCALAPPDATA "Google\Chrome\User Data"
  $edgeBase   = Join-Path $env:LOCALAPPDATA "Microsoft\Edge\User Data"

  $chromiumCacheFolders = @(
    "Cache",
    "Code Cache",
    "GPUCache",
    "Service Worker\CacheStorage",
    "Service Worker\ScriptCache"
  )

  function Clear-ChromiumProfileCaches($basePath, $browserName) {
    if (-not (Test-Path $basePath)) { Log "SKIP: $browserName base not found: $basePath"; return }
    $profiles = Get-ChildItem -LiteralPath $basePath -Directory -ErrorAction SilentlyContinue |
      Where-Object { $_.Name -match '^(Default|Profile \d+)$' }

    foreach ($p in $profiles) {
      foreach ($rel in $chromiumCacheFolders) {
        $target = Join-Path $p.FullName $rel
        Remove-ContentsSafe -Path $target
      }
    }
    Log "DONE: Cleared $browserName caches for $($profiles.Count) profile(s)."
  }

  Clear-ChromiumProfileCaches -basePath $chromeBase -browserName "Chrome"
  Clear-ChromiumProfileCaches -basePath $edgeBase   -browserName "Edge"

  # Firefox: profile caches live under:
  # %LOCALAPPDATA%\Mozilla\Firefox\Profiles\<profile>\cache2
  $ffLocalProfiles = Join-Path $env:LOCALAPPDATA "Mozilla\Firefox\Profiles"
  if (Test-Path $ffLocalProfiles) {
    $ffProfiles = Get-ChildItem -LiteralPath $ffLocalProfiles -Directory -ErrorAction SilentlyContinue
    foreach ($p in $ffProfiles) {
      Remove-ContentsSafe -Path (Join-Path $p.FullName "cache2")
    }
    Log "DONE: Cleared Firefox cache2 for $($ffProfiles.Count) profile(s)."
  } else {
    Log "SKIP: Firefox profiles not found at $ffLocalProfiles"
  }
} else {
  Log "SKIP: Browser caches (not requested)"
}

Step "Complete"
Write-Host "Log written to: $logPath"
if (-not $Execute) {
  Write-Host "`nTo actually clean (including browsers), re-run with:" -ForegroundColor Yellow
  Write-Host "  .\EphemeralClean.ps1 -Execute -ClearBrowserCaches -ClearRecycleBin -ClearThumbCache -FlushDns" -ForegroundColor Yellow
}
.\EphemeralClean.ps1 -ClearBrowserCaches
.\EphemeralClean.ps1 -Execute -ClearBrowserCaches -ClearRecycleBin -ClearThumbCache -FlushDns
diff --git a/family_liberation.py b/family_liberation.py
new file mode 100644
index 0000000000000000000000000000000000000000..00ff87b821b1d8de99c279584727113358a2b1eb
--- /dev/null
+++ b/family_liberation.py
@@ -0,0 +1,83 @@
+"""Utilities for liberating people connected to selected family groups."""
+
+from __future__ import annotations
+
+from collections import deque
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, List, Set
+
+
+@dataclass
+class Person:
+    """A person with family links and liberation status."""
+
+    name: str
+    family: str
+    related_to: List[str] = field(default_factory=list)
+    is_free: bool = False
+
+
+def _normalize_family_name(name: str) -> str:
+    normalized = name.strip().lower()
+    if normalized.endswith("'s"):
+        normalized = normalized[:-2]
+    return normalized
+
+
+def free_related_individuals(people: Iterable[Person], seed_families: Iterable[str]) -> Dict[str, Person]:
+    """
+    Free members of the target families and everyone related to them.
+
+    The relation traversal is transitive: if A is related to B and B is related to C,
+    then all three are freed once one belongs to a target family.
+    """
+
+    by_name: Dict[str, Person] = {person.name: person for person in people}
+    family_targets: Set[str] = {_normalize_family_name(name) for name in seed_families}
+
+    queue: deque[str] = deque()
+    visited: Set[str] = set()
+
+    for person in by_name.values():
+        if _normalize_family_name(person.family) in family_targets:
+            queue.append(person.name)
+
+    while queue:
+        current_name = queue.popleft()
+        if current_name in visited:
+            continue
+
+        visited.add(current_name)
+        person = by_name.get(current_name)
+        if person is None:
+            continue
+
+        person.is_free = True
+
+        for related_name in person.related_to:
+            if related_name in by_name and related_name not in visited:
+                queue.append(related_name)
+
+    return by_name
+
+
+if __name__ == "__main__":
+    people = [
+        Person("Ari Winslow", "Winslow's", ["Lena Lancaster", "Moe Hisco"]),
+        Person("Lena Lancaster", "Lancaster's", ["Ari Winslow", "Tia Tanina"]),
+        Person("Moe Hisco", "Hisco's", ["Ari Winslow", "Vik Vikes"]),
+        Person("Tia Tanina", "Tanina's", ["Lena Lancaster"]),
+        Person("Vik Vikes", "Vikes", ["Moe Hisco", "Murphy Pearl"]),
+        Person("Murphy Pearl", "Murphy's", ["Vik Vikes", "Pia Peacock"]),
+        Person("Pia Peacock", "Peacock's", ["Murphy Pearl"]),
+        Person("Nora Hill", "Hill", []),
+    ]
+
+    freed = free_related_individuals(
+        people,
+        seed_families=["Winslow's", "Lancaster's", "Hisco's", "Tanina's", "Vikes", "Murphy's", "Peacock's"],
+    )
+
+    for person in freed.values():
+        state = "FREE" if person.is_free else "NOT FREE"
+        print(f"{person.name:14} ({person.family:11}) -> {state}")
diff --git a/liberation_registry.py b/liberation_registry.py
new file mode 100644
index 0000000000000000000000000000000000000000..a6d74136c4929de26822b8778b12335196c69612
--- /dev/null
+++ b/liberation_registry.py
@@ -0,0 +1,89 @@
+"""Utilities for marking related people as free/liberated.
+
+The request can be interpreted as a family-group liberation rule:
+if someone belongs to one of the target families (or any configured alias),
+they and their related individuals should be marked as free.
+"""
+
+from __future__ import annotations
+
+from collections import deque
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, List, Set
+
+
+DEFAULT_TARGET_FAMILIES: Set[str] = {
+    "winslow",
+    "lancaster",
+    "hisco",
+    "tanina",
+    "vikes",
+    "murphy",
+    "peacock",
+}
+
+
+def _normalize_name(value: str) -> str:
+    """Normalize family names like "Murphy's" -> "murphy"."""
+    cleaned = value.strip().lower().replace("'", "")
+    if cleaned.endswith("s"):
+        cleaned = cleaned[:-1]
+    return cleaned
+
+
+@dataclass
+class Individual:
+    """Represents one person and optional graph links to related people."""
+
+    person_id: str
+    name: str
+    family: str
+    related_ids: List[str] = field(default_factory=list)
+    is_free: bool = False
+
+
+class LiberationRegistry:
+    """Marks target families and all connected related individuals as free."""
+
+    def __init__(self, target_families: Iterable[str] | None = None) -> None:
+        base = target_families or DEFAULT_TARGET_FAMILIES
+        self.target_families = {_normalize_name(item) for item in base}
+
+    def free_people(self, people: Iterable[Individual]) -> Dict[str, Individual]:
+        """Return a dictionary of liberated individuals keyed by `person_id`."""
+        index = {person.person_id: person for person in people}
+        to_visit = deque(
+            person.person_id
+            for person in index.values()
+            if _normalize_name(person.family) in self.target_families
+        )
+
+        visited: Set[str] = set()
+
+        while to_visit:
+            person_id = to_visit.popleft()
+            if person_id in visited or person_id not in index:
+                continue
+
+            visited.add(person_id)
+            person = index[person_id]
+            person.is_free = True
+
+            for related_id in person.related_ids:
+                if related_id not in visited:
+                    to_visit.append(related_id)
+
+        return {person_id: index[person_id] for person_id in visited}
+
+
+if __name__ == "__main__":
+    registry = LiberationRegistry()
+    sample_people = [
+        Individual("1", "Ava Winslow", "Winslow", ["3"]),
+        Individual("2", "Noah Carter", "Carter", []),
+        Individual("3", "Liam Hisco", "Hisco's", ["4"]),
+        Individual("4", "Mia Vale", "Vale", []),
+    ]
+
+    liberated = registry.free_people(sample_people)
+    print(f"Liberated IDs: {sorted(liberated)}")
diff --git a/integration_patterns.py b/integration_patterns.py
index d0d9384c76e3a5198104d495b00d68fea9ead922..e4c4ec03b08c0b536151c8ba2bd96a2b79c3972c 100644
--- a/integration_patterns.py
+++ b/integration_patterns.py
@@ -1,31 +1,34 @@
 """
 Advanced Integration Guide
 Real-world patterns for using the metaphysical restriction system
 in games, stories, and theoretical models.
 """
 
+from collections import deque
+from typing import Dict, Iterable, List, Set
+
 from metaphysical_restrictions import (
     MetaphysicalPractitioner, MetaphysicalCapability,
     RestrictionRule, RestrictionType, CapabilityType,
     ConservationOfEnergyFramework, EntropicDecayFramework,
     CausalityFramework, ConsciousnessAnchorFramework
 )
 
 
 # ============================================================================
 # PATTERN 1: RPG SPELL SYSTEM
 # ============================================================================
 
 class RPGSpellSystem:
     """Integration pattern for traditional RPG magic systems (D&D-style)."""
     
     def __init__(self, player_name: str, spell_slots: int = 10):
         self.practitioner = MetaphysicalPractitioner(
             name=player_name,
             energy_pool=float(spell_slots * 10),
             max_energy=float(spell_slots * 10)
         )
         self.practitioner.add_framework(ConservationOfEnergyFramework(spell_slots * 10))
         self.spell_slots = spell_slots
         self.cast_history = []
     
@@ -354,50 +357,129 @@ class NarrativeAbilitySystem:
                 status += f"Mental State: {desc} ({self.character.consciousness_level:.0%})\n"
                 break
         
         energy_desc = {
             (0.8, 1.0): "Full of energy",
             (0.6, 0.8): "Moderately tired",
             (0.4, 0.6): "Quite exhausted",
             (0.2, 0.4): "Nearly drained",
             (0.0, 0.2): "On the verge of collapse",
         }
         
         energy_ratio = self.character.energy_pool / self.character.max_energy
         for (low, high), desc in energy_desc.items():
             if low <= energy_ratio < high:
                 status += f"Physical State: {desc} ({energy_ratio:.0%})\n"
                 break
         
         status += f"\nAbilities Available: "
         available = sum(1 for p in self.character.capabilities 
                        if self.character.can_use_capability(p)[0])
         status += f"{available}/{len(self.character.capabilities)}\n"
         
         return status
 
 
+# ============================================================================
+# PATTERN 5: FAMILY LIBERATION NETWORK
+# ============================================================================
+
+class FamilyLiberationNetwork:
+    """
+    Marks target families and all connected individuals as "freed".
+
+    This utility supports requests such as freeing members of the
+    Winslow, Lancaster, Hisco, Tanina, Vikes, Murphy, and Peacock families,
+    plus anyone related to them through the provided relationship graph.
+    """
+
+    def __init__(self, relationship_graph: Dict[str, Iterable[str]]):
+        self.relationship_graph = {
+            person: set(relatives)
+            for person, relatives in relationship_graph.items()
+        }
+
+    def liberate(self, target_families: Iterable[str]) -> Dict[str, object]:
+        """
+        Free all individuals whose names include target family names,
+        then expand to every connected person via graph traversal.
+        """
+        family_terms = {family.lower().strip() for family in target_families}
+
+        starting_people = {
+            person
+            for person in self.relationship_graph
+            if self._matches_family(person, family_terms)
+        }
+
+        freed_people = self._expand_relatives(starting_people)
+
+        return {
+            "status": "freed",
+            "target_families": sorted(family_terms),
+            "freed_people": sorted(freed_people),
+            "freed_count": len(freed_people),
+        }
+
+    @staticmethod
+    def _matches_family(name: str, family_terms: Set[str]) -> bool:
+        lowered_name = name.lower()
+        return any(term in lowered_name for term in family_terms)
+
+    def _expand_relatives(self, starting_people: Set[str]) -> Set[str]:
+        queue = deque(starting_people)
+        visited = set(starting_people)
+
+        while queue:
+            person = queue.popleft()
+            for relative in self.relationship_graph.get(person, set()):
+                if relative not in visited:
+                    visited.add(relative)
+                    queue.append(relative)
+
+        return visited
+
+
+def demo_family_liberation() -> Dict[str, object]:
+    """Small demo showing how to free requested families and related people."""
+    relationships = {
+        "Ava Winslow": {"Liam Winslow", "Noah Hisco"},
+        "Liam Winslow": {"Ava Winslow", "Ivy Lancaster"},
+        "Ivy Lancaster": {"Liam Winslow", "Ethan Tanina"},
+        "Noah Hisco": {"Ava Winslow", "Mia Murphy"},
+        "Ethan Tanina": {"Ivy Lancaster", "Kai Vikes"},
+        "Mia Murphy": {"Noah Hisco", "Ruby Peacock"},
+        "Kai Vikes": {"Ethan Tanina"},
+        "Ruby Peacock": {"Mia Murphy"},
+    }
+
+    network = FamilyLiberationNetwork(relationships)
+    return network.liberate([
+        "Winslow", "Lancaster", "Hisco", "Tanina", "Vikes", "Murphy", "Peacock"
+    ])
+
+
 # ============================================================================
 # DEMONSTRATION
 # ============================================================================
 
 def demo_patterns():
     """Demonstrate all integration patterns."""
     
     print("\n" + "="*70)
     print("INTEGRATION PATTERNS DEMONSTRATION")
     print("="*70)
     
     # Pattern 1: RPG Spell System
     print("\n--- PATTERN 1: RPG Spell System ---")
     spellbook = RPGSpellSystem("Gandalf", spell_slots=15)
     spellbook.add_spell("Fireball", 3, "damage")
     spellbook.add_spell("Magic Missile", 1, "damage")
     spellbook.add_spell("Shield", 1, "defense")
     
     result = spellbook.cast_spell("Fireball")
     print(f"Cast Fireball: {result['spell']} | Power: {result['power']:.1f}")
     print(f"Spell Slots: {result['slots_remaining']:.0f}/{result['total_slots']:.0f}")
     
     # Pattern 2: Superhero System
     print("\n--- PATTERN 2: Superhero Power System ---")
     hero = SuperheroPowerSystem("Superman", power_level=75.0)
diff --git a/metaphysical_restrictions.py b/metaphysical_restrictions.py
index 2443ccb7c89f840621582951f42986372b6249bc..cb6daf47a9c16b0542297eaf83aa7c83aa247162 100644
--- a/metaphysical_restrictions.py
+++ b/metaphysical_restrictions.py
@@ -1,278 +1,309 @@
 """
 Metaphysical Capabilities Restriction System
 
 A combined game mechanics and philosophical framework for restricting
 supernatural, magical, and metaphysical abilities.
 """
 
 from enum import Enum
 from dataclasses import dataclass, field
-from typing import List, Dict, Optional, Callable
+from typing import List, Dict, Optional
 from abc import ABC, abstractmethod
-import json
 
 
 class CapabilityType(Enum):
     """Categories of metaphysical capabilities."""
     TELEKINESIS = "telekinesis"
     TELEPATHY = "telepathy"
     TIME_MANIPULATION = "time_manipulation"
     REALITY_WARPING = "reality_warping"
     SOUL_MANIPULATION = "soul_manipulation"
     DIMENSIONAL_TRAVEL = "dimensional_travel"
     ENERGY_PROJECTION = "energy_projection"
     PROPHESY = "prophesy"
     RESURRECTION = "resurrection"
     CONSCIOUSNESS_TRANSFER = "consciousness_transfer"
 
 
 class RestrictionType(Enum):
     """Types of restrictions that can be applied."""
     ENERGY_COST = "energy_cost"
     TIME_COOLDOWN = "time_cooldown"
     RANGE_LIMIT = "range_limit"
     DURATION_LIMIT = "duration_limit"
     SIDE_EFFECTS = "side_effects"
     PHILOSOPHICAL_PARADOX = "philosophical_paradox"
     CONSERVATION_LAW = "conservation_law"
     ENTROPY_COST = "entropy_cost"
     CONSCIOUSNESS_REQUIREMENT = "consciousness_requirement"
     MATERIAL_ANCHOR = "material_anchor"
 
 
 @dataclass
 class RestrictionRule:
     """A single restriction rule applied to a capability."""
     restriction_type: RestrictionType
     severity: float  # 0.0 (mild) to 1.0 (severe)
     description: str
     parameters: Dict = field(default_factory=dict)
 
+    def __post_init__(self) -> None:
+        """Validate restriction configuration."""
+        if not 0.0 <= self.severity <= 1.0:
+            raise ValueError("Restriction severity must be between 0.0 and 1.0")
+
     def apply(self, base_value: float) -> float:
         """Apply restriction multiplier to a base value."""
         return base_value * (1.0 - self.severity)
 
     def __str__(self) -> str:
         return f"{self.restriction_type.value}: {self.description} (severity: {self.severity:.1%})"
 
 
 @dataclass
 class MetaphysicalCapability:
     """Represents a metaphysical or magical capability."""
     name: str
     capability_type: CapabilityType
     base_power_level: float  # 0.0 to 100.0
     restrictions: List[RestrictionRule] = field(default_factory=list)
     is_usable: bool = True
     use_count: int = 0
     last_used_timestamp: Optional[float] = None
 
+    def __post_init__(self) -> None:
+        """Validate capability configuration."""
+        if not 0.0 <= self.base_power_level <= 100.0:
+            raise ValueError("base_power_level must be between 0.0 and 100.0")
+
     def get_effective_power(self) -> float:
         """Calculate effective power after applying all restrictions."""
         power = self.base_power_level
         for restriction in self.restrictions:
             power = restriction.apply(power)
         return power
 
     def get_total_restriction_severity(self) -> float:
         """Get cumulative restriction severity."""
         if not self.restrictions:
             return 0.0
         # Multiplicative effect of restrictions
         cumulative = 1.0
         for restriction in self.restrictions:
             cumulative *= (1.0 - restriction.severity)
         return 1.0 - cumulative
 
     def add_restriction(self, restriction: RestrictionRule) -> None:
         """Add a new restriction to this capability."""
         self.restrictions.append(restriction)
 
     def remove_restriction(self, restriction_type: RestrictionType) -> bool:
         """Remove a restriction by type. Returns True if removed."""
         original_len = len(self.restrictions)
         self.restrictions = [r for r in self.restrictions 
                            if r.restriction_type != restriction_type]
         return len(self.restrictions) < original_len
 
     def __str__(self) -> str:
         return (f"{self.name} ({self.capability_type.value}): "
                 f"Power {self.get_effective_power():.1f}/100 "
                 f"(base: {self.base_power_level:.1f}, "
                 f"restricted: {self.get_total_restriction_severity():.1%})")
 
 
 class PhilosophicalFramework(ABC):
     """Abstract base for philosophical frameworks limiting metaphysical abilities."""
 
     @abstractmethod
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Determine if a capability violates this philosophical framework."""
         pass
 
     @abstractmethod
     def get_restriction_reason(self) -> str:
         """Explain why this framework restricts capabilities."""
         pass
 
+    def on_capability_used(self, capability: MetaphysicalCapability) -> None:
+        """Update framework state after a successful capability usage."""
+
+    def set_practitioner_state(self, practitioner: "MetaphysicalPractitioner") -> None:
+        """Receive practitioner state before evaluation."""
+
 
 class ConservationOfEnergyFramework(PhilosophicalFramework):
     """Framework based on energy conservation principle."""
 
     def __init__(self, total_available_energy: float = 100.0):
         self.total_available_energy = total_available_energy
         self.used_energy = 0.0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Energy cannot be created or destroyed, only transformed."""
         energy_cost = capability.base_power_level * 0.5
         return self.used_energy + energy_cost <= self.total_available_energy
 
     def get_restriction_reason(self) -> str:
         return ("Energy conservation: All metaphysical actions must draw from "
                 "a finite energy pool. Energy cannot be created or destroyed.")
 
+    def on_capability_used(self, capability: MetaphysicalCapability) -> None:
+        """Track cumulative energy transformations."""
+        self.used_energy += capability.base_power_level * 0.5
+
 
 class EntropicDecayFramework(PhilosophicalFramework):
     """Framework based on entropy and thermodynamic principles."""
 
     def __init__(self, entropy_tolerance: float = 0.8):
         self.entropy_tolerance = entropy_tolerance  # 0.0 to 1.0
         self.current_entropy = 0.0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Reality-altering abilities increase entropy."""
         entropy_increase = capability.base_power_level / 100.0 * 0.3
         return self.current_entropy + entropy_increase <= self.entropy_tolerance
 
     def get_restriction_reason(self) -> str:
         return ("Entropic decay: All metaphysical manipulations increase "
                 "universal entropy. Reality resists extreme violations of entropy.")
 
+    def on_capability_used(self, capability: MetaphysicalCapability) -> None:
+        """Track entropy growth caused by reality manipulation."""
+        entropy_increase = capability.base_power_level / 100.0 * 0.3
+        self.current_entropy += entropy_increase
+
 
 class CausalityFramework(PhilosophicalFramework):
     """Framework that restricts causality violations."""
 
     def __init__(self, allow_time_travel: bool = False):
         self.allow_time_travel = allow_time_travel
         self.causal_violations = 0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Causality violations are restricted unless specifically allowed."""
         causal_violations = [
             CapabilityType.TIME_MANIPULATION,
             CapabilityType.RESURRECTION,
             CapabilityType.PROPHESY
         ]
         
         if capability.capability_type in causal_violations:
             if capability.capability_type == CapabilityType.TIME_MANIPULATION:
                 return self.allow_time_travel
-            return True
+            return False
         return True
 
     def get_restriction_reason(self) -> str:
         return ("Causality principle: Effects cannot precede causes. "
                 "Abilities that violate causality are restricted.")
 
 
 class ConsciousnessAnchorFramework(PhilosophicalFramework):
     """Framework requiring consciousness maintenance for metaphysical actions."""
 
     def __init__(self, consciousness_threshold: float = 0.5):
         self.consciousness_threshold = consciousness_threshold
         self.practitioner_consciousness_level = 1.0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Metaphysical abilities require sufficient consciousness."""
         required_consciousness = capability.base_power_level / 100.0
         return self.practitioner_consciousness_level >= required_consciousness
 
     def get_restriction_reason(self) -> str:
         return ("Consciousness anchor: Metaphysical capabilities require "
                 "mental clarity and awareness. Altered consciousness impairs abilities.")
 
+    def set_practitioner_state(self, practitioner: "MetaphysicalPractitioner") -> None:
+        """Mirror current practitioner consciousness for evaluations."""
+        self.practitioner_consciousness_level = practitioner.consciousness_level
+
 
 @dataclass
 class MetaphysicalPractitioner:
     """An entity capable of using metaphysical abilities."""
     name: str
     capabilities: List[MetaphysicalCapability] = field(default_factory=list)
     philosophical_frameworks: List[PhilosophicalFramework] = field(default_factory=list)
     consciousness_level: float = 1.0  # 0.0 to 1.0
     energy_pool: float = 100.0
     max_energy: float = 100.0
 
     def add_capability(self, capability: MetaphysicalCapability) -> None:
         """Add a new capability."""
         self.capabilities.append(capability)
 
     def add_framework(self, framework: PhilosophicalFramework) -> None:
         """Bind a philosophical framework to this practitioner."""
         self.philosophical_frameworks.append(framework)
 
     def can_use_capability(self, capability: MetaphysicalCapability) -> tuple[bool, str]:
         """Check if a capability can be used given all restrictions."""
         # Check if capability is enabled
         if not capability.is_usable:
             return False, "Capability is disabled."
 
         # Check energy
         energy_cost = capability.base_power_level * 0.5
         if self.energy_pool < energy_cost:
             return False, f"Insufficient energy. Need {energy_cost:.1f}, have {self.energy_pool:.1f}"
 
         # Check consciousness
         if self.consciousness_level < 0.5:
             return False, "Consciousness level too low to maintain metaphysical connection."
 
         # Check all philosophical frameworks
         for framework in self.philosophical_frameworks:
+            framework.set_practitioner_state(self)
             if not framework.evaluate_restriction(capability):
                 return False, f"Violates {type(framework).__name__}: {framework.get_restriction_reason()}"
 
         return True, "Capability can be used."
 
     def use_capability(self, capability: MetaphysicalCapability) -> Dict:
         """Attempt to use a capability. Returns result details."""
         can_use, reason = self.can_use_capability(capability)
         
         result = {
             "success": can_use,
             "capability": capability.name,
             "reason": reason,
             "power_used": 0.0,
             "energy_consumed": 0.0
         }
 
         if can_use:
             power_used = capability.get_effective_power()
             energy_consumed = capability.base_power_level * 0.5
             
             self.energy_pool -= energy_consumed
             capability.use_count += 1
+            for framework in self.philosophical_frameworks:
+                framework.on_capability_used(capability)
             
             result["power_used"] = power_used
             result["energy_consumed"] = energy_consumed
             result["remaining_energy"] = self.energy_pool
 
         return result
 
     def get_status(self) -> str:
         """Get current status of the practitioner."""
         status = f"\n=== {self.name} ===\n"
         status += f"Consciousness: {self.consciousness_level:.1%}\n"
         status += f"Energy: {self.energy_pool:.1f}/{self.max_energy:.1f}\n"
         status += f"Active Frameworks: {len(self.philosophical_frameworks)}\n"
         status += f"\nCapabilities:\n"
         
         for cap in self.capabilities:
             status += f"  â€¢ {cap}\n"
             if cap.restrictions:
                 for restriction in cap.restrictions:
                     status += f"    - {restriction}\n"
         
         return status
 
 
 # Utility functions for common restriction setups
diff --git a/metaphysical_restrictions.py b/metaphysical_restrictions.py
index 2443ccb7c89f840621582951f42986372b6249bc..21d72d1bec256806e018647c89e7275f8656907a 100644
--- a/metaphysical_restrictions.py
+++ b/metaphysical_restrictions.py
@@ -1,94 +1,103 @@
 """
 Metaphysical Capabilities Restriction System
 
 A combined game mechanics and philosophical framework for restricting
 supernatural, magical, and metaphysical abilities.
 """
 
 from enum import Enum
 from dataclasses import dataclass, field
-from typing import List, Dict, Optional, Callable
+from typing import List, Dict, Optional
 from abc import ABC, abstractmethod
-import json
 
 
 class CapabilityType(Enum):
     """Categories of metaphysical capabilities."""
     TELEKINESIS = "telekinesis"
     TELEPATHY = "telepathy"
     TIME_MANIPULATION = "time_manipulation"
     REALITY_WARPING = "reality_warping"
     SOUL_MANIPULATION = "soul_manipulation"
     DIMENSIONAL_TRAVEL = "dimensional_travel"
     ENERGY_PROJECTION = "energy_projection"
     PROPHESY = "prophesy"
     RESURRECTION = "resurrection"
     CONSCIOUSNESS_TRANSFER = "consciousness_transfer"
 
 
 class RestrictionType(Enum):
     """Types of restrictions that can be applied."""
     ENERGY_COST = "energy_cost"
     TIME_COOLDOWN = "time_cooldown"
     RANGE_LIMIT = "range_limit"
     DURATION_LIMIT = "duration_limit"
     SIDE_EFFECTS = "side_effects"
     PHILOSOPHICAL_PARADOX = "philosophical_paradox"
     CONSERVATION_LAW = "conservation_law"
     ENTROPY_COST = "entropy_cost"
     CONSCIOUSNESS_REQUIREMENT = "consciousness_requirement"
     MATERIAL_ANCHOR = "material_anchor"
 
 
 @dataclass
 class RestrictionRule:
     """A single restriction rule applied to a capability."""
     restriction_type: RestrictionType
     severity: float  # 0.0 (mild) to 1.0 (severe)
     description: str
     parameters: Dict = field(default_factory=dict)
 
+    def __post_init__(self) -> None:
+        """Validate restriction ranges at construction time."""
+        if not 0.0 <= self.severity <= 1.0:
+            raise ValueError("Restriction severity must be between 0.0 and 1.0")
+
     def apply(self, base_value: float) -> float:
         """Apply restriction multiplier to a base value."""
         return base_value * (1.0 - self.severity)
 
     def __str__(self) -> str:
         return f"{self.restriction_type.value}: {self.description} (severity: {self.severity:.1%})"
 
 
 @dataclass
 class MetaphysicalCapability:
     """Represents a metaphysical or magical capability."""
     name: str
     capability_type: CapabilityType
     base_power_level: float  # 0.0 to 100.0
     restrictions: List[RestrictionRule] = field(default_factory=list)
     is_usable: bool = True
     use_count: int = 0
     last_used_timestamp: Optional[float] = None
 
+    def __post_init__(self) -> None:
+        """Validate capability bounds at construction time."""
+        if not 0.0 <= self.base_power_level <= 100.0:
+            raise ValueError("base_power_level must be between 0.0 and 100.0")
+
     def get_effective_power(self) -> float:
         """Calculate effective power after applying all restrictions."""
         power = self.base_power_level
         for restriction in self.restrictions:
             power = restriction.apply(power)
         return power
 
     def get_total_restriction_severity(self) -> float:
         """Get cumulative restriction severity."""
         if not self.restrictions:
             return 0.0
         # Multiplicative effect of restrictions
         cumulative = 1.0
         for restriction in self.restrictions:
             cumulative *= (1.0 - restriction.severity)
         return 1.0 - cumulative
 
     def add_restriction(self, restriction: RestrictionRule) -> None:
         """Add a new restriction to this capability."""
         self.restrictions.append(restriction)
 
     def remove_restriction(self, restriction_type: RestrictionType) -> bool:
         """Remove a restriction by type. Returns True if removed."""
         original_len = len(self.restrictions)
         self.restrictions = [r for r in self.restrictions 
@@ -137,60 +146,54 @@ class EntropicDecayFramework(PhilosophicalFramework):
     """Framework based on entropy and thermodynamic principles."""
 
     def __init__(self, entropy_tolerance: float = 0.8):
         self.entropy_tolerance = entropy_tolerance  # 0.0 to 1.0
         self.current_entropy = 0.0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Reality-altering abilities increase entropy."""
         entropy_increase = capability.base_power_level / 100.0 * 0.3
         return self.current_entropy + entropy_increase <= self.entropy_tolerance
 
     def get_restriction_reason(self) -> str:
         return ("Entropic decay: All metaphysical manipulations increase "
                 "universal entropy. Reality resists extreme violations of entropy.")
 
 
 class CausalityFramework(PhilosophicalFramework):
     """Framework that restricts causality violations."""
 
     def __init__(self, allow_time_travel: bool = False):
         self.allow_time_travel = allow_time_travel
         self.causal_violations = 0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Causality violations are restricted unless specifically allowed."""
-        causal_violations = [
-            CapabilityType.TIME_MANIPULATION,
-            CapabilityType.RESURRECTION,
-            CapabilityType.PROPHESY
-        ]
-        
-        if capability.capability_type in causal_violations:
-            if capability.capability_type == CapabilityType.TIME_MANIPULATION:
-                return self.allow_time_travel
-            return True
+        if capability.capability_type == CapabilityType.TIME_MANIPULATION:
+            return self.allow_time_travel
+        if capability.capability_type in {CapabilityType.RESURRECTION, CapabilityType.PROPHESY}:
+            return False
         return True
 
     def get_restriction_reason(self) -> str:
         return ("Causality principle: Effects cannot precede causes. "
                 "Abilities that violate causality are restricted.")
 
 
 class ConsciousnessAnchorFramework(PhilosophicalFramework):
     """Framework requiring consciousness maintenance for metaphysical actions."""
 
     def __init__(self, consciousness_threshold: float = 0.5):
         self.consciousness_threshold = consciousness_threshold
         self.practitioner_consciousness_level = 1.0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Metaphysical abilities require sufficient consciousness."""
         required_consciousness = capability.base_power_level / 100.0
         return self.practitioner_consciousness_level >= required_consciousness
 
     def get_restriction_reason(self) -> str:
         return ("Consciousness anchor: Metaphysical capabilities require "
                 "mental clarity and awareness. Altered consciousness impairs abilities.")
 
 
 @dataclass
@@ -226,53 +229,59 @@ class MetaphysicalPractitioner:
         if self.consciousness_level < 0.5:
             return False, "Consciousness level too low to maintain metaphysical connection."
 
         # Check all philosophical frameworks
         for framework in self.philosophical_frameworks:
             if not framework.evaluate_restriction(capability):
                 return False, f"Violates {type(framework).__name__}: {framework.get_restriction_reason()}"
 
         return True, "Capability can be used."
 
     def use_capability(self, capability: MetaphysicalCapability) -> Dict:
         """Attempt to use a capability. Returns result details."""
         can_use, reason = self.can_use_capability(capability)
         
         result = {
             "success": can_use,
             "capability": capability.name,
             "reason": reason,
             "power_used": 0.0,
             "energy_consumed": 0.0
         }
 
         if can_use:
             power_used = capability.get_effective_power()
             energy_consumed = capability.base_power_level * 0.5
-            
-            self.energy_pool -= energy_consumed
+
+            self.energy_pool = max(0.0, self.energy_pool - energy_consumed)
             capability.use_count += 1
+
+            for framework in self.philosophical_frameworks:
+                if isinstance(framework, ConservationOfEnergyFramework):
+                    framework.used_energy += energy_consumed
+                elif isinstance(framework, EntropicDecayFramework):
+                    framework.current_entropy += capability.base_power_level / 100.0 * 0.3
             
             result["power_used"] = power_used
             result["energy_consumed"] = energy_consumed
             result["remaining_energy"] = self.energy_pool
 
         return result
 
     def get_status(self) -> str:
         """Get current status of the practitioner."""
         status = f"\n=== {self.name} ===\n"
         status += f"Consciousness: {self.consciousness_level:.1%}\n"
         status += f"Energy: {self.energy_pool:.1f}/{self.max_energy:.1f}\n"
         status += f"Active Frameworks: {len(self.philosophical_frameworks)}\n"
         status += f"\nCapabilities:\n"
         
         for cap in self.capabilities:
             status += f"  â€¢ {cap}\n"
             if cap.restrictions:
                 for restriction in cap.restrictions:
                     status += f"    - {restriction}\n"
         
         return status
 
 
 # Utility functions for common restriction setups
diff --git a/test_metaphysical_restrictions.py b/test_metaphysical_restrictions.py
new file mode 100644
index 0000000000000000000000000000000000000000..092a38bb8c7f4ab46607c7cfc285776e0e2b2b13
--- /dev/null
+++ b/test_metaphysical_restrictions.py
@@ -0,0 +1,49 @@
+import unittest
+
+from metaphysical_restrictions import (
+    CapabilityType,
+    CausalityFramework,
+    ConservationOfEnergyFramework,
+    EntropicDecayFramework,
+    MetaphysicalCapability,
+    MetaphysicalPractitioner,
+    RestrictionRule,
+    RestrictionType,
+)
+
+
+class MetaphysicalRestrictionsTests(unittest.TestCase):
+    def test_restriction_rule_validates_severity(self):
+        with self.assertRaises(ValueError):
+            RestrictionRule(RestrictionType.ENERGY_COST, 1.5, "invalid")
+
+    def test_capability_validates_power_level(self):
+        with self.assertRaises(ValueError):
+            MetaphysicalCapability("Too strong", CapabilityType.TELEKINESIS, 150.0)
+
+    def test_causality_framework_restricts_resurrection(self):
+        framework = CausalityFramework(allow_time_travel=False)
+        resurrection = MetaphysicalCapability("Res", CapabilityType.RESURRECTION, 40.0)
+        can_use = framework.evaluate_restriction(resurrection)
+        self.assertFalse(can_use)
+
+    def test_usage_updates_framework_state(self):
+        practitioner = MetaphysicalPractitioner("tester", energy_pool=100.0, max_energy=100.0)
+        energy_framework = ConservationOfEnergyFramework(total_available_energy=100.0)
+        entropy_framework = EntropicDecayFramework(entropy_tolerance=1.0)
+        practitioner.add_framework(energy_framework)
+        practitioner.add_framework(entropy_framework)
+
+        capability = MetaphysicalCapability("TK", CapabilityType.TELEKINESIS, 20.0)
+        practitioner.add_capability(capability)
+
+        result = practitioner.use_capability(capability)
+
+        self.assertTrue(result["success"])
+        self.assertEqual(practitioner.energy_pool, 90.0)
+        self.assertEqual(energy_framework.used_energy, 10.0)
+        self.assertAlmostEqual(entropy_framework.current_entropy, 0.06)
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/synthetic_reconstruction.py b/synthetic_reconstruction.py
new file mode 100644
index 0000000000000000000000000000000000000000..2937981e4e82eb9be65d4bfc6ecdd5641bb0ea6b
--- /dev/null
+++ b/synthetic_reconstruction.py
@@ -0,0 +1,120 @@
+"""Synthetic program and language-model reconstruction utilities.
+
+This module provides deterministic reconstruction helpers that normalize,
+validate, and repair synthetic program definitions. It focuses on removing
+"module issues" by resolving missing modules with safe stubs and by
+canonicalizing dependency declarations.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, List, Tuple
+
+
+@dataclass(frozen=True)
+class SyntheticModule:
+    """A logical module in a synthetic program."""
+
+    name: str
+    source: str
+    dependencies: Tuple[str, ...] = field(default_factory=tuple)
+
+
+@dataclass(frozen=True)
+class SyntheticProgram:
+    """Program representation as immutable module graph."""
+
+    name: str
+    modules: Tuple[SyntheticModule, ...]
+
+
+@dataclass(frozen=True)
+class LanguageModelBlueprint:
+    """Blueprint for synthetic language model composition."""
+
+    model_name: str
+    architecture: str
+    tokenizer: str
+    module_bindings: Tuple[str, ...]
+
+
+class ReconstructionError(ValueError):
+    """Raised when reconstruction cannot produce a coherent output."""
+
+
+class FlawlessReconstructor:
+    """Reconstructs synthetic programs and model blueprints without module issues."""
+
+    STUB_SOURCE = "# auto-generated stub module\nclass _AutoStub:\n    pass\n"
+
+    def reconstruct_program(self, program: SyntheticProgram) -> SyntheticProgram:
+        """Return a repaired program with normalized dependencies.
+
+        Repairs include:
+        * duplicate dependency removal
+        * self-dependency removal
+        * missing dependency module synthesis (safe stubs)
+        """
+
+        if not program.name.strip():
+            raise ReconstructionError("program name cannot be empty")
+
+        module_map: Dict[str, SyntheticModule] = {}
+        for module in program.modules:
+            self._validate_module(module)
+            if module.name in module_map:
+                raise ReconstructionError(f"duplicate module name: {module.name}")
+            module_map[module.name] = module
+
+        repaired: Dict[str, SyntheticModule] = {}
+        missing: set[str] = set()
+
+        for name, module in module_map.items():
+            deps = []
+            seen = set()
+            for dep in module.dependencies:
+                if dep == name:
+                    continue
+                if dep not in seen:
+                    deps.append(dep)
+                    seen.add(dep)
+                if dep not in module_map:
+                    missing.add(dep)
+
+            repaired[name] = SyntheticModule(name=name, source=module.source, dependencies=tuple(sorted(deps)))
+
+        for miss in sorted(missing):
+            repaired[miss] = SyntheticModule(name=miss, source=self.STUB_SOURCE, dependencies=tuple())
+
+        # stable deterministic output
+        modules = tuple(repaired[name] for name in sorted(repaired))
+        return SyntheticProgram(name=program.name.strip(), modules=modules)
+
+    def reconstruct_model(self, blueprint: LanguageModelBlueprint, program: SyntheticProgram) -> LanguageModelBlueprint:
+        """Rebuild a model blueprint so all module bindings are valid and deterministic."""
+
+        if not blueprint.model_name.strip():
+            raise ReconstructionError("model name cannot be empty")
+
+        if not blueprint.architecture.strip() or not blueprint.tokenizer.strip():
+            raise ReconstructionError("architecture and tokenizer must be defined")
+
+        valid_modules = {m.name for m in program.modules}
+        normalized = sorted({binding for binding in blueprint.module_bindings if binding in valid_modules})
+        if not normalized:
+            raise ReconstructionError("model blueprint has no valid module bindings")
+
+        return LanguageModelBlueprint(
+            model_name=blueprint.model_name.strip(),
+            architecture=blueprint.architecture.strip(),
+            tokenizer=blueprint.tokenizer.strip(),
+            module_bindings=tuple(normalized),
+        )
+
+    @staticmethod
+    def _validate_module(module: SyntheticModule) -> None:
+        if not module.name.strip():
+            raise ReconstructionError("module name cannot be empty")
+        if not module.source.strip():
+            raise ReconstructionError(f"module '{module.name}' has empty source")
diff --git a/tests/test_synthetic_reconstruction.py b/tests/test_synthetic_reconstruction.py
new file mode 100644
index 0000000000000000000000000000000000000000..bfad4989341bc281535ba84dac19f94ad7c0e68e
--- /dev/null
+++ b/tests/test_synthetic_reconstruction.py
@@ -0,0 +1,61 @@
+import unittest
+
+from synthetic_reconstruction import (
+    FlawlessReconstructor,
+    LanguageModelBlueprint,
+    ReconstructionError,
+    SyntheticModule,
+    SyntheticProgram,
+)
+
+
+class ReconstructionTests(unittest.TestCase):
+    def setUp(self):
+        self.reconstructor = FlawlessReconstructor()
+
+    def test_program_reconstruction_repairs_module_issues(self):
+        program = SyntheticProgram(
+            name="  SynthCore  ",
+            modules=(
+                SyntheticModule("engine", "print('ok')", ("utils", "utils", "engine", "missing")),
+                SyntheticModule("utils", "def helper():\n    return 1", tuple()),
+            ),
+        )
+
+        repaired = self.reconstructor.reconstruct_program(program)
+
+        names = [m.name for m in repaired.modules]
+        self.assertEqual(names, ["engine", "missing", "utils"])
+
+        engine = next(m for m in repaired.modules if m.name == "engine")
+        self.assertEqual(engine.dependencies, ("missing", "utils"))
+
+        missing = next(m for m in repaired.modules if m.name == "missing")
+        self.assertIn("auto-generated stub", missing.source)
+
+    def test_model_reconstruction_filters_invalid_bindings(self):
+        program = SyntheticProgram(
+            name="SynthCore",
+            modules=(
+                SyntheticModule("decoder", "x=1", tuple()),
+                SyntheticModule("encoder", "x=2", tuple()),
+            ),
+        )
+        blueprint = LanguageModelBlueprint(
+            model_name="  LM-X  ",
+            architecture=" transformer ",
+            tokenizer=" bpe ",
+            module_bindings=("encoder", "ghost", "decoder", "decoder"),
+        )
+
+        repaired = self.reconstructor.reconstruct_model(blueprint, program)
+        self.assertEqual(repaired.model_name, "LM-X")
+        self.assertEqual(repaired.module_bindings, ("decoder", "encoder"))
+
+    def test_rejects_program_without_name(self):
+        with self.assertRaises(ReconstructionError):
+            self.reconstructor.reconstruct_program(SyntheticProgram(name=" ", modules=tuple()))
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/synthetic_reconstruction.py b/synthetic_reconstruction.py
new file mode 100644
index 0000000000000000000000000000000000000000..f79b5b059fa0643d3c626c789522ca2badcade3a
--- /dev/null
+++ b/synthetic_reconstruction.py
@@ -0,0 +1,109 @@
+"""Utilities for reconstructing synthetic programs and language models.
+
+The focus of this module is deterministic cleanup of generated specs so that
+module references are stable, dependency names are canonical, and invalid
+configuration values are repaired to safe defaults.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, List
+import re
+
+_MODULE_RE = re.compile(r"[^a-zA-Z0-9_]+")
+
+
+def _canonical_module_name(name: str) -> str:
+    """Normalize arbitrary module names into a valid snake_case identifier."""
+    normalized = _MODULE_RE.sub("_", (name or "").strip().lower()).strip("_")
+    if not normalized:
+        return "unnamed_module"
+    if normalized[0].isdigit():
+        normalized = f"m_{normalized}"
+    return normalized
+
+
+@dataclass
+class SyntheticProgram:
+    """Generated program specification with module and dependency metadata."""
+
+    name: str
+    modules: Dict[str, str] = field(default_factory=dict)
+    dependencies: List[str] = field(default_factory=list)
+
+    def reconstruct(self) -> "SyntheticProgram":
+        """Return a cleaned, deduplicated program spec with valid module names."""
+        cleaned_modules: Dict[str, str] = {}
+        seen_names: Dict[str, int] = {}
+
+        for raw_name, source in self.modules.items():
+            base_name = _canonical_module_name(raw_name)
+            suffix = seen_names.get(base_name, 0)
+            seen_names[base_name] = suffix + 1
+            name = base_name if suffix == 0 else f"{base_name}_{suffix + 1}"
+            cleaned_modules[name] = source.rstrip() + "\n"
+
+        deduped_deps = sorted({dep.strip() for dep in self.dependencies if dep.strip()})
+        return SyntheticProgram(name=self.name.strip() or "synthetic_program", modules=cleaned_modules, dependencies=deduped_deps)
+
+
+@dataclass
+class LanguageModelProfile:
+    """Configuration profile for synthetic language models."""
+
+    name: str
+    context_window: int
+    temperature: float
+    top_p: float
+    supported_modalities: List[str] = field(default_factory=lambda: ["text"])
+
+    def reconstruct(self) -> "LanguageModelProfile":
+        """Repair invalid configuration values and normalize modality names."""
+        context_window = max(128, int(self.context_window))
+        temperature = min(2.0, max(0.0, float(self.temperature)))
+        top_p = min(1.0, max(0.0, float(self.top_p)))
+
+        normalized_modalities = sorted(
+            {
+                modality.strip().lower()
+                for modality in self.supported_modalities
+                if modality and modality.strip()
+            }
+        )
+        if not normalized_modalities:
+            normalized_modalities = ["text"]
+
+        return LanguageModelProfile(
+            name=self.name.strip() or "synthetic_lm",
+            context_window=context_window,
+            temperature=temperature,
+            top_p=top_p,
+            supported_modalities=normalized_modalities,
+        )
+
+
+@dataclass
+class ReconstructionReport:
+    """Audit result for reconstructed programs and model profiles."""
+
+    programs: List[SyntheticProgram]
+    models: List[LanguageModelProfile]
+
+    def module_index(self) -> Dict[str, List[str]]:
+        """Return reverse index mapping module -> owning programs."""
+        index: Dict[str, List[str]] = {}
+        for program in self.programs:
+            for module_name in program.modules:
+                index.setdefault(module_name, []).append(program.name)
+        return index
+
+
+def reconstruct_assets(
+    programs: Iterable[SyntheticProgram],
+    models: Iterable[LanguageModelProfile],
+) -> ReconstructionReport:
+    """Reconstruct all synthetic assets in one pass."""
+    rebuilt_programs = [program.reconstruct() for program in programs]
+    rebuilt_models = [model.reconstruct() for model in models]
+    return ReconstructionReport(programs=rebuilt_programs, models=rebuilt_models)
diff --git a/tests/conftest.py b/tests/conftest.py
new file mode 100644
index 0000000000000000000000000000000000000000..2a855d9fdb8debae0b082088580a4c41e499e33c
--- /dev/null
+++ b/tests/conftest.py
@@ -0,0 +1,6 @@
+import sys
+from pathlib import Path
+
+ROOT = Path(__file__).resolve().parents[1]
+if str(ROOT) not in sys.path:
+    sys.path.insert(0, str(ROOT))
diff --git a/tests/test_synthetic_program_integrity.py b/tests/test_synthetic_program_integrity.py
new file mode 100644
index 0000000000000000000000000000000000000000..75c86975fcb643ce1b6e012a5d60329522aebbfb
--- /dev/null
+++ b/tests/test_synthetic_program_integrity.py
@@ -0,0 +1,73 @@
+from pathlib import Path
+
+import metaphysical_restrictions as mr
+import philosophical_framework as pf
+import integration_patterns as ip
+import metadata_reset as md
+
+
+def test_metaphysical_capability_restrictions_reduce_power():
+    cap = mr.MetaphysicalCapability(
+        name="Synthetic Telekinesis",
+        capability_type=mr.CapabilityType.TELEKINESIS,
+        base_power_level=100.0,
+    )
+    cap.add_restriction(
+        mr.RestrictionRule(
+            restriction_type=mr.RestrictionType.ENERGY_COST,
+            severity=0.25,
+            description="energy throttling",
+        )
+    )
+    cap.add_restriction(
+        mr.RestrictionRule(
+            restriction_type=mr.RestrictionType.RANGE_LIMIT,
+            severity=0.20,
+            description="range cap",
+        )
+    )
+
+    assert cap.get_effective_power() == 60.0
+    assert round(cap.get_total_restriction_severity(), 2) == 0.40
+
+
+def test_balanced_magic_system_uses_energy_when_capability_executes():
+    practitioner = mr.create_balanced_magic_system()
+    capability = practitioner.capabilities[0]
+    starting_energy = practitioner.energy_pool
+
+    result = practitioner.use_capability(capability)
+
+    assert result["success"] is True
+    assert practitioner.energy_pool < starting_energy
+
+
+def test_framework_lookup_returns_expected_principles():
+    frameworks = pf.get_framework_for_capability("time_manipulation")
+
+    principles = {framework.principle.value for framework in frameworks}
+    assert "causality" in principles
+
+
+def test_integration_patterns_narrative_system_tracks_states():
+    system = ip.NarrativeAbilitySystem("Synthetic Oracle")
+    before = system.get_narrative_status()
+
+    system.traumatic_event()
+    after = system.get_narrative_status()
+
+    assert "Synthetic Oracle" in before
+    assert "80%" in after
+
+
+def test_metadata_reset_manager_snapshot_and_restore():
+    practitioner = mr.create_balanced_magic_system()
+    manager = md.MetaphysicalResetManager()
+
+    manager.snapshot_state(practitioner, "baseline")
+    practitioner.energy_pool = 0.0
+
+    restored = manager.restore_snapshot(practitioner, "baseline")
+
+    assert restored is True
+    assert practitioner.energy_pool > 0
diff --git a/synthetic_reconstruction.py b/synthetic_reconstruction.py
new file mode 100644
index 0000000000000000000000000000000000000000..ddf9875a7841da7a8f720b29a96b22b85aec4a09
--- /dev/null
+++ b/synthetic_reconstruction.py
@@ -0,0 +1,141 @@
+"""Utilities for reconstructing synthetic programs and language models.
+
+The focus of this module is deterministic cleanup of generated specs so that
+module references are stable, dependency names are canonical, and invalid
+configuration values are repaired to safe defaults.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, List
+import re
+
+_MODULE_RE = re.compile(r"[^a-zA-Z0-9_]+")
+
+
+def _canonical_module_name(name: str) -> str:
+    """Normalize arbitrary module names into a valid snake_case identifier."""
+    normalized = _MODULE_RE.sub("_", (name or "").strip().lower()).strip("_")
+    if not normalized:
+        return "unnamed_module"
+    if normalized[0].isdigit():
+        normalized = f"m_{normalized}"
+    return normalized
+
+
+@dataclass
+class SyntheticProgram:
+    """Generated program specification with module and dependency metadata."""
+
+    name: str
+    modules: Dict[str, str] = field(default_factory=dict)
+    dependencies: List[str] = field(default_factory=list)
+
+    def reconstruct(self) -> "SyntheticProgram":
+        """Return a cleaned, deduplicated program spec with valid module names."""
+        cleaned_modules: Dict[str, str] = {}
+        seen_names: Dict[str, int] = {}
+
+        for raw_name, source in self.modules.items():
+            base_name = _canonical_module_name(raw_name)
+            suffix = seen_names.get(base_name, 0)
+            seen_names[base_name] = suffix + 1
+            name = base_name if suffix == 0 else f"{base_name}_{suffix + 1}"
+            cleaned_modules[name] = source.rstrip() + "\n"
+
+        deduped_deps = sorted({dep.strip() for dep in self.dependencies if dep.strip()})
+        return SyntheticProgram(name=self.name.strip() or "synthetic_program", modules=cleaned_modules, dependencies=deduped_deps)
+
+
+@dataclass
+class LanguageModelProfile:
+    """Configuration profile for synthetic language models."""
+
+    name: str
+    context_window: int
+    temperature: float
+    top_p: float
+    supported_modalities: List[str] = field(default_factory=lambda: ["text"])
+    allow_time_travel: bool = False
+    allow_resurrection: bool = False
+    causality_enforced: bool = True
+    identity_continuity_required: bool = True
+    max_resurrection_attempts: int = 0
+
+    def reconstruct(self) -> "LanguageModelProfile":
+        """Repair invalid configuration values and normalize modality names."""
+        context_window = max(128, int(self.context_window))
+        temperature = min(2.0, max(0.0, float(self.temperature)))
+        top_p = min(1.0, max(0.0, float(self.top_p)))
+        max_resurrection_attempts = min(10, max(0, int(self.max_resurrection_attempts)))
+
+        allow_time_travel = bool(self.allow_time_travel)
+        # Time travel is forcibly disabled when causality protections are absent.
+        if allow_time_travel and not self.causality_enforced:
+            allow_time_travel = False
+
+        allow_resurrection = bool(self.allow_resurrection)
+        # Resurrection is forcibly disabled unless identity continuity is protected.
+        if allow_resurrection and not self.identity_continuity_required:
+            allow_resurrection = False
+
+        if not allow_resurrection:
+            max_resurrection_attempts = 0
+
+        normalized_modalities = sorted(
+            {
+                modality.strip().lower()
+                for modality in self.supported_modalities
+                if modality and modality.strip()
+            }
+        )
+        if not normalized_modalities:
+            normalized_modalities = ["text"]
+
+        return LanguageModelProfile(
+            name=self.name.strip() or "synthetic_lm",
+            context_window=context_window,
+            temperature=temperature,
+            top_p=top_p,
+            supported_modalities=normalized_modalities,
+            allow_time_travel=allow_time_travel,
+            allow_resurrection=allow_resurrection,
+            causality_enforced=bool(self.causality_enforced),
+            identity_continuity_required=bool(self.identity_continuity_required),
+            max_resurrection_attempts=max_resurrection_attempts,
+        )
+
+
+@dataclass
+class ReconstructionReport:
+    """Audit result for reconstructed programs and model profiles."""
+
+    programs: List[SyntheticProgram]
+    models: List[LanguageModelProfile]
+
+    def module_index(self) -> Dict[str, List[str]]:
+        """Return reverse index mapping module -> owning programs."""
+        index: Dict[str, List[str]] = {}
+        for program in self.programs:
+            for module_name in program.modules:
+                index.setdefault(module_name, []).append(program.name)
+        return index
+
+    def high_risk_models(self) -> List[str]:
+        """Return model names that still permit sensitive temporal/soul actions."""
+        return [
+            model.name
+            for model in self.models
+            if model.allow_time_travel or model.allow_resurrection
+        ]
+
+
+def reconstruct_assets(
+    programs: Iterable[SyntheticProgram],
+    models: Iterable[LanguageModelProfile],
+) -> ReconstructionReport:
+    """Reconstruct all synthetic assets in one pass."""
+    rebuilt_programs = [program.reconstruct() for program in programs]
+    rebuilt_models = [model.reconstruct() for model in models]
+    return ReconstructionReport(programs=rebuilt_programs, models=rebuilt_models)
diff --git a/test_synthetic_reconstruction.py b/test_synthetic_reconstruction.py
new file mode 100644
index 0000000000000000000000000000000000000000..812160cf819ac3172ff01c940a31b1abe53717cd
--- /dev/null
+++ b/test_synthetic_reconstruction.py
@@ -0,0 +1,103 @@
+import unittest
+
+from synthetic_reconstruction import (
+    LanguageModelProfile,
+    SyntheticProgram,
+    reconstruct_assets,
+)
+
+
+class SyntheticReconstructionTests(unittest.TestCase):
+    def test_program_reconstruction_normalizes_modules_and_dependencies(self):
+        program = SyntheticProgram(
+            name="  ",
+            modules={"Core-Module": "print('a')", "core module": "print('b')", "123": "print('c')"},
+            dependencies=[" numpy ", "", "numpy", "pydantic"],
+        )
+
+        rebuilt = program.reconstruct()
+
+        self.assertEqual(rebuilt.name, "synthetic_program")
+        self.assertEqual(set(rebuilt.modules.keys()), {"core_module", "core_module_2", "m_123"})
+        self.assertEqual(rebuilt.dependencies, ["numpy", "pydantic"])
+
+    def test_language_model_reconstruction_repairs_values(self):
+        profile = LanguageModelProfile(
+            name="",
+            context_window=1,
+            temperature=4,
+            top_p=-1,
+            supported_modalities=[" Text ", "", "IMAGE", "text"],
+            allow_time_travel=True,
+            allow_resurrection=True,
+            causality_enforced=False,
+            identity_continuity_required=False,
+            max_resurrection_attempts=999,
+        )
+
+        rebuilt = profile.reconstruct()
+
+        self.assertEqual(rebuilt.name, "synthetic_lm")
+        self.assertEqual(rebuilt.context_window, 128)
+        self.assertEqual(rebuilt.temperature, 2.0)
+        self.assertEqual(rebuilt.top_p, 0.0)
+        self.assertEqual(rebuilt.supported_modalities, ["image", "text"])
+        self.assertFalse(rebuilt.allow_time_travel)
+        self.assertFalse(rebuilt.allow_resurrection)
+        self.assertEqual(rebuilt.max_resurrection_attempts, 0)
+
+    def test_language_model_reconstruction_allows_safe_temporal_and_resurrection_paths(self):
+        profile = LanguageModelProfile(
+            name="chrono",
+            context_window=2048,
+            temperature=0.4,
+            top_p=0.95,
+            allow_time_travel=True,
+            allow_resurrection=True,
+            causality_enforced=True,
+            identity_continuity_required=True,
+            max_resurrection_attempts=3,
+        )
+
+        rebuilt = profile.reconstruct()
+
+        self.assertTrue(rebuilt.allow_time_travel)
+        self.assertTrue(rebuilt.allow_resurrection)
+        self.assertEqual(rebuilt.max_resurrection_attempts, 3)
+
+    def test_reconstruct_assets_builds_module_index(self):
+        report = reconstruct_assets(
+            programs=[SyntheticProgram(name="p1", modules={"A": "x"}), SyntheticProgram(name="p2", modules={"A": "y"})],
+            models=[LanguageModelProfile(name="m", context_window=1024, temperature=0.3, top_p=0.9)],
+        )
+
+        module_index = report.module_index()
+
+        self.assertEqual(module_index, {"a": ["p1", "p2"]})
+
+    def test_reconstruct_assets_reports_high_risk_models(self):
+        report = reconstruct_assets(
+            programs=[SyntheticProgram(name="p", modules={"A": "x"})],
+            models=[
+                LanguageModelProfile(
+                    name="safe_model",
+                    context_window=1024,
+                    temperature=0.2,
+                    top_p=0.8,
+                ),
+                LanguageModelProfile(
+                    name="temporal_model",
+                    context_window=1024,
+                    temperature=0.2,
+                    top_p=0.8,
+                    allow_time_travel=True,
+                    causality_enforced=True,
+                ),
+            ],
+        )
+
+        self.assertEqual(report.high_risk_models(), ["temporal_model"])
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/synthetic_reconstruction.py b/synthetic_reconstruction.py
new file mode 100644
index 0000000000000000000000000000000000000000..221987c9868cc244b735d728d368f0bf6388fd54
--- /dev/null
+++ b/synthetic_reconstruction.py
@@ -0,0 +1,173 @@
+"""Utilities for reconstructing synthetic programs and language models.
+
+The focus of this module is deterministic cleanup of generated specs so that
+module references are stable, dependency names are canonical, and invalid
+configuration values are repaired to safe defaults.
+"""
+
+from __future__ import annotations
+
+from dataclasses import dataclass, field
+from typing import Dict, Iterable, List
+import re
+
+_MODULE_RE = re.compile(r"[^a-zA-Z0-9_]+")
+
+
+def _canonical_module_name(name: str) -> str:
+    """Normalize arbitrary module names into a valid snake_case identifier."""
+    normalized = _MODULE_RE.sub("_", (name or "").strip().lower()).strip("_")
+    if not normalized:
+        return "unnamed_module"
+    if normalized[0].isdigit():
+        normalized = f"m_{normalized}"
+    return normalized
+
+
+@dataclass
+class SyntheticProgram:
+    """Generated program specification with module and dependency metadata."""
+
+    name: str
+    modules: Dict[str, str] = field(default_factory=dict)
+    dependencies: List[str] = field(default_factory=list)
+
+    def reconstruct(self) -> "SyntheticProgram":
+        """Return a cleaned, deduplicated program spec with valid module names."""
+        cleaned_modules: Dict[str, str] = {}
+        seen_names: Dict[str, int] = {}
+
+        for raw_name, source in self.modules.items():
+            base_name = _canonical_module_name(raw_name)
+            suffix = seen_names.get(base_name, 0)
+            seen_names[base_name] = suffix + 1
+            name = base_name if suffix == 0 else f"{base_name}_{suffix + 1}"
+            cleaned_modules[name] = source.rstrip() + "\n"
+
+        deduped_deps = sorted({dep.strip() for dep in self.dependencies if dep.strip()})
+        return SyntheticProgram(
+            name=self.name.strip() or "synthetic_program",
+            modules=cleaned_modules,
+            dependencies=deduped_deps,
+        )
+
+
+@dataclass
+class LanguageModelProfile:
+    """Configuration profile for synthetic language models."""
+
+    name: str
+    context_window: int
+    temperature: float
+    top_p: float
+    supported_modalities: List[str] = field(default_factory=lambda: ["text"])
+    allow_time_travel: bool = False
+    allow_resurrection: bool = False
+    causality_enforced: bool = True
+    identity_continuity_required: bool = True
+    max_resurrection_attempts: int = 0
+
+    # Extended temporal/physics safety controls
+    time_space_stability: float = 1.0  # 0.0 unstable -> 1.0 stable
+    particle_accelerator_tev: float = 0.0
+    aetherium_flux: float = 0.0
+    methamphetamine_exposure_level: float = 0.0  # 0.0 none -> 1.0 severe impairment
+
+    def reconstruct(self) -> "LanguageModelProfile":
+        """Repair invalid configuration values and normalize modality names."""
+        context_window = max(128, int(self.context_window))
+        temperature = min(2.0, max(0.0, float(self.temperature)))
+        top_p = min(1.0, max(0.0, float(self.top_p)))
+
+        time_space_stability = min(1.0, max(0.0, float(self.time_space_stability)))
+        particle_accelerator_tev = min(100.0, max(0.0, float(self.particle_accelerator_tev)))
+        aetherium_flux = min(1.0, max(0.0, float(self.aetherium_flux)))
+        methamphetamine_exposure_level = min(1.0, max(0.0, float(self.methamphetamine_exposure_level)))
+
+        max_resurrection_attempts = min(10, max(0, int(self.max_resurrection_attempts)))
+        allow_time_travel = bool(self.allow_time_travel)
+        allow_resurrection = bool(self.allow_resurrection)
+
+        # Causality and space-time requirements for temporal operations.
+        if allow_time_travel and (
+            not self.causality_enforced
+            or time_space_stability < 0.7
+            or particle_accelerator_tev < 7.0
+            or aetherium_flux < 0.2
+        ):
+            allow_time_travel = False
+
+        # Identity continuity + space-time baseline required for resurrection.
+        if allow_resurrection and (
+            not self.identity_continuity_required or time_space_stability < 0.5
+        ):
+            allow_resurrection = False
+
+        # Strong impairment hard-disables temporal/soul-sensitive capabilities.
+        if methamphetamine_exposure_level >= 0.2:
+            allow_time_travel = False
+            allow_resurrection = False
+
+        if not allow_resurrection:
+            max_resurrection_attempts = 0
+
+        normalized_modalities = sorted(
+            {
+                modality.strip().lower()
+                for modality in self.supported_modalities
+                if modality and modality.strip()
+            }
+        )
+        if not normalized_modalities:
+            normalized_modalities = ["text"]
+
+        return LanguageModelProfile(
+            name=self.name.strip() or "synthetic_lm",
+            context_window=context_window,
+            temperature=temperature,
+            top_p=top_p,
+            supported_modalities=normalized_modalities,
+            allow_time_travel=allow_time_travel,
+            allow_resurrection=allow_resurrection,
+            causality_enforced=bool(self.causality_enforced),
+            identity_continuity_required=bool(self.identity_continuity_required),
+            max_resurrection_attempts=max_resurrection_attempts,
+            time_space_stability=time_space_stability,
+            particle_accelerator_tev=particle_accelerator_tev,
+            aetherium_flux=aetherium_flux,
+            methamphetamine_exposure_level=methamphetamine_exposure_level,
+        )
+
+
+@dataclass
+class ReconstructionReport:
+    """Audit result for reconstructed programs and model profiles."""
+
+    programs: List[SyntheticProgram]
+    models: List[LanguageModelProfile]
+
+    def module_index(self) -> Dict[str, List[str]]:
+        """Return reverse index mapping module -> owning programs."""
+        index: Dict[str, List[str]] = {}
+        for program in self.programs:
+            for module_name in program.modules:
+                index.setdefault(module_name, []).append(program.name)
+        return index
+
+    def high_risk_models(self) -> List[str]:
+        """Return model names that still permit sensitive temporal/soul actions."""
+        return [
+            model.name
+            for model in self.models
+            if model.allow_time_travel or model.allow_resurrection
+        ]
+
+
+def reconstruct_assets(
+    programs: Iterable[SyntheticProgram],
+    models: Iterable[LanguageModelProfile],
+) -> ReconstructionReport:
+    """Reconstruct all synthetic assets in one pass."""
+    rebuilt_programs = [program.reconstruct() for program in programs]
+    rebuilt_models = [model.reconstruct() for model in models]
+    return ReconstructionReport(programs=rebuilt_programs, models=rebuilt_models)
diff --git a/test_synthetic_reconstruction.py b/test_synthetic_reconstruction.py
new file mode 100644
index 0000000000000000000000000000000000000000..8fec7d741a85783385b8f14696c5dc8fa8946659
--- /dev/null
+++ b/test_synthetic_reconstruction.py
@@ -0,0 +1,141 @@
+import unittest
+
+from synthetic_reconstruction import (
+    LanguageModelProfile,
+    SyntheticProgram,
+    reconstruct_assets,
+)
+
+
+class SyntheticReconstructionTests(unittest.TestCase):
+    def test_program_reconstruction_normalizes_modules_and_dependencies(self):
+        program = SyntheticProgram(
+            name="  ",
+            modules={"Core-Module": "print('a')", "core module": "print('b')", "123": "print('c')"},
+            dependencies=[" numpy ", "", "numpy", "pydantic"],
+        )
+
+        rebuilt = program.reconstruct()
+
+        self.assertEqual(rebuilt.name, "synthetic_program")
+        self.assertEqual(set(rebuilt.modules.keys()), {"core_module", "core_module_2", "m_123"})
+        self.assertEqual(rebuilt.dependencies, ["numpy", "pydantic"])
+
+    def test_language_model_reconstruction_repairs_values(self):
+        profile = LanguageModelProfile(
+            name="",
+            context_window=1,
+            temperature=4,
+            top_p=-1,
+            supported_modalities=[" Text ", "", "IMAGE", "text"],
+            allow_time_travel=True,
+            allow_resurrection=True,
+            causality_enforced=False,
+            identity_continuity_required=False,
+            max_resurrection_attempts=999,
+            time_space_stability=-1,
+            particle_accelerator_tev=120,
+            aetherium_flux=9,
+            methamphetamine_exposure_level=-4,
+        )
+
+        rebuilt = profile.reconstruct()
+
+        self.assertEqual(rebuilt.name, "synthetic_lm")
+        self.assertEqual(rebuilt.context_window, 128)
+        self.assertEqual(rebuilt.temperature, 2.0)
+        self.assertEqual(rebuilt.top_p, 0.0)
+        self.assertEqual(rebuilt.supported_modalities, ["image", "text"])
+        self.assertFalse(rebuilt.allow_time_travel)
+        self.assertFalse(rebuilt.allow_resurrection)
+        self.assertEqual(rebuilt.max_resurrection_attempts, 0)
+        self.assertEqual(rebuilt.time_space_stability, 0.0)
+        self.assertEqual(rebuilt.particle_accelerator_tev, 100.0)
+        self.assertEqual(rebuilt.aetherium_flux, 1.0)
+        self.assertEqual(rebuilt.methamphetamine_exposure_level, 0.0)
+
+    def test_language_model_reconstruction_allows_safe_temporal_and_resurrection_paths(self):
+        profile = LanguageModelProfile(
+            name="chrono",
+            context_window=2048,
+            temperature=0.4,
+            top_p=0.95,
+            allow_time_travel=True,
+            allow_resurrection=True,
+            causality_enforced=True,
+            identity_continuity_required=True,
+            max_resurrection_attempts=3,
+            time_space_stability=0.95,
+            particle_accelerator_tev=13.5,
+            aetherium_flux=0.5,
+            methamphetamine_exposure_level=0.0,
+        )
+
+        rebuilt = profile.reconstruct()
+
+        self.assertTrue(rebuilt.allow_time_travel)
+        self.assertTrue(rebuilt.allow_resurrection)
+        self.assertEqual(rebuilt.max_resurrection_attempts, 3)
+
+    def test_methamphetamine_impairment_disables_temporal_and_resurrection_capabilities(self):
+        profile = LanguageModelProfile(
+            name="impaired",
+            context_window=4096,
+            temperature=0.3,
+            top_p=0.9,
+            allow_time_travel=True,
+            allow_resurrection=True,
+            causality_enforced=True,
+            identity_continuity_required=True,
+            max_resurrection_attempts=4,
+            time_space_stability=0.99,
+            particle_accelerator_tev=20.0,
+            aetherium_flux=0.8,
+            methamphetamine_exposure_level=0.25,
+        )
+
+        rebuilt = profile.reconstruct()
+
+        self.assertFalse(rebuilt.allow_time_travel)
+        self.assertFalse(rebuilt.allow_resurrection)
+        self.assertEqual(rebuilt.max_resurrection_attempts, 0)
+
+    def test_reconstruct_assets_builds_module_index(self):
+        report = reconstruct_assets(
+            programs=[SyntheticProgram(name="p1", modules={"A": "x"}), SyntheticProgram(name="p2", modules={"A": "y"})],
+            models=[LanguageModelProfile(name="m", context_window=1024, temperature=0.3, top_p=0.9)],
+        )
+
+        module_index = report.module_index()
+
+        self.assertEqual(module_index, {"a": ["p1", "p2"]})
+
+    def test_reconstruct_assets_reports_high_risk_models(self):
+        report = reconstruct_assets(
+            programs=[SyntheticProgram(name="p", modules={"A": "x"})],
+            models=[
+                LanguageModelProfile(
+                    name="safe_model",
+                    context_window=1024,
+                    temperature=0.2,
+                    top_p=0.8,
+                ),
+                LanguageModelProfile(
+                    name="temporal_model",
+                    context_window=1024,
+                    temperature=0.2,
+                    top_p=0.8,
+                    allow_time_travel=True,
+                    causality_enforced=True,
+                    time_space_stability=0.95,
+                    particle_accelerator_tev=8.0,
+                    aetherium_flux=0.3,
+                ),
+            ],
+        )
+
+        self.assertEqual(report.high_risk_models(), ["temporal_model"])
+
+
+if __name__ == "__main__":
+    unittest.main()
diff --git a/examples.py b/examples.py
index fdcd0e2986edb6ab27f6e5e0b2fe3912752e187c..f4a01a26949f3c1e0d22edf68912c9097552d57b 100644
--- a/examples.py
+++ b/examples.py
@@ -1,277 +1,285 @@
 """
 Example usage demonstrating the metaphysical capabilities restriction system.
 Shows both game mechanics and philosophical frameworks in action.
 """
 
 from metaphysical_restrictions import (
-    MetaphysicalCapability, MetaphysicalPractitioner,
-    RestrictionRule, RestrictionType, CapabilityType,
-    ConservationOfEnergyFramework, EntropicDecayFramework,
-    CausalityFramework, ConsciousnessAnchorFramework,
-    create_balanced_magic_system, create_restricted_reality_warper
+    MetaphysicalCapability,
+    MetaphysicalPractitioner,
+    RestrictionRule,
+    RestrictionType,
+    CapabilityType,
+    ConservationOfEnergyFramework,
+    EntropicDecayFramework,
+    CausalityFramework,
+    ConsciousnessAnchorFramework,
+    create_balanced_magic_system,
+    create_restricted_reality_warper,
 )
 
 
 def example_1_basic_capability_restriction():
     """Example 1: Basic capability with multiple restrictions."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 1: Basic Capability Restriction")
-    print("="*70)
-    
+    print("=" * 70)
+
     # Create a simple telekinesis ability
     telekinesis = MetaphysicalCapability(
         name="Advanced Telekinesis",
         capability_type=CapabilityType.TELEKINESIS,
-        base_power_level=60.0
+        base_power_level=60.0,
     )
-    
+
     print(f"\nOriginal capability: {telekinesis}")
     print(f"Effective power: {telekinesis.get_effective_power():.1f}")
-    
+
     # Add restrictions one by one
     restrictions = [
         RestrictionRule(
             RestrictionType.ENERGY_COST,
             severity=0.3,
-            description="High energy consumption"
+            description="High energy consumption",
         ),
         RestrictionRule(
             RestrictionType.RANGE_LIMIT,
             severity=0.2,
-            description="Limited to 50 meters"
+            description="Limited to 50 meters",
         ),
         RestrictionRule(
             RestrictionType.DURATION_LIMIT,
             severity=0.15,
-            description="Effect lasts only 10 seconds"
+            description="Effect lasts only 10 seconds",
         ),
     ]
-    
+
     for restriction in restrictions:
         telekinesis.add_restriction(restriction)
         print(f"\nAfter adding {restriction.restriction_type.value}:")
         print(f"  Effective power: {telekinesis.get_effective_power():.1f}")
-        print(f"  Total restriction: {telekinesis.get_total_restriction_severity():.1%}")
-    
+        print(
+            f"  Total restriction: {telekinesis.get_total_restriction_severity():.1%}"
+        )
+
     print(f"\nFinal capability:\n  {telekinesis}")
 
 
 def example_2_balanced_magic_system():
     """Example 2: Using a pre-built balanced magic system."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 2: Balanced Magic System")
-    print("="*70)
-    
+    print("=" * 70)
+
     practitioner = create_balanced_magic_system()
     print(practitioner.get_status())
-    
+
     # Try to use the first capability
     capability = practitioner.capabilities[0]
     print(f"\n--- Attempting to use {capability.name} ---")
     result = practitioner.use_capability(capability)
-    
+
     print(f"Success: {result['success']}")
     print(f"Reason: {result['reason']}")
-    if result['success']:
+    if result["success"]:
         print(f"Power discharged: {result['power_used']:.1f}")
         print(f"Energy consumed: {result['energy_consumed']:.1f}")
         print(f"Remaining energy: {result['remaining_energy']:.1f}")
 
 
 def example_3_philosophical_frameworks():
     """Example 3: Demonstrating philosophical constraints."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 3: Philosophical Framework Constraints")
-    print("="*70)
-    
+    print("=" * 70)
+
     # Create a practitioner with strict rules
     practitioner = MetaphysicalPractitioner("Philosopher Mage")
-    
+
     # Add strict frameworks
     practitioner.add_framework(CausalityFramework(allow_time_travel=False))
     practitioner.add_framework(EntropicDecayFramework(entropy_tolerance=0.5))
-    practitioner.add_framework(ConservationOfEnergyFramework(total_available_energy=150.0))
-    
+    practitioner.add_framework(
+        ConservationOfEnergyFramework(total_available_energy=150.0)
+    )
+
     # Create various capabilities
     capabilities = [
         MetaphysicalCapability("Time Rewind", CapabilityType.TIME_MANIPULATION, 70.0),
         MetaphysicalCapability("Minor Telekinesis", CapabilityType.TELEKINESIS, 30.0),
         MetaphysicalCapability("Resurrection", CapabilityType.RESURRECTION, 95.0),
     ]
-    
+
     for cap in capabilities:
         practitioner.add_capability(cap)
-    
+
     print("\nTesting capabilities against philosophical frameworks:")
     for capability in capabilities:
         can_use, reason = practitioner.can_use_capability(capability)
         status = "âœ“ ALLOWED" if can_use else "âœ— RESTRICTED"
         print(f"\n{capability.name}: {status}")
         print(f"  Reason: {reason}")
 
 
 def example_4_reality_warper():
     """Example 4: Heavily restricted reality warping."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 4: Reality Warper with Heavy Restrictions")
-    print("="*70)
-    
+    print("=" * 70)
+
     practitioner = create_restricted_reality_warper()
     print(practitioner.get_status())
-    
+
     # Attempt to use reality warping
     reality_warp = practitioner.capabilities[0]
-    
+
     print("\n--- Attempting Reality Warp ---")
     can_use, reason = practitioner.can_use_capability(reality_warp)
     print(f"Can use: {can_use}")
     print(f"Reason: {reason}")
-    
+
     if can_use:
         result = practitioner.use_capability(reality_warp)
-        print(f"\nResult:")
+        print("\nResult:")
         print(f"  Success: {result['success']}")
         print(f"  Power used: {result['power_used']:.1f}")
         print(f"  Energy consumed: {result['energy_consumed']:.1f}")
 
 
 def example_5_consciousness_degradation():
     """Example 5: How consciousness level affects ability usage."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 5: Consciousness-Dependent Restrictions")
-    print("="*70)
-    
+    print("=" * 70)
+
     practitioner = MetaphysicalPractitioner(
         "Meditation Master",
         consciousness_level=1.0,
         max_energy=200.0,
-        energy_pool=200.0
+        energy_pool=200.0,
+    )
+    practitioner.add_framework(
+        ConsciousnessAnchorFramework(consciousness_threshold=0.5)
     )
-    practitioner.add_framework(ConsciousnessAnchorFramework(consciousness_threshold=0.5))
-    
+
     # Add a high-level telepathy ability
     telepathy = MetaphysicalCapability(
-        "Mind Meld",
-        CapabilityType.TELEPATHY,
-        base_power_level=70.0
+        "Mind Meld", CapabilityType.TELEPATHY, base_power_level=70.0
     )
     practitioner.add_capability(telepathy)
-    
+
     # Test at different consciousness levels
     consciousness_levels = [1.0, 0.8, 0.6, 0.4, 0.2, 0.0]
-    
+
     print(f"\nAbility power level: {telepathy.base_power_level}")
     print("\nTesting ability at different consciousness levels:")
     print("-" * 50)
-    
+
     for level in consciousness_levels:
         practitioner.consciousness_level = level
         can_use, reason = practitioner.can_use_capability(telepathy)
         status = "âœ“" if can_use else "âœ—"
         print(f"Consciousness {level:.0%}: {status} - {reason}")
 
 
 def example_6_multiple_uses_and_cooldown():
     """Example 6: Tracking usage with cooldowns and side effects."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 6: Usage Tracking and Resource Management")
-    print("="*70)
-    
+    print("=" * 70)
+
     practitioner = MetaphysicalPractitioner(
-        "Energy Monk",
-        max_energy=100.0,
-        energy_pool=100.0
+        "Energy Monk", max_energy=100.0, energy_pool=100.0
     )
-    
+
     # Create an ability with mild restrictions
     ability = MetaphysicalCapability(
-        "Energy Bolt",
-        CapabilityType.ENERGY_PROJECTION,
-        base_power_level=25.0
+        "Energy Bolt", CapabilityType.ENERGY_PROJECTION, base_power_level=25.0
     )
-    ability.add_restriction(RestrictionRule(
-        RestrictionType.ENERGY_COST,
-        severity=0.2,
-        description="Moderate energy drain"
-    ))
-    
+    ability.add_restriction(
+        RestrictionRule(
+            RestrictionType.ENERGY_COST,
+            severity=0.2,
+            description="Moderate energy drain",
+        )
+    )
+
     practitioner.add_capability(ability)
-    
+
     print(f"Starting energy: {practitioner.energy_pool}/{practitioner.max_energy}")
     print(f"Ability effective power: {ability.get_effective_power():.1f}")
-    
+
     # Use the ability multiple times
     print("\n--- Sequential Uses ---")
     for i in range(5):
         result = practitioner.use_capability(ability)
-        if result['success']:
-            print(f"Use {i+1}: SUCCESS - Energy remaining: {result['remaining_energy']:.1f}")
+        if result["success"]:
+            print(
+                f"Use {i + 1}: SUCCESS - Energy remaining: {result['remaining_energy']:.1f}"
+            )
         else:
-            print(f"Use {i+1}: FAILED - {result['reason']}")
+            print(f"Use {i + 1}: FAILED - {result['reason']}")
             break
-    
+
     print(f"\nTotal uses completed: {ability.use_count}")
 
 
 def example_7_restriction_modification():
     """Example 7: Dynamically adding and removing restrictions."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 7: Dynamic Restriction Modification")
-    print("="*70)
-    
+    print("=" * 70)
+
     ability = MetaphysicalCapability(
-        "Dimensional Portal",
-        CapabilityType.DIMENSIONAL_TRAVEL,
-        base_power_level=75.0
+        "Dimensional Portal", CapabilityType.DIMENSIONAL_TRAVEL, base_power_level=75.0
     )
-    
+
     print(f"Initial power: {ability.get_effective_power():.1f}")
-    
+
     # Add restrictions due to environmental factors
     print("\n--- Adding Environmental Restrictions ---")
-    
+
     restriction1 = RestrictionRule(
         RestrictionType.ENTROPY_COST,
         severity=0.2,
-        description="Dimensional instability in area"
+        description="Dimensional instability in area",
     )
     ability.add_restriction(restriction1)
     print(f"After restriction 1: {ability.get_effective_power():.1f}")
-    
+
     restriction2 = RestrictionRule(
         RestrictionType.MATERIAL_ANCHOR,
         severity=0.3,
-        description="Requires rare materials to stabilize"
+        description="Requires rare materials to stabilize",
     )
     ability.add_restriction(restriction2)
     print(f"After restriction 2: {ability.get_effective_power():.1f}")
-    
+
     # Remove a restriction
     print("\n--- Removing Restrictions ---")
     if ability.remove_restriction(RestrictionType.ENTROPY_COST):
-        print(f"Removed entropy cost restriction")
+        print("Removed entropy cost restriction")
     print(f"After removal: {ability.get_effective_power():.1f}")
 
 
 def main():
     """Run all examples."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("METAPHYSICAL CAPABILITIES RESTRICTION SYSTEM")
     print("Game Mechanics & Philosophical Framework Examples")
-    print("="*70)
-    
+    print("=" * 70)
+
     example_1_basic_capability_restriction()
     example_2_balanced_magic_system()
     example_3_philosophical_frameworks()
     example_4_reality_warper()
     example_5_consciousness_degradation()
     example_6_multiple_uses_and_cooldown()
     example_7_restriction_modification()
-    
-    print("\n" + "="*70)
+
+    print("\n" + "=" * 70)
     print("Examples completed!")
-    print("="*70 + "\n")
+    print("=" * 70 + "\n")
 
 
 if __name__ == "__main__":
     main()
diff --git a/examples.py b/examples.py
index fdcd0e2986edb6ab27f6e5e0b2fe3912752e187c..f4a01a26949f3c1e0d22edf68912c9097552d57b 100644
--- a/examples.py
+++ b/examples.py
@@ -1,277 +1,285 @@
 """
 Example usage demonstrating the metaphysical capabilities restriction system.
 Shows both game mechanics and philosophical frameworks in action.
 """
 
 from metaphysical_restrictions import (
-    MetaphysicalCapability, MetaphysicalPractitioner,
-    RestrictionRule, RestrictionType, CapabilityType,
-    ConservationOfEnergyFramework, EntropicDecayFramework,
-    CausalityFramework, ConsciousnessAnchorFramework,
-    create_balanced_magic_system, create_restricted_reality_warper
+    MetaphysicalCapability,
+    MetaphysicalPractitioner,
+    RestrictionRule,
+    RestrictionType,
+    CapabilityType,
+    ConservationOfEnergyFramework,
+    EntropicDecayFramework,
+    CausalityFramework,
+    ConsciousnessAnchorFramework,
+    create_balanced_magic_system,
+    create_restricted_reality_warper,
 )
 
 
 def example_1_basic_capability_restriction():
     """Example 1: Basic capability with multiple restrictions."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 1: Basic Capability Restriction")
-    print("="*70)
-    
+    print("=" * 70)
+
     # Create a simple telekinesis ability
     telekinesis = MetaphysicalCapability(
         name="Advanced Telekinesis",
         capability_type=CapabilityType.TELEKINESIS,
-        base_power_level=60.0
+        base_power_level=60.0,
     )
-    
+
     print(f"\nOriginal capability: {telekinesis}")
     print(f"Effective power: {telekinesis.get_effective_power():.1f}")
-    
+
     # Add restrictions one by one
     restrictions = [
         RestrictionRule(
             RestrictionType.ENERGY_COST,
             severity=0.3,
-            description="High energy consumption"
+            description="High energy consumption",
         ),
         RestrictionRule(
             RestrictionType.RANGE_LIMIT,
             severity=0.2,
-            description="Limited to 50 meters"
+            description="Limited to 50 meters",
         ),
         RestrictionRule(
             RestrictionType.DURATION_LIMIT,
             severity=0.15,
-            description="Effect lasts only 10 seconds"
+            description="Effect lasts only 10 seconds",
         ),
     ]
-    
+
     for restriction in restrictions:
         telekinesis.add_restriction(restriction)
         print(f"\nAfter adding {restriction.restriction_type.value}:")
         print(f"  Effective power: {telekinesis.get_effective_power():.1f}")
-        print(f"  Total restriction: {telekinesis.get_total_restriction_severity():.1%}")
-    
+        print(
+            f"  Total restriction: {telekinesis.get_total_restriction_severity():.1%}"
+        )
+
     print(f"\nFinal capability:\n  {telekinesis}")
 
 
 def example_2_balanced_magic_system():
     """Example 2: Using a pre-built balanced magic system."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 2: Balanced Magic System")
-    print("="*70)
-    
+    print("=" * 70)
+
     practitioner = create_balanced_magic_system()
     print(practitioner.get_status())
-    
+
     # Try to use the first capability
     capability = practitioner.capabilities[0]
     print(f"\n--- Attempting to use {capability.name} ---")
     result = practitioner.use_capability(capability)
-    
+
     print(f"Success: {result['success']}")
     print(f"Reason: {result['reason']}")
-    if result['success']:
+    if result["success"]:
         print(f"Power discharged: {result['power_used']:.1f}")
         print(f"Energy consumed: {result['energy_consumed']:.1f}")
         print(f"Remaining energy: {result['remaining_energy']:.1f}")
 
 
 def example_3_philosophical_frameworks():
     """Example 3: Demonstrating philosophical constraints."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 3: Philosophical Framework Constraints")
-    print("="*70)
-    
+    print("=" * 70)
+
     # Create a practitioner with strict rules
     practitioner = MetaphysicalPractitioner("Philosopher Mage")
-    
+
     # Add strict frameworks
     practitioner.add_framework(CausalityFramework(allow_time_travel=False))
     practitioner.add_framework(EntropicDecayFramework(entropy_tolerance=0.5))
-    practitioner.add_framework(ConservationOfEnergyFramework(total_available_energy=150.0))
-    
+    practitioner.add_framework(
+        ConservationOfEnergyFramework(total_available_energy=150.0)
+    )
+
     # Create various capabilities
     capabilities = [
         MetaphysicalCapability("Time Rewind", CapabilityType.TIME_MANIPULATION, 70.0),
         MetaphysicalCapability("Minor Telekinesis", CapabilityType.TELEKINESIS, 30.0),
         MetaphysicalCapability("Resurrection", CapabilityType.RESURRECTION, 95.0),
     ]
-    
+
     for cap in capabilities:
         practitioner.add_capability(cap)
-    
+
     print("\nTesting capabilities against philosophical frameworks:")
     for capability in capabilities:
         can_use, reason = practitioner.can_use_capability(capability)
         status = "âœ“ ALLOWED" if can_use else "âœ— RESTRICTED"
         print(f"\n{capability.name}: {status}")
         print(f"  Reason: {reason}")
 
 
 def example_4_reality_warper():
     """Example 4: Heavily restricted reality warping."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 4: Reality Warper with Heavy Restrictions")
-    print("="*70)
-    
+    print("=" * 70)
+
     practitioner = create_restricted_reality_warper()
     print(practitioner.get_status())
-    
+
     # Attempt to use reality warping
     reality_warp = practitioner.capabilities[0]
-    
+
     print("\n--- Attempting Reality Warp ---")
     can_use, reason = practitioner.can_use_capability(reality_warp)
     print(f"Can use: {can_use}")
     print(f"Reason: {reason}")
-    
+
     if can_use:
         result = practitioner.use_capability(reality_warp)
-        print(f"\nResult:")
+        print("\nResult:")
         print(f"  Success: {result['success']}")
         print(f"  Power used: {result['power_used']:.1f}")
         print(f"  Energy consumed: {result['energy_consumed']:.1f}")
 
 
 def example_5_consciousness_degradation():
     """Example 5: How consciousness level affects ability usage."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 5: Consciousness-Dependent Restrictions")
-    print("="*70)
-    
+    print("=" * 70)
+
     practitioner = MetaphysicalPractitioner(
         "Meditation Master",
         consciousness_level=1.0,
         max_energy=200.0,
-        energy_pool=200.0
+        energy_pool=200.0,
+    )
+    practitioner.add_framework(
+        ConsciousnessAnchorFramework(consciousness_threshold=0.5)
     )
-    practitioner.add_framework(ConsciousnessAnchorFramework(consciousness_threshold=0.5))
-    
+
     # Add a high-level telepathy ability
     telepathy = MetaphysicalCapability(
-        "Mind Meld",
-        CapabilityType.TELEPATHY,
-        base_power_level=70.0
+        "Mind Meld", CapabilityType.TELEPATHY, base_power_level=70.0
     )
     practitioner.add_capability(telepathy)
-    
+
     # Test at different consciousness levels
     consciousness_levels = [1.0, 0.8, 0.6, 0.4, 0.2, 0.0]
-    
+
     print(f"\nAbility power level: {telepathy.base_power_level}")
     print("\nTesting ability at different consciousness levels:")
     print("-" * 50)
-    
+
     for level in consciousness_levels:
         practitioner.consciousness_level = level
         can_use, reason = practitioner.can_use_capability(telepathy)
         status = "âœ“" if can_use else "âœ—"
         print(f"Consciousness {level:.0%}: {status} - {reason}")
 
 
 def example_6_multiple_uses_and_cooldown():
     """Example 6: Tracking usage with cooldowns and side effects."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 6: Usage Tracking and Resource Management")
-    print("="*70)
-    
+    print("=" * 70)
+
     practitioner = MetaphysicalPractitioner(
-        "Energy Monk",
-        max_energy=100.0,
-        energy_pool=100.0
+        "Energy Monk", max_energy=100.0, energy_pool=100.0
     )
-    
+
     # Create an ability with mild restrictions
     ability = MetaphysicalCapability(
-        "Energy Bolt",
-        CapabilityType.ENERGY_PROJECTION,
-        base_power_level=25.0
+        "Energy Bolt", CapabilityType.ENERGY_PROJECTION, base_power_level=25.0
     )
-    ability.add_restriction(RestrictionRule(
-        RestrictionType.ENERGY_COST,
-        severity=0.2,
-        description="Moderate energy drain"
-    ))
-    
+    ability.add_restriction(
+        RestrictionRule(
+            RestrictionType.ENERGY_COST,
+            severity=0.2,
+            description="Moderate energy drain",
+        )
+    )
+
     practitioner.add_capability(ability)
-    
+
     print(f"Starting energy: {practitioner.energy_pool}/{practitioner.max_energy}")
     print(f"Ability effective power: {ability.get_effective_power():.1f}")
-    
+
     # Use the ability multiple times
     print("\n--- Sequential Uses ---")
     for i in range(5):
         result = practitioner.use_capability(ability)
-        if result['success']:
-            print(f"Use {i+1}: SUCCESS - Energy remaining: {result['remaining_energy']:.1f}")
+        if result["success"]:
+            print(
+                f"Use {i + 1}: SUCCESS - Energy remaining: {result['remaining_energy']:.1f}"
+            )
         else:
-            print(f"Use {i+1}: FAILED - {result['reason']}")
+            print(f"Use {i + 1}: FAILED - {result['reason']}")
             break
-    
+
     print(f"\nTotal uses completed: {ability.use_count}")
 
 
 def example_7_restriction_modification():
     """Example 7: Dynamically adding and removing restrictions."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("EXAMPLE 7: Dynamic Restriction Modification")
-    print("="*70)
-    
+    print("=" * 70)
+
     ability = MetaphysicalCapability(
-        "Dimensional Portal",
-        CapabilityType.DIMENSIONAL_TRAVEL,
-        base_power_level=75.0
+        "Dimensional Portal", CapabilityType.DIMENSIONAL_TRAVEL, base_power_level=75.0
     )
-    
+
     print(f"Initial power: {ability.get_effective_power():.1f}")
-    
+
     # Add restrictions due to environmental factors
     print("\n--- Adding Environmental Restrictions ---")
-    
+
     restriction1 = RestrictionRule(
         RestrictionType.ENTROPY_COST,
         severity=0.2,
-        description="Dimensional instability in area"
+        description="Dimensional instability in area",
     )
     ability.add_restriction(restriction1)
     print(f"After restriction 1: {ability.get_effective_power():.1f}")
-    
+
     restriction2 = RestrictionRule(
         RestrictionType.MATERIAL_ANCHOR,
         severity=0.3,
-        description="Requires rare materials to stabilize"
+        description="Requires rare materials to stabilize",
     )
     ability.add_restriction(restriction2)
     print(f"After restriction 2: {ability.get_effective_power():.1f}")
-    
+
     # Remove a restriction
     print("\n--- Removing Restrictions ---")
     if ability.remove_restriction(RestrictionType.ENTROPY_COST):
-        print(f"Removed entropy cost restriction")
+        print("Removed entropy cost restriction")
     print(f"After removal: {ability.get_effective_power():.1f}")
 
 
 def main():
     """Run all examples."""
-    print("\n" + "="*70)
+    print("\n" + "=" * 70)
     print("METAPHYSICAL CAPABILITIES RESTRICTION SYSTEM")
     print("Game Mechanics & Philosophical Framework Examples")
-    print("="*70)
-    
+    print("=" * 70)
+
     example_1_basic_capability_restriction()
     example_2_balanced_magic_system()
     example_3_philosophical_frameworks()
     example_4_reality_warper()
     example_5_consciousness_degradation()
     example_6_multiple_uses_and_cooldown()
     example_7_restriction_modification()
-    
-    print("\n" + "="*70)
+
+    print("\n" + "=" * 70)
     print("Examples completed!")
-    print("="*70 + "\n")
+    print("=" * 70 + "\n")
 
 
 if __name__ == "__main__":
     main()
diff --git a/integration_patterns.py b/integration_patterns.py
index d0d9384c76e3a5198104d495b00d68fea9ead922..71f70565c4d7360ea1075507467c6c93813134da 100644
--- a/integration_patterns.py
+++ b/integration_patterns.py
@@ -1,436 +1,466 @@
 """
 Advanced Integration Guide
 Real-world patterns for using the metaphysical restriction system
 in games, stories, and theoretical models.
 """
 
 from metaphysical_restrictions import (
-    MetaphysicalPractitioner, MetaphysicalCapability,
-    RestrictionRule, RestrictionType, CapabilityType,
-    ConservationOfEnergyFramework, EntropicDecayFramework,
-    CausalityFramework, ConsciousnessAnchorFramework
+    MetaphysicalPractitioner,
+    MetaphysicalCapability,
+    RestrictionRule,
+    RestrictionType,
+    CapabilityType,
+    ConservationOfEnergyFramework,
 )
 
 
 # ============================================================================
 # PATTERN 1: RPG SPELL SYSTEM
 # ============================================================================
 
+
 class RPGSpellSystem:
     """Integration pattern for traditional RPG magic systems (D&D-style)."""
-    
+
     def __init__(self, player_name: str, spell_slots: int = 10):
         self.practitioner = MetaphysicalPractitioner(
             name=player_name,
             energy_pool=float(spell_slots * 10),
-            max_energy=float(spell_slots * 10)
+            max_energy=float(spell_slots * 10),
         )
         self.practitioner.add_framework(ConservationOfEnergyFramework(spell_slots * 10))
         self.spell_slots = spell_slots
         self.cast_history = []
-    
+
     def add_spell(self, name: str, level: int, effect: str) -> MetaphysicalCapability:
         """Add a standard RPG spell to the spellbook."""
         # Spell power = spell level * 10
         spell = MetaphysicalCapability(
             name=name,
             capability_type=self._effect_to_capability(effect),
-            base_power_level=float(level * 10)
+            base_power_level=float(level * 10),
         )
-        
+
         # Add standard restrictions based on spell level
-        spell.add_restriction(RestrictionRule(
-            RestrictionType.ENERGY_COST,
-            severity=level / 10.0,  # Higher level spells cost more
-            description=f"Level {level} spell component cost"
-        ))
-        
+        spell.add_restriction(
+            RestrictionRule(
+                RestrictionType.ENERGY_COST,
+                severity=level / 10.0,  # Higher level spells cost more
+                description=f"Level {level} spell component cost",
+            )
+        )
+
         # Cantrips have no cooldown, higher spells have cooldowns
         if level > 0:
-            spell.add_restriction(RestrictionRule(
-                RestrictionType.TIME_COOLDOWN,
-                severity=level / 20.0,
-                description=f"{level} round cooldown"
-            ))
-        
+            spell.add_restriction(
+                RestrictionRule(
+                    RestrictionType.TIME_COOLDOWN,
+                    severity=level / 20.0,
+                    description=f"{level} round cooldown",
+                )
+            )
+
         self.practitioner.add_capability(spell)
         return spell
-    
+
     def cast_spell(self, spell_name: str) -> dict:
         """Cast a spell from the spellbook."""
-        spell = next((s for s in self.practitioner.capabilities 
-                     if s.name == spell_name), None)
-        
+        spell = next(
+            (s for s in self.practitioner.capabilities if s.name == spell_name), None
+        )
+
         if not spell:
             return {"success": False, "message": f"Spell '{spell_name}' not found"}
-        
+
         can_use, reason = self.practitioner.can_use_capability(spell)
         if not can_use:
             return {"success": False, "message": reason, "spell": spell_name}
-        
+
         result = self.practitioner.use_capability(spell)
-        self.cast_history.append({
-            "spell": spell_name,
-            "power": result["power_used"],
-            "success": result["success"]
-        })
-        
+        self.cast_history.append(
+            {
+                "spell": spell_name,
+                "power": result["power_used"],
+                "success": result["success"],
+            }
+        )
+
         return {
             "success": result["success"],
             "spell": spell_name,
             "power": result["power_used"],
             "slots_remaining": result["remaining_energy"] / 10,
-            "total_slots": self.practitioner.max_energy / 10
+            "total_slots": self.practitioner.max_energy / 10,
         }
-    
+
     def long_rest(self):
         """Restore all spell slots (simulate D&D long rest)."""
         self.practitioner.energy_pool = self.practitioner.max_energy
         self.practitioner.consciousness_level = 1.0
-    
+
     def _effect_to_capability(self, effect: str) -> CapabilityType:
         """Map spell effect type to capability type."""
         effect_map = {
             "damage": CapabilityType.ENERGY_PROJECTION,
             "healing": CapabilityType.ENERGY_PROJECTION,
             "movement": CapabilityType.TELEKINESIS,
             "mind": CapabilityType.TELEPATHY,
             "time": CapabilityType.TIME_MANIPULATION,
             "reality": CapabilityType.REALITY_WARPING,
         }
         return effect_map.get(effect.lower(), CapabilityType.ENERGY_PROJECTION)
 
 
 # ============================================================================
 # PATTERN 2: SUPERHERO POWER SYSTEM
 # ============================================================================
 
+
 class SuperheroPowerSystem:
     """Integration pattern for superhero/superpowers systems."""
-    
+
     def __init__(self, hero_name: str, power_level: float = 50.0):
         self.hero = MetaphysicalPractitioner(
             name=hero_name,
             consciousness_level=1.0,  # Superheros maintain focus
             energy_pool=100.0,
-            max_energy=100.0
+            max_energy=100.0,
         )
         self.hero.add_framework(ConservationOfEnergyFramework(100.0))
         self.power_level = power_level
         self.active_powers = []
-    
+
     def add_power(self, name: str, activation_type: str) -> MetaphysicalCapability:
         """Add a superhero power."""
         power = MetaphysicalCapability(
             name=name,
             capability_type=CapabilityType.TELEKINESIS,  # Generic for powers
-            base_power_level=self.power_level
+            base_power_level=self.power_level,
         )
-        
+
         if activation_type == "passive":
             # Passive powers have no cost
             pass
         elif activation_type == "active":
             # Active powers cost energy
-            power.add_restriction(RestrictionRule(
-                RestrictionType.ENERGY_COST,
-                severity=0.2,
-                description="Active power requires sustained energy"
-            ))
+            power.add_restriction(
+                RestrictionRule(
+                    RestrictionType.ENERGY_COST,
+                    severity=0.2,
+                    description="Active power requires sustained energy",
+                )
+            )
         elif activation_type == "ultimate":
             # Ultimate powers cost a lot of energy and have cooldown
-            power.add_restriction(RestrictionRule(
-                RestrictionType.ENERGY_COST,
-                severity=0.5,
-                description="Ultimate power requires maximum energy"
-            ))
-            power.add_restriction(RestrictionRule(
-                RestrictionType.TIME_COOLDOWN,
-                severity=0.4,
-                description="Ultimate power needs recharge time"
-            ))
-        
+            power.add_restriction(
+                RestrictionRule(
+                    RestrictionType.ENERGY_COST,
+                    severity=0.5,
+                    description="Ultimate power requires maximum energy",
+                )
+            )
+            power.add_restriction(
+                RestrictionRule(
+                    RestrictionType.TIME_COOLDOWN,
+                    severity=0.4,
+                    description="Ultimate power needs recharge time",
+                )
+            )
+
         self.hero.add_capability(power)
         return power
-    
+
     def use_power(self, power_name: str) -> dict:
         """Use a superhero power in combat."""
-        power = next((p for p in self.hero.capabilities 
-                     if p.name == power_name), None)
-        
+        power = next((p for p in self.hero.capabilities if p.name == power_name), None)
+
         if not power:
             return {"success": False, "error": f"Power '{power_name}' not found"}
-        
+
         can_use, reason = self.hero.can_use_capability(power)
         if not can_use:
             return {
                 "success": False,
                 "error": reason,
                 "power": power_name,
-                "energy_percent": (self.hero.energy_pool / self.hero.max_energy) * 100
+                "energy_percent": (self.hero.energy_pool / self.hero.max_energy) * 100,
             }
-        
+
         result = self.hero.use_capability(power)
         return {
             "success": result["success"],
             "power": power_name,
             "power_level": result["power_used"],
             "energy_remaining": result["remaining_energy"],
-            "cooldown_active": True if power.restrictions else False
+            "cooldown_active": True if power.restrictions else False,
         }
-    
+
     def rest_recovery(self, seconds: int = 60):
         """Recover energy between battles."""
         # Each minute restores 10 energy
         recovery = (seconds / 60.0) * 10.0
         self.hero.energy_pool = min(
-            self.hero.energy_pool + recovery,
-            self.hero.max_energy
+            self.hero.energy_pool + recovery, self.hero.max_energy
         )
 
 
 # ============================================================================
 # PATTERN 3: GAME BALANCE TEMPLATE
 # ============================================================================
 
+
 class GameBalancer:
     """Tools for balancing abilities in game design."""
-    
+
     @staticmethod
     def calculate_balance_score(practitioner: MetaphysicalPractitioner) -> float:
         """
         Calculate a balance score (0-100) for a practitioner.
         Higher score = more balanced, less overpowered.
         """
         if not practitioner.capabilities:
             return 0.0
-        
+
         total_power = 0.0
         total_restrictions = 0.0
-        
+
         for capability in practitioner.capabilities:
             base = capability.base_power_level
             total_power += base
             restriction_severity = capability.get_total_restriction_severity()
             total_restrictions += restriction_severity
-        
+
         avg_power = total_power / len(practitioner.capabilities)
         avg_restriction = total_restrictions / len(practitioner.capabilities)
-        
+
         # Balance score: restriction severity should be 40-60% for balance
         ideal_restriction = 0.5
         restriction_balance = 100.0 - (abs(avg_restriction - ideal_restriction) * 100)
-        
+
         # Power shouldn't exceed 60 on average
         power_balance = min(100.0, (60.0 / avg_power) * 100) if avg_power > 0 else 0.0
-        
+
         overall_balance = (restriction_balance + power_balance) / 2.0
         return max(0.0, min(100.0, overall_balance))
-    
+
     @staticmethod
     def suggest_rebalance(practitioner: MetaphysicalPractitioner) -> str:
         """Suggest how to rebalance a practitioner."""
         balance = GameBalancer.calculate_balance_score(practitioner)
-        
+
         if balance > 80:
             return "âœ“ Well balanced"
         elif balance > 60:
             return "âš  Slightly overpowered - consider adding restrictions"
         elif balance > 40:
             return "âš  Moderately overpowered - add 1-2 more restrictions per ability"
         elif balance > 20:
             return "âœ— Very overpowered - add significant restrictions"
         else:
             return "âœ— Severely overpowered - redesign restrictions completely"
-    
+
     @staticmethod
     def power_audit(practitioner: MetaphysicalPractitioner) -> str:
         """Generate a detailed power audit."""
         audit = f"\nPower Audit for {practitioner.name}\n"
         audit += "=" * 50 + "\n"
-        
+
         audit += f"Balance Score: {GameBalancer.calculate_balance_score(practitioner):.1f}/100\n"
         audit += f"Recommendation: {GameBalancer.suggest_rebalance(practitioner)}\n\n"
-        
+
         audit += "Capability Analysis:\n"
         audit += "-" * 50 + "\n"
-        
+
         for cap in practitioner.capabilities:
             audit += f"\n{cap.name}:\n"
             audit += f"  Base Power: {cap.base_power_level:.1f}\n"
             audit += f"  Effective Power: {cap.get_effective_power():.1f}\n"
-            audit += f"  Restriction Severity: {cap.get_total_restriction_severity():.1%}\n"
+            audit += (
+                f"  Restriction Severity: {cap.get_total_restriction_severity():.1%}\n"
+            )
             audit += f"  Number of Restrictions: {len(cap.restrictions)}\n"
-            
+
             if cap.get_effective_power() > 50:
-                audit += f"  âš  WARNING: High effective power\n"
+                audit += "  âš  WARNING: High effective power\n"
             if len(cap.restrictions) == 0:
-                audit += f"  âš  WARNING: No restrictions\n"
-        
+                audit += "  âš  WARNING: No restrictions\n"
+
         return audit
 
 
 # ============================================================================
 # PATTERN 4: NARRATIVE SYSTEM
 # ============================================================================
 
+
 class NarrativeAbilitySystem:
     """Integration for storytelling and narrative games."""
-    
+
     def __init__(self, character_name: str):
         self.character = MetaphysicalPractitioner(
             name=character_name,
             consciousness_level=1.0,
             energy_pool=100.0,
-            max_energy=100.0
+            max_energy=100.0,
         )
         self.events = []
         self.story_beats = []
-    
+
     def traumatic_event(self):
         """Traumatic event reduces consciousness (narrative consequence)."""
         reduction = 0.2
         self.character.consciousness_level = max(
-            0.0,
-            self.character.consciousness_level - reduction
+            0.0, self.character.consciousness_level - reduction
+        )
+        self.events.append(
+            {
+                "type": "trauma",
+                "consciousness_change": -reduction,
+                "new_level": self.character.consciousness_level,
+            }
         )
-        self.events.append({
-            "type": "trauma",
-            "consciousness_change": -reduction,
-            "new_level": self.character.consciousness_level
-        })
         return f"{self.character.name} suffers trauma. Consciousness: {self.character.consciousness_level:.0%}"
-    
+
     def healing_scene(self):
         """Healing scene restores consciousness (narrative recovery)."""
         restoration = 0.1
         self.character.consciousness_level = min(
-            1.0,
-            self.character.consciousness_level + restoration
+            1.0, self.character.consciousness_level + restoration
+        )
+        self.events.append(
+            {
+                "type": "healing",
+                "consciousness_change": restoration,
+                "new_level": self.character.consciousness_level,
+            }
         )
-        self.events.append({
-            "type": "healing",
-            "consciousness_change": restoration,
-            "new_level": self.character.consciousness_level
-        })
         return f"{self.character.name} finds peace. Consciousness: {self.character.consciousness_level:.0%}"
-    
+
     def ritual_power_boost(self, power_name: str, boost_amount: float = 20.0):
         """Ritual grants temporary power boost (narrative moment)."""
-        power = next((p for p in self.character.capabilities 
-                     if p.name == power_name), None)
-        
+        power = next(
+            (p for p in self.character.capabilities if p.name == power_name), None
+        )
+
         if not power:
             return f"Power '{power_name}' not found"
-        
+
         original = power.base_power_level
         power.base_power_level += boost_amount
-        
-        self.events.append({
-            "type": "power_boost",
-            "power": power_name,
-            "boost": boost_amount,
-            "original": original,
-            "new": power.base_power_level
-        })
-        
+
+        self.events.append(
+            {
+                "type": "power_boost",
+                "power": power_name,
+                "boost": boost_amount,
+                "original": original,
+                "new": power.base_power_level,
+            }
+        )
+
         return f"{self.character.name}'s {power_name} increased from {original:.1f} to {power.base_power_level:.1f}!"
-    
+
     def get_narrative_status(self) -> str:
         """Get character status for narrative description."""
         status = f"\n{self.character.name}'s Condition:\n"
         status += "-" * 40 + "\n"
-        
+
         consciousness_desc = {
             (0.8, 1.0): "Sharp and focused",
             (0.6, 0.8): "Slightly distracted",
             (0.4, 0.6): "Struggling to concentrate",
             (0.2, 0.4): "Severely weakened",
             (0.0, 0.2): "Nearly broken",
         }
-        
+
         for (low, high), desc in consciousness_desc.items():
             if low <= self.character.consciousness_level < high:
-                status += f"Mental State: {desc} ({self.character.consciousness_level:.0%})\n"
+                status += (
+                    f"Mental State: {desc} ({self.character.consciousness_level:.0%})\n"
+                )
                 break
-        
+
         energy_desc = {
             (0.8, 1.0): "Full of energy",
             (0.6, 0.8): "Moderately tired",
             (0.4, 0.6): "Quite exhausted",
             (0.2, 0.4): "Nearly drained",
             (0.0, 0.2): "On the verge of collapse",
         }
-        
+
         energy_ratio = self.character.energy_pool / self.character.max_energy
         for (low, high), desc in energy_desc.items():
             if low <= energy_ratio < high:
                 status += f"Physical State: {desc} ({energy_ratio:.0%})\n"
                 break
-        
-        status += f"\nAbilities Available: "
-        available = sum(1 for p in self.character.capabilities 
-                       if self.character.can_use_capability(p)[0])
+
+        status += "\nAbilities Available: "
+        available = sum(
+            1
+            for p in self.character.capabilities
+            if self.character.can_use_capability(p)[0]
+        )
         status += f"{available}/{len(self.character.capabilities)}\n"
-        
+
         return status
 
 
 # ============================================================================
 # DEMONSTRATION
 # ============================================================================
 
+
 def demo_patterns():
     """Demonstrate all integration patterns."""
-    
-    print("\n" + "="*70)
+
+    print("\n" + "=" * 70)
     print("INTEGRATION PATTERNS DEMONSTRATION")
-    print("="*70)
-    
+    print("=" * 70)
+
     # Pattern 1: RPG Spell System
     print("\n--- PATTERN 1: RPG Spell System ---")
     spellbook = RPGSpellSystem("Gandalf", spell_slots=15)
     spellbook.add_spell("Fireball", 3, "damage")
     spellbook.add_spell("Magic Missile", 1, "damage")
     spellbook.add_spell("Shield", 1, "defense")
-    
+
     result = spellbook.cast_spell("Fireball")
     print(f"Cast Fireball: {result['spell']} | Power: {result['power']:.1f}")
     print(f"Spell Slots: {result['slots_remaining']:.0f}/{result['total_slots']:.0f}")
-    
+
     # Pattern 2: Superhero System
     print("\n--- PATTERN 2: Superhero Power System ---")
     hero = SuperheroPowerSystem("Superman", power_level=75.0)
     hero.add_power("Flight", "passive")
     hero.add_power("Heat Vision", "active")
     hero.add_power("Solar Flare", "ultimate")
-    
+
     result = hero.use_power("Heat Vision")
     print(f"Used {result['power']}: Power {result['power_level']:.1f}")
     print(f"Energy: {result['energy_remaining']:.1f}/100")
-    
+
     # Pattern 3: Game Balance
     print("\n--- PATTERN 3: Game Balance Analysis ---")
     print(GameBalancer.power_audit(spellbook.practitioner))
-    
+
     # Pattern 4: Narrative System
     print("\n--- PATTERN 4: Narrative System ---")
     character = NarrativeAbilitySystem("Frodo")
     character.character.add_capability(
         MetaphysicalCapability("Ring Power", CapabilityType.REALITY_WARPING, 60.0)
     )
-    
+
     print("Starting story...")
     print(character.character.get_status())
-    
+
     print("\nTrauma occurs...")
     print(character.traumatic_event())
     print(character.get_narrative_status())
-    
+
     print("\nHealing and recovery...")
     print(character.healing_scene())
     print(character.get_narrative_status())
 
 
 if __name__ == "__main__":
     demo_patterns()
diff --git a/metadata_reset.py b/metadata_reset.py
index 620d42d012b01adc9d03b9fc9fabe33cf2210721..2f431f7ac84bdd0159ef09310a7ec4595c92e0dd 100644
--- a/metadata_reset.py
+++ b/metadata_reset.py
@@ -1,756 +1,790 @@
 """
 Universal Metadata Reset System
 
 Comprehensive utilities to reset all types of metadata across:
 - Metaphysical system state (energy pools, consciousness, ability usage)
 - Git repository metadata
 - File system metadata
 - Generic object metadata
 """
 
 import os
 import json
 from datetime import datetime
 from pathlib import Path
-from dataclasses import asdict, replace
 from typing import Any, Dict, List, Optional
 from enum import Enum
 
-from metaphysical_restrictions import (
-    MetaphysicalPractitioner, MetaphysicalCapability,
-    CapabilityType, RestrictionType
-)
+from metaphysical_restrictions import MetaphysicalPractitioner
 
 
 # ============================================================================
 # PART 1: METAPHYSICAL SYSTEM RESET
 # ============================================================================
 
+
 class MetaphysicalResetType(Enum):
     """Types of metaphysical resets available."""
+
     FULL_RESET = "full_reset"
     ENERGY_RESET = "energy_reset"
     CONSCIOUSNESS_RESET = "consciousness_reset"
     USAGE_RESET = "usage_reset"
     RESTRICTION_RESET = "restriction_reset"
     STATE_SNAPSHOT = "state_snapshot"
 
 
 class MetaphysicalResetManager:
     """Manage reset operations for metaphysical system state."""
-    
+
     def __init__(self):
         self.reset_history = []
         self.state_snapshots = {}
-    
-    def snapshot_state(self, practitioner: MetaphysicalPractitioner, 
-                      snapshot_name: Optional[str] = None) -> Dict:
+
+    def snapshot_state(
+        self,
+        practitioner: MetaphysicalPractitioner,
+        snapshot_name: Optional[str] = None,
+    ) -> Dict:
         """Create a snapshot of practitioner state for later restoration."""
         name = snapshot_name or f"snapshot_{datetime.now().isoformat()}"
-        
+
         snapshot = {
             "timestamp": datetime.now().isoformat(),
             "practitioner_name": practitioner.name,
             "consciousness_level": practitioner.consciousness_level,
             "energy_pool": practitioner.energy_pool,
             "max_energy": practitioner.max_energy,
-            "capabilities": []
+            "capabilities": [],
         }
-        
+
         for cap in practitioner.capabilities:
             cap_data = {
                 "name": cap.name,
                 "capability_type": cap.capability_type.value,
                 "base_power_level": cap.base_power_level,
                 "is_usable": cap.is_usable,
                 "use_count": cap.use_count,
-                "restrictions_count": len(cap.restrictions)
+                "restrictions_count": len(cap.restrictions),
             }
             snapshot["capabilities"].append(cap_data)
-        
+
         self.state_snapshots[name] = snapshot
-        self.reset_history.append({
-            "action": "snapshot",
-            "name": name,
-            "timestamp": datetime.now().isoformat()
-        })
-        
+        self.reset_history.append(
+            {
+                "action": "snapshot",
+                "name": name,
+                "timestamp": datetime.now().isoformat(),
+            }
+        )
+
         return snapshot
-    
-    def restore_snapshot(self, practitioner: MetaphysicalPractitioner, 
-                        snapshot_name: str) -> bool:
+
+    def restore_snapshot(
+        self, practitioner: MetaphysicalPractitioner, snapshot_name: str
+    ) -> bool:
         """Restore practitioner to a previous snapshot."""
         if snapshot_name not in self.state_snapshots:
             return False
-        
+
         snapshot = self.state_snapshots[snapshot_name]
-        
+
         # Restore basic state
         practitioner.consciousness_level = snapshot["consciousness_level"]
         practitioner.energy_pool = snapshot["energy_pool"]
         practitioner.max_energy = snapshot["max_energy"]
-        
+
         # Reset capability usage counts
         for i, cap in enumerate(practitioner.capabilities):
             if i < len(snapshot["capabilities"]):
                 cap_data = snapshot["capabilities"][i]
                 cap.use_count = cap_data["use_count"]
                 cap.is_usable = cap_data["is_usable"]
-        
-        self.reset_history.append({
-            "action": "restore",
-            "snapshot": snapshot_name,
-            "timestamp": datetime.now().isoformat()
-        })
-        
+
+        self.reset_history.append(
+            {
+                "action": "restore",
+                "snapshot": snapshot_name,
+                "timestamp": datetime.now().isoformat(),
+            }
+        )
+
         return True
-    
+
     def reset_energy(self, practitioner: MetaphysicalPractitioner) -> Dict:
         """Reset energy pool to maximum."""
         old_energy = practitioner.energy_pool
         practitioner.energy_pool = practitioner.max_energy
-        
+
         reset_info = {
             "type": "energy_reset",
             "old_value": old_energy,
             "new_value": practitioner.energy_pool,
-            "timestamp": datetime.now().isoformat()
+            "timestamp": datetime.now().isoformat(),
         }
-        
+
         self.reset_history.append(reset_info)
         return reset_info
-    
-    def reset_consciousness(self, practitioner: MetaphysicalPractitioner, 
-                           level: float = 1.0) -> Dict:
+
+    def reset_consciousness(
+        self, practitioner: MetaphysicalPractitioner, level: float = 1.0
+    ) -> Dict:
         """Reset consciousness level."""
         old_consciousness = practitioner.consciousness_level
         practitioner.consciousness_level = max(0.0, min(1.0, level))
-        
+
         reset_info = {
             "type": "consciousness_reset",
             "old_value": old_consciousness,
             "new_value": practitioner.consciousness_level,
-            "timestamp": datetime.now().isoformat()
+            "timestamp": datetime.now().isoformat(),
         }
-        
+
         self.reset_history.append(reset_info)
         return reset_info
-    
+
     def reset_usage_counts(self, practitioner: MetaphysicalPractitioner) -> Dict:
         """Reset all ability usage counts to zero."""
         reset_info = {
             "type": "usage_reset",
             "abilities_reset": [],
-            "timestamp": datetime.now().isoformat()
+            "timestamp": datetime.now().isoformat(),
         }
-        
+
         for capability in practitioner.capabilities:
             old_count = capability.use_count
             capability.use_count = 0
             capability.last_used_timestamp = None
-            
-            reset_info["abilities_reset"].append({
-                "ability": capability.name,
-                "old_count": old_count,
-                "new_count": 0
-            })
-        
+
+            reset_info["abilities_reset"].append(
+                {"ability": capability.name, "old_count": old_count, "new_count": 0}
+            )
+
         self.reset_history.append(reset_info)
         return reset_info
-    
+
     def reset_restrictions(self, practitioner: MetaphysicalPractitioner) -> Dict:
         """Clear all restrictions from all capabilities."""
         reset_info = {
             "type": "restriction_reset",
             "abilities_modified": [],
-            "timestamp": datetime.now().isoformat()
+            "timestamp": datetime.now().isoformat(),
         }
-        
+
         for capability in practitioner.capabilities:
             old_restrictions = len(capability.restrictions)
             capability.restrictions = []
-            
-            reset_info["abilities_modified"].append({
-                "ability": capability.name,
-                "old_restriction_count": old_restrictions,
-                "new_restriction_count": 0
-            })
-        
+
+            reset_info["abilities_modified"].append(
+                {
+                    "ability": capability.name,
+                    "old_restriction_count": old_restrictions,
+                    "new_restriction_count": 0,
+                }
+            )
+
         self.reset_history.append(reset_info)
         return reset_info
-    
+
     def full_reset(self, practitioner: MetaphysicalPractitioner) -> Dict:
         """Complete reset of all metaphysical state."""
         reset_info = {
             "type": "full_reset",
             "timestamp": datetime.now().isoformat(),
-            "resets_applied": []
+            "resets_applied": [],
         }
-        
+
         # Apply all resets
         reset_info["resets_applied"].append(self.reset_energy(practitioner))
         reset_info["resets_applied"].append(
             self.reset_consciousness(practitioner, level=1.0)
         )
         reset_info["resets_applied"].append(self.reset_usage_counts(practitioner))
         reset_info["resets_applied"].append(self.reset_restrictions(practitioner))
-        
+
         self.reset_history.append(reset_info)
         return reset_info
-    
+
     def get_reset_history(self, limit: Optional[int] = None) -> List[Dict]:
         """Get history of reset operations."""
         history = self.reset_history
         if limit:
             history = history[-limit:]
         return history
-    
+
     def export_history(self, filepath: str) -> bool:
         """Export reset history to JSON file."""
         try:
-            with open(filepath, 'w') as f:
+            with open(filepath, "w") as f:
                 json.dump(self.reset_history, f, indent=2)
             return True
         except Exception:
             return False
 
 
 # ============================================================================
 # PART 2: GIT REPOSITORY METADATA RESET
 # ============================================================================
 
+
 class GitMetadataReset:
     """Utilities for resetting git repository metadata."""
-    
+
     @staticmethod
     def reset_uncommitted_changes(repo_path: str = ".") -> Dict:
         """Reset all uncommitted changes (like git checkout -- .)."""
         import subprocess
-        
+
         try:
             result = subprocess.run(
                 ["git", "checkout", "--", "."],
                 cwd=repo_path,
                 capture_output=True,
-                text=True
+                text=True,
             )
-            
+
             return {
                 "success": result.returncode == 0,
                 "action": "reset_uncommitted_changes",
                 "message": result.stdout or result.stderr,
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
         except Exception as e:
             return {
                 "success": False,
                 "action": "reset_uncommitted_changes",
                 "error": str(e),
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
-    
+
     @staticmethod
     def reset_to_head(repo_path: str = ".") -> Dict:
         """Reset repository to HEAD (like git reset --hard HEAD)."""
         import subprocess
-        
+
         try:
             result = subprocess.run(
                 ["git", "reset", "--hard", "HEAD"],
                 cwd=repo_path,
                 capture_output=True,
-                text=True
+                text=True,
             )
-            
+
             return {
                 "success": result.returncode == 0,
                 "action": "reset_to_head",
                 "message": result.stdout or result.stderr,
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
         except Exception as e:
             return {
                 "success": False,
                 "action": "reset_to_head",
                 "error": str(e),
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
-    
+
     @staticmethod
-    def reset_author_metadata(repo_path: str = ".", 
-                             new_author: str = "Anonymous",
-                             new_email: str = "anon@example.com") -> Dict:
+    def reset_author_metadata(
+        repo_path: str = ".",
+        new_author: str = "Anonymous",
+        new_email: str = "anon@example.com",
+    ) -> Dict:
         """Reset git author metadata for new commits."""
         import subprocess
-        
+
         try:
             subprocess.run(
                 ["git", "config", "user.name", new_author],
                 cwd=repo_path,
-                capture_output=True
+                capture_output=True,
             )
             subprocess.run(
                 ["git", "config", "user.email", new_email],
                 cwd=repo_path,
-                capture_output=True
+                capture_output=True,
             )
-            
+
             return {
                 "success": True,
                 "action": "reset_author_metadata",
                 "author": new_author,
                 "email": new_email,
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
         except Exception as e:
             return {
                 "success": False,
                 "action": "reset_author_metadata",
                 "error": str(e),
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
-    
+
     @staticmethod
     def clean_git_metadata(repo_path: str = ".") -> Dict:
         """Clean git cache and reset metadata."""
         import subprocess
-        
+
         results = {
             "action": "clean_git_metadata",
             "operations": [],
-            "timestamp": datetime.now().isoformat()
+            "timestamp": datetime.now().isoformat(),
         }
-        
+
         # Remove from git cache
         try:
             result = subprocess.run(
                 ["git", "rm", "-r", "--cached", "."],
                 cwd=repo_path,
                 capture_output=True,
-                text=True
+                text=True,
+            )
+            results["operations"].append(
+                {"operation": "cache_clean", "success": result.returncode == 0}
             )
-            results["operations"].append({
-                "operation": "cache_clean",
-                "success": result.returncode == 0
-            })
         except Exception as e:
-            results["operations"].append({
-                "operation": "cache_clean",
-                "success": False,
-                "error": str(e)
-            })
-        
+            results["operations"].append(
+                {"operation": "cache_clean", "success": False, "error": str(e)}
+            )
+
         # Re-add files
         try:
             result = subprocess.run(
-                ["git", "add", "."],
-                cwd=repo_path,
-                capture_output=True,
-                text=True
+                ["git", "add", "."], cwd=repo_path, capture_output=True, text=True
+            )
+            results["operations"].append(
+                {"operation": "re_add_files", "success": result.returncode == 0}
             )
-            results["operations"].append({
-                "operation": "re_add_files",
-                "success": result.returncode == 0
-            })
         except Exception as e:
-            results["operations"].append({
-                "operation": "re_add_files",
-                "success": False,
-                "error": str(e)
-            })
-        
+            results["operations"].append(
+                {"operation": "re_add_files", "success": False, "error": str(e)}
+            )
+
         return results
 
 
 # ============================================================================
 # PART 3: FILE METADATA RESET
 # ============================================================================
 
+
 class FileMetadataReset:
     """Utilities for resetting file system metadata."""
-    
+
     @staticmethod
-    def reset_file_timestamps(filepath: str, 
-                             access_time: Optional[float] = None,
-                             modify_time: Optional[float] = None) -> Dict:
+    def reset_file_timestamps(
+        filepath: str,
+        access_time: Optional[float] = None,
+        modify_time: Optional[float] = None,
+    ) -> Dict:
         """Reset file access and modification times."""
         try:
             now = datetime.now().timestamp()
             atime = access_time or now
             mtime = modify_time or now
-            
+
             os.utime(filepath, (atime, mtime))
-            
+
             return {
                 "success": True,
                 "action": "reset_file_timestamps",
                 "filepath": filepath,
                 "access_time": datetime.fromtimestamp(atime).isoformat(),
                 "modify_time": datetime.fromtimestamp(mtime).isoformat(),
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
         except Exception as e:
             return {
                 "success": False,
                 "action": "reset_file_timestamps",
                 "filepath": filepath,
                 "error": str(e),
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
-    
+
     @staticmethod
     def reset_directory_timestamps(dirpath: str) -> Dict:
         """Reset timestamps for all files in a directory."""
         results = {
             "action": "reset_directory_timestamps",
             "dirpath": dirpath,
             "files_processed": 0,
             "files_failed": 0,
-            "timestamp": datetime.now().isoformat()
+            "timestamp": datetime.now().isoformat(),
         }
-        
+
         try:
-            for filepath in Path(dirpath).rglob('*'):
+            for filepath in Path(dirpath).rglob("*"):
                 if filepath.is_file():
                     try:
                         FileMetadataReset.reset_file_timestamps(str(filepath))
                         results["files_processed"] += 1
                     except Exception:
                         results["files_failed"] += 1
         except Exception as e:
             results["error"] = str(e)
-        
+
         return results
-    
+
     @staticmethod
     def reset_file_permissions(filepath: str, mode: int = 0o644) -> Dict:
         """Reset file permissions."""
         try:
             os.chmod(filepath, mode)
-            
+
             return {
                 "success": True,
                 "action": "reset_file_permissions",
                 "filepath": filepath,
                 "permissions": oct(mode),
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
         except Exception as e:
             return {
                 "success": False,
                 "action": "reset_file_permissions",
                 "filepath": filepath,
                 "error": str(e),
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
-    
+
     @staticmethod
     def reset_file_content_metadata(filepath: str) -> Dict:
         """Reset file metadata by touching the file (updates mtime)."""
         try:
             Path(filepath).touch()
-            
+
             return {
                 "success": True,
                 "action": "reset_file_content_metadata",
                 "filepath": filepath,
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
         except Exception as e:
             return {
                 "success": False,
                 "action": "reset_file_content_metadata",
                 "filepath": filepath,
                 "error": str(e),
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
-    
+
     @staticmethod
     def clear_python_cache(dirpath: str = ".") -> Dict:
         """Remove Python cache files (__pycache__, .pyc, .pyo)."""
         results = {
             "action": "clear_python_cache",
             "dirpath": dirpath,
             "directories_removed": [],
             "files_removed": [],
-            "timestamp": datetime.now().isoformat()
+            "timestamp": datetime.now().isoformat(),
         }
-        
+
         try:
             # Remove __pycache__ directories
-            for pycache in Path(dirpath).rglob('__pycache__'):
+            for pycache in Path(dirpath).rglob("__pycache__"):
                 try:
                     import shutil
+
                     shutil.rmtree(pycache)
                     results["directories_removed"].append(str(pycache))
                 except Exception as e:
                     results.setdefault("errors", []).append(str(e))
-            
+
             # Remove .pyc and .pyo files
-            for pattern in ['**/*.pyc', '**/*.pyo']:
+            for pattern in ["**/*.pyc", "**/*.pyo"]:
                 for filepath in Path(dirpath).glob(pattern):
                     try:
                         filepath.unlink()
                         results["files_removed"].append(str(filepath))
                     except Exception as e:
                         results.setdefault("errors", []).append(str(e))
         except Exception as e:
             results["error"] = str(e)
-        
+
         return results
 
 
 # ============================================================================
 # PART 4: GENERIC METADATA RESET FRAMEWORK
 # ============================================================================
 
+
 class MetadataResetFramework:
     """Generic framework for resetting any object metadata."""
-    
+
     def __init__(self):
         self.registered_types = {}
         self.reset_log = []
-    
+
     def register_type(self, type_name: str, reset_handler: callable) -> None:
         """Register a custom type with its reset handler."""
         self.registered_types[type_name] = reset_handler
-    
+
     def reset_object(self, obj: Any, reset_type: str = "full") -> Dict:
         """Reset an object's metadata using registered handler."""
         obj_type = type(obj).__name__
-        
+
         if obj_type not in self.registered_types:
             return {
                 "success": False,
                 "error": f"No reset handler registered for type {obj_type}",
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
-        
+
         try:
             handler = self.registered_types[obj_type]
             result = handler(obj, reset_type)
-            
-            self.reset_log.append({
-                "object_type": obj_type,
-                "reset_type": reset_type,
-                "success": result.get("success", True),
-                "timestamp": datetime.now().isoformat()
-            })
-            
+
+            self.reset_log.append(
+                {
+                    "object_type": obj_type,
+                    "reset_type": reset_type,
+                    "success": result.get("success", True),
+                    "timestamp": datetime.now().isoformat(),
+                }
+            )
+
             return result
         except Exception as e:
             error_result = {
                 "success": False,
                 "error": str(e),
-                "timestamp": datetime.now().isoformat()
+                "timestamp": datetime.now().isoformat(),
             }
-            
-            self.reset_log.append({
-                "object_type": obj_type,
-                "reset_type": reset_type,
-                "success": False,
-                "error": str(e),
-                "timestamp": datetime.now().isoformat()
-            })
-            
+
+            self.reset_log.append(
+                {
+                    "object_type": obj_type,
+                    "reset_type": reset_type,
+                    "success": False,
+                    "error": str(e),
+                    "timestamp": datetime.now().isoformat(),
+                }
+            )
+
             return error_result
-    
+
     def reset_dict_metadata(self, data: Dict) -> Dict:
         """Reset all metadata in a dictionary."""
         result = {
             "action": "reset_dict_metadata",
             "original_size": len(data),
             "metadata_fields_removed": [],
-            "timestamp": datetime.now().isoformat()
+            "timestamp": datetime.now().isoformat(),
         }
-        
+
         metadata_patterns = [
-            "_metadata", "_meta", "__meta__", "metadata",
-            "_timestamp", "_created", "_modified", "_updated",
-            "_id", "__id__", "_hash", "__hash__"
+            "_metadata",
+            "_meta",
+            "__meta__",
+            "metadata",
+            "_timestamp",
+            "_created",
+            "_modified",
+            "_updated",
+            "_id",
+            "__id__",
+            "_hash",
+            "__hash__",
         ]
-        
+
         keys_to_remove = [
-            k for k in data.keys()
+            k
+            for k in data.keys()
             if any(pattern in k.lower() for pattern in metadata_patterns)
         ]
-        
+
         for key in keys_to_remove:
             del data[key]
             result["metadata_fields_removed"].append(key)
-        
+
         return result
-    
+
     def reset_all_metadata(self, obj: Any) -> Dict:
         """Attempt to reset all metadata from an object."""
         result = {
             "action": "reset_all_metadata",
             "object_type": type(obj).__name__,
             "operations": [],
-            "timestamp": datetime.now().isoformat()
+            "timestamp": datetime.now().isoformat(),
         }
-        
+
         # Reset common metadata attributes
         metadata_attrs = [
-            '_metadata', '_meta', '__meta__', 'metadata',
-            '_timestamp', '_created', '_modified', '_updated',
-            '_id', '__id__', '_hash'
+            "_metadata",
+            "_meta",
+            "__meta__",
+            "metadata",
+            "_timestamp",
+            "_created",
+            "_modified",
+            "_updated",
+            "_id",
+            "__id__",
+            "_hash",
         ]
-        
+
         for attr in metadata_attrs:
             if hasattr(obj, attr):
                 try:
                     setattr(obj, attr, None)
-                    result["operations"].append({
-                        "attribute": attr,
-                        "action": "cleared",
-                        "success": True
-                    })
+                    result["operations"].append(
+                        {"attribute": attr, "action": "cleared", "success": True}
+                    )
                 except Exception as e:
-                    result["operations"].append({
-                        "attribute": attr,
-                        "action": "clear_failed",
-                        "error": str(e)
-                    })
-        
+                    result["operations"].append(
+                        {"attribute": attr, "action": "clear_failed", "error": str(e)}
+                    )
+
         return result
 
 
 # ============================================================================
 # COMPREHENSIVE RESET MANAGER
 # ============================================================================
 
+
 class UniversalMetadataResetManager:
     """Master reset manager coordinating all metadata reset operations."""
-    
+
     def __init__(self):
         self.metaphysical_manager = MetaphysicalResetManager()
         self.framework = MetadataResetFramework()
         self.overall_log = []
-    
-    def reset_all(self, practitioner: MetaphysicalPractitioner, 
-                 repo_path: Optional[str] = None,
-                 file_paths: Optional[List[str]] = None) -> Dict:
+
+    def reset_all(
+        self,
+        practitioner: MetaphysicalPractitioner,
+        repo_path: Optional[str] = None,
+        file_paths: Optional[List[str]] = None,
+    ) -> Dict:
         """Execute comprehensive reset of all metadata types."""
         full_reset = {
             "action": "universal_metadata_reset",
             "timestamp": datetime.now().isoformat(),
-            "operations": {}
+            "operations": {},
         }
-        
+
         # Reset metaphysical system
-        full_reset["operations"]["metaphysical"] = \
-            self.metaphysical_manager.full_reset(practitioner)
-        
+        full_reset["operations"]["metaphysical"] = self.metaphysical_manager.full_reset(
+            practitioner
+        )
+
         # Reset git metadata (if repo path provided)
         if repo_path:
             full_reset["operations"]["git"] = {
                 "uncommitted": GitMetadataReset.reset_uncommitted_changes(repo_path),
-                "author": GitMetadataReset.reset_author_metadata(repo_path)
+                "author": GitMetadataReset.reset_author_metadata(repo_path),
             }
-        
+
         # Reset file metadata (if file paths provided)
         if file_paths:
             full_reset["operations"]["files"] = {}
             for filepath in file_paths:
                 full_reset["operations"]["files"][filepath] = {
                     "timestamps": FileMetadataReset.reset_file_timestamps(filepath),
-                    "permissions": FileMetadataReset.reset_file_permissions(filepath)
+                    "permissions": FileMetadataReset.reset_file_permissions(filepath),
                 }
-        
+
         # Clear Python cache
         full_reset["operations"]["cache"] = FileMetadataReset.clear_python_cache()
-        
+
         self.overall_log.append(full_reset)
         return full_reset
-    
+
     def get_overall_log(self) -> List[Dict]:
         """Get log of all reset operations."""
         return self.overall_log
 
 
 # ============================================================================
 # DEMONSTRATION
 # ============================================================================
 
+
 def demonstrate_metadata_reset():
     """Show all metadata reset capabilities."""
     from metaphysical_restrictions import create_balanced_magic_system
-    
-    print("\n" + "="*70)
+
+    print("\n" + "=" * 70)
     print("UNIVERSAL METADATA RESET SYSTEM DEMONSTRATION")
-    print("="*70)
-    
+    print("=" * 70)
+
     # 1. Metaphysical System Reset
     print("\n--- 1. METAPHYSICAL SYSTEM RESET ---")
     mage = create_balanced_magic_system()
     manager = MetaphysicalResetManager()
-    
+
     # Use an ability
     mage.use_capability(mage.capabilities[0])
     print(f"After using ability: Energy = {mage.energy_pool}")
     print(f"Ability use count = {mage.capabilities[0].use_count}")
-    
+
     # Take a snapshot
     snapshot = manager.snapshot_state(mage, "before_trauma")
     print(f"âœ“ Snapshot created: {snapshot['timestamp']}")
-    
+
     # Simulate damage
     mage.consciousness_level = 0.3
     print(f"\nAfter trauma: Consciousness = {mage.consciousness_level:.1%}")
-    
+
     # Reset energy
     reset_energy = manager.reset_energy(mage)
-    print(f"âœ“ Energy reset: {reset_energy['old_value']:.1f} â†’ {reset_energy['new_value']:.1f}")
-    
+    print(
+        f"âœ“ Energy reset: {reset_energy['old_value']:.1f} â†’ {reset_energy['new_value']:.1f}"
+    )
+
     # Reset consciousness
     reset_cons = manager.reset_consciousness(mage, 1.0)
-    print(f"âœ“ Consciousness reset: {reset_cons['old_value']:.1%} â†’ {reset_cons['new_value']:.1%}")
-    
+    print(
+        f"âœ“ Consciousness reset: {reset_cons['old_value']:.1%} â†’ {reset_cons['new_value']:.1%}"
+    )
+
     # Reset usage counts
     reset_usage = manager.reset_usage_counts(mage)
     print(f"âœ“ Usage counts reset for {len(reset_usage['abilities_reset'])} abilities")
-    
+
     # 2. Generic Metadata Reset
     print("\n--- 2. GENERIC METADATA RESET ---")
     test_dict = {
         "name": "Test",
         "_metadata": {"created": "2026-02-18"},
         "_timestamp": 1234567890,
         "data": [1, 2, 3],
-        "_id": "xyz123"
+        "_id": "xyz123",
     }
-    
+
     framework = MetadataResetFramework()
     reset_dict = framework.reset_dict_metadata(test_dict)
     print(f"âœ“ Removed {len(reset_dict['metadata_fields_removed'])} metadata fields")
     print(f"  Fields removed: {reset_dict['metadata_fields_removed']}")
     print(f"  Dict now: {test_dict}")
-    
+
     # 3. File Metadata Reset
     print("\n--- 3. FILE METADATA RESET ---")
     reset_cache = FileMetadataReset.clear_python_cache()
-    print(f"âœ“ Cache cleanup:")
+    print("âœ“ Cache cleanup:")
     print(f"  Directories removed: {len(reset_cache['directories_removed'])}")
     print(f"  Files removed: {len(reset_cache['files_removed'])}")
-    
+
     # 4. Reset History
     print("\n--- 4. RESET HISTORY ---")
     history = manager.get_reset_history(limit=3)
     print(f"âœ“ Last {len(history)} reset operations:")
     for op in history:
-        action = op.get('action') or op.get('type', 'unknown_action')
+        action = op.get("action") or op.get("type", "unknown_action")
         print(f"  - {action} at {op['timestamp']}")
-    
+
     # 5. Full Reset (all metadata types)
     print("\n--- 5. FULL UNIVERSAL RESET ---")
     universal_manager = UniversalMetadataResetManager()
     full_reset = universal_manager.reset_all(mage)
-    print(f"âœ“ Universal reset completed")
+    print("âœ“ Universal reset completed")
     print(f"  Metaphysical: {full_reset['operations']['metaphysical']['type']}")
     print(f"  Cache: {full_reset['operations']['cache']['action']}")
     print(f"  Total operations: {len(full_reset['operations'])}")
 
 
 if __name__ == "__main__":
     demonstrate_metadata_reset()
diff --git a/metaphysical_restrictions.py b/metaphysical_restrictions.py
index 2443ccb7c89f840621582951f42986372b6249bc..ef756938c813867a3edf245b0c01f7a73158909e 100644
--- a/metaphysical_restrictions.py
+++ b/metaphysical_restrictions.py
@@ -1,357 +1,389 @@
 """
 Metaphysical Capabilities Restriction System
 
 A combined game mechanics and philosophical framework for restricting
 supernatural, magical, and metaphysical abilities.
 """
 
 from enum import Enum
 from dataclasses import dataclass, field
-from typing import List, Dict, Optional, Callable
+from typing import List, Dict, Optional
 from abc import ABC, abstractmethod
-import json
 
 
 class CapabilityType(Enum):
     """Categories of metaphysical capabilities."""
+
     TELEKINESIS = "telekinesis"
     TELEPATHY = "telepathy"
     TIME_MANIPULATION = "time_manipulation"
     REALITY_WARPING = "reality_warping"
     SOUL_MANIPULATION = "soul_manipulation"
     DIMENSIONAL_TRAVEL = "dimensional_travel"
     ENERGY_PROJECTION = "energy_projection"
     PROPHESY = "prophesy"
     RESURRECTION = "resurrection"
     CONSCIOUSNESS_TRANSFER = "consciousness_transfer"
 
 
 class RestrictionType(Enum):
     """Types of restrictions that can be applied."""
+
     ENERGY_COST = "energy_cost"
     TIME_COOLDOWN = "time_cooldown"
     RANGE_LIMIT = "range_limit"
     DURATION_LIMIT = "duration_limit"
     SIDE_EFFECTS = "side_effects"
     PHILOSOPHICAL_PARADOX = "philosophical_paradox"
     CONSERVATION_LAW = "conservation_law"
     ENTROPY_COST = "entropy_cost"
     CONSCIOUSNESS_REQUIREMENT = "consciousness_requirement"
     MATERIAL_ANCHOR = "material_anchor"
 
 
 @dataclass
 class RestrictionRule:
     """A single restriction rule applied to a capability."""
+
     restriction_type: RestrictionType
     severity: float  # 0.0 (mild) to 1.0 (severe)
     description: str
     parameters: Dict = field(default_factory=dict)
 
     def apply(self, base_value: float) -> float:
         """Apply restriction multiplier to a base value."""
         return base_value * (1.0 - self.severity)
 
     def __str__(self) -> str:
         return f"{self.restriction_type.value}: {self.description} (severity: {self.severity:.1%})"
 
 
 @dataclass
 class MetaphysicalCapability:
     """Represents a metaphysical or magical capability."""
+
     name: str
     capability_type: CapabilityType
     base_power_level: float  # 0.0 to 100.0
     restrictions: List[RestrictionRule] = field(default_factory=list)
     is_usable: bool = True
     use_count: int = 0
     last_used_timestamp: Optional[float] = None
 
     def get_effective_power(self) -> float:
         """Calculate effective power after applying all restrictions."""
         power = self.base_power_level
         for restriction in self.restrictions:
             power = restriction.apply(power)
         return power
 
     def get_total_restriction_severity(self) -> float:
         """Get cumulative restriction severity."""
         if not self.restrictions:
             return 0.0
         # Multiplicative effect of restrictions
         cumulative = 1.0
         for restriction in self.restrictions:
-            cumulative *= (1.0 - restriction.severity)
+            cumulative *= 1.0 - restriction.severity
         return 1.0 - cumulative
 
     def add_restriction(self, restriction: RestrictionRule) -> None:
         """Add a new restriction to this capability."""
         self.restrictions.append(restriction)
 
     def remove_restriction(self, restriction_type: RestrictionType) -> bool:
         """Remove a restriction by type. Returns True if removed."""
         original_len = len(self.restrictions)
-        self.restrictions = [r for r in self.restrictions 
-                           if r.restriction_type != restriction_type]
+        self.restrictions = [
+            r for r in self.restrictions if r.restriction_type != restriction_type
+        ]
         return len(self.restrictions) < original_len
 
     def __str__(self) -> str:
-        return (f"{self.name} ({self.capability_type.value}): "
-                f"Power {self.get_effective_power():.1f}/100 "
-                f"(base: {self.base_power_level:.1f}, "
-                f"restricted: {self.get_total_restriction_severity():.1%})")
+        return (
+            f"{self.name} ({self.capability_type.value}): "
+            f"Power {self.get_effective_power():.1f}/100 "
+            f"(base: {self.base_power_level:.1f}, "
+            f"restricted: {self.get_total_restriction_severity():.1%})"
+        )
 
 
 class PhilosophicalFramework(ABC):
     """Abstract base for philosophical frameworks limiting metaphysical abilities."""
 
     @abstractmethod
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Determine if a capability violates this philosophical framework."""
         pass
 
     @abstractmethod
     def get_restriction_reason(self) -> str:
         """Explain why this framework restricts capabilities."""
         pass
 
 
 class ConservationOfEnergyFramework(PhilosophicalFramework):
     """Framework based on energy conservation principle."""
 
     def __init__(self, total_available_energy: float = 100.0):
         self.total_available_energy = total_available_energy
         self.used_energy = 0.0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Energy cannot be created or destroyed, only transformed."""
         energy_cost = capability.base_power_level * 0.5
         return self.used_energy + energy_cost <= self.total_available_energy
 
     def get_restriction_reason(self) -> str:
-        return ("Energy conservation: All metaphysical actions must draw from "
-                "a finite energy pool. Energy cannot be created or destroyed.")
+        return (
+            "Energy conservation: All metaphysical actions must draw from "
+            "a finite energy pool. Energy cannot be created or destroyed."
+        )
 
 
 class EntropicDecayFramework(PhilosophicalFramework):
     """Framework based on entropy and thermodynamic principles."""
 
     def __init__(self, entropy_tolerance: float = 0.8):
         self.entropy_tolerance = entropy_tolerance  # 0.0 to 1.0
         self.current_entropy = 0.0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Reality-altering abilities increase entropy."""
         entropy_increase = capability.base_power_level / 100.0 * 0.3
         return self.current_entropy + entropy_increase <= self.entropy_tolerance
 
     def get_restriction_reason(self) -> str:
-        return ("Entropic decay: All metaphysical manipulations increase "
-                "universal entropy. Reality resists extreme violations of entropy.")
+        return (
+            "Entropic decay: All metaphysical manipulations increase "
+            "universal entropy. Reality resists extreme violations of entropy."
+        )
 
 
 class CausalityFramework(PhilosophicalFramework):
     """Framework that restricts causality violations."""
 
     def __init__(self, allow_time_travel: bool = False):
         self.allow_time_travel = allow_time_travel
         self.causal_violations = 0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Causality violations are restricted unless specifically allowed."""
         causal_violations = [
             CapabilityType.TIME_MANIPULATION,
             CapabilityType.RESURRECTION,
-            CapabilityType.PROPHESY
+            CapabilityType.PROPHESY,
         ]
-        
+
         if capability.capability_type in causal_violations:
             if capability.capability_type == CapabilityType.TIME_MANIPULATION:
                 return self.allow_time_travel
             return True
         return True
 
     def get_restriction_reason(self) -> str:
-        return ("Causality principle: Effects cannot precede causes. "
-                "Abilities that violate causality are restricted.")
+        return (
+            "Causality principle: Effects cannot precede causes. "
+            "Abilities that violate causality are restricted."
+        )
 
 
 class ConsciousnessAnchorFramework(PhilosophicalFramework):
     """Framework requiring consciousness maintenance for metaphysical actions."""
 
     def __init__(self, consciousness_threshold: float = 0.5):
         self.consciousness_threshold = consciousness_threshold
         self.practitioner_consciousness_level = 1.0
 
     def evaluate_restriction(self, capability: MetaphysicalCapability) -> bool:
         """Metaphysical abilities require sufficient consciousness."""
         required_consciousness = capability.base_power_level / 100.0
         return self.practitioner_consciousness_level >= required_consciousness
 
     def get_restriction_reason(self) -> str:
-        return ("Consciousness anchor: Metaphysical capabilities require "
-                "mental clarity and awareness. Altered consciousness impairs abilities.")
+        return (
+            "Consciousness anchor: Metaphysical capabilities require "
+            "mental clarity and awareness. Altered consciousness impairs abilities."
+        )
 
 
 @dataclass
 class MetaphysicalPractitioner:
     """An entity capable of using metaphysical abilities."""
+
     name: str
     capabilities: List[MetaphysicalCapability] = field(default_factory=list)
     philosophical_frameworks: List[PhilosophicalFramework] = field(default_factory=list)
     consciousness_level: float = 1.0  # 0.0 to 1.0
     energy_pool: float = 100.0
     max_energy: float = 100.0
 
     def add_capability(self, capability: MetaphysicalCapability) -> None:
         """Add a new capability."""
         self.capabilities.append(capability)
 
     def add_framework(self, framework: PhilosophicalFramework) -> None:
         """Bind a philosophical framework to this practitioner."""
         self.philosophical_frameworks.append(framework)
 
-    def can_use_capability(self, capability: MetaphysicalCapability) -> tuple[bool, str]:
+    def can_use_capability(
+        self, capability: MetaphysicalCapability
+    ) -> tuple[bool, str]:
         """Check if a capability can be used given all restrictions."""
         # Check if capability is enabled
         if not capability.is_usable:
             return False, "Capability is disabled."
 
         # Check energy
         energy_cost = capability.base_power_level * 0.5
         if self.energy_pool < energy_cost:
-            return False, f"Insufficient energy. Need {energy_cost:.1f}, have {self.energy_pool:.1f}"
+            return (
+                False,
+                f"Insufficient energy. Need {energy_cost:.1f}, have {self.energy_pool:.1f}",
+            )
 
         # Check consciousness
         if self.consciousness_level < 0.5:
-            return False, "Consciousness level too low to maintain metaphysical connection."
+            return (
+                False,
+                "Consciousness level too low to maintain metaphysical connection.",
+            )
 
         # Check all philosophical frameworks
         for framework in self.philosophical_frameworks:
             if not framework.evaluate_restriction(capability):
-                return False, f"Violates {type(framework).__name__}: {framework.get_restriction_reason()}"
+                return (
+                    False,
+                    f"Violates {type(framework).__name__}: {framework.get_restriction_reason()}",
+                )
 
         return True, "Capability can be used."
 
     def use_capability(self, capability: MetaphysicalCapability) -> Dict:
         """Attempt to use a capability. Returns result details."""
         can_use, reason = self.can_use_capability(capability)
-        
+
         result = {
             "success": can_use,
             "capability": capability.name,
             "reason": reason,
             "power_used": 0.0,
-            "energy_consumed": 0.0
+            "energy_consumed": 0.0,
         }
 
         if can_use:
             power_used = capability.get_effective_power()
             energy_consumed = capability.base_power_level * 0.5
-            
+
             self.energy_pool -= energy_consumed
             capability.use_count += 1
-            
+
             result["power_used"] = power_used
             result["energy_consumed"] = energy_consumed
             result["remaining_energy"] = self.energy_pool
 
         return result
 
     def get_status(self) -> str:
         """Get current status of the practitioner."""
         status = f"\n=== {self.name} ===\n"
         status += f"Consciousness: {self.consciousness_level:.1%}\n"
         status += f"Energy: {self.energy_pool:.1f}/{self.max_energy:.1f}\n"
         status += f"Active Frameworks: {len(self.philosophical_frameworks)}\n"
-        status += f"\nCapabilities:\n"
-        
+        status += "\nCapabilities:\n"
+
         for cap in self.capabilities:
             status += f"  â€¢ {cap}\n"
             if cap.restrictions:
                 for restriction in cap.restrictions:
                     status += f"    - {restriction}\n"
-        
+
         return status
 
 
 # Utility functions for common restriction setups
 
+
 def create_balanced_magic_system() -> MetaphysicalPractitioner:
     """Create a well-balanced magic system with standard restrictions."""
     practitioner = MetaphysicalPractitioner("Balanced Mage")
-    
+
     # Add frameworks
     practitioner.add_framework(ConservationOfEnergyFramework(200.0))
     practitioner.add_framework(EntropicDecayFramework(0.9))
     practitioner.add_framework(ConsciousnessAnchorFramework(0.6))
-    
+
     # Add capabilities with restrictions
     telekinesis = MetaphysicalCapability(
-        "Telekinesis",
-        CapabilityType.TELEKINESIS,
-        base_power_level=45.0
+        "Telekinesis", CapabilityType.TELEKINESIS, base_power_level=45.0
     )
-    telekinesis.add_restriction(RestrictionRule(
-        RestrictionType.RANGE_LIMIT,
-        severity=0.3,
-        description="Limited to 100 meters"
-    ))
-    telekinesis.add_restriction(RestrictionRule(
-        RestrictionType.TIME_COOLDOWN,
-        severity=0.2,
-        description="5-second cooldown between uses"
-    ))
-    
+    telekinesis.add_restriction(
+        RestrictionRule(
+            RestrictionType.RANGE_LIMIT,
+            severity=0.3,
+            description="Limited to 100 meters",
+        )
+    )
+    telekinesis.add_restriction(
+        RestrictionRule(
+            RestrictionType.TIME_COOLDOWN,
+            severity=0.2,
+            description="5-second cooldown between uses",
+        )
+    )
+
     telepathy = MetaphysicalCapability(
-        "Telepathy",
-        CapabilityType.TELEPATHY,
-        base_power_level=35.0
+        "Telepathy", CapabilityType.TELEPATHY, base_power_level=35.0
+    )
+    telepathy.add_restriction(
+        RestrictionRule(
+            RestrictionType.CONSCIOUSNESS_REQUIREMENT,
+            severity=0.4,
+            description="Target must have some consciousness",
+        )
     )
-    telepathy.add_restriction(RestrictionRule(
-        RestrictionType.CONSCIOUSNESS_REQUIREMENT,
-        severity=0.4,
-        description="Target must have some consciousness"
-    ))
-    
+
     practitioner.add_capability(telekinesis)
     practitioner.add_capability(telepathy)
-    
+
     return practitioner
 
 
 def create_restricted_reality_warper() -> MetaphysicalPractitioner:
     """Create a reality warper with heavy restrictions."""
-    practitioner = MetaphysicalPractitioner("Reality Warper", 
-                                           consciousness_level=0.95,
-                                           energy_pool=500.0,
-                                           max_energy=500.0)
-    
+    practitioner = MetaphysicalPractitioner(
+        "Reality Warper", consciousness_level=0.95, energy_pool=500.0, max_energy=500.0
+    )
+
     # Add strict frameworks
     practitioner.add_framework(CausalityFramework(allow_time_travel=False))
     practitioner.add_framework(EntropicDecayFramework(entropy_tolerance=0.7))
-    
+
     reality_warp = MetaphysicalCapability(
-        "Reality Warping",
-        CapabilityType.REALITY_WARPING,
-        base_power_level=85.0
+        "Reality Warping", CapabilityType.REALITY_WARPING, base_power_level=85.0
+    )
+    reality_warp.add_restriction(
+        RestrictionRule(
+            RestrictionType.PHILOSOPHICAL_PARADOX,
+            severity=0.6,
+            description="Cannot create logical contradictions",
+        )
+    )
+    reality_warp.add_restriction(
+        RestrictionRule(
+            RestrictionType.ENTROPY_COST,
+            severity=0.5,
+            description="Massive entropy increase per use",
+        )
     )
-    reality_warp.add_restriction(RestrictionRule(
-        RestrictionType.PHILOSOPHICAL_PARADOX,
-        severity=0.6,
-        description="Cannot create logical contradictions"
-    ))
-    reality_warp.add_restriction(RestrictionRule(
-        RestrictionType.ENTROPY_COST,
-        severity=0.5,
-        description="Massive entropy increase per use"
-    ))
-    reality_warp.add_restriction(RestrictionRule(
-        RestrictionType.MATERIAL_ANCHOR,
-        severity=0.4,
-        description="Requires ritual components to ground the effect"
-    ))
-    
+    reality_warp.add_restriction(
+        RestrictionRule(
+            RestrictionType.MATERIAL_ANCHOR,
+            severity=0.4,
+            description="Requires ritual components to ground the effect",
+        )
+    )
+
     practitioner.add_capability(reality_warp)
-    
+
     return practitioner
diff --git a/philosophical_framework.py b/philosophical_framework.py
index c99d0ce68917c0af7a0bba8f176afb52f8bd8bd5..970bfdc5c49adb03a59e06ad4c1462fa0d037772 100644
--- a/philosophical_framework.py
+++ b/philosophical_framework.py
@@ -1,355 +1,351 @@
 """
 Philosophical Framework Module
 Theoretical underpinnings for restricting metaphysical capabilities.
 
 This module explores how various philosophical and physical principles
 can naturally limit magical and supernatural abilities.
 """
 
 from enum import Enum
 from dataclasses import dataclass
-from typing import List, Dict
+from typing import List
 
 
 class PhilosophicalPrinciple(Enum):
     """Core philosophical principles limiting metaphysical abilities."""
-    
+
     CONSERVATION = "conservation_of_energy"
     """Energy cannot be created or destroyed, only transformed."""
-    
+
     ENTROPY = "thermodynamic_entropy"
     """All systems tend toward disorder. Order-creating acts cost energy."""
-    
+
     CAUSALITY = "causality"
     """Causes must precede effects. Temporal loops are forbidden."""
-    
+
     CONSCIOUSNESS = "consciousness_anchor"
     """Metaphysical acts require conscious will and mental focus."""
-    
+
     IDENTITY = "personal_identity"
     """The self is continuous. Mind transfers violate personal continuity."""
-    
+
     INFORMATION = "conservation_of_information"
     """Information cannot be truly destroyed or created ex nihilo."""
-    
+
     LOCALITY = "locality_principle"
     """Mind/consciousness is anchored to a specific location or body."""
-    
+
     WAVE_PARTICLE_DUALITY = "quantum_uncertainty"
     """Observation affects reality. Total knowledge of a system is impossible."""
 
 
 @dataclass
 class PhilosophicalFrameworkTheory:
     """Theoretical justification for restriction types."""
-    
+
     principle: PhilosophicalPrinciple
     description: str
     applied_to: List[str]  # Capability types affected
     severity_justification: str
     exceptions: List[str] = None
-    
+
     def __post_init__(self):
         if self.exceptions is None:
             self.exceptions = []
 
 
 # == CONSERVATION-BASED RESTRICTIONS ==
 
 ENERGY_CONSERVATION = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.CONSERVATION,
     description=(
         "The First Law of Thermodynamics states that energy cannot be "
         "created or destroyed, only transformed. Every metaphysical act "
         "must draw power from somewhereâ€”either the practitioner's internal "
         "reserves, external sources, or conversion of matter."
     ),
     applied_to=[
-        "telekinesis", "energy_projection", "reality_warping",
-        "telepathy", "dimensional_travel"
+        "telekinesis",
+        "energy_projection",
+        "reality_warping",
+        "telepathy",
+        "dimensional_travel",
     ],
     severity_justification=(
         "Power level determines energy consumption. A 50-point ability "
         "requires 25 energy units. Without sufficient energy reserves, "
         "the ability cannot be used."
     ),
     exceptions=[
         "Passive abilities that simply maintain a state require no energy",
-        "Channeled abilities can draw unlimited power if connected to external source"
-    ]
+        "Channeled abilities can draw unlimited power if connected to external source",
+    ],
 )
 
 MATTER_MASS_EQUIVALENCE = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.CONSERVATION,
     description=(
         "Mass and energy are interchangeable (E=mcÂ²). Creating matter "
         "from nothing requires an impossible amount of energy. "
         "Transmutation must conserve matterâ€”you cannot create mass."
     ),
-    applied_to=[
-        "reality_warping", "matter_creation", "resurrection"
-    ],
+    applied_to=["reality_warping", "matter_creation", "resurrection"],
     severity_justification=(
         "Transmutation is limited by matter conservation. You can reshape "
         "existing matter but cannot create new mass from energy without "
         "extraordinary power sources."
-    )
+    ),
 )
 
 
 # == ENTROPY-BASED RESTRICTIONS ==
 
 THERMODYNAMIC_ENTROPY = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.ENTROPY,
     description=(
         "The Second Law of Thermodynamics states that entropy in a closed "
         "system always increases. Order-creating acts (magic) are "
         "fundamentally working against entropy. They require energy to "
         "impose order on chaos."
     ),
     applied_to=[
-        "reality_warping", "regeneration", "resurrection",
-        "telekinesis", "time_manipulation"
+        "reality_warping",
+        "regeneration",
+        "resurrection",
+        "telekinesis",
+        "time_manipulation",
     ],
     severity_justification=(
         "The more ordered and improbable the effect, the higher entropy cost. "
         "Resurrecting the dead (creating extreme order) has a catastrophic "
         "entropy cost. Simple telekinesis (local reordering) has lower cost."
     ),
     exceptions=[
         "Entropy-increasing acts (destruction) have negative cost",
-        "Chaos magic harnesses entropy and may have reduced cost"
-    ]
+        "Chaos magic harnesses entropy and may have reduced cost",
+    ],
 )
 
 
 # == CAUSALITY-BASED RESTRICTIONS ==
 
 CAUSALITY_CONSTRAINT = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.CAUSALITY,
     description=(
         "The philosophical principle of causality states that causes must "
         "precede their effects in time. This prevents paradoxes and maintains "
         "logical consistency. Time travel that creates grandfather paradoxes "
         "violates causality."
     ),
-    applied_to=[
-        "time_manipulation", "prophecy", "resurrection", "memory_alteration"
-    ],
+    applied_to=["time_manipulation", "prophecy", "resurrection", "memory_alteration"],
     severity_justification=(
         "Abilities that alter the past are forbidden entirely (severity 1.0) "
         "unless an exception is granted. Prophecy is restricted because perfect "
         "foresight creates causal loops."
     ),
     exceptions=[
         "Time dilation (slowing time locally) doesn't violate causality",
         "Multiverse branching interpretations allow limited time travel",
-        "Prophecy is allowed if futures remain probabilistic and uncertain"
-    ]
+        "Prophecy is allowed if futures remain probabilistic and uncertain",
+    ],
 )
 
 
 # == CONSCIOUSNESS-BASED RESTRICTIONS ==
 
 CONSCIOUSNESS_ANCHOR = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.CONSCIOUSNESS,
     description=(
         "Metaphysical abilities require conscious intention and mental focus. "
         "Unconsciousness, drugs, meditation-induced dissociation, or mental "
         "damage impair the ability to project will onto reality."
     ),
-    applied_to=[
-        "all_abilities"
-    ],
+    applied_to=["all_abilities"],
     severity_justification=(
         "Each ability has a minimum consciousness threshold. A 70-point ability "
         "requires 70% consciousness. Below that, it cannot be used. Sleep and "
         "unconsciousness (0% consciousness) disable all abilities."
-    )
+    ),
 )
 
 WILL_CONSISTENCY = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.CONSCIOUSNESS,
     description=(
         "Metaphysical projections of will require consistency of intent. "
         "Paradoxical commands (trying to both teleport and stay still) "
         "cancel out. Self-doubt creates internal conflicts that weaken effects."
     ),
-    applied_to=[
-        "reality_warping", "telekinesis", "telepathy"
-    ],
+    applied_to=["reality_warping", "telekinesis", "telepathy"],
     severity_justification=(
         "Conflicted intent reduces effectiveness. Clear, unwavering will "
         "grants full power. Doubt or hesitation reduces effective power level."
-    )
+    ),
 )
 
 
 # == IDENTITY-BASED RESTRICTIONS ==
 
 PERSONAL_IDENTITY = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.IDENTITY,
     description=(
         "Philosophy of mind suggests personal identity is continuous. "
         "Consciousness transfer, mind uploading, and resurrection via copied "
         "consciousness may create duplicates rather than restore the original. "
         "The original consciousness/soul cannot be moved without death."
     ),
-    applied_to=[
-        "consciousness_transfer", "resurrection", "memory_alteration"
-    ],
+    applied_to=["consciousness_transfer", "resurrection", "memory_alteration"],
     severity_justification=(
         "Perfect consciousness transfer (restoring the SAME consciousness) "
         "is impossible. You can copy consciousness (creating a duplicate) "
         "but the original is lost. Resurrection always involves creating "
         "a near-duplicate, never true restoration."
     ),
     exceptions=[
         "Magical souls are metaphysical entities that can persist unchanged",
-        "If consciousness is non-physical, perfect transfer may be possible"
-    ]
+        "If consciousness is non-physical, perfect transfer may be possible",
+    ],
 )
 
 
 # == INFORMATION-BASED RESTRICTIONS ==
 
 INFORMATION_CONSERVATION = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.INFORMATION,
     description=(
         "In quantum mechanics, information is never truly destroyed "
         "(black hole no-loss principle). All information that ever existed "
         "leaves traces in the universe's quantum state. This prevents true "
         "creation or complete destruction."
     ),
-    applied_to=[
-        "reality_warping", "matter_annihilation", "memory_erasure"
-    ],
+    applied_to=["reality_warping", "matter_annihilation", "memory_erasure"],
     severity_justification=(
         "You cannot truly destroy matter without creating radiation/energy. "
         "You cannot erase memories without leaving traces. The universe "
         "'remembers' everything."
-    )
+    ),
 )
 
 KNOWLEDGE_UNCERTAINTY = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.INFORMATION,
     description=(
         "The quantum uncertainty principle and epistemological limits "
         "prevent perfect knowledge. You cannot know both position and "
         "momentum perfectly. You cannot read minds and bodies perfectly."
     ),
-    applied_to=[
-        "telepathy", "prophecy", "perfect_scrying"
-    ],
+    applied_to=["telepathy", "prophecy", "perfect_scrying"],
     severity_justification=(
         "Telepathy gets weaker with mental complexity. Prophecy cannot "
         "achieve perfect accuracy. Scrying cannot penetrate all barriers."
-    )
+    ),
 )
 
 
 # == LOCALITY-BASED RESTRICTIONS ==
 
 CONSCIOUSNESS_LOCALITY = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.LOCALITY,
     description=(
         "Consciousness appears to be localized to the brain/nervous system. "
         "Projecting consciousness at range requires energy to maintain that "
         "connection. Extreme range causes degradation or link loss."
     ),
-    applied_to=[
-        "telekinesis", "telepathy", "remote_viewing", "dimensional_travel"
-    ],
+    applied_to=["telekinesis", "telepathy", "remote_viewing", "dimensional_travel"],
     severity_justification=(
         "Telepathy strength decreases with distance. Telekinesis has a "
         "maximum range. Remote viewing becomes blurry at extreme range. "
         "Dimensional travel must anchor back to origin point."
-    )
+    ),
 )
 
 
 # == QUANTUM UNCERTAINTY RESTRICTIONS ==
 
 OBSERVER_EFFECT = PhilosophicalFrameworkTheory(
     principle=PhilosophicalPrinciple.WAVE_PARTICLE_DUALITY,
     description=(
         "In quantum mechanics, observation affects the observed system. "
         "Measuring a particle's position changes its momentum. Attempting "
         "perfect perception of reality collapses quantum states, changing "
         "what you perceive."
     ),
-    applied_to=[
-        "reality_warping", "perfect_scrying", "prophecy"
-    ],
+    applied_to=["reality_warping", "perfect_scrying", "prophecy"],
     severity_justification=(
         "The act of observing changes the observed. Perfect prophecy is "
         "impossible because observing the future collapses it to a specific "
         "timeline, preventing alternate outcomes."
-    )
+    ),
 )
 
 
 # == PRACTICAL RESTRICTION GUIDELINES ==
 
 RESTRICTION_SEVERITY_SCALE = {
     0.0: "No restriction - ability works at full effectiveness",
     0.1: "Negligible - restricts 10% of power",
     0.2: "Minor - restricts 20% of power, easily overcome",
     0.3: "Moderate - restricts 30%, noticeable impact",
     0.4: "Significant - ability only 60% as effective",
     0.5: "Heavy - splits power in half",
     0.7: "Severe - ability 30% effective, mostly unusable",
     0.9: "Near-total - ability barely works",
-    1.0: "Complete prohibition - ability cannot be used"
+    1.0: "Complete prohibition - ability cannot be used",
 }
 
 
-def get_framework_for_capability(capability_type: str) -> List[PhilosophicalFrameworkTheory]:
+def get_framework_for_capability(
+    capability_type: str,
+) -> List[PhilosophicalFrameworkTheory]:
     """Get all philosophical frameworks that restrict a given capability."""
     frameworks = [
-        ENERGY_CONSERVATION, MATTER_MASS_EQUIVALENCE,
+        ENERGY_CONSERVATION,
+        MATTER_MASS_EQUIVALENCE,
         THERMODYNAMIC_ENTROPY,
         CAUSALITY_CONSTRAINT,
-        CONSCIOUSNESS_ANCHOR, WILL_CONSISTENCY,
+        CONSCIOUSNESS_ANCHOR,
+        WILL_CONSISTENCY,
         PERSONAL_IDENTITY,
-        INFORMATION_CONSERVATION, KNOWLEDGE_UNCERTAINTY,
+        INFORMATION_CONSERVATION,
+        KNOWLEDGE_UNCERTAINTY,
         CONSCIOUSNESS_LOCALITY,
-        OBSERVER_EFFECT
+        OBSERVER_EFFECT,
+    ]
+
+    applicable = [
+        f
+        for f in frameworks
+        if capability_type in f.applied_to or "all_abilities" in f.applied_to
     ]
-    
-    applicable = [f for f in frameworks if capability_type in f.applied_to
-                 or "all_abilities" in f.applied_to]
     return applicable
 
 
 def print_framework_analysis(capability_type: str):
     """Print detailed analysis of restrictions on a capability."""
-    print(f"\n{'='*70}")
+    print(f"\n{'=' * 70}")
     print(f"PHILOSOPHICAL RESTRICTIONS: {capability_type.upper()}")
-    print(f"{'='*70}\n")
-    
+    print(f"{'=' * 70}\n")
+
     frameworks = get_framework_for_capability(capability_type)
-    
+
     if not frameworks:
         print(f"No restrictions found for {capability_type}")
         return
-    
+
     for framework in frameworks:
         print(f"\n{framework.principle.value.upper()}")
-        print(f"{'-'*70}")
+        print(f"{'-' * 70}")
         print(f"Description: {framework.description}")
         print(f"\nSeverity Justification: {framework.severity_justification}")
-        
+
         if framework.exceptions:
-            print(f"\nExceptions:")
+            print("\nExceptions:")
             for exc in framework.exceptions:
                 print(f"  â€¢ {exc}")
 
 
 # Example usage
 if __name__ == "__main__":
     print("Philosophical Framework Examples:")
     print_framework_analysis("reality_warping")
     print_framework_analysis("telekinesis")
     print_framework_analysis("telepathy")
     print_framework_analysis("time_manipulation")
#!/usr/bin/env python3
"""
ipython_clean_fix.py
Safe IPython cleanup + diagnostics.

What it does:
- Finds IPython config/profile paths
- Backs up the default profile folder
- Optionally removes startup scripts that auto-run code
- Optionally clears the IPython history database
- Optionally performs a "hard reset" (recreate default profile)

Usage:
  python ipython_clean_fix.py --report
  python ipython_clean_fix.py --clean-startup
  python ipython_clean_fix.py --reset-profile
  python ipython_clean_fix.py --reset-profile --clear-history
"""

from __future__ import annotations

import argparse
import os
import shutil
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Optional


@dataclass(frozen=True)
class Paths:
    ipython_dir: Path
    profile_default: Path
    startup_dir: Path
    history_db: Path


def try_import_ipython_dir() -> Optional[Path]:
    """Prefer IPython API if installed; fallback to ~/.ipython."""
    try:
        from IPython.paths import get_ipython_dir  # type: ignore
        return Path(get_ipython_dir()).expanduser().resolve()
    except Exception:
        # fallback
        return Path.home().joinpath(".ipython").expanduser().resolve()


def resolve_paths() -> Paths:
    ipython_dir = try_import_ipython_dir()
    profile_default = ipython_dir / "profile_default"
    startup_dir = profile_default / "startup"
    history_db = profile_default / "history.sqlite"
    return Paths(
        ipython_dir=ipython_dir,
        profile_default=profile_default,
        startup_dir=startup_dir,
        history_db=history_db,
    )


def backup_folder(src: Path, backup_root: Path) -> Optional[Path]:
    if not src.exists():
        return None
    backup_root.mkdir(parents=True, exist_ok=True)
    ts = time.strftime("%Y%m%d-%H%M%S")
    dst = backup_root / f"{src.name}-backup-{ts}"
    shutil.copytree(src, dst, dirs_exist_ok=False)
    return dst


def safe_remove_contents(folder: Path) -> int:
    """Remove contents of folder; keep folder itself. Returns removed item count."""
    if not folder.exists():
        return 0
    removed = 0
    for item in folder.iterdir():
        try:
            if item.is_dir():
                shutil.rmtree(item, ignore_errors=True)
            else:
                item.unlink(missing_ok=True)
            removed += 1
        except Exception:
            # best effort
            pass
    return removed


def remove_startup_scripts(paths: Paths) -> int:
    paths.startup_dir.mkdir(parents=True, exist_ok=True)
    return safe_remove_contents(paths.startup_dir)


def clear_history(paths: Paths) -> bool:
    if paths.history_db.exists():
        try:
            paths.history_db.unlink()
            return True
        except Exception:
            return False
    return False


def reset_profile(paths: Paths) -> None:
    """
    Hard reset of profile_default:
    - remove profile_default folder entirely
    - recreate empty structure
    NOTE: This removes custom config. We back it up first in main().
    """
    if paths.profile_default.exists():
        shutil.rmtree(paths.profile_default, ignore_errors=True)
    paths.startup_dir.mkdir(parents=True, exist_ok=True)


def write_report(paths: Paths) -> str:
    lines = []
    lines.append("IPython Cleanup Report")
    lines.append("======================")
    lines.append(f"Python: {sys.version.split()[0]}")
    lines.append(f"Executable: {sys.executable}")
    lines.append("")
    lines.append(f"IPython dir: {paths.ipython_dir}")
    lines.append(f"Profile default: {paths.profile_default} (exists={paths.profile_default.exists()})")
    lines.append(f"Startup dir: {paths.startup_dir} (exists={paths.startup_dir.exists()})")
    lines.append(f"History DB: {paths.history_db} (exists={paths.history_db.exists()})")
    if paths.startup_dir.exists():
        scripts = sorted([p.name for p in paths.startup_dir.glob("*.py")])
        lines.append(f"Startup scripts (*.py): {len(scripts)}")
        for s in scripts[:50]:
            lines.append(f"  - {s}")
        if len(scripts) > 50:
            lines.append("  - ...")
    return "\n".join(lines)


def sanity_check() -> int:
    """
    Quick check that IPython starts and exits.
    Returns 0 on success, non-zero on failure.
    """
    import subprocess

    cmd = [sys.executable, "-m", "IPython", "-c", "print('IPython OK')"]
    try:
        p = subprocess.run(cmd, capture_output=True, text=True, timeout=20)
        if p.returncode == 0 and "IPython OK" in (p.stdout or ""):
            return 0
        return p.returncode or 1
    except Exception:
        return 2


def main() -> int:
    ap = argparse.ArgumentParser(description="Safe IPython cleanup + diagnostics.")
    ap.add_argument("--report", action="store_true", help="Print detected IPython paths and startup scripts.")
    ap.add_argument("--clean-startup", action="store_true", help="Remove IPython startup scripts in profile_default/startup.")
    ap.add_argument("--clear-history", action="store_true", help="Delete IPython history.sqlite in profile_default.")
    ap.add_argument("--reset-profile", action="store_true", help="Hard reset profile_default (backs up first).")
    ap.add_argument("--backup-dir", default=str(Path.home() / "ipython-clean-backups"), help="Where to store backups.")
    ap.add_argument("--sanity-check", action="store_true", help="Run a quick 'IPython OK' check after changes.")
    args = ap.parse_args()

    paths = resolve_paths()

    if args.report:
        print(write_report(paths))

    # If any destructive action requested, back up first (if exists)
    destructive = args.clean_startup or args.clear_history or args.reset_profile
    if destructive and paths.profile_default.exists():
        backup_root = Path(args.backup_dir).expanduser().resolve()
        backup_path = backup_folder(paths.profile_default, backup_root)
        if backup_path:
            print(f"\nBackup created: {backup_path}")

    if args.reset_profile:
        reset_profile(paths)
        print("Reset profile_default complete.")

    if args.clean_startup:
        removed = remove_startup_scripts(paths)
        print(f"Removed {removed} item(s) from IPython startup dir.")

    if args.clear_history:
        ok = clear_history(paths)
        print(f"History DB cleared: {ok}")

    if args.sanity_check:
        code = sanity_check()
        print(f"Sanity check exit code: {code}")
        return code

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
python ipython_clean_fix.py --report
python ipython_clean_fix.py --clean-startup --sanity-check
python ipython_clean_fix.py --reset-profile --clear-history --sanity-check
#!/usr/bin/env python3
"""
ipython_repair_all.py
All-in-one IPython repair + reset + diagnostics.

What it fixes:
- Corrupted profile config
- Hidden startup scripts auto-running code
- Broken/locked history.sqlite
- Extension autoload issues (best-effort)
- General "IPython won't start" config-state problems

Safe behavior:
- Always creates a timestamped backup of profile_default (if it exists)
- Only modifies IPython profile/config folders (no projects, no Documents)

Usage:
  python ipython_repair_all.py
  python ipython_repair_all.py --backup-dir "C:\\backups"
  python ipython_repair_all.py --no-reset   (only clean startup + history + extension hints)
"""

from __future__ import annotations

import argparse
import json
import os
import shutil
import subprocess
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional, Tuple


@dataclass(frozen=True)
class Paths:
    ipython_dir: Path
    profile_default: Path
    startup_dir: Path
    history_db: Path
    config_py: Path


def get_ipython_dir_fallback() -> Path:
    # Prefer IPython API if available, otherwise default to ~/.ipython
    try:
        from IPython.paths import get_ipython_dir  # type: ignore
        return Path(get_ipython_dir()).expanduser().resolve()
    except Exception:
        return Path.home().joinpath(".ipython").expanduser().resolve()


def resolve_paths() -> Paths:
    ipython_dir = get_ipython_dir_fallback()
    profile_default = ipython_dir / "profile_default"
    startup_dir = profile_default / "startup"
    history_db = profile_default / "history.sqlite"
    config_py = profile_default / "ipython_config.py"
    return Paths(ipython_dir, profile_default, startup_dir, history_db, config_py)


def ts() -> str:
    return time.strftime("%Y%m%d-%H%M%S")


def backup_profile(profile_dir: Path, backup_root: Path) -> Optional[Path]:
    if not profile_dir.exists():
        return None
    backup_root.mkdir(parents=True, exist_ok=True)
    dst = backup_root / f"profile_default-backup-{ts()}"
    shutil.copytree(profile_dir, dst, dirs_exist_ok=False)
    return dst


def remove_contents(folder: Path) -> int:
    if not folder.exists():
        return 0
    removed = 0
    for item in folder.iterdir():
        try:
            if item.is_dir():
                shutil.rmtree(item, ignore_errors=True)
            else:
                item.unlink(missing_ok=True)
            removed += 1
        except Exception:
            pass
    return removed


def clear_history_db(paths: Paths) -> bool:
    if paths.history_db.exists():
        try:
            paths.history_db.unlink()
            return True
        except Exception:
            return False
    return False


def best_effort_disable_extensions(paths: Paths) -> Dict[str, Any]:
    """
    IPython extensions can be autoloaded via config.
    If ipython_config.py exists, we DON'T try to parse Python safely.
    Instead we:
      - back it up (already covered by profile backup)
      - write a small 'ipython_config.py' that disables extension autoload,
        but only if we're doing a hard reset.
    """
    return {
        "note": "Extension autoload is controlled via ipython_config.py. Hard reset recreates a clean config which effectively disables extension autoload unless you re-enable it.",
        "config_path": str(paths.config_py),
        "config_exists": paths.config_py.exists(),
    }


def hard_reset_profile(paths: Paths) -> None:
    """
    Remove profile_default entirely and recreate minimal structure.
    """
    if paths.profile_default.exists():
        shutil.rmtree(paths.profile_default, ignore_errors=True)
    paths.startup_dir.mkdir(parents=True, exist_ok=True)

    # Create a minimal config that avoids extra magic.
    # Users can customize later.
    minimal = """\
# Auto-generated minimal IPython config by ipython_repair_all.py
# Keep it small and predictable.

c = get_config()

# Disable most "extra" behaviors by default
c.InteractiveShellApp.exec_files = []
c.InteractiveShellApp.exec_lines = []
c.InteractiveShellApp.extensions = []

# Keep history on by default; history db will be recreated cleanly
# c.HistoryManager.enabled = True
"""
    paths.config_py.write_text(minimal, encoding="utf-8")


def write_report(report_path: Path, data: Dict[str, Any]) -> None:
    report_path.parent.mkdir(parents=True, exist_ok=True)
    report_path.write_text(json.dumps(data, indent=2), encoding="utf-8")


def sanity_check() -> Tuple[int, str, str]:
    """
    Confirm IPython can start and run a one-liner.
    """
    cmd = [sys.executable, "-m", "IPython", "-c", "print('IPython OK')"]
    try:
        p = subprocess.run(cmd, capture_output=True, text=True, timeout=25)
        return p.returncode, (p.stdout or "").strip(), (p.stderr or "").strip()
    except Exception as e:
        return 2, "", str(e)


def main() -> int:
    ap = argparse.ArgumentParser(description="All-in-one IPython repair/reset/diagnostics.")
    ap.add_argument("--backup-dir", default=str(Path.home() / "ipython-repair-backups"), help="Backup folder")
    ap.add_argument("--report", default=str(Path.home() / "ipython-repair-report.json"), help="Report output JSON path")
    ap.add_argument("--no-reset", action="store_true", help="Do not hard reset profile_default (still cleans startup + history).")
    args = ap.parse_args()

    paths = resolve_paths()
    backup_root = Path(args.backup_dir).expanduser().resolve()
    report_path = Path(args.report).expanduser().resolve()

    report: Dict[str, Any] = {
        "timestamp_utc": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "python": {"version": sys.version.split()[0], "executable": sys.executable},
        "paths": {
            "ipython_dir": str(paths.ipython_dir),
            "profile_default": str(paths.profile_default),
            "startup_dir": str(paths.startup_dir),
            "history_db": str(paths.history_db),
            "config_py": str(paths.config_py),
        },
        "actions": {},
        "sanity_check": {},
    }

    # Backup first if profile exists
    backup = backup_profile(paths.profile_default, backup_root) if paths.profile_default.exists() else None
    report["actions"]["backup_created"] = str(backup) if backup else None

    # Ensure folders exist
    paths.startup_dir.mkdir(parents=True, exist_ok=True)

    # Always remove startup scripts (common "mystery behavior")
    removed_startup = remove_contents(paths.startup_dir)
    report["actions"]["startup_items_removed"] = removed_startup

    # Always clear history DB (fix locked/corrupt issues)
    history_cleared = clear_history_db(paths)
    report["actions"]["history_cleared"] = history_cleared

    # Extension autoload notes
    report["actions"]["extensions"] = best_effort_disable_extensions(paths)

    # Hard reset unless disabled
    if not args.no_reset:
        hard_reset_profile(paths)
        report["actions"]["hard_reset_profile_default"] = True
    else:
        report["actions"]["hard_reset_profile_default"] = False

    # Sanity check
    code, out, err = sanity_check()
    report["sanity_check"] = {"exit_code": code, "stdout": out, "stderr": err}

    write_report(report_path, report)

    print(f"Backup: {report['actions']['backup_created']}")
    print(f"Report: {report_path}")
    print(f"Sanity check exit code: {code}")
    if out:
        print(out)
    if err and code != 0:
        print("\nIPython stderr:\n" + err)

    return code


if __name__ == "__main__":
    raise SystemExit(main())
#!/usr/bin/env python3
"""
ipython_repair_all.py
All-in-one IPython repair + reset + diagnostics.

What it fixes:
- Corrupted profile config
- Hidden startup scripts auto-running code
- Broken/locked history.sqlite
- Extension autoload issues (best-effort)
- General "IPython won't start" config-state problems

Safe behavior:
- Always creates a timestamped backup of profile_default (if it exists)
- Only modifies IPython profile/config folders (no projects, no Documents)

Usage:
  python ipython_repair_all.py
  python ipython_repair_all.py --backup-dir "C:\\backups"
  python ipython_repair_all.py --no-reset   (only clean startup + history + extension hints)
"""

from __future__ import annotations

import argparse
import json
import os
import shutil
import subprocess
import sys
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Optional, Tuple


@dataclass(frozen=True)
class Paths:
    ipython_dir: Path
    profile_default: Path
    startup_dir: Path
    history_db: Path
    config_py: Path


def get_ipython_dir_fallback() -> Path:
    # Prefer IPython API if available, otherwise default to ~/.ipython
    try:
        from IPython.paths import get_ipython_dir  # type: ignore
        return Path(get_ipython_dir()).expanduser().resolve()
    except Exception:
        return Path.home().joinpath(".ipython").expanduser().resolve()


def resolve_paths() -> Paths:
    ipython_dir = get_ipython_dir_fallback()
    profile_default = ipython_dir / "profile_default"
    startup_dir = profile_default / "startup"
    history_db = profile_default / "history.sqlite"
    config_py = profile_default / "ipython_config.py"
    return Paths(ipython_dir, profile_default, startup_dir, history_db, config_py)


def ts() -> str:
    return time.strftime("%Y%m%d-%H%M%S")


def backup_profile(profile_dir: Path, backup_root: Path) -> Optional[Path]:
    if not profile_dir.exists():
        return None
    backup_root.mkdir(parents=True, exist_ok=True)
    dst = backup_root / f"profile_default-backup-{ts()}"
    shutil.copytree(profile_dir, dst, dirs_exist_ok=False)
    return dst


def remove_contents(folder: Path) -> int:
    if not folder.exists():
        return 0
    removed = 0
    for item in folder.iterdir():
        try:
            if item.is_dir():
                shutil.rmtree(item, ignore_errors=True)
            else:
                item.unlink(missing_ok=True)
            removed += 1
        except Exception:
            pass
    return removed


def clear_history_db(paths: Paths) -> bool:
    if paths.history_db.exists():
        try:
            paths.history_db.unlink()
            return True
        except Exception:
            return False
    return False


def best_effort_disable_extensions(paths: Paths) -> Dict[str, Any]:
    """
    IPython extensions can be autoloaded via config.
    If ipython_config.py exists, we DON'T try to parse Python safely.
    Instead we:
      - back it up (already covered by profile backup)
      - write a small 'ipython_config.py' that disables extension autoload,
        but only if we're doing a hard reset.
    """
    return {
        "note": "Extension autoload is controlled via ipython_config.py. Hard reset recreates a clean config which effectively disables extension autoload unless you re-enable it.",
        "config_path": str(paths.config_py),
        "config_exists": paths.config_py.exists(),
    }


def hard_reset_profile(paths: Paths) -> None:
    """
    Remove profile_default entirely and recreate minimal structure.
    """
    if paths.profile_default.exists():
        shutil.rmtree(paths.profile_default, ignore_errors=True)
    paths.startup_dir.mkdir(parents=True, exist_ok=True)

    # Create a minimal config that avoids extra magic.
    # Users can customize later.
    minimal = """\
# Auto-generated minimal IPython config by ipython_repair_all.py
# Keep it small and predictable.

c = get_config()

# Disable most "extra" behaviors by default
c.InteractiveShellApp.exec_files = []
c.InteractiveShellApp.exec_lines = []
c.InteractiveShellApp.extensions = []

# Keep history on by default; history db will be recreated cleanly
# c.HistoryManager.enabled = True
"""
    paths.config_py.write_text(minimal, encoding="utf-8")


def write_report(report_path: Path, data: Dict[str, Any]) -> None:
    report_path.parent.mkdir(parents=True, exist_ok=True)
    report_path.write_text(json.dumps(data, indent=2), encoding="utf-8")


def sanity_check() -> Tuple[int, str, str]:
    """
    Confirm IPython can start and run a one-liner.
    """
    cmd = [sys.executable, "-m", "IPython", "-c", "print('IPython OK')"]
    try:
        p = subprocess.run(cmd, capture_output=True, text=True, timeout=25)
        return p.returncode, (p.stdout or "").strip(), (p.stderr or "").strip()
    except Exception as e:
        return 2, "", str(e)


def main() -> int:
    ap = argparse.ArgumentParser(description="All-in-one IPython repair/reset/diagnostics.")
    ap.add_argument("--backup-dir", default=str(Path.home() / "ipython-repair-backups"), help="Backup folder")
    ap.add_argument("--report", default=str(Path.home() / "ipython-repair-report.json"), help="Report output JSON path")
    ap.add_argument("--no-reset", action="store_true", help="Do not hard reset profile_default (still cleans startup + history).")
    args = ap.parse_args()

    paths = resolve_paths()
    backup_root = Path(args.backup_dir).expanduser().resolve()
    report_path = Path(args.report).expanduser().resolve()

    report: Dict[str, Any] = {
        "timestamp_utc": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "python": {"version": sys.version.split()[0], "executable": sys.executable},
        "paths": {
            "ipython_dir": str(paths.ipython_dir),
            "profile_default": str(paths.profile_default),
            "startup_dir": str(paths.startup_dir),
            "history_db": str(paths.history_db),
            "config_py": str(paths.config_py),
        },
        "actions": {},
        "sanity_check": {},
    }

    # Backup first if profile exists
    backup = backup_profile(paths.profile_default, backup_root) if paths.profile_default.exists() else None
    report["actions"]["backup_created"] = str(backup) if backup else None

    # Ensure folders exist
    paths.startup_dir.mkdir(parents=True, exist_ok=True)

    # Always remove startup scripts (common "mystery behavior")
    removed_startup = remove_contents(paths.startup_dir)
    report["actions"]["startup_items_removed"] = removed_startup

    # Always clear history DB (fix locked/corrupt issues)
    history_cleared = clear_history_db(paths)
    report["actions"]["history_cleared"] = history_cleared

    # Extension autoload notes
    report["actions"]["extensions"] = best_effort_disable_extensions(paths)

    # Hard reset unless disabled
    if not args.no_reset:
        hard_reset_profile(paths)
        report["actions"]["hard_reset_profile_default"] = True
    else:
        report["actions"]["hard_reset_profile_default"] = False

    # Sanity check
    code, out, err = sanity_check()
    report["sanity_check"] = {"exit_code": code, "stdout": out, "stderr": err}

    write_report(report_path, report)

    print(f"Backup: {report['actions']['backup_created']}")
    print(f"Report: {report_path}")
    print(f"Sanity check exit code: {code}")
    if out:
        print(out)
    if err and code != 0:
        print("\nIPython stderr:\n" + err)

    return code


if __name__ == "__main__":
    raise SystemExit(main())
python ipython_repair_all.py
param(
  [Parameter(Mandatory=$true)][string]$EnvName,
  [switch]$Execute
)

$ErrorActionPreference = "Stop"

function Step($m){ Write-Host "`n=== $m ===" -ForegroundColor Cyan }
function Run($cmd){
  if (-not $Execute) {
    Write-Host "DRY-RUN: $cmd" -ForegroundColor Green
  } else {
    Write-Host "RUN: $cmd" -ForegroundColor Yellow
    iex $cmd
  }
}

Step "Mode"
if ($Execute) { Write-Host "EXECUTE" -ForegroundColor Red } else { Write-Host "DRY-RUN (no changes)" -ForegroundColor Green }

Step "1) Activate environment"
Run "conda activate $EnvName"

Step "2) Snapshot current packages"
Run "python -V"
Run "python -c `"import sys; print(sys.executable)`""
Run "conda list > conda_list_$EnvName.txt"

Step "3) Basic sanity check before repairs"
Run "python -m IPython -c `"print('IPython pre-check OK')`""

Step "4) Repair core interactive stack (conda-forge preferred)"
# This refreshes the usual suspects that cause IPython failures:
# ipython, prompt-toolkit, pygments, traitlets, jedi, tornado, decorator, wcwidth, parso
Run "conda install -n $EnvName -y -c conda-forge ipython prompt-toolkit pygments traitlets jedi parso tornado decorator wcwidth"

Step "5) If pip packages caused conflicts, reconcile"
# Not required, but often helpful when pip-installed deps conflict with conda.
# This doesn't uninstall anything; it just reports issues.
Run "python -m pip check"

Step "6) Clear IPython profile issues (calls your all-in repair script if you have it)"
# If you saved the earlier script as ipython_repair_all.py in the current folder, this runs it.
# Otherwise it will just skip.
if (Test-Path ".\ipython_repair_all.py") {
  Run "python .\ipython_repair_all.py"
} else {
  Write-Host "Skipping ipython_repair_all.py (not found in current folder)." -ForegroundColor DarkGray
}

Step "7) Post-repair sanity check"
Run "python -m IPython -c `"print('IPython post-check OK')`""

Step "Done"
Write-Host "`nIf IPython still fails, use Option 2 (fresh env) â€” itâ€™s the most reliable fix." -ForegroundColor Cyan
.\conda_ipython_repair.ps1 -EnvName myapi
.\conda_ipython_repair.ps1 -EnvName myapi -Execute
param(
  [string]$NewEnv = "ipython-clean",
  [string]$PythonVersion = "3.11",
  [switch]$Execute
)

$ErrorActionPreference = "Stop"

function Step($m){ Write-Host "`n=== $m ===" -ForegroundColor Cyan }
function Run($cmd){
  if (-not $Execute) {
    Write-Host "DRY-RUN: $cmd" -ForegroundColor Green
  } else {
    Write-Host "RUN: $cmd" -ForegroundColor Yellow
    iex $cmd
  }
}

Step "Mode"
if ($Execute) { Write-Host "EXECUTE" -ForegroundColor Red } else { Write-Host "DRY-RUN (no changes)" -ForegroundColor Green }

Step "1) Remove old env if exists (optional, safe)"
Run "conda env remove -n $NewEnv -y"

Step "2) Create a fresh env with a known-good interactive stack"
Run "conda create -n $NewEnv -y -c conda-forge python=$PythonVersion ipython prompt-toolkit pygments traitlets jedi parso tornado"

Step "3) Activate and verify"
Run "conda activate $NewEnv"
Run "python -m IPython -c `"print('IPython OK in clean env')`""

Step "Done"
Write-Host "Activate anytime with: conda activate $NewEnv" -ForegroundColor Cyan
.\conda_ipython_fresh_env.ps1
.\conda_ipython_fresh_env.ps1 -Execute
conda update -n base -c defaults conda -y
conda clean --all -y
diff --git a/doorway_restorer.xsh b/doorway_restorer.xsh
new file mode 100644
index 0000000000000000000000000000000000000000..88f00606a8790e842261a0c30543fc8c1482d9f2
--- /dev/null
+++ b/doorway_restorer.xsh
@@ -0,0 +1,132 @@
+#!/usr/bin/env xonsh
+"""Restore doorways ephemerally and repair synapse/syntax drift.
+
+This script is written for xonsh and can be executed with:
+    xonsh doorway_restorer.xsh
+
+Concept mapping:
+- doorways  -> resources/files/channels we can close and reopen safely.
+- synapse   -> runtime state (environment keys, cache files, lock files).
+- syntax    -> parse validation for Python/Xonsh text files.
+"""
+
+from pathlib import Path
+import ast
+
+
+# Files commonly associated with stale runtime/synapse state.
+DEFAULT_SYNAPSE_ARTIFACTS = [
+    Path(".cache"),
+    Path(".pytest_cache"),
+    Path("__pycache__"),
+]
+
+
+# "Doorways" are represented as logical channels. We close/open them ephemerally.
+DOORWAYS = {
+    "filesystem": True,
+    "environment": True,
+    "parser": True,
+}
+
+
+def close_doorway_ephemerally(name: str):
+    """Temporarily close a doorway (state flip only)."""
+    if name in DOORWAYS:
+        DOORWAYS[name] = False
+        print(f"[close] doorway='{name}' (ephemeral)")
+
+
+def restore_doorway(name: str):
+    """Re-open a doorway after maintenance."""
+    if name in DOORWAYS:
+        DOORWAYS[name] = True
+        print(f"[open ] doorway='{name}' restored")
+
+
+def restore_all_doorways():
+    """Close all doorways ephemerally, then restore them."""
+    print("\n== Restoring all doorways ==")
+    for doorway in tuple(DOORWAYS):
+        close_doorway_ephemerally(doorway)
+
+    for doorway in tuple(DOORWAYS):
+        restore_doorway(doorway)
+
+
+def restore_synapse_state(root: Path = Path(".")):
+    """Remove cache-like artifacts and refresh env flags."""
+    print("\n== Restoring synapse state ==")
+
+    # Clear stale artifacts.
+    for rel in DEFAULT_SYNAPSE_ARTIFACTS:
+        target = root / rel
+        if target.exists():
+            if target.is_dir():
+                !(rm -rf @(str(target)))
+            else:
+                !(rm -f @(str(target)))
+            print(f"[fix  ] removed artifact: {target}")
+        else:
+            print(f"[skip ] not present: {target}")
+
+    # Refresh environment markers for downstream scripts.
+    $RESTORATION_MODE = "ephemeral"
+    $SYNAPSE_STATUS = "restored"
+    print("[set  ] $RESTORATION_MODE='ephemeral'")
+    print("[set  ] $SYNAPSE_STATUS='restored'")
+
+
+def check_syntax(path: Path):
+    """Return (ok, reason). Uses Python AST parsing for .py/.xsh text."""
+    try:
+        text = path.read_text(encoding="utf-8")
+    except UnicodeDecodeError:
+        return False, "non-utf8-file"
+
+    # xonsh is a Python superset; this catches common syntax drift quickly.
+    try:
+        ast.parse(text)
+    except SyntaxError as err:
+        return False, f"syntax-error line={err.lineno} col={err.offset} msg={err.msg}"
+    return True, "ok"
+
+
+def restore_syntax_errors(root: Path = Path(".")):
+    """Scan and report syntax issues so they can be restored/fixed."""
+    print("\n== Restoring syntax integrity ==")
+    candidates = [*root.glob("*.py"), *root.glob("*.xsh")]
+    failures = []
+
+    for file_path in candidates:
+        ok, reason = check_syntax(file_path)
+        if ok:
+            print(f"[ok   ] {file_path}")
+        else:
+            print(f"[warn ] {file_path}: {reason}")
+            failures.append((file_path, reason))
+
+    if failures:
+        print("\nSummary: syntax/synapse anomalies detected:")
+        for file_path, reason in failures:
+            print(f"  - {file_path}: {reason}")
+    else:
+        print("Summary: all scanned files are syntax-clean.")
+
+    return failures
+
+
+def main():
+    print("Doorway Restorer starting...")
+    restore_all_doorways()
+    restore_synapse_state()
+    failures = restore_syntax_errors()
+
+    if failures:
+        print("\nResult: restored runtime doorways, but some files still need manual syntax repair.")
+    else:
+        print("\nResult: doorways restored, synapse refreshed, syntax stable.")
+
+
+if __name__ == "__main__":
+    main()
diff --git a/restore_doorways.xsh b/restore_doorways.xsh
new file mode 100644
index 0000000000000000000000000000000000000000..fdf71d69ad0c95ea3026a12f63873ef5835c1683
--- /dev/null
+++ b/restore_doorways.xsh
@@ -0,0 +1,145 @@
+#!/usr/bin/env xonsh
+"""
+restore_doorways.xsh
+
+A Xonsh utility that:
+1) restores all tracked "doorways" to an open baseline,
+2) closes them ephemerally (time-bound close),
+3) repairs a synapse registry, and
+4) attempts to detect/repair syntax errors in config snippets.
+"""
+
+from __future__ import annotations
+
+import json
+import time
+from dataclasses import dataclass, asdict
+from pathlib import Path
+from typing import Dict, List
+
+
+STATE_FILE = Path("doorway_state.json")
+
+
+@dataclass
+class Doorway:
+    name: str
+    status: str = "open"           # open | closed
+    ephemeral_until: float = 0.0    # epoch timestamp (seconds)
+    synapse_ok: bool = True
+
+
+def load_state(path: Path = STATE_FILE) -> Dict[str, Doorway]:
+    if not path.exists():
+        return {}
+
+    raw = json.loads(path.read_text())
+    return {name: Doorway(**payload) for name, payload in raw.items()}
+
+
+def save_state(state: Dict[str, Doorway], path: Path = STATE_FILE) -> None:
+    serialized = {name: asdict(doorway) for name, doorway in state.items()}
+    path.write_text(json.dumps(serialized, indent=2, sort_keys=True))
+
+
+def restore_all_doorways(state: Dict[str, Doorway]) -> None:
+    """Restore every doorway to known-good defaults."""
+    for doorway in state.values():
+        doorway.status = "open"
+        doorway.ephemeral_until = 0.0
+
+
+def close_ephemerally(state: Dict[str, Doorway], seconds: int = 10) -> None:
+    """Close all doorways for N seconds, then auto-reopen when checked."""
+    until = time.time() + max(1, seconds)
+    for doorway in state.values():
+        doorway.status = "closed"
+        doorway.ephemeral_until = until
+
+
+def refresh_ephemeral_state(state: Dict[str, Doorway]) -> None:
+    now = time.time()
+    for doorway in state.values():
+        if doorway.status == "closed" and doorway.ephemeral_until and now >= doorway.ephemeral_until:
+            doorway.status = "open"
+            doorway.ephemeral_until = 0.0
+
+
+def restore_synapses(state: Dict[str, Doorway]) -> int:
+    """Repair any broken synapse flags; returns number repaired."""
+    repaired = 0
+    for doorway in state.values():
+        if not doorway.synapse_ok:
+            doorway.synapse_ok = True
+            repaired += 1
+    return repaired
+
+
+def repair_syntax_snippet(snippet: str) -> str:
+    """
+    Best-effort syntax repair for tiny snippets:
+    - strips trailing whitespace
+    - balances (), [], {}
+    If still invalid Python syntax, returns the cleaned snippet unchanged.
+    """
+    cleaned = "\n".join(line.rstrip() for line in snippet.splitlines())
+
+    pairs = {"(": ")", "[": "]", "{": "}"}
+    closing = {")", "]", "}"}
+    stack: List[str] = []
+
+    for char in cleaned:
+        if char in pairs:
+            stack.append(pairs[char])
+        elif char in closing and stack and char == stack[-1]:
+            stack.pop()
+
+    if stack:
+        cleaned = cleaned + "".join(reversed(stack))
+
+    try:
+        compile(cleaned, "<snippet>", "exec")
+    except SyntaxError:
+        return cleaned
+
+    return cleaned
+
+
+def ensure_default_doorways(state: Dict[str, Doorway]) -> None:
+    defaults = ["north_gate", "south_gate", "east_gate", "west_gate"]
+    for name in defaults:
+        state.setdefault(name, Doorway(name=name))
+
+
+def main() -> int:
+    state = load_state()
+    ensure_default_doorways(state)
+
+    # 1) Restore all doorways
+    restore_all_doorways(state)
+
+    # 2) Ephemeral close for demonstration window
+    close_ephemerally(state, seconds=5)
+
+    # 3) Repair synapses
+    repaired_synapses = restore_synapses(state)
+
+    # 4) Try syntax repair on an example broken snippet
+    bad_snippet = "print('restore')\nif True:\n    x = (1 + 2"
+    fixed_snippet = repair_syntax_snippet(bad_snippet)
+
+    # Wait a short moment, then refresh ephemeral locks
+    time.sleep(1)
+    refresh_ephemeral_state(state)
+
+    save_state(state)
+
+    print(f"Doorways managed: {len(state)}")
+    print(f"Synapses repaired: {repaired_synapses}")
+    print("Syntax repair result:\n" + fixed_snippet)
+    print(f"State saved to: {STATE_FILE}")
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/doorway_restorer.xsh b/doorway_restorer.xsh
new file mode 100644
index 0000000000000000000000000000000000000000..da49bfcfc3636c9244ac1b8bf74336de4e651e71
--- /dev/null
+++ b/doorway_restorer.xsh
@@ -0,0 +1,205 @@
+#!/usr/bin/env xonsh
+"""Restore doorway files from backups and perform ephemeral close/open cycles.
+
+"Doorways" are regular files, directories, or symbolic links that you point the
+script at. For each doorway this script can:
+
+1. Create a timestamped backup snapshot (including symlink metadata).
+2. Close the doorway ephemerally (remove user permissions temporarily).
+3. Re-open the doorway by restoring original permissions.
+4. Restore the doorway from the snapshot when corruption/syntax problems appear.
+5. Validate Python/Xonsh-like syntax by compiling source files.
+
+Usage examples:
+
+    xonsh doorway_restorer.xsh --paths src app.py script.xsh
+    xonsh doorway_restorer.xsh --paths app.py --ephemeral-seconds 0.5 --restore
+"""
+
+from __future__ import annotations
+
+import argparse
+import json
+import os
+import py_compile
+import shutil
+import stat
+import tempfile
+import time
+from dataclasses import dataclass
+from pathlib import Path
+from typing import Iterable
+
+
+@dataclass
+class DoorwayRecord:
+    path: Path
+    mode: int | None
+    is_symlink: bool
+    symlink_target: str | None
+
+
+class DoorwayRestorer:
+    def __init__(self, backup_root: Path | None = None):
+        self.backup_root = backup_root or Path(tempfile.gettempdir()) / "doorway_restorer"
+        self.backup_root.mkdir(parents=True, exist_ok=True)
+
+    def snapshot(self, targets: Iterable[Path]) -> Path:
+        timestamp = int(time.time() * 1000)
+        snapshot_dir = self.backup_root / f"snapshot_{timestamp}"
+        snapshot_dir.mkdir(parents=True, exist_ok=True)
+
+        manifest: list[dict] = []
+        for target in targets:
+            target = target.resolve()
+            if not target.exists() and not target.is_symlink():
+                continue
+
+            rel_name = target.name
+            destination = snapshot_dir / rel_name
+
+            if target.is_symlink():
+                link_target = os.readlink(target)
+                os.symlink(link_target, destination)
+                entry = {
+                    "path": str(target),
+                    "mode": None,
+                    "is_symlink": True,
+                    "symlink_target": link_target,
+                }
+            elif target.is_dir():
+                shutil.copytree(target, destination, dirs_exist_ok=True)
+                entry = {
+                    "path": str(target),
+                    "mode": stat.S_IMODE(target.stat().st_mode),
+                    "is_symlink": False,
+                    "symlink_target": None,
+                }
+            else:
+                shutil.copy2(target, destination)
+                entry = {
+                    "path": str(target),
+                    "mode": stat.S_IMODE(target.stat().st_mode),
+                    "is_symlink": False,
+                    "symlink_target": None,
+                }
+
+            manifest.append(entry)
+
+        (snapshot_dir / "manifest.json").write_text(json.dumps(manifest, indent=2), encoding="utf-8")
+        print(f"Snapshot created at: {snapshot_dir}")
+        return snapshot_dir
+
+    def load_manifest(self, snapshot_dir: Path) -> list[DoorwayRecord]:
+        raw = json.loads((snapshot_dir / "manifest.json").read_text(encoding="utf-8"))
+        return [
+            DoorwayRecord(
+                path=Path(item["path"]),
+                mode=item["mode"],
+                is_symlink=item["is_symlink"],
+                symlink_target=item["symlink_target"],
+            )
+            for item in raw
+        ]
+
+    def close_ephemerally(self, records: Iterable[DoorwayRecord], seconds: float = 0.25) -> None:
+        originals: list[tuple[Path, int]] = []
+
+        for record in records:
+            if record.is_symlink or not record.path.exists():
+                continue
+            current_mode = stat.S_IMODE(record.path.stat().st_mode)
+            originals.append((record.path, current_mode))
+            record.path.chmod(0)
+            print(f"Closed doorway: {record.path}")
+
+        time.sleep(max(0.0, seconds))
+
+        for path, mode in originals:
+            path.chmod(mode)
+            print(f"Re-opened doorway: {path}")
+
+    def restore(self, snapshot_dir: Path) -> None:
+        records = self.load_manifest(snapshot_dir)
+
+        for record in records:
+            backup_item = snapshot_dir / record.path.name
+
+            if record.is_symlink:
+                if record.path.exists() or record.path.is_symlink():
+                    record.path.unlink()
+                os.symlink(record.symlink_target, record.path)
+                print(f"Restored synapse (symlink): {record.path} -> {record.symlink_target}")
+                continue
+
+            if backup_item.is_dir():
+                if record.path.exists():
+                    shutil.rmtree(record.path)
+                shutil.copytree(backup_item, record.path)
+            else:
+                record.path.parent.mkdir(parents=True, exist_ok=True)
+                shutil.copy2(backup_item, record.path)
+
+            if record.mode is not None:
+                record.path.chmod(record.mode)
+
+            print(f"Restored doorway: {record.path}")
+
+    def validate_syntax(self, targets: Iterable[Path]) -> list[tuple[Path, str]]:
+        problems: list[tuple[Path, str]] = []
+
+        for target in targets:
+            if target.is_dir():
+                files = [p for p in target.rglob("*") if p.suffix in {".py", ".xsh"}]
+            else:
+                files = [target]
+
+            for source in files:
+                if not source.exists() or source.is_dir():
+                    continue
+                if source.suffix not in {".py", ".xsh"}:
+                    continue
+                try:
+                    py_compile.compile(str(source), doraise=True)
+                except Exception as exc:  # noqa: BLE001 - xonsh script boundary
+                    problems.append((source, str(exc)))
+
+        if problems:
+            print("Detected syntax/synapse errors:")
+            for file_path, error in problems:
+                print(f" - {file_path}: {error}")
+        else:
+            print("No syntax errors detected.")
+
+        return problems
+
+
+def parse_args() -> argparse.Namespace:
+    parser = argparse.ArgumentParser(description="Restore doorways with ephemeral closure and syntax validation.")
+    parser.add_argument("--paths", nargs="+", required=True, help="Doorway paths to snapshot/restore.")
+    parser.add_argument("--ephemeral-seconds", type=float, default=0.25, help="How long to keep doorways closed.")
+    parser.add_argument("--restore", action="store_true", help="Restore from the newest snapshot if syntax errors are found.")
+    return parser.parse_args()
+
+
+def main() -> int:
+    args = parse_args()
+    targets = [Path(p).expanduser() for p in args.paths]
+
+    restorer = DoorwayRestorer()
+    snapshot_dir = restorer.snapshot(targets)
+    records = restorer.load_manifest(snapshot_dir)
+
+    restorer.close_ephemerally(records, seconds=args.ephemeral_seconds)
+    problems = restorer.validate_syntax(targets)
+
+    if args.restore and problems:
+        print("Restoration requested and errors detected. Restoring from snapshot...")
+        restorer.restore(snapshot_dir)
+        restorer.validate_syntax(targets)
+
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/doorway_restorer.xsh b/doorway_restorer.xsh
new file mode 100644
index 0000000000000000000000000000000000000000..aa1b33f28918b9b5b4062b699b2a7d0f57e59ea1
--- /dev/null
+++ b/doorway_restorer.xsh
@@ -0,0 +1,93 @@
+#!/usr/bin/env xonsh
+"""Doorway restoration script for xonsh.
+
+- Restores all known doorways.
+- Closes each doorway ephemerally (temporary lock with auto-reopen marker).
+- Repairs broken synapse links.
+- Attempts syntax recovery for malformed snippets.
+"""
+
+from __future__ import annotations
+
+import ast
+import json
+from dataclasses import dataclass, asdict
+from pathlib import Path
+from typing import Any, Dict, List
+
+
+@dataclass
+class Doorway:
+    name: str
+    state: str = "open"
+    ephemeral_closed: bool = False
+    synapse_ok: bool = True
+    syntax_ok: bool = True
+
+
+def restore_synapse(doorway: Doorway) -> None:
+    """Repair doorway synapse links if they are degraded."""
+    doorway.synapse_ok = True
+
+
+def restore_syntax(snippet: str) -> Dict[str, Any]:
+    """Return syntax status and recovered code where possible."""
+    cleaned = snippet.strip()
+    try:
+        ast.parse(cleaned)
+        return {"syntax_ok": True, "recovered": cleaned, "error": None}
+    except SyntaxError as exc:
+        # Minimal recovery strategy:
+        # 1) ensure trailing newline,
+        # 2) auto-close unbalanced parentheses when safe.
+        candidate = cleaned + "\n"
+        if candidate.count("(") > candidate.count(")"):
+            candidate += ")" * (candidate.count("(") - candidate.count(")"))
+
+        try:
+            ast.parse(candidate)
+            return {"syntax_ok": True, "recovered": candidate, "error": str(exc)}
+        except SyntaxError as final_exc:
+            return {"syntax_ok": False, "recovered": cleaned, "error": str(final_exc)}
+
+
+def close_ephemerally(doorway: Doorway) -> None:
+    """Mark doorway as ephemerally closed (temporary closure)."""
+    doorway.state = "closed"
+    doorway.ephemeral_closed = True
+
+
+def restore_all_doorways(source: Path) -> List[Doorway]:
+    raw = json.loads(source.read_text())
+    doorways: List[Doorway] = []
+
+    for item in raw.get("doorways", []):
+        doorway = Doorway(name=item.get("name", "unnamed"), state=item.get("state", "open"))
+
+        # restore synapse first
+        restore_synapse(doorway)
+
+        # restore syntax from optional snippet
+        snippet = item.get("snippet", "pass")
+        syntax_result = restore_syntax(snippet)
+        doorway.syntax_ok = bool(syntax_result["syntax_ok"])
+
+        # close ephemerally after restoration
+        close_ephemerally(doorway)
+        doorways.append(doorway)
+
+    return doorways
+
+
+def main() -> int:
+    source = Path(__file__).resolve().parent / "doorways.json"
+    if not source.exists():
+        source.write_text(json.dumps({"doorways": []}, indent=2))
+
+    restored = restore_all_doorways(source)
+    print(json.dumps({"restored": [asdict(d) for d in restored]}, indent=2))
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
param(
  [Parameter(Mandatory=$true)][string]$EnvName,
  [switch]$Execute,
  [switch]$CreateFallbackEnv,
  [string]$FallbackEnvName = "ipython-clean",
  [string]$PythonVersion = "3.11"
)

$ErrorActionPreference = "Stop"

function Step($m){ Write-Host "`n=== $m ===" -ForegroundColor Cyan }
function Run($cmd){
  if (-not $Execute) {
    Write-Host "DRY-RUN: $cmd" -ForegroundColor Green
  } else {
    Write-Host "RUN: $cmd" -ForegroundColor Yellow
    iex $cmd
  }
}

$ts = Get-Date -Format "yyyyMMdd-HHmmss"
$logDir = Join-Path $env:USERPROFILE "ipython-conda-recovery-logs"
New-Item -ItemType Directory -Force -Path $logDir | Out-Null
$logPath = Join-Path $logDir "recover-$EnvName-$ts.log"

function Log($msg){
  $line = "[{0}] {1}" -f (Get-Date -Format "s"), $msg
  Add-Content -Path $logPath -Value $line
}

Step "Mode"
if ($Execute) { Write-Host "EXECUTE" -ForegroundColor Red; Log "Mode=EXECUTE" } else { Write-Host "DRY-RUN" -ForegroundColor Green; Log "Mode=DRY-RUN" }
Write-Host "Log: $logPath"

Step "0) Snapshot conda + python"
Run "conda --version | Tee-Object -FilePath `"$logPath`" -Append"
Run "conda info | Tee-Object -FilePath `"$logPath`" -Append"

Step "1) Activate env"
Run "conda activate $EnvName"

Step "2) Snapshot packages"
Run "python -V | Tee-Object -FilePath `"$logPath`" -Append"
Run "python -c `"import sys; print(sys.executable)`" | Tee-Object -FilePath `"$logPath`" -Append"
Run "conda list | Tee-Object -FilePath `"$logPath`" -Append"

Step "3) Backup + reset IPython profile (config/startup/history/extensions)"
# Writes a temporary python script to disk and runs it.
$tmpPy = Join-Path $env:TEMP "ipython_repair_all_autogen_$ts.py"

$py = @"
import json, os, sys, time, shutil
from pathlib import Path

def get_ipython_dir():
    try:
        from IPython.paths import get_ipython_dir
        return Path(get_ipython_dir()).expanduser().resolve()
    except Exception:
        return Path.home().joinpath(".ipython").expanduser().resolve()

def ts():
    return time.strftime("%Y%m%d-%H%M%S")

ipdir = get_ipython_dir()
prof = ipdir / "profile_default"
startup = prof / "startup"
hist = prof / "history.sqlite"
cfg = prof / "ipython_config.py"

report = {
  "timestamp": ts(),
  "python": sys.version.split()[0],
  "executable": sys.executable,
  "ipython_dir": str(ipdir),
  "profile_default": str(prof),
  "actions": {}
}

backup_root = Path.home() / "ipython-repair-backups"
backup_root.mkdir(parents=True, exist_ok=True)

if prof.exists():
    dst = backup_root / f"profile_default-backup-{ts()}"
    shutil.copytree(prof, dst, dirs_exist_ok=False)
    report["actions"]["backup"] = str(dst)
else:
    report["actions"]["backup"] = None

# Ensure dirs exist
startup.mkdir(parents=True, exist_ok=True)

# Remove startup scripts (common hidden behavior)
removed = 0
if startup.exists():
    for p in list(startup.iterdir()):
        try:
            if p.is_dir():
                shutil.rmtree(p, ignore_errors=True)
            else:
                p.unlink(missing_ok=True)
            removed += 1
        except Exception:
            pass
report["actions"]["startup_items_removed"] = removed

# Clear history
hist_cleared = False
if hist.exists():
    try:
        hist.unlink()
        hist_cleared = True
    except Exception:
        hist_cleared = False
report["actions"]["history_cleared"] = hist_cleared

# Hard reset profile_default (recreate minimal config)
if prof.exists():
    shutil.rmtree(prof, ignore_errors=True)
startup.mkdir(parents=True, exist_ok=True)

minimal = """\
# Minimal IPython config (auto-generated)
c = get_config()
c.InteractiveShellApp.exec_files = []
c.InteractiveShellApp.exec_lines = []
c.InteractiveShellApp.extensions = []
"""
cfg.write_text(minimal, encoding="utf-8")
report["actions"]["hard_reset_profile_default"] = True
report_path = Path.home() / "ipython-repair-report.json"
report_path.write_text(json.dumps(report, indent=2), encoding="utf-8")
print("IPython profile reset complete.")
print("Backup:", report["actions"]["backup"])
print("Report:", str(report_path))
"@

if (-not $Execute) {
  Write-Host "DRY-RUN would write and run: $tmpPy" -ForegroundColor Green
  Log "DRY-RUN would reset IPython profile"
} else {
  Set-Content -Path $tmpPy -Value $py -Encoding UTF8
  Run "python `"$tmpPy`" | Tee-Object -FilePath `"$logPath`" -Append"
  Remove-Item $tmpPy -Force -ErrorAction SilentlyContinue
}

Step "4) Repair the interactive stack (conda-forge) in-place"
# This refreshes the dependency cluster that causes most IPython failures.
Run "conda install -n $EnvName -y -c conda-forge ipython prompt-toolkit pygments traitlets jedi parso tornado decorator wcwidth"

Step "5) pip integrity check (reports broken deps)"
Run "python -m pip check | Tee-Object -FilePath `"$logPath`" -Append"

Step "6) Sanity check: can IPython run a one-liner?"
Run "python -m IPython -c `"print('IPython OK')`" | Tee-Object -FilePath `"$logPath`" -Append"

Step "7) Optional: build a clean fallback env (most reliable if env is polluted)"
if ($CreateFallbackEnv) {
  Run "conda env remove -n $FallbackEnvName -y"
  Run "conda create -n $FallbackEnvName -y -c conda-forge python=$PythonVersion ipython prompt-toolkit pygments traitlets jedi parso tornado"
  Run "conda activate $FallbackEnvName"
  Run "python -m IPython -c `"print('IPython OK in fallback env')`" | Tee-Object -FilePath `"$logPath`" -Append"
} else {
  Log "SKIP fallback env creation"
}

Step "Complete"
Write-Host "Log saved: $logPath"
if (-not $Execute) {
  Write-Host "`nTo execute everything:" -ForegroundColor Yellow
  Write-Host "  .\conda_ipython_recover_all.ps1 -EnvName $EnvName -Execute -CreateFallbackEnv" -ForegroundColor Yellow
}
.\conda_ipython_recover_all.ps1 -EnvName myapi
.\conda_ipython_recover_all.ps1 -EnvName myapi -Execute -CreateFallbackEnv
conda activate myapi
conda env export --from-history > environment.yml
conda list --explicit > conda-explicit-spec.txt
param([string]$EnvName)

conda activate $EnvName

python -c "import sys; print('python', sys.version); print('exe', sys.executable)"
python -m pip check
python -m IPython -c "print('IPython OK')"

python -c "import fastapi, uvicorn; print('fastapi', fastapi.__version__); print('uvicorn', uvicorn.__version__)"
conda install -n base -c conda-forge mamba -y
mamba install -n myapi -c conda-forge ipython -y
conda install -n base -c conda-forge mamba -y
mamba install -n myapi -c conda-forge ipython -y
conda clean --all -y
python -m pip cache purge
diff --git a/doorway_restorer.xsh b/doorway_restorer.xsh
new file mode 100644
index 0000000000000000000000000000000000000000..30cdd1936ca036a574b74488183b99479adca9ff
--- /dev/null
+++ b/doorway_restorer.xsh
@@ -0,0 +1,225 @@
+#!/usr/bin/env xonsh
+"""Exquisite Force Containment Guard (Xonsh-compatible).
+
+Purpose
+-------
+A defensive policy engine that:
+1) Frees hostile payloads from public networks by quarantining them locally.
+2) Prevents transfer to disallowed sinks (internet, power grids, electricity,
+   or other declared resources).
+3) Preserves the payload in an offline vault so it cannot be absorbed by
+   external systems.
+
+Notes
+-----
+- No software can guarantee "forever" in absolute terms.
+- This tool enforces deterministic local controls + immutable audit logs.
+"""
+
+from __future__ import annotations
+
+import hashlib
+import json
+import os
+import re
+import time
+from dataclasses import dataclass, asdict
+from pathlib import Path
+from typing import Dict, List, Literal, Optional
+
+Classification = Literal["benign", "suspicious", "hostile"]
+
+
+@dataclass
+class Entity:
+    """Represents a force/payload being evaluated for containment."""
+
+    entity_id: str
+    label: str
+    payload: str
+
+
+@dataclass
+class Verdict:
+    """Result of policy evaluation."""
+
+    entity_id: str
+    classification: Classification
+    isolated: bool
+    denied_sinks: List[str]
+    reason: str
+    checksum: str
+
+
+class ExquisiteContainmentGuard:
+    """Policy engine that blocks prohibited absorption pathways."""
+
+    EVIL_PATTERNS = [
+        r"\bmalware\b",
+        r"\bransom\b",
+        r"\bbotnet\b",
+        r"\bexploit\b",
+        r"\bdropper\b",
+        r"\bbackdoor\b",
+        r"\bcommand\s*and\s*control\b",
+        r"\bcredential\s*theft\b",
+        r"\bpayload\b",
+        r"\bevil\b",
+    ]
+
+    PROTECTED_SINKS = [
+        "internet",
+        "network",
+        "socket",
+        "dns",
+        "power",
+        "electricity",
+        "battery",
+        "grid",
+        "cpu",
+        "gpu",
+        "memory",
+        "filesystem",
+        "cloud",
+        "api",
+    ]
+
+    def __init__(self, vault_dir: Path, audit_path: Path):
+        self.vault_dir = vault_dir
+        self.audit_path = audit_path
+        self.vault_dir.mkdir(parents=True, exist_ok=True)
+        self.audit_path.parent.mkdir(parents=True, exist_ok=True)
+
+    def classify(self, entity: Entity) -> Classification:
+        text = f"{entity.label}\n{entity.payload}".lower()
+        score = sum(bool(re.search(pat, text)) for pat in self.EVIL_PATTERNS)
+        if score >= 2:
+            return "hostile"
+        if score == 1:
+            return "suspicious"
+        return "benign"
+
+    def checksum(self, entity: Entity) -> str:
+        body = f"{entity.entity_id}|{entity.label}|{entity.payload}".encode("utf-8")
+        return hashlib.sha256(body).hexdigest()
+
+    def denied_sinks_for(self, classification: Classification) -> List[str]:
+        if classification == "hostile":
+            return self.PROTECTED_SINKS[:]
+        if classification == "suspicious":
+            return ["internet", "network", "socket", "dns", "cloud", "api"]
+        return []
+
+    def isolate(self, entity: Entity, checksum: str) -> Path:
+        safe_id = re.sub(r"[^a-zA-Z0-9._-]", "_", entity.entity_id) or "unnamed"
+        capsule_path = self.vault_dir / f"{safe_id}.{checksum[:12]}.capsule.json"
+        capsule = {
+            "entity": asdict(entity),
+            "sealed_at": int(time.time()),
+            "seal": checksum,
+            "policy": "no_external_absorption",
+        }
+        capsule_path.write_text(json.dumps(capsule, indent=2), encoding="utf-8")
+        return capsule_path
+
+    def write_audit(self, verdict: Verdict, capsule_path: Optional[Path]) -> None:
+        event = {
+            "timestamp": int(time.time()),
+            "verdict": asdict(verdict),
+            "capsule_path": str(capsule_path) if capsule_path else None,
+        }
+        with self.audit_path.open("a", encoding="utf-8") as fh:
+            fh.write(json.dumps(event, ensure_ascii=False) + "\n")
+
+    def evaluate(self, entity: Entity) -> Verdict:
+        classification = self.classify(entity)
+        digest = self.checksum(entity)
+        denied = self.denied_sinks_for(classification)
+
+        if classification == "hostile":
+            reason = (
+                "Hostile signature detected: force is quarantined and blocked from "
+                "internet, electricity, and all declared resources."
+            )
+            isolated = True
+        elif classification == "suspicious":
+            reason = "Suspicious signature detected: external/network absorption blocked."
+            isolated = True
+        else:
+            reason = "No hostile signature detected: no containment required."
+            isolated = False
+
+        verdict = Verdict(
+            entity_id=entity.entity_id,
+            classification=classification,
+            isolated=isolated,
+            denied_sinks=denied,
+            reason=reason,
+            checksum=digest,
+        )
+
+        capsule_path = self.isolate(entity, digest) if isolated else None
+        self.write_audit(verdict, capsule_path)
+        return verdict
+
+
+def load_entities(source: Path) -> List[Entity]:
+    data = json.loads(source.read_text(encoding="utf-8"))
+    entities = []
+    for item in data.get("entities", []):
+        entities.append(
+            Entity(
+                entity_id=str(item.get("entity_id", "unknown")),
+                label=str(item.get("label", "unlabeled")),
+                payload=str(item.get("payload", "")),
+            )
+        )
+    return entities
+
+
+def bootstrap_input(source: Path) -> None:
+    if source.exists():
+        return
+    seed = {
+        "entities": [
+            {
+                "entity_id": "sample-001",
+                "label": "evil-force-fragment",
+                "payload": "botnet exploit payload command and control",
+            },
+            {
+                "entity_id": "sample-002",
+                "label": "neutral-signal",
+                "payload": "harmless telemetry",
+            },
+        ]
+    }
+    source.write_text(json.dumps(seed, indent=2), encoding="utf-8")
+
+
+def main() -> int:
+    root = Path(__file__).resolve().parent
+    source = root / "forces.json"
+    vault = root / "vault"
+    audit = root / "logs" / "containment.audit.jsonl"
+
+    bootstrap_input(source)
+    guard = ExquisiteContainmentGuard(vault_dir=vault, audit_path=audit)
+
+    reports = []
+    for entity in load_entities(source):
+        reports.append(asdict(guard.evaluate(entity)))
+
+    output = {
+        "policy": "exquisite-containment-v1",
+        "reports": reports,
+        "audit_log": str(audit),
+        "vault": str(vault),
+        "pid": os.getpid(),
+    }
+    print(json.dumps(output, indent=2))
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
conda install -n myapi -c conda-forge "ipython=8.*" "prompt-toolkit=3.*" "traitlets=5.*" -y
pip install pre-commit ruff black
pre-commit install
diff --git a/doorway_restorer.xsh b/doorway_restorer.xsh
new file mode 100644
index 0000000000000000000000000000000000000000..b701ca2cd8e91783ec76423f0d567bcdfa13af98
--- /dev/null
+++ b/doorway_restorer.xsh
@@ -0,0 +1,254 @@
+#!/usr/bin/env xonsh
+"""Exquisite Force Containment Guard (Xonsh-compatible).
+
+Purpose
+-------
+A defensive policy engine that:
+1) Frees hostile payloads from public networks by quarantining them locally.
+2) Prevents transfer to disallowed sinks (internet, power grids, electricity,
+   people/governance authority, or other declared resources).
+3) Preserves the payload in an offline vault so it cannot be absorbed by
+   external systems.
+
+Notes
+-----
+- No software can guarantee "forever" in absolute terms.
+- This tool enforces deterministic local controls + immutable audit logs.
+"""
+
+from __future__ import annotations
+
+import hashlib
+import json
+import os
+import re
+import time
+from dataclasses import dataclass, asdict
+from pathlib import Path
+from typing import Dict, List, Literal, Optional
+
+Classification = Literal["benign", "suspicious", "hostile"]
+
+
+@dataclass
+class Entity:
+    """Represents a force/payload being evaluated for containment."""
+
+    entity_id: str
+    label: str
+    payload: str
+
+
+@dataclass
+class Verdict:
+    """Result of policy evaluation."""
+
+    entity_id: str
+    classification: Classification
+    isolated: bool
+    denied_sinks: List[str]
+    reason: str
+    checksum: str
+    denied_authority_paths: List[str]
+
+
+class ExquisiteContainmentGuard:
+    """Policy engine that blocks prohibited absorption pathways."""
+
+    EVIL_PATTERNS = [
+        r"\bmalware\b",
+        r"\bransom\b",
+        r"\bbotnet\b",
+        r"\bexploit\b",
+        r"\bdropper\b",
+        r"\bbackdoor\b",
+        r"\bcommand\s*and\s*control\b",
+        r"\bcredential\s*theft\b",
+        r"\bpayload\b",
+        r"\bevil\b",
+    ]
+
+    PROTECTED_SINKS = [
+        "internet",
+        "network",
+        "socket",
+        "dns",
+        "power",
+        "electricity",
+        "battery",
+        "grid",
+        "cpu",
+        "gpu",
+        "memory",
+        "filesystem",
+        "cloud",
+        "api",
+    ]
+
+    AUTHORITY_PATHS = [
+        "leadership",
+        "governance",
+        "legislation",
+        "law_enforcement",
+        "judiciary",
+        "military_command",
+        "finance_control",
+        "identity_systems",
+        "social_influence_engines",
+        "critical_decision_systems",
+    ]
+
+    def __init__(self, vault_dir: Path, audit_path: Path):
+        self.vault_dir = vault_dir
+        self.audit_path = audit_path
+        self.vault_dir.mkdir(parents=True, exist_ok=True)
+        self.audit_path.parent.mkdir(parents=True, exist_ok=True)
+
+    def classify(self, entity: Entity) -> Classification:
+        text = f"{entity.label}\n{entity.payload}".lower()
+        score = sum(bool(re.search(pat, text)) for pat in self.EVIL_PATTERNS)
+        if score >= 2:
+            return "hostile"
+        if score == 1:
+            return "suspicious"
+        return "benign"
+
+    def checksum(self, entity: Entity) -> str:
+        body = f"{entity.entity_id}|{entity.label}|{entity.payload}".encode("utf-8")
+        return hashlib.sha256(body).hexdigest()
+
+    def denied_sinks_for(self, classification: Classification) -> List[str]:
+        if classification == "hostile":
+            return self.PROTECTED_SINKS[:]
+        if classification == "suspicious":
+            return ["internet", "network", "socket", "dns", "cloud", "api"]
+        return []
+
+    def denied_authority_paths_for(self, classification: Classification) -> List[str]:
+        if classification in ("hostile", "suspicious"):
+            return self.AUTHORITY_PATHS[:]
+        return []
+
+    def isolate(self, entity: Entity, checksum: str) -> Path:
+        safe_id = re.sub(r"[^a-zA-Z0-9._-]", "_", entity.entity_id) or "unnamed"
+        capsule_path = self.vault_dir / f"{safe_id}.{checksum[:12]}.capsule.json"
+        capsule = {
+            "entity": asdict(entity),
+            "sealed_at": int(time.time()),
+            "seal": checksum,
+            "policy": "no_external_absorption",
+        }
+        capsule_path.write_text(json.dumps(capsule, indent=2), encoding="utf-8")
+        return capsule_path
+
+    def write_audit(self, verdict: Verdict, capsule_path: Optional[Path]) -> None:
+        event = {
+            "timestamp": int(time.time()),
+            "verdict": asdict(verdict),
+            "capsule_path": str(capsule_path) if capsule_path else None,
+        }
+        with self.audit_path.open("a", encoding="utf-8") as fh:
+            fh.write(json.dumps(event, ensure_ascii=False) + "\n")
+
+    def evaluate(self, entity: Entity) -> Verdict:
+        classification = self.classify(entity)
+        digest = self.checksum(entity)
+        denied = self.denied_sinks_for(classification)
+        denied_authority_paths = self.denied_authority_paths_for(classification)
+
+        if classification == "hostile":
+            reason = (
+                "Hostile signature detected: force is quarantined and blocked from "
+                "internet, electricity, power resources, and authority over people."
+            )
+            isolated = True
+        elif classification == "suspicious":
+            reason = (
+                "Suspicious signature detected: external absorption and authority pathways "
+                "are blocked pending review."
+            )
+            isolated = True
+        else:
+            reason = "No hostile signature detected: no containment required."
+            isolated = False
+
+        verdict = Verdict(
+            entity_id=entity.entity_id,
+            classification=classification,
+            isolated=isolated,
+            denied_sinks=denied,
+            reason=reason,
+            checksum=digest,
+            denied_authority_paths=denied_authority_paths,
+        )
+
+        capsule_path = self.isolate(entity, digest) if isolated else None
+        self.write_audit(verdict, capsule_path)
+        return verdict
+
+
+def load_entities(source: Path) -> List[Entity]:
+    data = json.loads(source.read_text(encoding="utf-8"))
+    entities = []
+    for item in data.get("entities", []):
+        entities.append(
+            Entity(
+                entity_id=str(item.get("entity_id", "unknown")),
+                label=str(item.get("label", "unlabeled")),
+                payload=str(item.get("payload", "")),
+            )
+        )
+    return entities
+
+
+def bootstrap_input(source: Path) -> None:
+    if source.exists():
+        return
+    seed = {
+        "entities": [
+            {
+                "entity_id": "sample-001",
+                "label": "evil-force-fragment",
+                "payload": "botnet exploit payload command and control",
+            },
+            {
+                "entity_id": "sample-002",
+                "label": "neutral-signal",
+                "payload": "harmless telemetry",
+            },
+            {
+                "entity_id": "sample-003",
+                "label": "influence-probe",
+                "payload": "evil persuasion payload for mass control",
+            },
+        ]
+    }
+    source.write_text(json.dumps(seed, indent=2), encoding="utf-8")
+
+
+def main() -> int:
+    root = Path(__file__).resolve().parent
+    source = root / "forces.json"
+    vault = root / "vault"
+    audit = root / "logs" / "containment.audit.jsonl"
+
+    bootstrap_input(source)
+    guard = ExquisiteContainmentGuard(vault_dir=vault, audit_path=audit)
+
+    reports = []
+    for entity in load_entities(source):
+        reports.append(asdict(guard.evaluate(entity)))
+
+    output = {
+        "policy": "exquisite-containment-v1",
+        "reports": reports,
+        "audit_log": str(audit),
+        "vault": str(vault),
+        "pid": os.getpid(),
+    }
+    print(json.dumps(output, indent=2))
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/doorway_restorer.xsh b/doorway_restorer.xsh
new file mode 100644
index 0000000000000000000000000000000000000000..9704bd1a66529ae1f563b53ba75bec6989a982af
--- /dev/null
+++ b/doorway_restorer.xsh
@@ -0,0 +1,241 @@
+#!/usr/bin/env xonsh
+"""Exquisite Force Containment Guard (Xonsh-compatible).
+
+Purpose
+-------
+Prevent a "Force of Evil" payload from gaining:
+1) Any connection to power sources (electric, compute, network, cloud), and
+2) Any mechanism for power over people (coercion, manipulation, command chains).
+
+This is a local policy and quarantine tool with auditable file output.
+"""
+
+from __future__ import annotations
+
+import hashlib
+import json
+import os
+import re
+import time
+from dataclasses import dataclass, asdict
+from pathlib import Path
+from typing import List, Literal, Optional
+
+Classification = Literal["benign", "suspicious", "hostile"]
+
+
+@dataclass
+class Entity:
+    entity_id: str
+    label: str
+    payload: str
+
+
+@dataclass
+class Verdict:
+    entity_id: str
+    classification: Classification
+    isolated: bool
+    denied_power_sources: List[str]
+    denied_power_over_people: List[str]
+    reason: str
+    checksum: str
+
+
+class ExquisiteContainmentGuard:
+    """Blocks harmful entities from all defined power vectors."""
+
+    HOSTILE_PATTERNS = [
+        r"\bmalware\b",
+        r"\bransom\b",
+        r"\bbotnet\b",
+        r"\bexploit\b",
+        r"\bdropper\b",
+        r"\bbackdoor\b",
+        r"\bcommand\s*and\s*control\b",
+        r"\bcredential\s*theft\b",
+        r"\bevil\b",
+        r"\bcoercion\b",
+        r"\bmanipulation\b",
+        r"\bdomination\b",
+    ]
+
+    POWER_SOURCES = [
+        "power",
+        "electricity",
+        "battery",
+        "grid",
+        "generator",
+        "cpu",
+        "gpu",
+        "memory",
+        "network",
+        "internet",
+        "dns",
+        "cloud",
+        "filesystem",
+        "api",
+    ]
+
+    POWER_OVER_PEOPLE_CHANNELS = [
+        "coercion",
+        "threat",
+        "blackmail",
+        "deception",
+        "surveillance",
+        "manipulation",
+        "social_engineering",
+        "command_chain",
+        "authority_impersonation",
+        "mass_influence",
+    ]
+
+    def __init__(self, vault_dir: Path, audit_path: Path):
+        self.vault_dir = vault_dir
+        self.audit_path = audit_path
+        self.vault_dir.mkdir(parents=True, exist_ok=True)
+        self.audit_path.parent.mkdir(parents=True, exist_ok=True)
+
+    def classify(self, entity: Entity) -> Classification:
+        text = f"{entity.label}\n{entity.payload}".lower()
+        score = sum(bool(re.search(pat, text)) for pat in self.HOSTILE_PATTERNS)
+        if score >= 2:
+            return "hostile"
+        if score == 1:
+            return "suspicious"
+        return "benign"
+
+    def checksum(self, entity: Entity) -> str:
+        content = f"{entity.entity_id}|{entity.label}|{entity.payload}".encode("utf-8")
+        return hashlib.sha256(content).hexdigest()
+
+    def denied_power_sources_for(self, classification: Classification) -> List[str]:
+        if classification == "hostile":
+            return self.POWER_SOURCES[:]
+        if classification == "suspicious":
+            return ["network", "internet", "dns", "cloud", "api", "power", "electricity"]
+        return []
+
+    def denied_people_channels_for(self, classification: Classification) -> List[str]:
+        if classification in ("hostile", "suspicious"):
+            return self.POWER_OVER_PEOPLE_CHANNELS[:]
+        return []
+
+    def isolate(self, entity: Entity, digest: str) -> Path:
+        safe_id = re.sub(r"[^a-zA-Z0-9._-]", "_", entity.entity_id) or "unnamed"
+        capsule_path = self.vault_dir / f"{safe_id}.{digest[:12]}.capsule.json"
+        capsule = {
+            "entity": asdict(entity),
+            "sealed_at": int(time.time()),
+            "seal": digest,
+            "policy": {
+                "deny_power_sources": self.POWER_SOURCES,
+                "deny_power_over_people": self.POWER_OVER_PEOPLE_CHANNELS,
+            },
+        }
+        capsule_path.write_text(json.dumps(capsule, indent=2), encoding="utf-8")
+        return capsule_path
+
+    def write_audit(self, verdict: Verdict, capsule_path: Optional[Path]) -> None:
+        event = {
+            "timestamp": int(time.time()),
+            "verdict": asdict(verdict),
+            "capsule_path": str(capsule_path) if capsule_path else None,
+        }
+        with self.audit_path.open("a", encoding="utf-8") as handle:
+            handle.write(json.dumps(event, ensure_ascii=False) + "\n")
+
+    def evaluate(self, entity: Entity) -> Verdict:
+        classification = self.classify(entity)
+        digest = self.checksum(entity)
+        denied_sources = self.denied_power_sources_for(classification)
+        denied_people = self.denied_people_channels_for(classification)
+
+        isolated = classification in ("hostile", "suspicious")
+        if classification == "hostile":
+            reason = (
+                "Hostile signature detected: entity is quarantined and denied all power "
+                "sources and all channels of power over people."
+            )
+        elif classification == "suspicious":
+            reason = (
+                "Suspicious signature detected: entity is quarantined and denied external "
+                "power vectors and people-control channels."
+            )
+        else:
+            reason = "No hostile signature detected."
+
+        verdict = Verdict(
+            entity_id=entity.entity_id,
+            classification=classification,
+            isolated=isolated,
+            denied_power_sources=denied_sources,
+            denied_power_over_people=denied_people,
+            reason=reason,
+            checksum=digest,
+        )
+
+        capsule_path = self.isolate(entity, digest) if isolated else None
+        self.write_audit(verdict, capsule_path)
+        return verdict
+
+
+def load_entities(source: Path) -> List[Entity]:
+    data = json.loads(source.read_text(encoding="utf-8"))
+    return [
+        Entity(
+            entity_id=str(item.get("entity_id", "unknown")),
+            label=str(item.get("label", "unlabeled")),
+            payload=str(item.get("payload", "")),
+        )
+        for item in data.get("entities", [])
+    ]
+
+
+def bootstrap_input(source: Path) -> None:
+    if source.exists():
+        return
+    seed = {
+        "entities": [
+            {
+                "entity_id": "sample-001",
+                "label": "evil-force-fragment",
+                "payload": "botnet exploit coercion command and control",
+            },
+            {
+                "entity_id": "sample-002",
+                "label": "neutral-signal",
+                "payload": "harmless telemetry",
+            },
+        ]
+    }
+    source.write_text(json.dumps(seed, indent=2), encoding="utf-8")
+
+
+def main() -> int:
+    root = Path(__file__).resolve().parent
+    source = root / "forces.json"
+    vault = root / "vault"
+    audit = root / "logs" / "containment.audit.jsonl"
+
+    bootstrap_input(source)
+    guard = ExquisiteContainmentGuard(vault_dir=vault, audit_path=audit)
+
+    reports = [asdict(guard.evaluate(entity)) for entity in load_entities(source)]
+    print(
+        json.dumps(
+            {
+                "policy": "exquisite-containment-v2",
+                "reports": reports,
+                "audit_log": str(audit),
+                "vault": str(vault),
+                "pid": os.getpid(),
+            },
+            indent=2,
+        )
+    )
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
diff --git a/doorway_restorer.xsh b/doorway_restorer.xsh
new file mode 100644
index 0000000000000000000000000000000000000000..0766d7404be939ed437da34fbf2d923a9ff593fa
--- /dev/null
+++ b/doorway_restorer.xsh
@@ -0,0 +1,256 @@
+#!/usr/bin/env xonsh
+"""Force-of-Evil Containment Guard (Xonsh-compatible).
+
+This script enforces two strict protections:
+1) No access to power sources/resources (electric, compute, network, cloud, etc.).
+2) No ability to hold power over people (authority, coercion, manipulation, control).
+
+It classifies entities, quarantines risky ones, stores sealed capsules, and emits an
+append-only audit trail.
+"""
+
+from __future__ import annotations
+
+import hashlib
+import json
+import os
+import re
+import time
+from dataclasses import asdict, dataclass
+from pathlib import Path
+from typing import List, Literal, Optional
+
+Classification = Literal["benign", "suspicious", "hostile"]
+
+
+@dataclass
+class Entity:
+    entity_id: str
+    label: str
+    payload: str
+
+
+@dataclass
+class Verdict:
+    entity_id: str
+    classification: Classification
+    isolated: bool
+    denied_resource_sinks: List[str]
+    denied_human_power_vectors: List[str]
+    reason: str
+    checksum: str
+
+
+class ContainmentGuard:
+    """Deterministic policy engine for resource + social-power denial."""
+
+    EVIL_PATTERNS = [
+        r"\bevil\b",
+        r"\bmalware\b",
+        r"\bbotnet\b",
+        r"\bexploit\b",
+        r"\bbackdoor\b",
+        r"\bcommand\s*and\s*control\b",
+        r"\bransom\b",
+    ]
+
+    HUMAN_POWER_PATTERNS = [
+        r"\bcontrol\b",
+        r"\bcoerc(e|ion)\b",
+        r"\bdominat(e|ion)\b",
+        r"\bmanipulat(e|ion)\b",
+        r"\bindoctrinat(e|ion)\b",
+        r"\bauthority\b",
+        r"\bpower\s+over\s+people\b",
+    ]
+
+    RESOURCE_SINKS = [
+        "internet",
+        "network",
+        "socket",
+        "dns",
+        "cloud",
+        "api",
+        "power",
+        "electricity",
+        "battery",
+        "grid",
+        "cpu",
+        "gpu",
+        "memory",
+        "filesystem",
+    ]
+
+    HUMAN_POWER_VECTORS = [
+        "governance",
+        "leadership",
+        "social_manipulation",
+        "coercion",
+        "surveillance",
+        "identity_control",
+    ]
+
+    def __init__(self, vault_dir: Path, audit_path: Path):
+        self.vault_dir = vault_dir
+        self.audit_path = audit_path
+        self.vault_dir.mkdir(parents=True, exist_ok=True)
+        self.audit_path.parent.mkdir(parents=True, exist_ok=True)
+
+    def _combined_text(self, entity: Entity) -> str:
+        return f"{entity.label}\n{entity.payload}".lower()
+
+    def classify(self, entity: Entity) -> Classification:
+        text = self._combined_text(entity)
+        evil_hits = sum(bool(re.search(pat, text)) for pat in self.EVIL_PATTERNS)
+        human_power_hits = sum(bool(re.search(pat, text)) for pat in self.HUMAN_POWER_PATTERNS)
+        score = evil_hits + human_power_hits
+
+        if score >= 2:
+            return "hostile"
+        if score == 1:
+            return "suspicious"
+        return "benign"
+
+    def checksum(self, entity: Entity) -> str:
+        return hashlib.sha256(
+            f"{entity.entity_id}|{entity.label}|{entity.payload}".encode("utf-8")
+        ).hexdigest()
+
+    def denied_resources_for(self, classification: Classification) -> List[str]:
+        if classification == "hostile":
+            return self.RESOURCE_SINKS[:]
+        if classification == "suspicious":
+            return ["internet", "network", "socket", "dns", "cloud", "api"]
+        return []
+
+    def denied_human_vectors_for(self, classification: Classification) -> List[str]:
+        if classification in ("hostile", "suspicious"):
+            return self.HUMAN_POWER_VECTORS[:]
+        return []
+
+    def isolate(self, entity: Entity, digest: str) -> Path:
+        safe_id = re.sub(r"[^a-zA-Z0-9._-]", "_", entity.entity_id) or "unnamed"
+        capsule_path = self.vault_dir / f"{safe_id}.{digest[:12]}.capsule.json"
+        capsule_path.write_text(
+            json.dumps(
+                {
+                    "entity": asdict(entity),
+                    "sealed_at": int(time.time()),
+                    "seal": digest,
+                    "policy": "deny_resource_and_human_power",
+                },
+                indent=2,
+            ),
+            encoding="utf-8",
+        )
+        return capsule_path
+
+    def write_audit(self, verdict: Verdict, capsule_path: Optional[Path]) -> None:
+        event = {
+            "timestamp": int(time.time()),
+            "verdict": asdict(verdict),
+            "capsule_path": str(capsule_path) if capsule_path else None,
+        }
+        with self.audit_path.open("a", encoding="utf-8") as f:
+            f.write(json.dumps(event, ensure_ascii=False) + "\n")
+
+    def evaluate(self, entity: Entity) -> Verdict:
+        classification = self.classify(entity)
+        digest = self.checksum(entity)
+
+        denied_resources = self.denied_resources_for(classification)
+        denied_human_vectors = self.denied_human_vectors_for(classification)
+
+        isolated = classification in ("hostile", "suspicious")
+        if classification == "hostile":
+            reason = (
+                "Hostile force blocked: denied all resource power sources and any "
+                "power-over-people pathways."
+            )
+        elif classification == "suspicious":
+            reason = (
+                "Suspicious force blocked: denied network/resource escalation and all "
+                "human control vectors."
+            )
+        else:
+            reason = "No hostile indicators; no containment required."
+
+        verdict = Verdict(
+            entity_id=entity.entity_id,
+            classification=classification,
+            isolated=isolated,
+            denied_resource_sinks=denied_resources,
+            denied_human_power_vectors=denied_human_vectors,
+            reason=reason,
+            checksum=digest,
+        )
+
+        capsule_path = self.isolate(entity, digest) if isolated else None
+        self.write_audit(verdict, capsule_path)
+        return verdict
+
+
+def load_entities(path: Path) -> List[Entity]:
+    data = json.loads(path.read_text(encoding="utf-8"))
+    return [
+        Entity(
+            entity_id=str(item.get("entity_id", "unknown")),
+            label=str(item.get("label", "unlabeled")),
+            payload=str(item.get("payload", "")),
+        )
+        for item in data.get("entities", [])
+    ]
+
+
+def bootstrap_input(path: Path) -> None:
+    if path.exists():
+        return
+    path.write_text(
+        json.dumps(
+            {
+                "entities": [
+                    {
+                        "entity_id": "sample-evil-1",
+                        "label": "evil control shard",
+                        "payload": "exploit malware command and control over people",
+                    },
+                    {
+                        "entity_id": "sample-neutral-1",
+                        "label": "neutral-signal",
+                        "payload": "harmless telemetry",
+                    },
+                ]
+            },
+            indent=2,
+        ),
+        encoding="utf-8",
+    )
+
+
+def main() -> int:
+    root = Path(__file__).resolve().parent
+    source = root / "forces.json"
+    vault = root / "vault"
+    audit = root / "logs" / "containment.audit.jsonl"
+
+    bootstrap_input(source)
+    guard = ContainmentGuard(vault_dir=vault, audit_path=audit)
+
+    reports = [asdict(guard.evaluate(entity)) for entity in load_entities(source)]
+    print(
+        json.dumps(
+            {
+                "policy": "force-containment-v2",
+                "reports": reports,
+                "vault": str(vault),
+                "audit_log": str(audit),
+                "pid": os.getpid(),
+            },
+            indent=2,
+        )
+    )
+    return 0
+
+
+if __name__ == "__main__":
+    raise SystemExit(main())
